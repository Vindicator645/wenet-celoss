/home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000
dictionary: /home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000_units.txt
run_2_20_rnnt_bias_both_2_class_more_layers_0-3word_fintune.sh: init method is file:///home/work_nfs6/tyxu/workspace/wenet-bias-celoss/examples/librispeech/s0/exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/ddp_init
2023-02-21 21:14:49,972 INFO training on multiple gpus, this gpu 1
2023-02-21 21:14:49,972 INFO training on multiple gpus, this gpu 6
2023-02-21 21:14:49,972 INFO training on multiple gpus, this gpu 5
2023-02-21 21:14:49,973 INFO training on multiple gpus, this gpu 7
2023-02-21 21:14:49,973 INFO training on multiple gpus, this gpu 2
2023-02-21 21:14:49,973 INFO training on multiple gpus, this gpu 3
2023-02-21 21:14:49,974 INFO training on multiple gpus, this gpu 0
2023-02-21 21:14:50,038 INFO training on multiple gpus, this gpu 4
2023-02-21 21:19:00,490 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-21 21:19:00,645 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2023-02-21 21:19:00,826 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-21 21:19:01,525 INFO Added key: store_based_barrier_key:1 to store for rank: 4
2023-02-21 21:19:01,750 INFO Added key: store_based_barrier_key:1 to store for rank: 5
2023-02-21 21:19:02,840 INFO Added key: store_based_barrier_key:1 to store for rank: 6
2023-02-21 21:19:04,993 INFO Added key: store_based_barrier_key:1 to store for rank: 7
2023-02-21 21:19:11,667 INFO Waiting in store based barrier to initialize process group for rank: 4, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2023-02-21 21:19:15,161 INFO Waiting in store based barrier to initialize process group for rank: 1, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2023-02-21 21:19:15,889 INFO Waiting in store based barrier to initialize process group for rank: 5, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2023-02-21 21:19:16,575 INFO Waiting in store based barrier to initialize process group for rank: 7, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2023-02-21 21:19:16,646 INFO Added key: store_based_barrier_key:1 to store for rank: 3
2023-02-21 21:19:16,723 INFO Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:16,736 INFO Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:17,517 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:17,902 INFO Waiting in store based barrier to initialize process group for rank: 2, key: store_based_barrier_key:1 (world_size=8, worker_count=8, timeout=0:30:00)
2023-02-21 21:19:17,902 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:19,747 INFO Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:19,946 INFO Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=8, worker_count=8, timeout=0:30:00)
2023-02-21 21:19:19,946 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:22,314 INFO Waiting in store based barrier to initialize process group for rank: 4, key: store_based_barrier_key:1 (world_size=8, worker_count=8, timeout=0:30:00)
2023-02-21 21:19:22,314 INFO Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:24,299 INFO Waiting in store based barrier to initialize process group for rank: 6, key: store_based_barrier_key:1 (world_size=8, worker_count=8, timeout=0:30:00)
2023-02-21 21:19:24,299 INFO Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:19:30,450 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:30,475 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:30,501 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:30,531 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:30,556 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:30,583 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:30,619 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:30,640 INFO Checkpoint: loading from checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/10.pt for GPU
2023-02-21 21:19:56,148 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:19:56,150 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:19:56,186 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:19:56,188 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:19:56,206 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:19:56,208 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:19:56,235 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:19:56,238 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:19:56,338 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:19:56,339 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:19:56,416 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:19:56,418 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:19:56,518 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:19:56,521 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 21:19:56,523 INFO Epoch 11 TRAIN info lr 4e-08
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:19:56,525 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-21 21:20:57,373 DEBUG TRAIN Batch 11/0 loss 186.854736 loss_att 77.171387 loss_ctc 301.264771 loss_rnnt 193.138733 hw_loss 0.746238 lr 0.00052195 rank 2
2023-02-21 21:20:57,377 DEBUG TRAIN Batch 11/0 loss 276.564972 loss_att 80.112610 loss_ctc 1389.739380 loss_rnnt 167.120560 hw_loss 0.584284 lr 0.00052195 rank 4
2023-02-21 21:20:57,380 DEBUG TRAIN Batch 11/0 loss 389.520538 loss_att 71.173264 loss_ctc 1060.426025 loss_rnnt 363.138580 hw_loss 1.119969 lr 0.00052195 rank 6
2023-02-21 21:20:57,384 DEBUG TRAIN Batch 11/0 loss 434.559235 loss_att 72.900795 loss_ctc 1131.058350 loss_rnnt 413.650665 hw_loss 0.700651 lr 0.00052195 rank 3
2023-02-21 21:20:57,446 DEBUG TRAIN Batch 11/0 loss 191.435104 loss_att 76.939270 loss_ctc 488.988068 loss_rnnt 174.330704 hw_loss 0.618432 lr 0.00052195 rank 1
2023-02-21 21:20:57,454 DEBUG TRAIN Batch 11/0 loss 226.550919 loss_att 85.779358 loss_ctc 774.933228 loss_rnnt 181.203979 hw_loss 0.719286 lr 0.00052195 rank 0
2023-02-21 21:20:57,500 DEBUG TRAIN Batch 11/0 loss 365.634064 loss_att 76.064697 loss_ctc 1148.540649 loss_rnnt 318.716766 hw_loss 0.831824 lr 0.00052195 rank 5
2023-02-21 21:20:57,600 DEBUG TRAIN Batch 11/0 loss 228.761124 loss_att 77.251205 loss_ctc 851.277283 loss_rnnt 175.737686 hw_loss 0.606117 lr 0.00052195 rank 7
2023-02-21 21:22:11,680 DEBUG TRAIN Batch 11/100 loss 229.759659 loss_att 291.579712 loss_ctc 216.397018 loss_rnnt 219.120239 hw_loss 0.107054 lr 0.00052167 rank 3
2023-02-21 21:22:11,681 DEBUG TRAIN Batch 11/100 loss 200.894180 loss_att 239.474152 loss_ctc 191.231873 loss_rnnt 194.392365 hw_loss 0.138955 lr 0.00052167 rank 1
2023-02-21 21:22:11,683 DEBUG TRAIN Batch 11/100 loss 301.406433 loss_att 333.713013 loss_ctc 304.119141 loss_rnnt 294.451447 hw_loss 0.247413 lr 0.00052167 rank 4
2023-02-21 21:22:11,683 DEBUG TRAIN Batch 11/100 loss 276.524536 loss_att 320.608276 loss_ctc 255.583298 loss_rnnt 270.390808 hw_loss 0.204631 lr 0.00052167 rank 5
2023-02-21 21:22:11,683 DEBUG TRAIN Batch 11/100 loss 212.294235 loss_att 255.221252 loss_ctc 206.103027 loss_rnnt 204.441513 hw_loss 0.174027 lr 0.00052167 rank 2
2023-02-21 21:22:11,684 DEBUG TRAIN Batch 11/100 loss 249.936356 loss_att 310.779907 loss_ctc 240.952148 loss_rnnt 238.859314 hw_loss 0.199182 lr 0.00052167 rank 0
2023-02-21 21:22:11,688 DEBUG TRAIN Batch 11/100 loss 265.872986 loss_att 295.210907 loss_ctc 259.120972 loss_rnnt 260.852020 hw_loss 0.100617 lr 0.00052167 rank 6
2023-02-21 21:22:11,737 DEBUG TRAIN Batch 11/100 loss 230.455368 loss_att 268.904022 loss_ctc 230.732834 loss_rnnt 222.577667 hw_loss 0.283068 lr 0.00052167 rank 7
2023-02-21 21:23:24,662 DEBUG TRAIN Batch 11/200 loss 208.985611 loss_att 290.177521 loss_ctc 217.306808 loss_rnnt 191.488434 hw_loss 0.279916 lr 0.00052139 rank 2
2023-02-21 21:23:24,663 DEBUG TRAIN Batch 11/200 loss 148.237549 loss_att 287.244110 loss_ctc 131.290283 loss_rnnt 122.539062 hw_loss 0.294052 lr 0.00052139 rank 5
2023-02-21 21:23:24,665 DEBUG TRAIN Batch 11/200 loss 142.064743 loss_att 253.722183 loss_ctc 125.412582 loss_rnnt 121.867859 hw_loss 0.160655 lr 0.00052139 rank 7
2023-02-21 21:23:24,665 DEBUG TRAIN Batch 11/200 loss 139.037643 loss_att 256.838257 loss_ctc 114.249817 loss_rnnt 118.610184 hw_loss 0.323203 lr 0.00052139 rank 0
2023-02-21 21:23:24,665 DEBUG TRAIN Batch 11/200 loss 197.887650 loss_att 311.737732 loss_ctc 176.674057 loss_rnnt 177.807312 hw_loss 0.260232 lr 0.00052139 rank 6
2023-02-21 21:23:24,668 DEBUG TRAIN Batch 11/200 loss 140.459824 loss_att 234.493973 loss_ctc 119.237778 loss_rnnt 124.399254 hw_loss 0.156305 lr 0.00052139 rank 3
2023-02-21 21:23:24,668 DEBUG TRAIN Batch 11/200 loss 181.385361 loss_att 271.869751 loss_ctc 167.441437 loss_rnnt 165.050293 hw_loss 0.182596 lr 0.00052139 rank 4
2023-02-21 21:23:24,667 DEBUG TRAIN Batch 11/200 loss 179.724335 loss_att 288.973389 loss_ctc 154.556061 loss_rnnt 161.169861 hw_loss 0.113293 lr 0.00052139 rank 1
2023-02-21 21:24:38,140 DEBUG TRAIN Batch 11/300 loss 159.196640 loss_att 292.620026 loss_ctc 142.358658 loss_rnnt 134.637573 hw_loss 0.223960 lr 0.00052110 rank 0
2023-02-21 21:24:38,147 DEBUG TRAIN Batch 11/300 loss 137.493622 loss_att 255.187820 loss_ctc 120.524948 loss_rnnt 116.134987 hw_loss 0.154253 lr 0.00052110 rank 2
2023-02-21 21:24:38,152 DEBUG TRAIN Batch 11/300 loss 153.607040 loss_att 297.968933 loss_ctc 134.748154 loss_rnnt 127.154091 hw_loss 0.178252 lr 0.00052110 rank 3
2023-02-21 21:24:38,152 DEBUG TRAIN Batch 11/300 loss 136.420425 loss_att 275.369812 loss_ctc 124.037743 loss_rnnt 110.087852 hw_loss 0.363191 lr 0.00052110 rank 5
2023-02-21 21:24:38,153 DEBUG TRAIN Batch 11/300 loss 111.403542 loss_att 243.391724 loss_ctc 88.369476 loss_rnnt 87.900192 hw_loss 0.331742 lr 0.00052110 rank 6
2023-02-21 21:24:38,157 DEBUG TRAIN Batch 11/300 loss 128.507736 loss_att 251.210022 loss_ctc 121.189468 loss_rnnt 104.793228 hw_loss 0.280874 lr 0.00052110 rank 7
2023-02-21 21:24:38,159 DEBUG TRAIN Batch 11/300 loss 134.933594 loss_att 278.285278 loss_ctc 116.188057 loss_rnnt 108.644478 hw_loss 0.221606 lr 0.00052110 rank 4
2023-02-21 21:24:38,175 DEBUG TRAIN Batch 11/300 loss 124.922791 loss_att 244.016052 loss_ctc 115.455460 loss_rnnt 102.151642 hw_loss 0.402747 lr 0.00052110 rank 1
2023-02-21 21:25:51,587 DEBUG TRAIN Batch 11/400 loss 98.740158 loss_att 235.788055 loss_ctc 84.373077 loss_rnnt 73.173637 hw_loss 0.136033 lr 0.00052082 rank 3
2023-02-21 21:25:51,598 DEBUG TRAIN Batch 11/400 loss 115.414078 loss_att 239.723480 loss_ctc 110.017937 loss_rnnt 91.103874 hw_loss 0.314630 lr 0.00052082 rank 2
2023-02-21 21:25:51,605 DEBUG TRAIN Batch 11/400 loss 123.127159 loss_att 230.282166 loss_ctc 125.764725 loss_rnnt 101.156403 hw_loss 0.352643 lr 0.00052082 rank 1
2023-02-21 21:25:51,608 DEBUG TRAIN Batch 11/400 loss 107.144989 loss_att 249.201965 loss_ctc 95.103256 loss_rnnt 80.200104 hw_loss 0.260728 lr 0.00052082 rank 5
2023-02-21 21:25:51,608 DEBUG TRAIN Batch 11/400 loss 114.046410 loss_att 248.501862 loss_ctc 100.491364 loss_rnnt 88.765961 hw_loss 0.368823 lr 0.00052082 rank 6
2023-02-21 21:25:51,609 DEBUG TRAIN Batch 11/400 loss 90.567146 loss_att 231.959244 loss_ctc 75.961456 loss_rnnt 64.113564 hw_loss 0.229848 lr 0.00052082 rank 4
2023-02-21 21:25:51,611 DEBUG TRAIN Batch 11/400 loss 136.174408 loss_att 268.642487 loss_ctc 123.909882 loss_rnnt 111.201180 hw_loss 0.215387 lr 0.00052082 rank 0
2023-02-21 21:25:51,656 DEBUG TRAIN Batch 11/400 loss 124.873657 loss_att 265.362152 loss_ctc 109.659164 loss_rnnt 98.719322 hw_loss 0.159799 lr 0.00052082 rank 7
2023-02-21 21:27:03,196 DEBUG TRAIN Batch 11/500 loss 93.522102 loss_att 182.127899 loss_ctc 86.966782 loss_rnnt 76.486465 hw_loss 0.353487 lr 0.00052054 rank 2
2023-02-21 21:27:03,198 DEBUG TRAIN Batch 11/500 loss 117.784325 loss_att 252.250122 loss_ctc 105.992371 loss_rnnt 92.296707 hw_loss 0.312588 lr 0.00052054 rank 6
2023-02-21 21:27:03,201 DEBUG TRAIN Batch 11/500 loss 79.578690 loss_att 189.356659 loss_ctc 61.904930 loss_rnnt 59.791191 hw_loss 0.353269 lr 0.00052054 rank 7
2023-02-21 21:27:03,201 DEBUG TRAIN Batch 11/500 loss 67.051468 loss_att 174.808044 loss_ctc 53.021622 loss_rnnt 47.158531 hw_loss 0.398012 lr 0.00052054 rank 4
2023-02-21 21:27:03,203 DEBUG TRAIN Batch 11/500 loss 88.390800 loss_att 190.543228 loss_ctc 71.587585 loss_rnnt 70.041573 hw_loss 0.298436 lr 0.00052054 rank 3
2023-02-21 21:27:03,206 DEBUG TRAIN Batch 11/500 loss 80.916862 loss_att 198.225571 loss_ctc 72.934929 loss_rnnt 58.323059 hw_loss 0.368100 lr 0.00052054 rank 0
2023-02-21 21:27:03,206 DEBUG TRAIN Batch 11/500 loss 122.284325 loss_att 228.639771 loss_ctc 112.341125 loss_rnnt 102.202423 hw_loss 0.256070 lr 0.00052054 rank 1
2023-02-21 21:27:03,206 DEBUG TRAIN Batch 11/500 loss 110.216400 loss_att 216.696777 loss_ctc 100.213120 loss_rnnt 90.142776 hw_loss 0.208724 lr 0.00052054 rank 5
2023-02-21 21:28:15,949 DEBUG TRAIN Batch 11/600 loss 59.572891 loss_att 123.188232 loss_ctc 59.329418 loss_rnnt 46.688622 hw_loss 0.363117 lr 0.00052026 rank 5
2023-02-21 21:28:15,955 DEBUG TRAIN Batch 11/600 loss 50.152706 loss_att 111.156075 loss_ctc 48.935162 loss_rnnt 37.840897 hw_loss 0.512763 lr 0.00052026 rank 7
2023-02-21 21:28:15,956 DEBUG TRAIN Batch 11/600 loss 47.612030 loss_att 94.997421 loss_ctc 43.086075 loss_rnnt 38.546341 hw_loss 0.360124 lr 0.00052026 rank 3
2023-02-21 21:28:15,958 DEBUG TRAIN Batch 11/600 loss 68.452660 loss_att 132.691589 loss_ctc 65.298538 loss_rnnt 55.848740 hw_loss 0.331287 lr 0.00052026 rank 0
2023-02-21 21:28:15,958 DEBUG TRAIN Batch 11/600 loss 62.814728 loss_att 121.337608 loss_ctc 57.209320 loss_rnnt 51.702656 hw_loss 0.290399 lr 0.00052026 rank 2
2023-02-21 21:28:15,959 DEBUG TRAIN Batch 11/600 loss 69.139000 loss_att 141.916428 loss_ctc 65.006706 loss_rnnt 54.990730 hw_loss 0.269533 lr 0.00052026 rank 1
2023-02-21 21:28:15,961 DEBUG TRAIN Batch 11/600 loss 78.915466 loss_att 162.888519 loss_ctc 70.945534 loss_rnnt 63.036682 hw_loss 0.275307 lr 0.00052026 rank 6
2023-02-21 21:28:16,006 DEBUG TRAIN Batch 11/600 loss 58.411369 loss_att 114.760681 loss_ctc 58.281517 loss_rnnt 46.956924 hw_loss 0.378552 lr 0.00052026 rank 4
2023-02-21 21:29:30,836 DEBUG TRAIN Batch 11/700 loss 40.456017 loss_att 112.207024 loss_ctc 32.372215 loss_rnnt 26.996994 hw_loss 0.349985 lr 0.00051997 rank 2
2023-02-21 21:29:30,838 DEBUG TRAIN Batch 11/700 loss 86.101166 loss_att 180.605377 loss_ctc 78.087502 loss_rnnt 68.170593 hw_loss 0.184163 lr 0.00051997 rank 6
2023-02-21 21:29:30,840 DEBUG TRAIN Batch 11/700 loss 103.673538 loss_att 203.033417 loss_ctc 97.268173 loss_rnnt 84.508514 hw_loss 0.275801 lr 0.00051997 rank 3
2023-02-21 21:29:30,843 DEBUG TRAIN Batch 11/700 loss 80.756195 loss_att 204.751129 loss_ctc 81.164543 loss_rnnt 55.746548 hw_loss 0.292896 lr 0.00051997 rank 4
2023-02-21 21:29:30,844 DEBUG TRAIN Batch 11/700 loss 95.093529 loss_att 191.881500 loss_ctc 90.315308 loss_rnnt 76.294556 hw_loss 0.147137 lr 0.00051997 rank 0
2023-02-21 21:29:30,846 DEBUG TRAIN Batch 11/700 loss 65.459984 loss_att 165.718170 loss_ctc 59.280651 loss_rnnt 46.007774 hw_loss 0.420890 lr 0.00051997 rank 7
2023-02-21 21:29:30,847 DEBUG TRAIN Batch 11/700 loss 93.350746 loss_att 232.937103 loss_ctc 77.661667 loss_rnnt 67.299614 hw_loss 0.423252 lr 0.00051997 rank 1
2023-02-21 21:29:30,848 DEBUG TRAIN Batch 11/700 loss 68.061386 loss_att 168.410965 loss_ctc 66.414703 loss_rnnt 48.021378 hw_loss 0.355591 lr 0.00051997 rank 5
2023-02-21 21:30:43,285 DEBUG TRAIN Batch 11/800 loss 74.229553 loss_att 155.459076 loss_ctc 76.707893 loss_rnnt 57.428612 hw_loss 0.421097 lr 0.00051969 rank 2
2023-02-21 21:30:43,289 DEBUG TRAIN Batch 11/800 loss 75.190666 loss_att 160.211945 loss_ctc 75.290565 loss_rnnt 58.092922 hw_loss 0.150320 lr 0.00051969 rank 3
2023-02-21 21:30:43,291 DEBUG TRAIN Batch 11/800 loss 85.688103 loss_att 164.567307 loss_ctc 81.410660 loss_rnnt 70.354584 hw_loss 0.240005 lr 0.00051969 rank 0
2023-02-21 21:30:43,291 DEBUG TRAIN Batch 11/800 loss 59.685841 loss_att 138.018219 loss_ctc 50.217529 loss_rnnt 45.202766 hw_loss 0.148187 lr 0.00051969 rank 1
2023-02-21 21:30:43,294 DEBUG TRAIN Batch 11/800 loss 89.134033 loss_att 183.516998 loss_ctc 75.917816 loss_rnnt 71.881592 hw_loss 0.258763 lr 0.00051969 rank 4
2023-02-21 21:30:43,296 DEBUG TRAIN Batch 11/800 loss 59.008270 loss_att 136.477219 loss_ctc 60.762066 loss_rnnt 43.072659 hw_loss 0.389969 lr 0.00051969 rank 7
2023-02-21 21:30:43,296 DEBUG TRAIN Batch 11/800 loss 83.167404 loss_att 140.967529 loss_ctc 78.372597 loss_rnnt 72.113739 hw_loss 0.249268 lr 0.00051969 rank 6
2023-02-21 21:30:43,299 DEBUG TRAIN Batch 11/800 loss 40.858284 loss_att 101.075958 loss_ctc 42.322235 loss_rnnt 28.430416 hw_loss 0.354629 lr 0.00051969 rank 5
2023-02-21 21:31:56,693 DEBUG TRAIN Batch 11/900 loss 57.865841 loss_att 120.015198 loss_ctc 49.257484 loss_rnnt 46.518471 hw_loss 0.122397 lr 0.00051941 rank 3
2023-02-21 21:31:56,717 DEBUG TRAIN Batch 11/900 loss 77.401749 loss_att 141.850922 loss_ctc 71.579880 loss_rnnt 65.190575 hw_loss 0.182972 lr 0.00051941 rank 2
2023-02-21 21:31:56,717 DEBUG TRAIN Batch 11/900 loss 43.193653 loss_att 102.565071 loss_ctc 43.633476 loss_rnnt 31.196440 hw_loss 0.120532 lr 0.00051941 rank 0
2023-02-21 21:31:56,718 DEBUG TRAIN Batch 11/900 loss 71.588684 loss_att 124.062866 loss_ctc 73.108322 loss_rnnt 60.690468 hw_loss 0.376409 lr 0.00051941 rank 4
2023-02-21 21:31:56,718 DEBUG TRAIN Batch 11/900 loss 100.019722 loss_att 158.618988 loss_ctc 99.847069 loss_rnnt 88.179832 hw_loss 0.268226 lr 0.00051941 rank 6
2023-02-21 21:31:56,722 DEBUG TRAIN Batch 11/900 loss 70.752556 loss_att 149.016479 loss_ctc 70.589859 loss_rnnt 54.974300 hw_loss 0.275929 lr 0.00051941 rank 5
2023-02-21 21:31:56,722 DEBUG TRAIN Batch 11/900 loss 93.079163 loss_att 168.594727 loss_ctc 85.642357 loss_rnnt 78.860588 hw_loss 0.200705 lr 0.00051941 rank 7
2023-02-21 21:31:56,770 DEBUG TRAIN Batch 11/900 loss 73.272766 loss_att 133.583618 loss_ctc 70.018906 loss_rnnt 61.581436 hw_loss 0.118147 lr 0.00051941 rank 1
2023-02-21 21:33:10,253 DEBUG TRAIN Batch 11/1000 loss 64.419937 loss_att 113.089615 loss_ctc 71.925346 loss_rnnt 53.454536 hw_loss 0.432633 lr 0.00051913 rank 5
2023-02-21 21:33:10,256 DEBUG TRAIN Batch 11/1000 loss 51.647594 loss_att 114.433029 loss_ctc 49.766590 loss_rnnt 39.215664 hw_loss 0.235584 lr 0.00051913 rank 0
2023-02-21 21:33:10,262 DEBUG TRAIN Batch 11/1000 loss 56.763397 loss_att 104.482285 loss_ctc 56.965218 loss_rnnt 47.020767 hw_loss 0.322387 lr 0.00051913 rank 2
2023-02-21 21:33:10,264 DEBUG TRAIN Batch 11/1000 loss 40.856670 loss_att 74.441193 loss_ctc 43.590973 loss_rnnt 33.648239 hw_loss 0.238035 lr 0.00051913 rank 7
2023-02-21 21:33:10,267 DEBUG TRAIN Batch 11/1000 loss 54.506443 loss_att 98.643356 loss_ctc 53.966599 loss_rnnt 45.612839 hw_loss 0.259126 lr 0.00051913 rank 3
2023-02-21 21:33:10,270 DEBUG TRAIN Batch 11/1000 loss 42.623585 loss_att 82.652184 loss_ctc 41.838203 loss_rnnt 34.622478 hw_loss 0.187694 lr 0.00051913 rank 6
2023-02-21 21:33:10,273 DEBUG TRAIN Batch 11/1000 loss 38.196846 loss_att 80.156250 loss_ctc 33.147415 loss_rnnt 30.354128 hw_loss 0.232673 lr 0.00051913 rank 4
2023-02-21 21:33:10,294 DEBUG TRAIN Batch 11/1000 loss 37.022938 loss_att 90.632095 loss_ctc 31.957760 loss_rnnt 26.862110 hw_loss 0.214405 lr 0.00051913 rank 1
2023-02-21 21:34:24,911 DEBUG TRAIN Batch 11/1100 loss 49.203537 loss_att 96.535812 loss_ctc 48.889286 loss_rnnt 39.643219 hw_loss 0.254558 lr 0.00051885 rank 3
2023-02-21 21:34:24,914 DEBUG TRAIN Batch 11/1100 loss 37.098625 loss_att 65.633255 loss_ctc 38.548893 loss_rnnt 31.077244 hw_loss 0.227032 lr 0.00051885 rank 2
2023-02-21 21:34:24,915 DEBUG TRAIN Batch 11/1100 loss 49.259628 loss_att 74.912193 loss_ctc 51.961319 loss_rnnt 43.557014 hw_loss 0.397261 lr 0.00051885 rank 7
2023-02-21 21:34:24,916 DEBUG TRAIN Batch 11/1100 loss 30.537985 loss_att 75.729294 loss_ctc 42.201813 loss_rnnt 19.827684 hw_loss 0.219111 lr 0.00051885 rank 6
2023-02-21 21:34:24,920 DEBUG TRAIN Batch 11/1100 loss 37.001431 loss_att 65.237770 loss_ctc 42.308636 loss_rnnt 30.472506 hw_loss 0.326303 lr 0.00051885 rank 0
2023-02-21 21:34:24,923 DEBUG TRAIN Batch 11/1100 loss 40.993149 loss_att 74.040108 loss_ctc 44.836739 loss_rnnt 33.733299 hw_loss 0.258710 lr 0.00051885 rank 4
2023-02-21 21:34:24,951 DEBUG TRAIN Batch 11/1100 loss 41.384338 loss_att 84.998207 loss_ctc 36.258335 loss_rnnt 33.239346 hw_loss 0.198167 lr 0.00051885 rank 1
2023-02-21 21:34:24,970 DEBUG TRAIN Batch 11/1100 loss 49.157433 loss_att 92.685097 loss_ctc 47.686989 loss_rnnt 40.496861 hw_loss 0.283298 lr 0.00051885 rank 5
2023-02-21 21:35:37,971 DEBUG TRAIN Batch 11/1200 loss 51.479671 loss_att 73.427078 loss_ctc 55.360901 loss_rnnt 46.401470 hw_loss 0.321041 lr 0.00051857 rank 2
2023-02-21 21:35:37,976 DEBUG TRAIN Batch 11/1200 loss 31.716049 loss_att 52.958382 loss_ctc 32.596436 loss_rnnt 27.216314 hw_loss 0.251031 lr 0.00051857 rank 3
2023-02-21 21:35:37,982 DEBUG TRAIN Batch 11/1200 loss 20.647476 loss_att 46.402119 loss_ctc 19.978895 loss_rnnt 15.492602 hw_loss 0.174542 lr 0.00051857 rank 1
2023-02-21 21:35:37,984 DEBUG TRAIN Batch 11/1200 loss 21.612621 loss_att 38.421207 loss_ctc 24.646717 loss_rnnt 17.660118 hw_loss 0.349196 lr 0.00051857 rank 7
2023-02-21 21:35:37,984 DEBUG TRAIN Batch 11/1200 loss 37.945778 loss_att 61.980595 loss_ctc 40.506870 loss_rnnt 32.622261 hw_loss 0.328265 lr 0.00051857 rank 0
2023-02-21 21:35:37,986 DEBUG TRAIN Batch 11/1200 loss 51.787575 loss_att 65.877640 loss_ctc 58.920582 loss_rnnt 47.870209 hw_loss 0.278035 lr 0.00051857 rank 5
2023-02-21 21:35:37,988 DEBUG TRAIN Batch 11/1200 loss 39.336094 loss_att 57.767761 loss_ctc 41.515362 loss_rnnt 35.183224 hw_loss 0.329940 lr 0.00051857 rank 6
2023-02-21 21:35:38,034 DEBUG TRAIN Batch 11/1200 loss 36.475700 loss_att 53.973602 loss_ctc 35.134064 loss_rnnt 33.006519 hw_loss 0.278406 lr 0.00051857 rank 4
2023-02-21 21:36:49,745 DEBUG TRAIN Batch 11/1300 loss 52.157597 loss_att 89.943909 loss_ctc 57.721077 loss_rnnt 43.645439 hw_loss 0.399564 lr 0.00051829 rank 3
2023-02-21 21:36:49,747 DEBUG TRAIN Batch 11/1300 loss 33.096043 loss_att 46.987820 loss_ctc 37.370083 loss_rnnt 29.509182 hw_loss 0.447439 lr 0.00051829 rank 6
2023-02-21 21:36:49,747 DEBUG TRAIN Batch 11/1300 loss 29.596161 loss_att 40.459572 loss_ctc 32.253494 loss_rnnt 26.780981 hw_loss 0.540353 lr 0.00051829 rank 1
2023-02-21 21:36:49,753 DEBUG TRAIN Batch 11/1300 loss 52.639603 loss_att 79.420105 loss_ctc 50.141602 loss_rnnt 47.419918 hw_loss 0.368722 lr 0.00051829 rank 4
2023-02-21 21:36:49,754 DEBUG TRAIN Batch 11/1300 loss 54.565517 loss_att 95.615135 loss_ctc 57.276314 loss_rnnt 45.933304 hw_loss 0.114098 lr 0.00051829 rank 7
2023-02-21 21:36:49,754 DEBUG TRAIN Batch 11/1300 loss 27.551863 loss_att 61.866631 loss_ctc 29.808392 loss_rnnt 20.245501 hw_loss 0.267259 lr 0.00051829 rank 0
2023-02-21 21:36:49,755 DEBUG TRAIN Batch 11/1300 loss 59.822449 loss_att 101.505173 loss_ctc 65.007004 loss_rnnt 50.607628 hw_loss 0.350627 lr 0.00051829 rank 5
2023-02-21 21:36:49,758 DEBUG TRAIN Batch 11/1300 loss 48.313683 loss_att 90.044693 loss_ctc 46.270485 loss_rnnt 40.134827 hw_loss 0.197034 lr 0.00051829 rank 2
2023-02-21 21:38:04,138 DEBUG TRAIN Batch 11/1400 loss 47.882961 loss_att 79.125084 loss_ctc 52.101513 loss_rnnt 40.952946 hw_loss 0.223344 lr 0.00051802 rank 5
2023-02-21 21:38:04,142 DEBUG TRAIN Batch 11/1400 loss 42.936733 loss_att 61.459351 loss_ctc 42.970272 loss_rnnt 39.120216 hw_loss 0.201606 lr 0.00051802 rank 0
2023-02-21 21:38:04,143 DEBUG TRAIN Batch 11/1400 loss 45.966625 loss_att 91.387634 loss_ctc 53.783363 loss_rnnt 35.644440 hw_loss 0.367034 lr 0.00051802 rank 7
2023-02-21 21:38:04,143 DEBUG TRAIN Batch 11/1400 loss 48.523479 loss_att 72.206284 loss_ctc 59.059868 loss_rnnt 42.301373 hw_loss 0.151304 lr 0.00051802 rank 3
2023-02-21 21:38:04,150 DEBUG TRAIN Batch 11/1400 loss 46.504570 loss_att 69.618881 loss_ctc 50.858131 loss_rnnt 41.220539 hw_loss 0.151301 lr 0.00051802 rank 2
2023-02-21 21:38:04,156 DEBUG TRAIN Batch 11/1400 loss 50.315220 loss_att 75.651215 loss_ctc 55.727276 loss_rnnt 44.469830 hw_loss 0.106096 lr 0.00051802 rank 4
2023-02-21 21:38:04,170 DEBUG TRAIN Batch 11/1400 loss 32.795029 loss_att 67.533882 loss_ctc 33.881950 loss_rnnt 25.487638 hw_loss 0.402556 lr 0.00051802 rank 6
2023-02-21 21:38:04,189 DEBUG TRAIN Batch 11/1400 loss 48.866169 loss_att 81.128693 loss_ctc 53.156738 loss_rnnt 41.573711 hw_loss 0.502273 lr 0.00051802 rank 1
2023-02-21 21:39:18,146 DEBUG TRAIN Batch 11/1500 loss 22.247585 loss_att 37.921001 loss_ctc 25.351612 loss_rnnt 18.483458 hw_loss 0.404202 lr 0.00051774 rank 2
2023-02-21 21:39:18,146 DEBUG TRAIN Batch 11/1500 loss 38.296844 loss_att 60.334244 loss_ctc 39.535961 loss_rnnt 33.586224 hw_loss 0.258614 lr 0.00051774 rank 5
2023-02-21 21:39:18,147 DEBUG TRAIN Batch 11/1500 loss 29.029325 loss_att 61.393967 loss_ctc 30.910133 loss_rnnt 22.179403 hw_loss 0.236665 lr 0.00051774 rank 0
2023-02-21 21:39:18,148 DEBUG TRAIN Batch 11/1500 loss 34.167870 loss_att 53.189426 loss_ctc 37.426575 loss_rnnt 29.808968 hw_loss 0.225178 lr 0.00051774 rank 3
2023-02-21 21:39:18,149 DEBUG TRAIN Batch 11/1500 loss 27.798761 loss_att 49.322613 loss_ctc 34.349380 loss_rnnt 22.517494 hw_loss 0.193279 lr 0.00051774 rank 7
2023-02-21 21:39:18,149 DEBUG TRAIN Batch 11/1500 loss 43.814831 loss_att 67.362900 loss_ctc 34.227905 loss_rnnt 40.290249 hw_loss 0.174804 lr 0.00051774 rank 6
2023-02-21 21:39:18,154 DEBUG TRAIN Batch 11/1500 loss 31.646935 loss_att 59.641945 loss_ctc 30.332174 loss_rnnt 26.103514 hw_loss 0.224475 lr 0.00051774 rank 1
2023-02-21 21:39:18,158 DEBUG TRAIN Batch 11/1500 loss 51.779064 loss_att 71.302048 loss_ctc 59.629177 loss_rnnt 46.745773 hw_loss 0.153768 lr 0.00051774 rank 4
2023-02-21 21:40:30,051 DEBUG TRAIN Batch 11/1600 loss 52.266792 loss_att 81.939537 loss_ctc 52.538841 loss_rnnt 46.148029 hw_loss 0.277390 lr 0.00051746 rank 3
2023-02-21 21:40:30,059 DEBUG TRAIN Batch 11/1600 loss 30.309492 loss_att 44.495682 loss_ctc 33.941994 loss_rnnt 26.902271 hw_loss 0.160589 lr 0.00051746 rank 5
2023-02-21 21:40:30,060 DEBUG TRAIN Batch 11/1600 loss 26.626217 loss_att 40.543583 loss_ctc 28.591526 loss_rnnt 23.429361 hw_loss 0.283767 lr 0.00051746 rank 1
2023-02-21 21:40:30,060 DEBUG TRAIN Batch 11/1600 loss 40.212624 loss_att 63.301552 loss_ctc 45.916950 loss_rnnt 34.653954 hw_loss 0.338075 lr 0.00051746 rank 4
2023-02-21 21:40:30,061 DEBUG TRAIN Batch 11/1600 loss 27.037622 loss_att 46.680412 loss_ctc 29.996134 loss_rnnt 22.563076 hw_loss 0.284106 lr 0.00051746 rank 0
2023-02-21 21:40:30,062 DEBUG TRAIN Batch 11/1600 loss 43.739056 loss_att 66.174843 loss_ctc 44.863819 loss_rnnt 38.931854 hw_loss 0.318892 lr 0.00051746 rank 7
2023-02-21 21:40:30,063 DEBUG TRAIN Batch 11/1600 loss 46.038818 loss_att 66.582062 loss_ctc 50.107468 loss_rnnt 41.240303 hw_loss 0.276333 lr 0.00051746 rank 2
2023-02-21 21:40:30,065 DEBUG TRAIN Batch 11/1600 loss 34.157040 loss_att 51.211380 loss_ctc 33.734604 loss_rnnt 30.649220 hw_loss 0.287389 lr 0.00051746 rank 6
2023-02-21 21:41:42,250 DEBUG TRAIN Batch 11/1700 loss 28.262653 loss_att 57.512711 loss_ctc 26.119583 loss_rnnt 22.625113 hw_loss 0.137384 lr 0.00051718 rank 6
2023-02-21 21:41:42,268 DEBUG TRAIN Batch 11/1700 loss 21.226709 loss_att 38.456642 loss_ctc 24.453865 loss_rnnt 17.180166 hw_loss 0.319259 lr 0.00051718 rank 2
2023-02-21 21:41:42,272 DEBUG TRAIN Batch 11/1700 loss 36.338184 loss_att 51.880997 loss_ctc 37.137070 loss_rnnt 32.971851 hw_loss 0.283597 lr 0.00051718 rank 0
2023-02-21 21:41:42,273 DEBUG TRAIN Batch 11/1700 loss 34.202698 loss_att 51.090553 loss_ctc 34.021595 loss_rnnt 30.727016 hw_loss 0.229236 lr 0.00051718 rank 5
2023-02-21 21:41:42,273 DEBUG TRAIN Batch 11/1700 loss 27.096750 loss_att 40.851334 loss_ctc 29.056942 loss_rnnt 23.963003 hw_loss 0.227758 lr 0.00051718 rank 7
2023-02-21 21:41:42,273 DEBUG TRAIN Batch 11/1700 loss 49.881168 loss_att 69.138268 loss_ctc 60.352940 loss_rnnt 44.514679 hw_loss 0.222803 lr 0.00051718 rank 3
2023-02-21 21:41:42,276 DEBUG TRAIN Batch 11/1700 loss 30.354113 loss_att 47.293060 loss_ctc 31.717213 loss_rnnt 26.669043 hw_loss 0.216629 lr 0.00051718 rank 4
2023-02-21 21:41:42,317 DEBUG TRAIN Batch 11/1700 loss 30.403448 loss_att 49.966648 loss_ctc 31.959621 loss_rnnt 26.139900 hw_loss 0.268909 lr 0.00051718 rank 1
2023-02-21 21:42:57,386 DEBUG TRAIN Batch 11/1800 loss 30.215307 loss_att 50.294525 loss_ctc 35.426434 loss_rnnt 25.365635 hw_loss 0.260643 lr 0.00051691 rank 2
2023-02-21 21:42:57,386 DEBUG TRAIN Batch 11/1800 loss 31.148100 loss_att 38.212704 loss_ctc 32.868725 loss_rnnt 29.294703 hw_loss 0.395733 lr 0.00051691 rank 7
2023-02-21 21:42:57,386 DEBUG TRAIN Batch 11/1800 loss 33.550827 loss_att 42.875916 loss_ctc 37.167889 loss_rnnt 31.130295 hw_loss 0.137315 lr 0.00051691 rank 3
2023-02-21 21:42:57,388 DEBUG TRAIN Batch 11/1800 loss 19.180618 loss_att 31.164284 loss_ctc 18.394493 loss_rnnt 16.782068 hw_loss 0.199938 lr 0.00051691 rank 4
2023-02-21 21:42:57,391 DEBUG TRAIN Batch 11/1800 loss 41.403664 loss_att 56.889549 loss_ctc 46.632240 loss_rnnt 37.509075 hw_loss 0.188006 lr 0.00051691 rank 6
2023-02-21 21:42:57,394 DEBUG TRAIN Batch 11/1800 loss 33.417301 loss_att 45.558147 loss_ctc 35.859497 loss_rnnt 30.467749 hw_loss 0.367046 lr 0.00051691 rank 0
2023-02-21 21:42:57,399 DEBUG TRAIN Batch 11/1800 loss 33.657093 loss_att 51.356293 loss_ctc 34.623005 loss_rnnt 29.825642 hw_loss 0.305290 lr 0.00051691 rank 1
2023-02-21 21:42:57,447 DEBUG TRAIN Batch 11/1800 loss 36.302174 loss_att 47.384903 loss_ctc 37.647129 loss_rnnt 33.807018 hw_loss 0.186158 lr 0.00051691 rank 5
2023-02-21 21:44:10,354 DEBUG TRAIN Batch 11/1900 loss 39.936531 loss_att 55.932789 loss_ctc 43.504166 loss_rnnt 36.198009 hw_loss 0.119230 lr 0.00051663 rank 7
2023-02-21 21:44:10,359 DEBUG TRAIN Batch 11/1900 loss 18.252411 loss_att 21.129066 loss_ctc 21.557892 loss_rnnt 17.014288 hw_loss 0.416363 lr 0.00051663 rank 0
2023-02-21 21:44:10,358 DEBUG TRAIN Batch 11/1900 loss 29.412209 loss_att 36.214752 loss_ctc 36.616192 loss_rnnt 26.933695 hw_loss 0.295260 lr 0.00051663 rank 2
2023-02-21 21:44:10,360 DEBUG TRAIN Batch 11/1900 loss 19.754459 loss_att 25.073204 loss_ctc 23.518246 loss_rnnt 17.952154 hw_loss 0.443846 lr 0.00051663 rank 3
2023-02-21 21:44:10,363 DEBUG TRAIN Batch 11/1900 loss 25.695992 loss_att 34.497818 loss_ctc 32.733902 loss_rnnt 22.804571 hw_loss 0.361249 lr 0.00051663 rank 6
2023-02-21 21:44:10,364 DEBUG TRAIN Batch 11/1900 loss 18.106411 loss_att 20.202587 loss_ctc 22.509977 loss_rnnt 16.844772 hw_loss 0.478615 lr 0.00051663 rank 5
2023-02-21 21:44:10,371 DEBUG TRAIN Batch 11/1900 loss 31.359192 loss_att 34.691429 loss_ctc 29.418060 loss_rnnt 30.849300 hw_loss 0.191739 lr 0.00051663 rank 1
2023-02-21 21:44:10,373 DEBUG TRAIN Batch 11/1900 loss 18.253925 loss_att 25.210533 loss_ctc 19.341208 loss_rnnt 16.451349 hw_loss 0.499276 lr 0.00051663 rank 4
2023-02-21 21:45:23,285 DEBUG TRAIN Batch 11/2000 loss 49.423737 loss_att 81.396835 loss_ctc 52.937553 loss_rnnt 42.390057 hw_loss 0.319791 lr 0.00051636 rank 4
2023-02-21 21:45:23,293 DEBUG TRAIN Batch 11/2000 loss 21.045280 loss_att 34.819244 loss_ctc 23.873814 loss_rnnt 17.800491 hw_loss 0.211610 lr 0.00051636 rank 1
2023-02-21 21:45:23,305 DEBUG TRAIN Batch 11/2000 loss 55.407810 loss_att 72.295784 loss_ctc 58.641396 loss_rnnt 51.431164 hw_loss 0.314830 lr 0.00051636 rank 2
2023-02-21 21:45:23,307 DEBUG TRAIN Batch 11/2000 loss 24.401300 loss_att 37.108601 loss_ctc 27.293427 loss_rnnt 21.260740 hw_loss 0.400282 lr 0.00051636 rank 6
2023-02-21 21:45:23,311 DEBUG TRAIN Batch 11/2000 loss 36.299385 loss_att 60.330704 loss_ctc 39.537640 loss_rnnt 30.960499 hw_loss 0.189092 lr 0.00051636 rank 3
2023-02-21 21:45:23,314 DEBUG TRAIN Batch 11/2000 loss 22.236095 loss_att 40.937912 loss_ctc 20.189743 loss_rnnt 18.554577 hw_loss 0.401255 lr 0.00051636 rank 0
2023-02-21 21:45:23,316 DEBUG TRAIN Batch 11/2000 loss 29.697308 loss_att 43.462711 loss_ctc 31.234890 loss_rnnt 26.575384 hw_loss 0.307181 lr 0.00051636 rank 7
2023-02-21 21:45:23,332 DEBUG TRAIN Batch 11/2000 loss 30.351149 loss_att 45.432293 loss_ctc 35.997482 loss_rnnt 26.461617 hw_loss 0.225857 lr 0.00051636 rank 5
2023-02-21 21:46:37,264 DEBUG TRAIN Batch 11/2100 loss 28.689842 loss_att 50.808857 loss_ctc 32.979599 loss_rnnt 23.501904 hw_loss 0.360317 lr 0.00051608 rank 1
2023-02-21 21:46:37,265 DEBUG TRAIN Batch 11/2100 loss 23.176235 loss_att 35.206348 loss_ctc 20.964491 loss_rnnt 20.925224 hw_loss 0.262289 lr 0.00051608 rank 0
2023-02-21 21:46:37,267 DEBUG TRAIN Batch 11/2100 loss 30.680300 loss_att 48.689419 loss_ctc 29.420797 loss_rnnt 27.100372 hw_loss 0.273820 lr 0.00051608 rank 2
2023-02-21 21:46:37,273 DEBUG TRAIN Batch 11/2100 loss 33.058788 loss_att 53.344669 loss_ctc 37.704540 loss_rnnt 28.270552 hw_loss 0.209298 lr 0.00051608 rank 4
2023-02-21 21:46:37,274 DEBUG TRAIN Batch 11/2100 loss 58.929951 loss_att 81.832085 loss_ctc 60.031647 loss_rnnt 54.030029 hw_loss 0.323622 lr 0.00051608 rank 7
2023-02-21 21:46:37,275 DEBUG TRAIN Batch 11/2100 loss 35.567894 loss_att 61.693321 loss_ctc 31.899387 loss_rnnt 30.766403 hw_loss 0.122881 lr 0.00051608 rank 6
2023-02-21 21:46:37,278 DEBUG TRAIN Batch 11/2100 loss 15.698695 loss_att 31.466213 loss_ctc 12.450023 loss_rnnt 12.851233 hw_loss 0.238341 lr 0.00051608 rank 3
2023-02-21 21:46:37,306 DEBUG TRAIN Batch 11/2100 loss 26.457352 loss_att 41.481911 loss_ctc 26.810364 loss_rnnt 23.255623 hw_loss 0.280779 lr 0.00051608 rank 5
2023-02-21 21:47:50,357 DEBUG TRAIN Batch 11/2200 loss 47.511650 loss_att 76.444122 loss_ctc 52.177048 loss_rnnt 40.963238 hw_loss 0.262251 lr 0.00051581 rank 2
2023-02-21 21:47:50,373 DEBUG TRAIN Batch 11/2200 loss 37.516125 loss_att 50.116661 loss_ctc 40.989296 loss_rnnt 34.248558 hw_loss 0.533189 lr 0.00051581 rank 5
2023-02-21 21:47:50,374 DEBUG TRAIN Batch 11/2200 loss 35.882599 loss_att 45.623402 loss_ctc 43.022926 loss_rnnt 32.745548 hw_loss 0.444086 lr 0.00051581 rank 6
2023-02-21 21:47:50,375 DEBUG TRAIN Batch 11/2200 loss 25.038651 loss_att 41.763248 loss_ctc 20.958879 loss_rnnt 22.039282 hw_loss 0.372031 lr 0.00051581 rank 1
2023-02-21 21:47:50,376 DEBUG TRAIN Batch 11/2200 loss 38.154884 loss_att 58.508087 loss_ctc 40.523453 loss_rnnt 33.608513 hw_loss 0.299851 lr 0.00051581 rank 7
2023-02-21 21:47:50,377 DEBUG TRAIN Batch 11/2200 loss 22.682318 loss_att 31.160952 loss_ctc 26.956411 loss_rnnt 20.281094 hw_loss 0.254281 lr 0.00051581 rank 3
2023-02-21 21:47:50,380 DEBUG TRAIN Batch 11/2200 loss 42.052673 loss_att 52.702122 loss_ctc 47.825623 loss_rnnt 39.023312 hw_loss 0.243269 lr 0.00051581 rank 4
2023-02-21 21:47:50,418 DEBUG TRAIN Batch 11/2200 loss 34.815247 loss_att 47.358879 loss_ctc 35.150776 loss_rnnt 32.036545 hw_loss 0.422327 lr 0.00051581 rank 0
2023-02-21 21:49:03,489 DEBUG TRAIN Batch 11/2300 loss 36.648174 loss_att 62.182499 loss_ctc 33.253735 loss_rnnt 31.848745 hw_loss 0.272167 lr 0.00051553 rank 1
2023-02-21 21:49:03,491 DEBUG TRAIN Batch 11/2300 loss 30.099365 loss_att 37.749443 loss_ctc 36.130821 loss_rnnt 27.644955 hw_loss 0.225376 lr 0.00051553 rank 0
2023-02-21 21:49:03,494 DEBUG TRAIN Batch 11/2300 loss 29.413149 loss_att 42.625153 loss_ctc 29.130764 loss_rnnt 26.655045 hw_loss 0.287537 lr 0.00051553 rank 3
2023-02-21 21:49:03,494 DEBUG TRAIN Batch 11/2300 loss 24.506878 loss_att 34.679684 loss_ctc 29.502239 loss_rnnt 21.654964 hw_loss 0.283698 lr 0.00051553 rank 5
2023-02-21 21:49:03,495 DEBUG TRAIN Batch 11/2300 loss 34.282097 loss_att 55.435261 loss_ctc 38.741623 loss_rnnt 29.354229 hw_loss 0.192433 lr 0.00051553 rank 6
2023-02-21 21:49:03,499 DEBUG TRAIN Batch 11/2300 loss 22.857817 loss_att 31.027145 loss_ctc 28.100185 loss_rnnt 20.434238 hw_loss 0.170120 lr 0.00051553 rank 2
2023-02-21 21:49:03,500 DEBUG TRAIN Batch 11/2300 loss 19.627506 loss_att 31.936991 loss_ctc 18.876226 loss_rnnt 17.100559 hw_loss 0.309787 lr 0.00051553 rank 7
2023-02-21 21:49:03,539 DEBUG TRAIN Batch 11/2300 loss 21.018570 loss_att 34.647465 loss_ctc 25.050497 loss_rnnt 17.638771 hw_loss 0.218306 lr 0.00051553 rank 4
2023-02-21 21:50:16,392 DEBUG TRAIN Batch 11/2400 loss 31.527920 loss_att 46.231995 loss_ctc 37.390533 loss_rnnt 27.699200 hw_loss 0.199171 lr 0.00051526 rank 1
2023-02-21 21:50:16,410 DEBUG TRAIN Batch 11/2400 loss 51.858635 loss_att 67.172203 loss_ctc 59.599762 loss_rnnt 47.615746 hw_loss 0.277557 lr 0.00051526 rank 4
2023-02-21 21:50:16,410 DEBUG TRAIN Batch 11/2400 loss 35.901306 loss_att 48.087360 loss_ctc 38.868835 loss_rnnt 32.885101 hw_loss 0.343736 lr 0.00051526 rank 0
2023-02-21 21:50:16,414 DEBUG TRAIN Batch 11/2400 loss 24.063347 loss_att 30.454082 loss_ctc 30.358692 loss_rnnt 21.836988 hw_loss 0.204056 lr 0.00051526 rank 7
2023-02-21 21:50:16,417 DEBUG TRAIN Batch 11/2400 loss 29.875334 loss_att 41.137321 loss_ctc 31.845901 loss_rnnt 27.219246 hw_loss 0.264278 lr 0.00051526 rank 2
2023-02-21 21:50:16,419 DEBUG TRAIN Batch 11/2400 loss 33.232536 loss_att 44.316719 loss_ctc 41.346516 loss_rnnt 29.729622 hw_loss 0.382898 lr 0.00051526 rank 5
2023-02-21 21:50:16,422 DEBUG TRAIN Batch 11/2400 loss 21.488070 loss_att 27.454865 loss_ctc 29.199116 loss_rnnt 19.108286 hw_loss 0.296781 lr 0.00051526 rank 6
2023-02-21 21:50:16,434 DEBUG TRAIN Batch 11/2400 loss 27.564558 loss_att 39.599960 loss_ctc 30.579329 loss_rnnt 24.621000 hw_loss 0.252202 lr 0.00051526 rank 3
2023-02-21 21:51:31,564 DEBUG TRAIN Batch 11/2500 loss 31.244642 loss_att 43.229984 loss_ctc 37.231045 loss_rnnt 27.907232 hw_loss 0.266539 lr 0.00051499 rank 0
2023-02-21 21:51:31,575 DEBUG TRAIN Batch 11/2500 loss 36.834320 loss_att 37.616760 loss_ctc 42.779266 loss_rnnt 35.750626 hw_loss 0.252273 lr 0.00051499 rank 7
2023-02-21 21:51:31,577 DEBUG TRAIN Batch 11/2500 loss 45.610886 loss_att 55.632248 loss_ctc 48.295296 loss_rnnt 43.091381 hw_loss 0.294961 lr 0.00051499 rank 3
2023-02-21 21:51:31,578 DEBUG TRAIN Batch 11/2500 loss 27.040094 loss_att 29.603386 loss_ctc 28.674919 loss_rnnt 26.156195 hw_loss 0.287373 lr 0.00051499 rank 2
2023-02-21 21:51:31,579 DEBUG TRAIN Batch 11/2500 loss 29.026688 loss_att 34.300842 loss_ctc 35.736042 loss_rnnt 26.980213 hw_loss 0.181988 lr 0.00051499 rank 6
2023-02-21 21:51:31,580 DEBUG TRAIN Batch 11/2500 loss 28.123119 loss_att 37.151352 loss_ctc 33.023193 loss_rnnt 25.531431 hw_loss 0.248811 lr 0.00051499 rank 1
2023-02-21 21:51:31,581 DEBUG TRAIN Batch 11/2500 loss 33.051441 loss_att 38.864189 loss_ctc 37.572147 loss_rnnt 31.140333 hw_loss 0.273371 lr 0.00051499 rank 4
2023-02-21 21:51:31,635 DEBUG TRAIN Batch 11/2500 loss 31.831917 loss_att 39.793827 loss_ctc 36.324810 loss_rnnt 29.437592 hw_loss 0.380419 lr 0.00051499 rank 5
2023-02-21 21:52:43,827 DEBUG TRAIN Batch 11/2600 loss 59.380554 loss_att 67.646912 loss_ctc 63.642254 loss_rnnt 56.984158 hw_loss 0.327944 lr 0.00051471 rank 2
2023-02-21 21:52:43,830 DEBUG TRAIN Batch 11/2600 loss 19.993923 loss_att 27.432049 loss_ctc 19.093458 loss_rnnt 18.414055 hw_loss 0.398075 lr 0.00051471 rank 3
2023-02-21 21:52:43,833 DEBUG TRAIN Batch 11/2600 loss 15.992481 loss_att 28.268082 loss_ctc 17.197323 loss_rnnt 13.299829 hw_loss 0.144160 lr 0.00051471 rank 5
2023-02-21 21:52:43,834 DEBUG TRAIN Batch 11/2600 loss 22.241524 loss_att 35.371998 loss_ctc 21.319904 loss_rnnt 19.553146 hw_loss 0.347184 lr 0.00051471 rank 0
2023-02-21 21:52:43,836 DEBUG TRAIN Batch 11/2600 loss 22.721048 loss_att 36.779682 loss_ctc 24.999866 loss_rnnt 19.433731 hw_loss 0.322026 lr 0.00051471 rank 6
2023-02-21 21:52:43,838 DEBUG TRAIN Batch 11/2600 loss 16.913071 loss_att 30.326283 loss_ctc 11.601428 loss_rnnt 14.819240 hw_loss 0.223889 lr 0.00051471 rank 4
2023-02-21 21:52:43,838 DEBUG TRAIN Batch 11/2600 loss 18.948641 loss_att 28.415035 loss_ctc 24.299026 loss_rnnt 16.236660 hw_loss 0.197469 lr 0.00051471 rank 1
2023-02-21 21:52:43,839 DEBUG TRAIN Batch 11/2600 loss 34.944675 loss_att 44.244057 loss_ctc 40.039036 loss_rnnt 32.325775 hw_loss 0.149578 lr 0.00051471 rank 7
2023-02-21 21:53:56,652 DEBUG TRAIN Batch 11/2700 loss 15.038664 loss_att 28.306290 loss_ctc 16.050365 loss_rnnt 12.083972 hw_loss 0.311762 lr 0.00051444 rank 1
2023-02-21 21:53:56,663 DEBUG TRAIN Batch 11/2700 loss 8.775393 loss_att 21.569773 loss_ctc 6.652963 loss_rnnt 6.379760 hw_loss 0.224528 lr 0.00051444 rank 2
2023-02-21 21:53:56,667 DEBUG TRAIN Batch 11/2700 loss 29.549253 loss_att 34.809036 loss_ctc 37.603592 loss_rnnt 27.353622 hw_loss 0.130808 lr 0.00051444 rank 4
2023-02-21 21:53:56,670 DEBUG TRAIN Batch 11/2700 loss 30.497599 loss_att 44.505947 loss_ctc 34.178780 loss_rnnt 27.024786 hw_loss 0.338102 lr 0.00051444 rank 6
2023-02-21 21:53:56,671 DEBUG TRAIN Batch 11/2700 loss 24.028374 loss_att 31.138462 loss_ctc 29.043732 loss_rnnt 21.691406 hw_loss 0.461693 lr 0.00051444 rank 7
2023-02-21 21:53:56,673 DEBUG TRAIN Batch 11/2700 loss 28.382624 loss_att 42.514767 loss_ctc 31.979856 loss_rnnt 24.998318 hw_loss 0.146708 lr 0.00051444 rank 3
2023-02-21 21:53:56,674 DEBUG TRAIN Batch 11/2700 loss 15.004421 loss_att 23.183681 loss_ctc 19.523571 loss_rnnt 12.685089 hw_loss 0.151736 lr 0.00051444 rank 0
2023-02-21 21:53:56,676 DEBUG TRAIN Batch 11/2700 loss 18.126303 loss_att 23.446281 loss_ctc 19.090477 loss_rnnt 16.847076 hw_loss 0.162512 lr 0.00051444 rank 5
2023-02-21 21:55:10,307 DEBUG TRAIN Batch 11/2800 loss 37.470154 loss_att 42.486824 loss_ctc 43.535149 loss_rnnt 35.498451 hw_loss 0.299430 lr 0.00051417 rank 4
2023-02-21 21:55:10,309 DEBUG TRAIN Batch 11/2800 loss 28.786613 loss_att 34.964451 loss_ctc 35.702637 loss_rnnt 26.488279 hw_loss 0.263679 lr 0.00051417 rank 5
2023-02-21 21:55:10,310 DEBUG TRAIN Batch 11/2800 loss 31.248207 loss_att 39.593620 loss_ctc 36.753326 loss_rnnt 28.624115 hw_loss 0.414360 lr 0.00051417 rank 0
2023-02-21 21:55:10,316 DEBUG TRAIN Batch 11/2800 loss 57.988117 loss_att 70.249985 loss_ctc 68.543701 loss_rnnt 54.038765 hw_loss 0.167935 lr 0.00051417 rank 2
2023-02-21 21:55:10,317 DEBUG TRAIN Batch 11/2800 loss 23.834852 loss_att 33.646412 loss_ctc 25.569952 loss_rnnt 21.472082 hw_loss 0.317084 lr 0.00051417 rank 6
2023-02-21 21:55:10,318 DEBUG TRAIN Batch 11/2800 loss 48.632439 loss_att 50.925789 loss_ctc 46.800652 loss_rnnt 48.365761 hw_loss 0.097951 lr 0.00051417 rank 3
2023-02-21 21:55:10,319 DEBUG TRAIN Batch 11/2800 loss 40.919079 loss_att 48.538063 loss_ctc 40.358875 loss_rnnt 39.413994 hw_loss 0.104969 lr 0.00051417 rank 1
2023-02-21 21:55:10,365 DEBUG TRAIN Batch 11/2800 loss 28.376701 loss_att 38.777363 loss_ctc 29.853134 loss_rnnt 25.986492 hw_loss 0.212287 lr 0.00051417 rank 7
2023-02-21 21:56:23,351 DEBUG TRAIN Batch 11/2900 loss 21.253775 loss_att 30.947405 loss_ctc 24.250179 loss_rnnt 18.779942 hw_loss 0.254226 lr 0.00051390 rank 7
2023-02-21 21:56:23,361 DEBUG TRAIN Batch 11/2900 loss 23.107725 loss_att 36.538586 loss_ctc 19.966036 loss_rnnt 20.651081 hw_loss 0.355057 lr 0.00051390 rank 2
2023-02-21 21:56:23,362 DEBUG TRAIN Batch 11/2900 loss 29.518024 loss_att 40.428284 loss_ctc 34.712303 loss_rnnt 26.538145 hw_loss 0.197358 lr 0.00051390 rank 0
2023-02-21 21:56:23,363 DEBUG TRAIN Batch 11/2900 loss 36.028400 loss_att 51.022511 loss_ctc 47.298363 loss_rnnt 31.438343 hw_loss 0.166073 lr 0.00051390 rank 5
2023-02-21 21:56:23,363 DEBUG TRAIN Batch 11/2900 loss 30.596292 loss_att 34.703407 loss_ctc 42.791527 loss_rnnt 27.999559 hw_loss 0.279894 lr 0.00051390 rank 3
2023-02-21 21:56:23,364 DEBUG TRAIN Batch 11/2900 loss 28.371960 loss_att 31.936562 loss_ctc 29.761978 loss_rnnt 27.296722 hw_loss 0.331840 lr 0.00051390 rank 4
2023-02-21 21:56:23,366 DEBUG TRAIN Batch 11/2900 loss 20.862844 loss_att 32.019859 loss_ctc 27.043495 loss_rnnt 17.682091 hw_loss 0.234872 lr 0.00051390 rank 1
2023-02-21 21:56:23,379 DEBUG TRAIN Batch 11/2900 loss 27.510710 loss_att 32.764511 loss_ctc 31.973656 loss_rnnt 25.698429 hw_loss 0.312113 lr 0.00051390 rank 6
2023-02-21 21:57:35,489 DEBUG TRAIN Batch 11/3000 loss 31.090858 loss_att 35.972839 loss_ctc 32.873337 loss_rnnt 29.656921 hw_loss 0.412267 lr 0.00051362 rank 7
2023-02-21 21:57:35,491 DEBUG TRAIN Batch 11/3000 loss 24.374714 loss_att 32.009289 loss_ctc 25.425879 loss_rnnt 22.636213 hw_loss 0.133933 lr 0.00051362 rank 4
2023-02-21 21:57:35,492 DEBUG TRAIN Batch 11/3000 loss 20.793619 loss_att 25.002478 loss_ctc 22.016556 loss_rnnt 19.578609 hw_loss 0.394088 lr 0.00051362 rank 2
2023-02-21 21:57:35,492 DEBUG TRAIN Batch 11/3000 loss 22.709837 loss_att 31.233665 loss_ctc 27.151638 loss_rnnt 20.310312 hw_loss 0.192217 lr 0.00051362 rank 3
2023-02-21 21:57:35,493 DEBUG TRAIN Batch 11/3000 loss 35.969910 loss_att 47.334625 loss_ctc 40.269173 loss_rnnt 32.880142 hw_loss 0.456736 lr 0.00051362 rank 0
2023-02-21 21:57:35,495 DEBUG TRAIN Batch 11/3000 loss 36.651466 loss_att 46.791100 loss_ctc 42.985912 loss_rnnt 33.731762 hw_loss 0.088470 lr 0.00051362 rank 6
2023-02-21 21:57:35,497 DEBUG TRAIN Batch 11/3000 loss 21.510136 loss_att 30.336834 loss_ctc 19.412643 loss_rnnt 19.895067 hw_loss 0.242612 lr 0.00051362 rank 1
2023-02-21 21:57:35,500 DEBUG TRAIN Batch 11/3000 loss 28.976492 loss_att 30.938150 loss_ctc 26.092989 loss_rnnt 28.746639 hw_loss 0.416232 lr 0.00051362 rank 5
2023-02-21 21:58:48,134 DEBUG TRAIN Batch 11/3100 loss 19.813187 loss_att 27.246284 loss_ctc 19.415754 loss_rnnt 18.238880 hw_loss 0.263770 lr 0.00051335 rank 1
2023-02-21 21:58:48,135 DEBUG TRAIN Batch 11/3100 loss 12.032195 loss_att 19.242550 loss_ctc 13.662424 loss_rnnt 10.245031 hw_loss 0.239490 lr 0.00051335 rank 0
2023-02-21 21:58:48,150 DEBUG TRAIN Batch 11/3100 loss 15.846507 loss_att 16.494171 loss_ctc 16.486221 loss_rnnt 15.433822 hw_loss 0.370983 lr 0.00051335 rank 3
2023-02-21 21:58:48,151 DEBUG TRAIN Batch 11/3100 loss 26.081646 loss_att 30.063236 loss_ctc 25.112532 loss_rnnt 25.268791 hw_loss 0.273287 lr 0.00051335 rank 2
2023-02-21 21:58:48,151 DEBUG TRAIN Batch 11/3100 loss 23.910582 loss_att 30.985046 loss_ctc 28.060766 loss_rnnt 21.782433 hw_loss 0.299813 lr 0.00051335 rank 7
2023-02-21 21:58:48,152 DEBUG TRAIN Batch 11/3100 loss 20.880598 loss_att 29.542963 loss_ctc 20.661856 loss_rnnt 19.052952 hw_loss 0.233136 lr 0.00051335 rank 4
2023-02-21 21:58:48,152 DEBUG TRAIN Batch 11/3100 loss 21.790171 loss_att 23.189171 loss_ctc 26.886404 loss_rnnt 20.579998 hw_loss 0.470392 lr 0.00051335 rank 5
2023-02-21 21:58:48,154 DEBUG TRAIN Batch 11/3100 loss 39.719875 loss_att 48.327675 loss_ctc 45.515869 loss_rnnt 37.025833 hw_loss 0.374406 lr 0.00051335 rank 6
2023-02-21 22:00:03,473 DEBUG TRAIN Batch 11/3200 loss 15.887606 loss_att 18.124975 loss_ctc 20.428408 loss_rnnt 14.611084 hw_loss 0.419264 lr 0.00051308 rank 2
2023-02-21 22:00:03,474 DEBUG TRAIN Batch 11/3200 loss 31.064051 loss_att 37.813248 loss_ctc 38.730576 loss_rnnt 28.475266 hw_loss 0.406387 lr 0.00051308 rank 0
2023-02-21 22:00:03,475 DEBUG TRAIN Batch 11/3200 loss 16.548336 loss_att 18.479557 loss_ctc 17.360035 loss_rnnt 15.860719 hw_loss 0.362147 lr 0.00051308 rank 3
2023-02-21 22:00:03,476 DEBUG TRAIN Batch 11/3200 loss 26.982153 loss_att 42.396263 loss_ctc 30.118668 loss_rnnt 23.335846 hw_loss 0.272404 lr 0.00051308 rank 5
2023-02-21 22:00:03,477 DEBUG TRAIN Batch 11/3200 loss 26.522354 loss_att 36.309811 loss_ctc 26.122223 loss_rnnt 24.456051 hw_loss 0.304054 lr 0.00051308 rank 6
2023-02-21 22:00:03,477 DEBUG TRAIN Batch 11/3200 loss 20.899500 loss_att 40.955479 loss_ctc 21.623135 loss_rnnt 16.725639 hw_loss 0.124085 lr 0.00051308 rank 1
2023-02-21 22:00:03,524 DEBUG TRAIN Batch 11/3200 loss 29.275961 loss_att 31.338902 loss_ctc 32.759254 loss_rnnt 28.183224 hw_loss 0.404460 lr 0.00051308 rank 4
2023-02-21 22:00:03,538 DEBUG TRAIN Batch 11/3200 loss 31.554626 loss_att 42.888950 loss_ctc 39.115913 loss_rnnt 28.170889 hw_loss 0.203821 lr 0.00051308 rank 7
2023-02-21 22:01:15,747 DEBUG TRAIN Batch 11/3300 loss 23.681774 loss_att 44.471512 loss_ctc 28.530823 loss_rnnt 18.741035 hw_loss 0.255470 lr 0.00051281 rank 3
2023-02-21 22:01:15,751 DEBUG TRAIN Batch 11/3300 loss 22.979229 loss_att 33.216148 loss_ctc 30.677277 loss_rnnt 19.730595 hw_loss 0.327837 lr 0.00051281 rank 0
2023-02-21 22:01:15,753 DEBUG TRAIN Batch 11/3300 loss 9.924608 loss_att 16.712124 loss_ctc 9.533821 loss_rnnt 8.424530 hw_loss 0.365023 lr 0.00051281 rank 7
2023-02-21 22:01:15,753 DEBUG TRAIN Batch 11/3300 loss 20.813227 loss_att 34.329216 loss_ctc 27.636105 loss_rnnt 17.086002 hw_loss 0.214327 lr 0.00051281 rank 5
2023-02-21 22:01:15,754 DEBUG TRAIN Batch 11/3300 loss 28.782965 loss_att 46.028790 loss_ctc 35.019279 loss_rnnt 24.261074 hw_loss 0.452283 lr 0.00051281 rank 6
2023-02-21 22:01:15,756 DEBUG TRAIN Batch 11/3300 loss 22.577593 loss_att 31.423637 loss_ctc 31.637478 loss_rnnt 19.358349 hw_loss 0.453838 lr 0.00051281 rank 2
2023-02-21 22:01:15,760 DEBUG TRAIN Batch 11/3300 loss 11.547290 loss_att 24.539965 loss_ctc 16.436684 loss_rnnt 8.231399 hw_loss 0.122694 lr 0.00051281 rank 4
2023-02-21 22:01:15,809 DEBUG TRAIN Batch 11/3300 loss 41.067192 loss_att 50.564667 loss_ctc 49.446289 loss_rnnt 37.948013 hw_loss 0.192128 lr 0.00051281 rank 1
2023-02-21 22:02:28,525 DEBUG TRAIN Batch 11/3400 loss 21.416542 loss_att 31.438183 loss_ctc 21.147375 loss_rnnt 19.266563 hw_loss 0.340387 lr 0.00051254 rank 2
2023-02-21 22:02:28,525 DEBUG TRAIN Batch 11/3400 loss 19.125921 loss_att 23.280415 loss_ctc 20.441708 loss_rnnt 17.978752 hw_loss 0.264061 lr 0.00051254 rank 6
2023-02-21 22:02:28,526 DEBUG TRAIN Batch 11/3400 loss 13.455246 loss_att 19.223564 loss_ctc 13.339837 loss_rnnt 12.195274 hw_loss 0.228180 lr 0.00051254 rank 7
2023-02-21 22:02:28,527 DEBUG TRAIN Batch 11/3400 loss 19.701439 loss_att 27.932533 loss_ctc 20.809050 loss_rnnt 17.674614 hw_loss 0.436737 lr 0.00051254 rank 1
2023-02-21 22:02:28,528 DEBUG TRAIN Batch 11/3400 loss 56.886795 loss_att 65.932472 loss_ctc 56.059868 loss_rnnt 55.044250 hw_loss 0.269373 lr 0.00051254 rank 4
2023-02-21 22:02:28,531 DEBUG TRAIN Batch 11/3400 loss 19.149929 loss_att 29.656734 loss_ctc 21.001411 loss_rnnt 16.607033 hw_loss 0.365011 lr 0.00051254 rank 0
2023-02-21 22:02:28,531 DEBUG TRAIN Batch 11/3400 loss 16.926437 loss_att 28.514038 loss_ctc 17.841194 loss_rnnt 14.364715 hw_loss 0.229191 lr 0.00051254 rank 3
2023-02-21 22:02:28,531 DEBUG TRAIN Batch 11/3400 loss 16.287790 loss_att 21.867022 loss_ctc 19.439999 loss_rnnt 14.624792 hw_loss 0.237856 lr 0.00051254 rank 5
2023-02-21 22:03:41,965 DEBUG TRAIN Batch 11/3500 loss 16.269390 loss_att 27.480965 loss_ctc 17.925323 loss_rnnt 13.724194 hw_loss 0.153922 lr 0.00051228 rank 7
2023-02-21 22:03:41,974 DEBUG TRAIN Batch 11/3500 loss 16.561831 loss_att 23.720509 loss_ctc 19.624371 loss_rnnt 14.637806 hw_loss 0.157407 lr 0.00051228 rank 3
2023-02-21 22:03:41,974 DEBUG TRAIN Batch 11/3500 loss 34.364674 loss_att 42.554611 loss_ctc 35.318893 loss_rnnt 32.454102 hw_loss 0.272540 lr 0.00051228 rank 2
2023-02-21 22:03:41,977 DEBUG TRAIN Batch 11/3500 loss 16.116190 loss_att 17.951155 loss_ctc 17.522869 loss_rnnt 15.375774 hw_loss 0.348498 lr 0.00051228 rank 6
2023-02-21 22:03:41,977 DEBUG TRAIN Batch 11/3500 loss 28.336969 loss_att 36.674828 loss_ctc 29.953119 loss_rnnt 26.343342 hw_loss 0.207314 lr 0.00051228 rank 4
2023-02-21 22:03:41,978 DEBUG TRAIN Batch 11/3500 loss 19.117460 loss_att 24.704370 loss_ctc 20.345932 loss_rnnt 17.644714 hw_loss 0.359188 lr 0.00051228 rank 0
2023-02-21 22:03:41,980 DEBUG TRAIN Batch 11/3500 loss 9.888856 loss_att 18.220039 loss_ctc 10.533172 loss_rnnt 8.017627 hw_loss 0.223281 lr 0.00051228 rank 1
2023-02-21 22:03:41,984 DEBUG TRAIN Batch 11/3500 loss 15.706188 loss_att 20.153170 loss_ctc 17.528456 loss_rnnt 14.407533 hw_loss 0.311792 lr 0.00051228 rank 5
2023-02-21 22:04:55,973 DEBUG TRAIN Batch 11/3600 loss 26.658831 loss_att 36.696922 loss_ctc 29.594225 loss_rnnt 24.176168 hw_loss 0.156857 lr 0.00051201 rank 3
2023-02-21 22:04:55,973 DEBUG TRAIN Batch 11/3600 loss 27.137865 loss_att 36.459618 loss_ctc 26.882425 loss_rnnt 25.198536 hw_loss 0.204443 lr 0.00051201 rank 2
2023-02-21 22:04:55,976 DEBUG TRAIN Batch 11/3600 loss 37.441463 loss_att 44.052628 loss_ctc 40.089573 loss_rnnt 35.691273 hw_loss 0.140389 lr 0.00051201 rank 6
2023-02-21 22:04:55,979 DEBUG TRAIN Batch 11/3600 loss 21.050121 loss_att 29.362850 loss_ctc 21.208912 loss_rnnt 19.298172 hw_loss 0.127937 lr 0.00051201 rank 5
2023-02-21 22:04:55,981 DEBUG TRAIN Batch 11/3600 loss 25.518166 loss_att 30.036299 loss_ctc 33.931129 loss_rnnt 23.353441 hw_loss 0.261315 lr 0.00051201 rank 0
2023-02-21 22:04:55,983 DEBUG TRAIN Batch 11/3600 loss 31.815039 loss_att 40.632427 loss_ctc 36.070415 loss_rnnt 29.286116 hw_loss 0.371367 lr 0.00051201 rank 1
2023-02-21 22:04:55,983 DEBUG TRAIN Batch 11/3600 loss 14.836565 loss_att 26.650047 loss_ctc 18.653389 loss_rnnt 11.896828 hw_loss 0.127745 lr 0.00051201 rank 4
2023-02-21 22:04:56,028 DEBUG TRAIN Batch 11/3600 loss 18.881983 loss_att 25.297291 loss_ctc 20.833960 loss_rnnt 17.303638 hw_loss 0.065659 lr 0.00051201 rank 7
2023-02-21 22:06:10,496 DEBUG TRAIN Batch 11/3700 loss 38.004070 loss_att 47.231575 loss_ctc 41.429695 loss_rnnt 35.654305 hw_loss 0.089094 lr 0.00051174 rank 2
2023-02-21 22:06:10,497 DEBUG TRAIN Batch 11/3700 loss 24.151392 loss_att 34.114529 loss_ctc 25.472420 loss_rnnt 21.814293 hw_loss 0.315627 lr 0.00051174 rank 4
2023-02-21 22:06:10,498 DEBUG TRAIN Batch 11/3700 loss 23.265747 loss_att 29.978336 loss_ctc 26.423712 loss_rnnt 21.386002 hw_loss 0.217810 lr 0.00051174 rank 7
2023-02-21 22:06:10,499 DEBUG TRAIN Batch 11/3700 loss 18.477156 loss_att 21.626431 loss_ctc 20.264313 loss_rnnt 17.513277 hw_loss 0.179503 lr 0.00051174 rank 5
2023-02-21 22:06:10,498 DEBUG TRAIN Batch 11/3700 loss 24.991472 loss_att 30.165403 loss_ctc 25.390022 loss_rnnt 23.807346 hw_loss 0.180373 lr 0.00051174 rank 6
2023-02-21 22:06:10,501 DEBUG TRAIN Batch 11/3700 loss 32.597721 loss_att 46.300446 loss_ctc 39.811714 loss_rnnt 28.709009 hw_loss 0.349312 lr 0.00051174 rank 1
2023-02-21 22:06:10,504 DEBUG TRAIN Batch 11/3700 loss 28.598623 loss_att 29.674353 loss_ctc 32.492157 loss_rnnt 27.675440 hw_loss 0.354185 lr 0.00051174 rank 3
2023-02-21 22:06:10,552 DEBUG TRAIN Batch 11/3700 loss 28.640450 loss_att 41.403824 loss_ctc 33.270866 loss_rnnt 25.337059 hw_loss 0.249987 lr 0.00051174 rank 0
2023-02-21 22:07:22,774 DEBUG TRAIN Batch 11/3800 loss 27.295370 loss_att 34.882698 loss_ctc 35.895325 loss_rnnt 24.436544 hw_loss 0.365060 lr 0.00051147 rank 5
2023-02-21 22:07:22,786 DEBUG TRAIN Batch 11/3800 loss 21.753389 loss_att 26.926260 loss_ctc 24.240049 loss_rnnt 20.221695 hw_loss 0.310433 lr 0.00051147 rank 4
2023-02-21 22:07:22,786 DEBUG TRAIN Batch 11/3800 loss 25.883291 loss_att 28.176016 loss_ctc 29.220016 loss_rnnt 24.832350 hw_loss 0.276564 lr 0.00051147 rank 1
2023-02-21 22:07:22,789 DEBUG TRAIN Batch 11/3800 loss 12.372833 loss_att 14.612661 loss_ctc 14.371711 loss_rnnt 11.368114 hw_loss 0.544194 lr 0.00051147 rank 2
2023-02-21 22:07:22,793 DEBUG TRAIN Batch 11/3800 loss 17.779825 loss_att 24.381838 loss_ctc 19.560440 loss_rnnt 16.070429 hw_loss 0.284209 lr 0.00051147 rank 0
2023-02-21 22:07:22,793 DEBUG TRAIN Batch 11/3800 loss 26.415176 loss_att 29.273426 loss_ctc 25.073030 loss_rnnt 25.924963 hw_loss 0.182843 lr 0.00051147 rank 3
2023-02-21 22:07:22,795 DEBUG TRAIN Batch 11/3800 loss 18.895439 loss_att 22.372458 loss_ctc 23.288450 loss_rnnt 17.388592 hw_loss 0.423201 lr 0.00051147 rank 6
2023-02-21 22:07:22,834 DEBUG TRAIN Batch 11/3800 loss 21.299604 loss_att 24.738726 loss_ctc 24.335453 loss_rnnt 20.017006 hw_loss 0.356233 lr 0.00051147 rank 7
2023-02-21 22:08:37,591 DEBUG TRAIN Batch 11/3900 loss 23.865728 loss_att 25.356106 loss_ctc 25.776556 loss_rnnt 23.111414 hw_loss 0.377739 lr 0.00051120 rank 3
2023-02-21 22:08:37,593 DEBUG TRAIN Batch 11/3900 loss 24.538218 loss_att 25.194221 loss_ctc 28.881712 loss_rnnt 23.760229 hw_loss 0.126852 lr 0.00051120 rank 2
2023-02-21 22:08:37,594 DEBUG TRAIN Batch 11/3900 loss 27.072407 loss_att 33.469471 loss_ctc 26.706945 loss_rnnt 25.702713 hw_loss 0.260641 lr 0.00051120 rank 5
2023-02-21 22:08:37,596 DEBUG TRAIN Batch 11/3900 loss 23.592449 loss_att 32.812645 loss_ctc 21.596710 loss_rnnt 21.883762 hw_loss 0.245144 lr 0.00051120 rank 0
2023-02-21 22:08:37,597 DEBUG TRAIN Batch 11/3900 loss 22.969917 loss_att 29.677757 loss_ctc 22.117023 loss_rnnt 21.567549 hw_loss 0.327225 lr 0.00051120 rank 6
2023-02-21 22:08:37,598 DEBUG TRAIN Batch 11/3900 loss 23.814203 loss_att 41.661613 loss_ctc 24.721870 loss_rnnt 19.928009 hw_loss 0.366915 lr 0.00051120 rank 7
2023-02-21 22:08:37,641 DEBUG TRAIN Batch 11/3900 loss 12.599173 loss_att 26.443516 loss_ctc 14.587181 loss_rnnt 9.441488 hw_loss 0.232030 lr 0.00051120 rank 1
2023-02-21 22:08:37,645 DEBUG TRAIN Batch 11/3900 loss 27.149807 loss_att 41.929790 loss_ctc 29.360678 loss_rnnt 23.667120 hw_loss 0.434830 lr 0.00051120 rank 4
2023-02-21 22:09:50,601 DEBUG TRAIN Batch 11/4000 loss 42.633484 loss_att 53.659706 loss_ctc 52.276047 loss_rnnt 39.041275 hw_loss 0.189915 lr 0.00051094 rank 2
2023-02-21 22:09:50,601 DEBUG TRAIN Batch 11/4000 loss 16.312746 loss_att 26.108686 loss_ctc 23.022198 loss_rnnt 13.271243 hw_loss 0.351977 lr 0.00051094 rank 4
2023-02-21 22:09:50,603 DEBUG TRAIN Batch 11/4000 loss 21.906498 loss_att 32.058830 loss_ctc 23.210941 loss_rnnt 19.574474 hw_loss 0.239308 lr 0.00051094 rank 3
2023-02-21 22:09:50,609 DEBUG TRAIN Batch 11/4000 loss 17.410921 loss_att 25.303848 loss_ctc 18.709782 loss_rnnt 15.549395 hw_loss 0.205800 lr 0.00051094 rank 7
2023-02-21 22:09:50,608 DEBUG TRAIN Batch 11/4000 loss 35.902031 loss_att 40.362560 loss_ctc 42.404240 loss_rnnt 34.049019 hw_loss 0.176144 lr 0.00051094 rank 6
2023-02-21 22:09:50,610 DEBUG TRAIN Batch 11/4000 loss 26.555286 loss_att 29.937769 loss_ctc 34.368294 loss_rnnt 24.733032 hw_loss 0.195044 lr 0.00051094 rank 5
2023-02-21 22:09:50,611 DEBUG TRAIN Batch 11/4000 loss 29.437943 loss_att 41.309326 loss_ctc 37.367504 loss_rnnt 25.845877 hw_loss 0.300964 lr 0.00051094 rank 0
2023-02-21 22:09:50,655 DEBUG TRAIN Batch 11/4000 loss 22.017879 loss_att 26.573706 loss_ctc 24.186071 loss_rnnt 20.621582 hw_loss 0.367572 lr 0.00051094 rank 1
2023-02-21 22:11:03,596 DEBUG TRAIN Batch 11/4100 loss 29.615883 loss_att 36.194675 loss_ctc 29.619362 loss_rnnt 28.176098 hw_loss 0.231682 lr 0.00051067 rank 2
2023-02-21 22:11:03,600 DEBUG TRAIN Batch 11/4100 loss 15.377314 loss_att 19.630550 loss_ctc 20.308910 loss_rnnt 13.705311 hw_loss 0.307141 lr 0.00051067 rank 3
2023-02-21 22:11:03,602 DEBUG TRAIN Batch 11/4100 loss 21.983458 loss_att 29.971512 loss_ctc 26.506863 loss_rnnt 19.603992 hw_loss 0.335128 lr 0.00051067 rank 1
2023-02-21 22:11:03,606 DEBUG TRAIN Batch 11/4100 loss 15.947499 loss_att 17.722225 loss_ctc 16.921202 loss_rnnt 15.341078 hw_loss 0.228093 lr 0.00051067 rank 4
2023-02-21 22:11:03,606 DEBUG TRAIN Batch 11/4100 loss 28.767168 loss_att 38.392597 loss_ctc 36.633442 loss_rnnt 25.672247 hw_loss 0.226876 lr 0.00051067 rank 6
2023-02-21 22:11:03,608 DEBUG TRAIN Batch 11/4100 loss 29.969603 loss_att 35.720673 loss_ctc 33.055351 loss_rnnt 28.368145 hw_loss 0.074649 lr 0.00051067 rank 7
2023-02-21 22:11:03,611 DEBUG TRAIN Batch 11/4100 loss 19.813868 loss_att 21.506493 loss_ctc 27.228699 loss_rnnt 18.311167 hw_loss 0.329118 lr 0.00051067 rank 0
2023-02-21 22:11:03,615 DEBUG TRAIN Batch 11/4100 loss 32.579121 loss_att 42.492027 loss_ctc 40.468513 loss_rnnt 29.423161 hw_loss 0.227732 lr 0.00051067 rank 5
2023-02-21 22:12:15,532 DEBUG TRAIN Batch 11/4200 loss 22.775862 loss_att 30.949646 loss_ctc 24.456844 loss_rnnt 20.805595 hw_loss 0.208836 lr 0.00051040 rank 6
2023-02-21 22:12:15,548 DEBUG TRAIN Batch 11/4200 loss 9.499398 loss_att 14.659428 loss_ctc 11.375850 loss_rnnt 8.088112 hw_loss 0.242038 lr 0.00051040 rank 3
2023-02-21 22:12:15,548 DEBUG TRAIN Batch 11/4200 loss 16.559330 loss_att 25.090673 loss_ctc 19.524258 loss_rnnt 14.336790 hw_loss 0.226778 lr 0.00051040 rank 4
2023-02-21 22:12:15,549 DEBUG TRAIN Batch 11/4200 loss 9.254113 loss_att 15.887009 loss_ctc 10.920321 loss_rnnt 7.542162 hw_loss 0.306023 lr 0.00051040 rank 2
2023-02-21 22:12:15,551 DEBUG TRAIN Batch 11/4200 loss 21.628880 loss_att 29.029844 loss_ctc 21.148033 loss_rnnt 20.082954 hw_loss 0.243461 lr 0.00051040 rank 5
2023-02-21 22:12:15,552 DEBUG TRAIN Batch 11/4200 loss 30.440058 loss_att 40.031750 loss_ctc 31.815783 loss_rnnt 28.232578 hw_loss 0.198208 lr 0.00051040 rank 7
2023-02-21 22:12:15,552 DEBUG TRAIN Batch 11/4200 loss 21.757046 loss_att 24.568714 loss_ctc 20.252102 loss_rnnt 21.230190 hw_loss 0.309715 lr 0.00051040 rank 1
2023-02-21 22:12:15,556 DEBUG TRAIN Batch 11/4200 loss 15.370796 loss_att 19.293861 loss_ctc 18.860065 loss_rnnt 14.044603 hw_loss 0.143144 lr 0.00051040 rank 0
2023-02-21 22:13:29,638 DEBUG TRAIN Batch 11/4300 loss 21.001162 loss_att 30.831532 loss_ctc 22.558281 loss_rnnt 18.708595 hw_loss 0.222886 lr 0.00051014 rank 2
2023-02-21 22:13:29,643 DEBUG TRAIN Batch 11/4300 loss 10.850422 loss_att 17.166718 loss_ctc 9.369877 loss_rnnt 9.668814 hw_loss 0.217041 lr 0.00051014 rank 4
2023-02-21 22:13:29,646 DEBUG TRAIN Batch 11/4300 loss 36.297295 loss_att 44.968063 loss_ctc 39.765717 loss_rnnt 34.024914 hw_loss 0.142065 lr 0.00051014 rank 1
2023-02-21 22:13:29,647 DEBUG TRAIN Batch 11/4300 loss 30.994221 loss_att 36.981842 loss_ctc 33.585899 loss_rnnt 29.282965 hw_loss 0.315334 lr 0.00051014 rank 3
2023-02-21 22:13:29,648 DEBUG TRAIN Batch 11/4300 loss 19.093401 loss_att 23.716850 loss_ctc 22.015987 loss_rnnt 17.689922 hw_loss 0.167079 lr 0.00051014 rank 6
2023-02-21 22:13:29,650 DEBUG TRAIN Batch 11/4300 loss 34.914276 loss_att 39.026814 loss_ctc 39.335342 loss_rnnt 33.355858 hw_loss 0.274561 lr 0.00051014 rank 0
2023-02-21 22:13:29,654 DEBUG TRAIN Batch 11/4300 loss 35.331730 loss_att 39.624245 loss_ctc 39.833488 loss_rnnt 33.763634 hw_loss 0.205045 lr 0.00051014 rank 7
2023-02-21 22:13:29,656 DEBUG TRAIN Batch 11/4300 loss 16.387968 loss_att 19.280804 loss_ctc 17.691477 loss_rnnt 15.488808 hw_loss 0.275235 lr 0.00051014 rank 5
2023-02-21 22:14:42,310 DEBUG TRAIN Batch 11/4400 loss 29.082264 loss_att 31.064339 loss_ctc 32.705505 loss_rnnt 28.013433 hw_loss 0.354974 lr 0.00050987 rank 2
2023-02-21 22:14:42,311 DEBUG TRAIN Batch 11/4400 loss 18.203236 loss_att 28.966866 loss_ctc 20.312454 loss_rnnt 15.660414 hw_loss 0.204125 lr 0.00050987 rank 3
2023-02-21 22:14:42,313 DEBUG TRAIN Batch 11/4400 loss 12.536287 loss_att 15.482783 loss_ctc 12.597922 loss_rnnt 11.781341 hw_loss 0.295181 lr 0.00050987 rank 6
2023-02-21 22:14:42,314 DEBUG TRAIN Batch 11/4400 loss 26.606520 loss_att 37.138412 loss_ctc 27.323130 loss_rnnt 24.177956 hw_loss 0.424944 lr 0.00050987 rank 1
2023-02-21 22:14:42,317 DEBUG TRAIN Batch 11/4400 loss 18.444103 loss_att 23.672352 loss_ctc 19.453358 loss_rnnt 17.122185 hw_loss 0.265687 lr 0.00050987 rank 5
2023-02-21 22:14:42,318 DEBUG TRAIN Batch 11/4400 loss 16.948479 loss_att 22.617233 loss_ctc 18.874453 loss_rnnt 15.361341 hw_loss 0.368604 lr 0.00050987 rank 4
2023-02-21 22:14:42,319 DEBUG TRAIN Batch 11/4400 loss 18.821747 loss_att 24.436657 loss_ctc 21.947266 loss_rnnt 17.129101 hw_loss 0.286740 lr 0.00050987 rank 0
2023-02-21 22:14:42,320 DEBUG TRAIN Batch 11/4400 loss 25.152128 loss_att 26.404953 loss_ctc 26.689289 loss_rnnt 24.546299 hw_loss 0.281830 lr 0.00050987 rank 7
2023-02-21 22:15:54,863 DEBUG TRAIN Batch 11/4500 loss 56.313110 loss_att 97.331276 loss_ctc 69.234566 loss_rnnt 46.291176 hw_loss 0.178943 lr 0.00050961 rank 4
2023-02-21 22:15:54,876 DEBUG TRAIN Batch 11/4500 loss 29.947666 loss_att 29.730307 loss_ctc 31.748837 loss_rnnt 29.503616 hw_loss 0.463812 lr 0.00050961 rank 3
2023-02-21 22:15:54,878 DEBUG TRAIN Batch 11/4500 loss 14.281335 loss_att 19.631435 loss_ctc 15.658245 loss_rnnt 12.842842 hw_loss 0.346658 lr 0.00050961 rank 2
2023-02-21 22:15:54,879 DEBUG TRAIN Batch 11/4500 loss 12.360279 loss_att 21.822525 loss_ctc 12.316872 loss_rnnt 10.344076 hw_loss 0.242892 lr 0.00050961 rank 6
2023-02-21 22:15:54,881 DEBUG TRAIN Batch 11/4500 loss 11.722139 loss_att 18.528111 loss_ctc 11.043064 loss_rnnt 10.395098 hw_loss 0.105732 lr 0.00050961 rank 7
2023-02-21 22:15:54,885 DEBUG TRAIN Batch 11/4500 loss 15.775069 loss_att 16.512983 loss_ctc 17.661621 loss_rnnt 15.056801 hw_loss 0.598398 lr 0.00050961 rank 0
2023-02-21 22:15:54,886 DEBUG TRAIN Batch 11/4500 loss 20.894075 loss_att 31.412212 loss_ctc 25.777187 loss_rnnt 18.034016 hw_loss 0.197535 lr 0.00050961 rank 5
2023-02-21 22:15:54,890 DEBUG TRAIN Batch 11/4500 loss 13.041918 loss_att 13.316271 loss_ctc 15.100466 loss_rnnt 12.414507 hw_loss 0.558874 lr 0.00050961 rank 1
2023-02-21 22:17:08,450 DEBUG TRAIN Batch 11/4600 loss 20.005751 loss_att 27.104607 loss_ctc 23.454733 loss_rnnt 17.924742 hw_loss 0.377575 lr 0.00050934 rank 2
2023-02-21 22:17:08,459 DEBUG TRAIN Batch 11/4600 loss 18.377537 loss_att 22.134651 loss_ctc 18.468105 loss_rnnt 17.423351 hw_loss 0.357540 lr 0.00050934 rank 3
2023-02-21 22:17:08,460 DEBUG TRAIN Batch 11/4600 loss 22.917686 loss_att 29.435574 loss_ctc 21.639286 loss_rnnt 21.598698 hw_loss 0.348493 lr 0.00050934 rank 0
2023-02-21 22:17:08,462 DEBUG TRAIN Batch 11/4600 loss 38.173561 loss_att 43.043213 loss_ctc 37.359009 loss_rnnt 37.209225 hw_loss 0.185647 lr 0.00050934 rank 7
2023-02-21 22:17:08,461 DEBUG TRAIN Batch 11/4600 loss 22.134199 loss_att 25.476437 loss_ctc 24.757551 loss_rnnt 20.997734 hw_loss 0.221690 lr 0.00050934 rank 6
2023-02-21 22:17:08,470 DEBUG TRAIN Batch 11/4600 loss 28.255131 loss_att 33.164837 loss_ctc 33.025169 loss_rnnt 26.503235 hw_loss 0.251157 lr 0.00050934 rank 1
2023-02-21 22:17:08,499 DEBUG TRAIN Batch 11/4600 loss 15.291426 loss_att 28.186672 loss_ctc 20.795925 loss_rnnt 11.861278 hw_loss 0.219684 lr 0.00050934 rank 5
2023-02-21 22:17:08,501 DEBUG TRAIN Batch 11/4600 loss 17.966173 loss_att 29.417873 loss_ctc 19.541700 loss_rnnt 15.269917 hw_loss 0.367212 lr 0.00050934 rank 4
2023-02-21 22:18:21,086 DEBUG TRAIN Batch 11/4700 loss 25.187935 loss_att 29.934763 loss_ctc 28.979649 loss_rnnt 23.487268 hw_loss 0.460756 lr 0.00050908 rank 7
2023-02-21 22:18:21,090 DEBUG TRAIN Batch 11/4700 loss 19.177685 loss_att 24.059242 loss_ctc 24.193295 loss_rnnt 17.458517 hw_loss 0.138954 lr 0.00050908 rank 1
2023-02-21 22:18:21,096 DEBUG TRAIN Batch 11/4700 loss 13.915823 loss_att 21.694885 loss_ctc 13.621116 loss_rnnt 12.280151 hw_loss 0.223412 lr 0.00050908 rank 6
2023-02-21 22:18:21,098 DEBUG TRAIN Batch 11/4700 loss 20.753981 loss_att 24.985079 loss_ctc 24.008717 loss_rnnt 19.401066 hw_loss 0.136367 lr 0.00050908 rank 0
2023-02-21 22:18:21,098 DEBUG TRAIN Batch 11/4700 loss 36.776905 loss_att 44.107765 loss_ctc 49.006645 loss_rnnt 33.544113 hw_loss 0.254970 lr 0.00050908 rank 2
2023-02-21 22:18:21,105 DEBUG TRAIN Batch 11/4700 loss 18.838676 loss_att 30.490355 loss_ctc 20.194330 loss_rnnt 16.159634 hw_loss 0.314911 lr 0.00050908 rank 4
2023-02-21 22:18:21,106 DEBUG TRAIN Batch 11/4700 loss 21.055939 loss_att 24.812847 loss_ctc 22.373280 loss_rnnt 19.971949 hw_loss 0.294306 lr 0.00050908 rank 3
2023-02-21 22:18:21,142 DEBUG TRAIN Batch 11/4700 loss 29.861156 loss_att 39.764816 loss_ctc 34.888847 loss_rnnt 27.040512 hw_loss 0.317919 lr 0.00050908 rank 5
2023-02-21 22:19:33,324 DEBUG TRAIN Batch 11/4800 loss 25.641556 loss_att 29.203773 loss_ctc 30.698349 loss_rnnt 24.028534 hw_loss 0.424383 lr 0.00050882 rank 3
2023-02-21 22:19:33,324 DEBUG TRAIN Batch 11/4800 loss 10.935872 loss_att 18.152651 loss_ctc 13.215943 loss_rnnt 9.051224 hw_loss 0.257406 lr 0.00050882 rank 7
2023-02-21 22:19:33,326 DEBUG TRAIN Batch 11/4800 loss 34.408974 loss_att 42.093575 loss_ctc 40.795784 loss_rnnt 31.838892 hw_loss 0.340469 lr 0.00050882 rank 6
2023-02-21 22:19:33,329 DEBUG TRAIN Batch 11/4800 loss 15.772676 loss_att 21.319893 loss_ctc 17.665615 loss_rnnt 14.210056 hw_loss 0.376473 lr 0.00050882 rank 0
2023-02-21 22:19:33,328 DEBUG TRAIN Batch 11/4800 loss 19.119904 loss_att 26.929432 loss_ctc 23.752483 loss_rnnt 16.759344 hw_loss 0.339331 lr 0.00050882 rank 2
2023-02-21 22:19:33,331 DEBUG TRAIN Batch 11/4800 loss 30.515499 loss_att 39.395370 loss_ctc 31.458879 loss_rnnt 28.407328 hw_loss 0.387024 lr 0.00050882 rank 1
2023-02-21 22:19:33,334 DEBUG TRAIN Batch 11/4800 loss 28.662659 loss_att 37.201294 loss_ctc 32.892601 loss_rnnt 26.320625 hw_loss 0.131837 lr 0.00050882 rank 4
2023-02-21 22:19:33,343 DEBUG TRAIN Batch 11/4800 loss 17.682528 loss_att 25.671877 loss_ctc 22.607363 loss_rnnt 15.283807 hw_loss 0.270384 lr 0.00050882 rank 5
2023-02-21 22:20:46,269 DEBUG TRAIN Batch 11/4900 loss 30.414398 loss_att 41.336250 loss_ctc 34.632648 loss_rnnt 27.568493 hw_loss 0.185818 lr 0.00050855 rank 1
2023-02-21 22:20:46,273 DEBUG TRAIN Batch 11/4900 loss 18.013151 loss_att 21.526052 loss_ctc 21.094957 loss_rnnt 16.793190 hw_loss 0.199639 lr 0.00050855 rank 7
2023-02-21 22:20:46,276 DEBUG TRAIN Batch 11/4900 loss 21.337145 loss_att 33.292244 loss_ctc 27.069878 loss_rnnt 18.083595 hw_loss 0.184060 lr 0.00050855 rank 0
2023-02-21 22:20:46,284 DEBUG TRAIN Batch 11/4900 loss 19.225634 loss_att 28.822418 loss_ctc 19.862202 loss_rnnt 17.036789 hw_loss 0.346144 lr 0.00050855 rank 3
2023-02-21 22:20:46,285 DEBUG TRAIN Batch 11/4900 loss 21.530315 loss_att 30.213383 loss_ctc 24.065796 loss_rnnt 19.321781 hw_loss 0.250985 lr 0.00050855 rank 6
2023-02-21 22:20:46,289 DEBUG TRAIN Batch 11/4900 loss 23.007099 loss_att 24.366886 loss_ctc 27.515377 loss_rnnt 21.949654 hw_loss 0.345720 lr 0.00050855 rank 4
2023-02-21 22:20:46,289 DEBUG TRAIN Batch 11/4900 loss 20.797184 loss_att 25.073389 loss_ctc 24.557920 loss_rnnt 19.305996 hw_loss 0.252214 lr 0.00050855 rank 2
2023-02-21 22:20:46,335 DEBUG TRAIN Batch 11/4900 loss 13.968926 loss_att 29.206951 loss_ctc 18.967728 loss_rnnt 10.073170 hw_loss 0.340583 lr 0.00050855 rank 5
2023-02-21 22:22:01,205 DEBUG TRAIN Batch 11/5000 loss 10.573981 loss_att 15.631105 loss_ctc 10.856621 loss_rnnt 9.387657 hw_loss 0.257274 lr 0.00050829 rank 2
2023-02-21 22:22:01,207 DEBUG TRAIN Batch 11/5000 loss 18.595818 loss_att 29.069653 loss_ctc 25.367718 loss_rnnt 15.429411 hw_loss 0.316351 lr 0.00050829 rank 1
2023-02-21 22:22:01,209 DEBUG TRAIN Batch 11/5000 loss 23.606031 loss_att 26.878868 loss_ctc 28.071592 loss_rnnt 22.098343 hw_loss 0.483214 lr 0.00050829 rank 7
2023-02-21 22:22:01,209 DEBUG TRAIN Batch 11/5000 loss 22.453218 loss_att 26.416119 loss_ctc 27.072243 loss_rnnt 20.949917 hw_loss 0.177845 lr 0.00050829 rank 3
2023-02-21 22:22:01,212 DEBUG TRAIN Batch 11/5000 loss 20.544216 loss_att 24.712303 loss_ctc 24.299246 loss_rnnt 19.053921 hw_loss 0.292513 lr 0.00050829 rank 6
2023-02-21 22:22:01,216 DEBUG TRAIN Batch 11/5000 loss 25.055096 loss_att 30.170471 loss_ctc 30.007582 loss_rnnt 23.234478 hw_loss 0.257274 lr 0.00050829 rank 0
2023-02-21 22:22:01,219 DEBUG TRAIN Batch 11/5000 loss 40.059978 loss_att 41.936466 loss_ctc 42.365017 loss_rnnt 39.253639 hw_loss 0.231941 lr 0.00050829 rank 5
2023-02-21 22:22:01,262 DEBUG TRAIN Batch 11/5000 loss 23.855309 loss_att 27.174067 loss_ctc 29.771780 loss_rnnt 22.259552 hw_loss 0.268386 lr 0.00050829 rank 4
2023-02-21 22:23:14,645 DEBUG TRAIN Batch 11/5100 loss 20.924152 loss_att 21.641586 loss_ctc 28.481525 loss_rnnt 19.528679 hw_loss 0.458131 lr 0.00050803 rank 7
2023-02-21 22:23:14,654 DEBUG TRAIN Batch 11/5100 loss 14.688653 loss_att 15.757713 loss_ctc 17.144888 loss_rnnt 14.014981 hw_loss 0.248178 lr 0.00050803 rank 4
2023-02-21 22:23:14,655 DEBUG TRAIN Batch 11/5100 loss 18.611668 loss_att 23.196812 loss_ctc 23.639599 loss_rnnt 16.840401 hw_loss 0.344709 lr 0.00050803 rank 3
2023-02-21 22:23:14,657 DEBUG TRAIN Batch 11/5100 loss 10.155849 loss_att 11.393907 loss_ctc 11.012684 loss_rnnt 9.412265 hw_loss 0.715739 lr 0.00050803 rank 2
2023-02-21 22:23:14,660 DEBUG TRAIN Batch 11/5100 loss 25.784634 loss_att 28.075508 loss_ctc 33.744812 loss_rnnt 24.089300 hw_loss 0.329626 lr 0.00050803 rank 1
2023-02-21 22:23:14,662 DEBUG TRAIN Batch 11/5100 loss 15.452968 loss_att 22.891815 loss_ctc 15.145638 loss_rnnt 13.821704 hw_loss 0.345887 lr 0.00050803 rank 6
2023-02-21 22:23:14,671 DEBUG TRAIN Batch 11/5100 loss 12.859756 loss_att 13.853989 loss_ctc 13.446577 loss_rnnt 12.317620 hw_loss 0.496962 lr 0.00050803 rank 5
2023-02-21 22:23:14,708 DEBUG TRAIN Batch 11/5100 loss 25.330084 loss_att 29.494076 loss_ctc 30.322340 loss_rnnt 23.704115 hw_loss 0.239128 lr 0.00050803 rank 0
2023-02-21 22:24:26,411 DEBUG TRAIN Batch 11/5200 loss 15.817641 loss_att 29.411795 loss_ctc 16.207932 loss_rnnt 12.921097 hw_loss 0.235640 lr 0.00050776 rank 2
2023-02-21 22:24:26,413 DEBUG TRAIN Batch 11/5200 loss 17.575933 loss_att 27.097862 loss_ctc 22.305698 loss_rnnt 14.901083 hw_loss 0.262180 lr 0.00050776 rank 6
2023-02-21 22:24:26,417 DEBUG TRAIN Batch 11/5200 loss 9.653761 loss_att 20.602070 loss_ctc 10.249895 loss_rnnt 7.263504 hw_loss 0.227081 lr 0.00050776 rank 7
2023-02-21 22:24:26,419 DEBUG TRAIN Batch 11/5200 loss 14.449425 loss_att 22.569700 loss_ctc 13.589140 loss_rnnt 12.784778 hw_loss 0.291181 lr 0.00050776 rank 0
2023-02-21 22:24:26,420 DEBUG TRAIN Batch 11/5200 loss 40.744488 loss_att 56.379200 loss_ctc 51.367813 loss_rnnt 36.031578 hw_loss 0.317849 lr 0.00050776 rank 4
2023-02-21 22:24:26,420 DEBUG TRAIN Batch 11/5200 loss 20.367779 loss_att 33.264977 loss_ctc 21.972961 loss_rnnt 17.467224 hw_loss 0.200794 lr 0.00050776 rank 3
2023-02-21 22:24:26,420 DEBUG TRAIN Batch 11/5200 loss 18.971056 loss_att 21.950909 loss_ctc 20.512802 loss_rnnt 18.024208 hw_loss 0.272461 lr 0.00050776 rank 5
2023-02-21 22:24:26,424 DEBUG TRAIN Batch 11/5200 loss 19.027357 loss_att 25.188400 loss_ctc 23.034271 loss_rnnt 17.100451 hw_loss 0.300830 lr 0.00050776 rank 1
2023-02-21 22:25:40,041 DEBUG TRAIN Batch 11/5300 loss 22.523676 loss_att 26.524849 loss_ctc 28.924055 loss_rnnt 20.677500 hw_loss 0.361044 lr 0.00050750 rank 4
2023-02-21 22:25:40,042 DEBUG TRAIN Batch 11/5300 loss 23.950413 loss_att 29.385595 loss_ctc 27.863327 loss_rnnt 22.269489 hw_loss 0.135306 lr 0.00050750 rank 2
2023-02-21 22:25:40,043 DEBUG TRAIN Batch 11/5300 loss 14.256425 loss_att 23.495626 loss_ctc 16.561424 loss_rnnt 11.966872 hw_loss 0.251961 lr 0.00050750 rank 3
2023-02-21 22:25:40,043 DEBUG TRAIN Batch 11/5300 loss 18.799639 loss_att 23.157795 loss_ctc 26.712425 loss_rnnt 16.657064 hw_loss 0.404823 lr 0.00050750 rank 0
2023-02-21 22:25:40,044 DEBUG TRAIN Batch 11/5300 loss 17.648420 loss_att 27.983318 loss_ctc 16.146515 loss_rnnt 15.639991 hw_loss 0.265694 lr 0.00050750 rank 6
2023-02-21 22:25:40,047 DEBUG TRAIN Batch 11/5300 loss 28.564787 loss_att 31.567873 loss_ctc 30.894194 loss_rnnt 27.507812 hw_loss 0.273312 lr 0.00050750 rank 5
2023-02-21 22:25:40,069 DEBUG TRAIN Batch 11/5300 loss 22.707432 loss_att 36.975796 loss_ctc 29.949408 loss_rnnt 18.658087 hw_loss 0.431389 lr 0.00050750 rank 1
2023-02-21 22:25:40,092 DEBUG TRAIN Batch 11/5300 loss 13.897162 loss_att 18.355593 loss_ctc 12.875419 loss_rnnt 13.029257 hw_loss 0.210847 lr 0.00050750 rank 7
2023-02-21 22:26:53,336 DEBUG TRAIN Batch 11/5400 loss 12.089461 loss_att 17.130329 loss_ctc 16.897041 loss_rnnt 10.326794 hw_loss 0.212780 lr 0.00050724 rank 2
2023-02-21 22:26:53,338 DEBUG TRAIN Batch 11/5400 loss 35.677280 loss_att 45.827385 loss_ctc 41.043633 loss_rnnt 32.846535 hw_loss 0.159772 lr 0.00050724 rank 7
2023-02-21 22:26:53,338 DEBUG TRAIN Batch 11/5400 loss 22.698635 loss_att 32.673584 loss_ctc 26.896519 loss_rnnt 19.918564 hw_loss 0.422561 lr 0.00050724 rank 3
2023-02-21 22:26:53,338 DEBUG TRAIN Batch 11/5400 loss 16.053566 loss_att 21.700220 loss_ctc 17.966078 loss_rnnt 14.521488 hw_loss 0.277022 lr 0.00050724 rank 4
2023-02-21 22:26:53,340 DEBUG TRAIN Batch 11/5400 loss 16.732557 loss_att 22.230017 loss_ctc 20.085865 loss_rnnt 15.030537 hw_loss 0.291412 lr 0.00050724 rank 6
2023-02-21 22:26:53,341 DEBUG TRAIN Batch 11/5400 loss 15.305525 loss_att 19.970097 loss_ctc 18.538082 loss_rnnt 13.842981 hw_loss 0.184914 lr 0.00050724 rank 5
2023-02-21 22:26:53,348 DEBUG TRAIN Batch 11/5400 loss 36.094261 loss_att 40.294632 loss_ctc 39.886425 loss_rnnt 34.591270 hw_loss 0.294937 lr 0.00050724 rank 1
2023-02-21 22:26:53,393 DEBUG TRAIN Batch 11/5400 loss 21.610384 loss_att 22.570301 loss_ctc 23.784142 loss_rnnt 20.942579 hw_loss 0.348725 lr 0.00050724 rank 0
2023-02-21 22:28:05,814 DEBUG TRAIN Batch 11/5500 loss 18.702297 loss_att 25.356232 loss_ctc 22.399044 loss_rnnt 16.795795 hw_loss 0.155279 lr 0.00050698 rank 1
2023-02-21 22:28:05,823 DEBUG TRAIN Batch 11/5500 loss 17.671358 loss_att 24.397186 loss_ctc 19.258692 loss_rnnt 15.966831 hw_loss 0.276973 lr 0.00050698 rank 3
2023-02-21 22:28:05,824 DEBUG TRAIN Batch 11/5500 loss 19.367996 loss_att 26.160604 loss_ctc 22.473141 loss_rnnt 17.405834 hw_loss 0.355537 lr 0.00050698 rank 2
2023-02-21 22:28:05,825 DEBUG TRAIN Batch 11/5500 loss 20.667250 loss_att 27.871885 loss_ctc 23.859550 loss_rnnt 18.618908 hw_loss 0.340830 lr 0.00050698 rank 5
2023-02-21 22:28:05,826 DEBUG TRAIN Batch 11/5500 loss 15.629229 loss_att 21.416414 loss_ctc 16.739395 loss_rnnt 14.173882 hw_loss 0.281039 lr 0.00050698 rank 6
2023-02-21 22:28:05,826 DEBUG TRAIN Batch 11/5500 loss 23.802954 loss_att 29.617298 loss_ctc 23.170393 loss_rnnt 22.582806 hw_loss 0.265541 lr 0.00050698 rank 7
2023-02-21 22:28:05,830 DEBUG TRAIN Batch 11/5500 loss 27.333147 loss_att 35.946629 loss_ctc 35.091408 loss_rnnt 24.370073 hw_loss 0.386143 lr 0.00050698 rank 4
2023-02-21 22:28:05,884 DEBUG TRAIN Batch 11/5500 loss 18.640404 loss_att 27.610939 loss_ctc 22.194708 loss_rnnt 16.280487 hw_loss 0.172314 lr 0.00050698 rank 0
2023-02-21 22:29:18,621 DEBUG TRAIN Batch 11/5600 loss 25.677776 loss_att 31.500116 loss_ctc 30.571583 loss_rnnt 23.749052 hw_loss 0.209532 lr 0.00050672 rank 2
2023-02-21 22:29:18,625 DEBUG TRAIN Batch 11/5600 loss 14.468691 loss_att 24.808786 loss_ctc 16.089060 loss_rnnt 12.063528 hw_loss 0.227052 lr 0.00050672 rank 3
2023-02-21 22:29:18,626 DEBUG TRAIN Batch 11/5600 loss 18.685255 loss_att 20.941628 loss_ctc 21.937693 loss_rnnt 17.651997 hw_loss 0.278112 lr 0.00050672 rank 7
2023-02-21 22:29:18,625 DEBUG TRAIN Batch 11/5600 loss 31.031956 loss_att 38.082401 loss_ctc 40.769363 loss_rnnt 28.213154 hw_loss 0.206982 lr 0.00050672 rank 5
2023-02-21 22:29:18,628 DEBUG TRAIN Batch 11/5600 loss 16.776176 loss_att 20.877172 loss_ctc 20.716534 loss_rnnt 15.259654 hw_loss 0.320514 lr 0.00050672 rank 6
2023-02-21 22:29:18,630 DEBUG TRAIN Batch 11/5600 loss 23.115749 loss_att 25.616283 loss_ctc 26.306522 loss_rnnt 22.082905 hw_loss 0.201186 lr 0.00050672 rank 0
2023-02-21 22:29:18,653 DEBUG TRAIN Batch 11/5600 loss 19.067972 loss_att 29.960766 loss_ctc 18.958292 loss_rnnt 16.722477 hw_loss 0.340426 lr 0.00050672 rank 4
2023-02-21 22:29:18,679 DEBUG TRAIN Batch 11/5600 loss 25.689161 loss_att 31.471523 loss_ctc 33.071831 loss_rnnt 23.386751 hw_loss 0.302967 lr 0.00050672 rank 1
2023-02-21 22:30:33,846 DEBUG TRAIN Batch 11/5700 loss 11.769420 loss_att 14.590184 loss_ctc 14.241632 loss_rnnt 10.689119 hw_loss 0.349723 lr 0.00050646 rank 2
2023-02-21 22:30:33,851 DEBUG TRAIN Batch 11/5700 loss 17.411425 loss_att 20.489552 loss_ctc 19.128189 loss_rnnt 16.362152 hw_loss 0.383895 lr 0.00050646 rank 4
2023-02-21 22:30:33,852 DEBUG TRAIN Batch 11/5700 loss 14.528077 loss_att 23.450396 loss_ctc 18.694775 loss_rnnt 12.118538 hw_loss 0.130341 lr 0.00050646 rank 7
2023-02-21 22:30:33,855 DEBUG TRAIN Batch 11/5700 loss 19.293762 loss_att 19.769115 loss_ctc 25.291008 loss_rnnt 18.242193 hw_loss 0.294123 lr 0.00050646 rank 5
2023-02-21 22:30:33,857 DEBUG TRAIN Batch 11/5700 loss 12.192306 loss_att 18.228598 loss_ctc 15.521616 loss_rnnt 10.445194 hw_loss 0.179900 lr 0.00050646 rank 6
2023-02-21 22:30:33,858 DEBUG TRAIN Batch 11/5700 loss 22.908081 loss_att 28.675678 loss_ctc 23.668562 loss_rnnt 21.536514 hw_loss 0.218721 lr 0.00050646 rank 0
2023-02-21 22:30:33,859 DEBUG TRAIN Batch 11/5700 loss 32.522785 loss_att 33.874081 loss_ctc 38.857285 loss_rnnt 31.226095 hw_loss 0.340926 lr 0.00050646 rank 3
2023-02-21 22:30:33,860 DEBUG TRAIN Batch 11/5700 loss 19.894423 loss_att 21.785242 loss_ctc 22.476820 loss_rnnt 19.060875 hw_loss 0.208245 lr 0.00050646 rank 1
2023-02-21 22:31:46,503 DEBUG TRAIN Batch 11/5800 loss 7.669011 loss_att 10.159746 loss_ctc 3.834209 loss_rnnt 7.534951 hw_loss 0.276035 lr 0.00050620 rank 2
2023-02-21 22:31:46,504 DEBUG TRAIN Batch 11/5800 loss 17.883547 loss_att 19.898800 loss_ctc 19.263643 loss_rnnt 17.066334 hw_loss 0.431535 lr 0.00050620 rank 4
2023-02-21 22:31:46,504 DEBUG TRAIN Batch 11/5800 loss 16.888844 loss_att 17.012444 loss_ctc 19.472260 loss_rnnt 16.225697 hw_loss 0.551196 lr 0.00050620 rank 3
2023-02-21 22:31:46,509 DEBUG TRAIN Batch 11/5800 loss 12.077221 loss_att 18.896576 loss_ctc 13.689909 loss_rnnt 10.264294 hw_loss 0.438809 lr 0.00050620 rank 7
2023-02-21 22:31:46,511 DEBUG TRAIN Batch 11/5800 loss 14.359777 loss_att 23.278587 loss_ctc 19.763847 loss_rnnt 11.754789 hw_loss 0.188783 lr 0.00050620 rank 6
2023-02-21 22:31:46,512 DEBUG TRAIN Batch 11/5800 loss 33.218464 loss_att 30.158072 loss_ctc 38.219566 loss_rnnt 33.065605 hw_loss 0.183978 lr 0.00050620 rank 5
2023-02-21 22:31:46,513 DEBUG TRAIN Batch 11/5800 loss 28.688944 loss_att 34.103455 loss_ctc 30.018963 loss_rnnt 27.364157 hw_loss 0.121033 lr 0.00050620 rank 0
2023-02-21 22:31:46,559 DEBUG TRAIN Batch 11/5800 loss 18.702766 loss_att 22.011993 loss_ctc 21.100351 loss_rnnt 17.516544 hw_loss 0.383809 lr 0.00050620 rank 1
2023-02-21 22:32:58,495 DEBUG TRAIN Batch 11/5900 loss 9.318879 loss_att 11.742638 loss_ctc 7.909703 loss_rnnt 8.882172 hw_loss 0.262210 lr 0.00050594 rank 2
2023-02-21 22:32:58,502 DEBUG TRAIN Batch 11/5900 loss 16.268366 loss_att 30.552204 loss_ctc 18.946960 loss_rnnt 12.844668 hw_loss 0.393344 lr 0.00050594 rank 3
2023-02-21 22:32:58,503 DEBUG TRAIN Batch 11/5900 loss 22.655291 loss_att 29.061850 loss_ctc 25.746368 loss_rnnt 20.861143 hw_loss 0.188800 lr 0.00050594 rank 6
2023-02-21 22:32:58,505 DEBUG TRAIN Batch 11/5900 loss 17.798815 loss_att 24.813469 loss_ctc 19.714277 loss_rnnt 16.012676 hw_loss 0.239649 lr 0.00050594 rank 4
2023-02-21 22:32:58,505 DEBUG TRAIN Batch 11/5900 loss 16.244785 loss_att 26.729435 loss_ctc 16.214497 loss_rnnt 14.031437 hw_loss 0.225859 lr 0.00050594 rank 5
2023-02-21 22:32:58,505 DEBUG TRAIN Batch 11/5900 loss 5.161984 loss_att 10.704796 loss_ctc 5.679363 loss_rnnt 3.866764 hw_loss 0.220640 lr 0.00050594 rank 1
2023-02-21 22:32:58,506 DEBUG TRAIN Batch 11/5900 loss 19.706305 loss_att 30.120247 loss_ctc 20.392200 loss_rnnt 17.450312 hw_loss 0.153286 lr 0.00050594 rank 7
2023-02-21 22:32:58,509 DEBUG TRAIN Batch 11/5900 loss 19.626369 loss_att 29.856241 loss_ctc 24.072226 loss_rnnt 16.862242 hw_loss 0.235073 lr 0.00050594 rank 0
2023-02-21 22:34:12,736 DEBUG TRAIN Batch 11/6000 loss 20.641260 loss_att 32.816696 loss_ctc 25.323387 loss_rnnt 17.452820 hw_loss 0.242005 lr 0.00050568 rank 7
2023-02-21 22:34:12,745 DEBUG TRAIN Batch 11/6000 loss 26.253374 loss_att 35.329441 loss_ctc 30.056190 loss_rnnt 23.773674 hw_loss 0.295206 lr 0.00050568 rank 4
2023-02-21 22:34:12,749 DEBUG TRAIN Batch 11/6000 loss 23.025444 loss_att 29.051128 loss_ctc 24.839506 loss_rnnt 21.430578 hw_loss 0.277222 lr 0.00050568 rank 0
2023-02-21 22:34:12,749 DEBUG TRAIN Batch 11/6000 loss 17.520224 loss_att 20.289236 loss_ctc 17.775473 loss_rnnt 16.810867 hw_loss 0.227852 lr 0.00050568 rank 2
2023-02-21 22:34:12,750 DEBUG TRAIN Batch 11/6000 loss 32.764568 loss_att 33.922173 loss_ctc 34.758587 loss_rnnt 32.136005 hw_loss 0.245943 lr 0.00050568 rank 3
2023-02-21 22:34:12,751 DEBUG TRAIN Batch 11/6000 loss 9.608019 loss_att 17.274826 loss_ctc 8.779897 loss_rnnt 8.047648 hw_loss 0.257672 lr 0.00050568 rank 6
2023-02-21 22:34:12,764 DEBUG TRAIN Batch 11/6000 loss 17.337158 loss_att 27.211548 loss_ctc 21.685547 loss_rnnt 14.706705 hw_loss 0.142107 lr 0.00050568 rank 1
2023-02-21 22:34:12,796 DEBUG TRAIN Batch 11/6000 loss 6.967822 loss_att 12.449686 loss_ctc 9.008357 loss_rnnt 5.451786 hw_loss 0.276735 lr 0.00050568 rank 5
2023-02-21 22:35:26,014 DEBUG TRAIN Batch 11/6100 loss 23.684200 loss_att 30.272291 loss_ctc 33.535004 loss_rnnt 20.863632 hw_loss 0.355329 lr 0.00050542 rank 2
2023-02-21 22:35:26,016 DEBUG TRAIN Batch 11/6100 loss 11.682210 loss_att 19.202271 loss_ctc 14.273427 loss_rnnt 9.687138 hw_loss 0.272934 lr 0.00050542 rank 3
2023-02-21 22:35:26,018 DEBUG TRAIN Batch 11/6100 loss 22.313782 loss_att 31.737675 loss_ctc 23.902298 loss_rnnt 20.021505 hw_loss 0.366926 lr 0.00050542 rank 6
2023-02-21 22:35:26,018 DEBUG TRAIN Batch 11/6100 loss 12.447102 loss_att 15.830281 loss_ctc 15.795736 loss_rnnt 11.221240 hw_loss 0.192639 lr 0.00050542 rank 0
2023-02-21 22:35:26,023 DEBUG TRAIN Batch 11/6100 loss 28.015123 loss_att 31.656185 loss_ctc 36.216385 loss_rnnt 26.099245 hw_loss 0.176553 lr 0.00050542 rank 1
2023-02-21 22:35:26,023 DEBUG TRAIN Batch 11/6100 loss 25.230850 loss_att 34.371326 loss_ctc 34.494972 loss_rnnt 22.049231 hw_loss 0.221830 lr 0.00050542 rank 7
2023-02-21 22:35:26,023 DEBUG TRAIN Batch 11/6100 loss 16.325415 loss_att 23.499212 loss_ctc 17.273142 loss_rnnt 14.578121 hw_loss 0.349067 lr 0.00050542 rank 5
2023-02-21 22:35:26,071 DEBUG TRAIN Batch 11/6100 loss 9.439391 loss_att 17.266644 loss_ctc 12.449764 loss_rnnt 7.350059 hw_loss 0.229685 lr 0.00050542 rank 4
2023-02-21 22:36:37,892 DEBUG TRAIN Batch 11/6200 loss 17.838692 loss_att 27.436186 loss_ctc 21.927263 loss_rnnt 15.289711 hw_loss 0.158140 lr 0.00050517 rank 3
2023-02-21 22:36:37,905 DEBUG TRAIN Batch 11/6200 loss 20.251289 loss_att 24.244587 loss_ctc 27.111948 loss_rnnt 18.432423 hw_loss 0.197724 lr 0.00050517 rank 0
2023-02-21 22:36:37,906 DEBUG TRAIN Batch 11/6200 loss 24.842356 loss_att 28.116795 loss_ctc 28.513977 loss_rnnt 23.561104 hw_loss 0.256525 lr 0.00050517 rank 4
2023-02-21 22:36:37,906 DEBUG TRAIN Batch 11/6200 loss 17.939322 loss_att 22.936605 loss_ctc 25.717598 loss_rnnt 15.759800 hw_loss 0.268051 lr 0.00050517 rank 7
2023-02-21 22:36:37,907 DEBUG TRAIN Batch 11/6200 loss 25.533138 loss_att 28.876537 loss_ctc 26.203575 loss_rnnt 24.695627 hw_loss 0.148943 lr 0.00050517 rank 1
2023-02-21 22:36:37,908 DEBUG TRAIN Batch 11/6200 loss 15.511376 loss_att 15.893835 loss_ctc 18.829128 loss_rnnt 14.882678 hw_loss 0.205951 lr 0.00050517 rank 2
2023-02-21 22:36:37,909 DEBUG TRAIN Batch 11/6200 loss 23.960098 loss_att 27.189032 loss_ctc 27.511663 loss_rnnt 22.669207 hw_loss 0.321682 lr 0.00050517 rank 6
2023-02-21 22:36:37,914 DEBUG TRAIN Batch 11/6200 loss 22.729374 loss_att 22.890518 loss_ctc 23.537355 loss_rnnt 22.441010 hw_loss 0.278260 lr 0.00050517 rank 5
2023-02-21 22:37:50,620 DEBUG TRAIN Batch 11/6300 loss 12.371357 loss_att 17.046604 loss_ctc 13.980421 loss_rnnt 11.032601 hw_loss 0.354684 lr 0.00050491 rank 4
2023-02-21 22:37:50,622 DEBUG TRAIN Batch 11/6300 loss 24.424446 loss_att 26.323048 loss_ctc 28.955107 loss_rnnt 23.284550 hw_loss 0.292659 lr 0.00050491 rank 2
2023-02-21 22:37:50,625 DEBUG TRAIN Batch 11/6300 loss 38.664989 loss_att 45.312962 loss_ctc 43.779846 loss_rnnt 36.455322 hw_loss 0.371414 lr 0.00050491 rank 3
2023-02-21 22:37:50,627 DEBUG TRAIN Batch 11/6300 loss 26.929422 loss_att 41.756374 loss_ctc 23.839560 loss_rnnt 24.248243 hw_loss 0.239571 lr 0.00050491 rank 6
2023-02-21 22:37:50,631 DEBUG TRAIN Batch 11/6300 loss 22.409576 loss_att 24.745052 loss_ctc 27.815516 loss_rnnt 21.043091 hw_loss 0.334873 lr 0.00050491 rank 5
2023-02-21 22:37:50,632 DEBUG TRAIN Batch 11/6300 loss 17.719864 loss_att 18.698404 loss_ctc 21.329193 loss_rnnt 16.826330 hw_loss 0.406096 lr 0.00050491 rank 7
2023-02-21 22:37:50,676 DEBUG TRAIN Batch 11/6300 loss 22.641401 loss_att 30.350039 loss_ctc 31.016815 loss_rnnt 19.889046 hw_loss 0.176077 lr 0.00050491 rank 1
2023-02-21 22:37:50,683 DEBUG TRAIN Batch 11/6300 loss 20.008583 loss_att 24.952667 loss_ctc 25.227230 loss_rnnt 18.118895 hw_loss 0.384475 lr 0.00050491 rank 0
2023-02-21 22:39:05,349 DEBUG TRAIN Batch 11/6400 loss 14.708270 loss_att 15.301521 loss_ctc 17.819563 loss_rnnt 14.007572 hw_loss 0.313515 lr 0.00050465 rank 3
2023-02-21 22:39:05,352 DEBUG TRAIN Batch 11/6400 loss 40.294735 loss_att 45.743759 loss_ctc 55.360985 loss_rnnt 37.098331 hw_loss 0.183302 lr 0.00050465 rank 2
2023-02-21 22:39:05,354 DEBUG TRAIN Batch 11/6400 loss 15.242806 loss_att 16.941097 loss_ctc 19.890991 loss_rnnt 14.061224 hw_loss 0.416563 lr 0.00050465 rank 0
2023-02-21 22:39:05,357 DEBUG TRAIN Batch 11/6400 loss 6.291019 loss_att 8.174608 loss_ctc 8.395348 loss_rnnt 5.375590 hw_loss 0.484001 lr 0.00050465 rank 1
2023-02-21 22:39:05,358 DEBUG TRAIN Batch 11/6400 loss 14.744474 loss_att 22.538067 loss_ctc 16.604012 loss_rnnt 12.864463 hw_loss 0.137539 lr 0.00050465 rank 5
2023-02-21 22:39:05,359 DEBUG TRAIN Batch 11/6400 loss 17.618780 loss_att 16.585724 loss_ctc 20.150291 loss_rnnt 17.159637 hw_loss 0.615412 lr 0.00050465 rank 4
2023-02-21 22:39:05,362 DEBUG TRAIN Batch 11/6400 loss 13.521478 loss_att 18.415499 loss_ctc 19.776096 loss_rnnt 11.614981 hw_loss 0.175769 lr 0.00050465 rank 6
2023-02-21 22:39:05,402 DEBUG TRAIN Batch 11/6400 loss 31.247236 loss_att 39.230865 loss_ctc 37.121887 loss_rnnt 28.700338 hw_loss 0.312912 lr 0.00050465 rank 7
2023-02-21 22:40:18,232 DEBUG TRAIN Batch 11/6500 loss 23.951771 loss_att 27.739815 loss_ctc 30.716114 loss_rnnt 22.173893 hw_loss 0.221913 lr 0.00050439 rank 2
2023-02-21 22:40:18,237 DEBUG TRAIN Batch 11/6500 loss 13.449154 loss_att 19.810352 loss_ctc 16.112646 loss_rnnt 11.617735 hw_loss 0.382590 lr 0.00050439 rank 3
2023-02-21 22:40:18,238 DEBUG TRAIN Batch 11/6500 loss 8.079603 loss_att 14.462341 loss_ctc 8.646564 loss_rnnt 6.589578 hw_loss 0.258530 lr 0.00050439 rank 7
2023-02-21 22:40:18,238 DEBUG TRAIN Batch 11/6500 loss 20.004513 loss_att 25.352665 loss_ctc 18.613419 loss_rnnt 19.034683 hw_loss 0.160648 lr 0.00050439 rank 6
2023-02-21 22:40:18,240 DEBUG TRAIN Batch 11/6500 loss 24.476749 loss_att 27.158993 loss_ctc 25.781363 loss_rnnt 23.580235 hw_loss 0.348968 lr 0.00050439 rank 4
2023-02-21 22:40:18,242 DEBUG TRAIN Batch 11/6500 loss 17.815441 loss_att 22.072811 loss_ctc 19.842451 loss_rnnt 16.545383 hw_loss 0.278090 lr 0.00050439 rank 0
2023-02-21 22:40:18,242 DEBUG TRAIN Batch 11/6500 loss 9.135715 loss_att 13.858801 loss_ctc 8.817373 loss_rnnt 8.060270 hw_loss 0.324888 lr 0.00050439 rank 1
2023-02-21 22:40:18,247 DEBUG TRAIN Batch 11/6500 loss 18.124437 loss_att 28.798164 loss_ctc 27.313366 loss_rnnt 14.663783 hw_loss 0.188846 lr 0.00050439 rank 5
2023-02-21 22:41:30,298 DEBUG TRAIN Batch 11/6600 loss 27.507084 loss_att 30.115475 loss_ctc 30.401117 loss_rnnt 26.509350 hw_loss 0.169097 lr 0.00050414 rank 6
2023-02-21 22:41:30,299 DEBUG TRAIN Batch 11/6600 loss 14.992802 loss_att 15.199614 loss_ctc 16.122297 loss_rnnt 14.697754 hw_loss 0.193287 lr 0.00050414 rank 2
2023-02-21 22:41:30,300 DEBUG TRAIN Batch 11/6600 loss 7.391945 loss_att 11.821860 loss_ctc 8.014774 loss_rnnt 6.257359 hw_loss 0.310424 lr 0.00050414 rank 3
2023-02-21 22:41:30,302 DEBUG TRAIN Batch 11/6600 loss 13.308229 loss_att 18.053432 loss_ctc 15.477980 loss_rnnt 11.987797 hw_loss 0.153922 lr 0.00050414 rank 0
2023-02-21 22:41:30,303 DEBUG TRAIN Batch 11/6600 loss 28.322386 loss_att 38.266449 loss_ctc 35.016109 loss_rnnt 25.339376 hw_loss 0.190688 lr 0.00050414 rank 1
2023-02-21 22:41:30,303 DEBUG TRAIN Batch 11/6600 loss 15.114350 loss_att 21.068745 loss_ctc 14.593205 loss_rnnt 13.859111 hw_loss 0.250964 lr 0.00050414 rank 7
2023-02-21 22:41:30,305 DEBUG TRAIN Batch 11/6600 loss 8.073503 loss_att 14.017013 loss_ctc 12.328784 loss_rnnt 6.193567 hw_loss 0.232244 lr 0.00050414 rank 4
2023-02-21 22:41:30,307 DEBUG TRAIN Batch 11/6600 loss 15.674782 loss_att 24.525553 loss_ctc 20.005650 loss_rnnt 13.167036 hw_loss 0.300268 lr 0.00050414 rank 5
2023-02-21 22:42:43,693 DEBUG TRAIN Batch 11/6700 loss 20.447617 loss_att 28.938442 loss_ctc 24.543291 loss_rnnt 18.070091 hw_loss 0.249881 lr 0.00050388 rank 7
2023-02-21 22:42:43,693 DEBUG TRAIN Batch 11/6700 loss 17.420425 loss_att 21.371893 loss_ctc 19.686426 loss_rnnt 16.265156 hw_loss 0.117834 lr 0.00050388 rank 1
2023-02-21 22:42:43,703 DEBUG TRAIN Batch 11/6700 loss 22.735065 loss_att 29.642101 loss_ctc 28.080715 loss_rnnt 20.429684 hw_loss 0.396035 lr 0.00050388 rank 2
2023-02-21 22:42:43,705 DEBUG TRAIN Batch 11/6700 loss 19.120571 loss_att 30.244038 loss_ctc 22.180281 loss_rnnt 16.328176 hw_loss 0.299513 lr 0.00050388 rank 6
2023-02-21 22:42:43,707 DEBUG TRAIN Batch 11/6700 loss 9.494002 loss_att 13.669558 loss_ctc 8.233404 loss_rnnt 8.632187 hw_loss 0.365221 lr 0.00050388 rank 3
2023-02-21 22:42:43,711 DEBUG TRAIN Batch 11/6700 loss 24.749680 loss_att 29.655090 loss_ctc 34.812569 loss_rnnt 22.340466 hw_loss 0.162031 lr 0.00050388 rank 4
2023-02-21 22:42:43,712 DEBUG TRAIN Batch 11/6700 loss 27.233425 loss_att 35.858810 loss_ctc 30.627232 loss_rnnt 24.889166 hw_loss 0.312516 lr 0.00050388 rank 0
2023-02-21 22:42:43,759 DEBUG TRAIN Batch 11/6700 loss 23.969627 loss_att 29.737373 loss_ctc 28.038378 loss_rnnt 22.184935 hw_loss 0.166209 lr 0.00050388 rank 5
2023-02-21 22:43:58,417 DEBUG TRAIN Batch 11/6800 loss 17.574776 loss_att 27.813160 loss_ctc 18.230188 loss_rnnt 15.334292 hw_loss 0.197659 lr 0.00050363 rank 3
2023-02-21 22:43:58,419 DEBUG TRAIN Batch 11/6800 loss 22.989693 loss_att 24.651184 loss_ctc 27.847576 loss_rnnt 21.900822 hw_loss 0.204103 lr 0.00050363 rank 7
2023-02-21 22:43:58,420 DEBUG TRAIN Batch 11/6800 loss 13.901016 loss_att 17.004097 loss_ctc 16.248537 loss_rnnt 12.885120 hw_loss 0.154269 lr 0.00050363 rank 2
2023-02-21 22:43:58,423 DEBUG TRAIN Batch 11/6800 loss 14.769740 loss_att 18.595211 loss_ctc 17.318050 loss_rnnt 13.533014 hw_loss 0.247231 lr 0.00050363 rank 6
2023-02-21 22:43:58,427 DEBUG TRAIN Batch 11/6800 loss 13.340523 loss_att 17.350330 loss_ctc 14.579326 loss_rnnt 12.286257 hw_loss 0.163370 lr 0.00050363 rank 1
2023-02-21 22:43:58,428 DEBUG TRAIN Batch 11/6800 loss 19.755402 loss_att 28.114611 loss_ctc 28.461224 loss_rnnt 16.825006 hw_loss 0.183330 lr 0.00050363 rank 0
2023-02-21 22:43:58,427 DEBUG TRAIN Batch 11/6800 loss 15.451978 loss_att 22.574320 loss_ctc 23.894247 loss_rnnt 12.752674 hw_loss 0.279748 lr 0.00050363 rank 5
2023-02-21 22:43:58,471 DEBUG TRAIN Batch 11/6800 loss 16.984861 loss_att 20.155008 loss_ctc 21.819553 loss_rnnt 15.583816 hw_loss 0.229482 lr 0.00050363 rank 4
2023-02-21 22:45:11,594 DEBUG TRAIN Batch 11/6900 loss 10.283727 loss_att 12.846458 loss_ctc 14.584909 loss_rnnt 9.106216 hw_loss 0.171512 lr 0.00050337 rank 2
2023-02-21 22:45:11,595 DEBUG TRAIN Batch 11/6900 loss 15.164485 loss_att 18.457321 loss_ctc 20.242352 loss_rnnt 13.599287 hw_loss 0.430468 lr 0.00050337 rank 6
2023-02-21 22:45:11,600 DEBUG TRAIN Batch 11/6900 loss 10.527822 loss_att 12.465515 loss_ctc 12.207400 loss_rnnt 9.736536 hw_loss 0.337133 lr 0.00050337 rank 5
2023-02-21 22:45:11,601 DEBUG TRAIN Batch 11/6900 loss 18.126228 loss_att 25.855556 loss_ctc 24.667839 loss_rnnt 15.545934 hw_loss 0.304149 lr 0.00050337 rank 1
2023-02-21 22:45:11,603 DEBUG TRAIN Batch 11/6900 loss 17.244896 loss_att 20.678436 loss_ctc 19.396660 loss_rnnt 16.156483 hw_loss 0.215255 lr 0.00050337 rank 0
2023-02-21 22:45:11,602 DEBUG TRAIN Batch 11/6900 loss 11.949345 loss_att 14.836893 loss_ctc 14.415178 loss_rnnt 10.865636 hw_loss 0.332666 lr 0.00050337 rank 3
2023-02-21 22:45:11,603 DEBUG TRAIN Batch 11/6900 loss 17.653439 loss_att 18.547331 loss_ctc 20.353613 loss_rnnt 16.966862 hw_loss 0.277080 lr 0.00050337 rank 7
2023-02-21 22:45:11,644 DEBUG TRAIN Batch 11/6900 loss 16.069986 loss_att 18.502008 loss_ctc 20.541756 loss_rnnt 14.894786 hw_loss 0.173552 lr 0.00050337 rank 4
2023-02-21 22:46:23,634 DEBUG TRAIN Batch 11/7000 loss 10.832067 loss_att 12.552437 loss_ctc 13.740652 loss_rnnt 9.853783 hw_loss 0.461998 lr 0.00050312 rank 2
2023-02-21 22:46:23,640 DEBUG TRAIN Batch 11/7000 loss 12.495356 loss_att 14.144375 loss_ctc 12.233925 loss_rnnt 12.067365 hw_loss 0.249458 lr 0.00050312 rank 3
2023-02-21 22:46:23,641 DEBUG TRAIN Batch 11/7000 loss 40.497410 loss_att 45.604317 loss_ctc 39.944759 loss_rnnt 39.459339 hw_loss 0.169447 lr 0.00050312 rank 6
2023-02-21 22:46:23,643 DEBUG TRAIN Batch 11/7000 loss 16.843885 loss_att 21.044582 loss_ctc 17.603054 loss_rnnt 15.752131 hw_loss 0.281989 lr 0.00050312 rank 7
2023-02-21 22:46:23,645 DEBUG TRAIN Batch 11/7000 loss 16.523151 loss_att 19.646107 loss_ctc 19.262363 loss_rnnt 15.320240 hw_loss 0.399547 lr 0.00050312 rank 1
2023-02-21 22:46:23,646 DEBUG TRAIN Batch 11/7000 loss 14.803719 loss_att 20.057331 loss_ctc 18.754475 loss_rnnt 13.093184 hw_loss 0.249458 lr 0.00050312 rank 5
2023-02-21 22:46:23,652 DEBUG TRAIN Batch 11/7000 loss 13.606198 loss_att 16.060070 loss_ctc 15.021524 loss_rnnt 12.675455 hw_loss 0.471107 lr 0.00050312 rank 0
2023-02-21 22:46:23,693 DEBUG TRAIN Batch 11/7000 loss 14.185965 loss_att 16.410852 loss_ctc 16.629257 loss_rnnt 13.229838 hw_loss 0.347581 lr 0.00050312 rank 4
2023-02-21 22:47:38,197 DEBUG TRAIN Batch 11/7100 loss 21.977211 loss_att 27.297760 loss_ctc 27.863066 loss_rnnt 19.982088 hw_loss 0.274187 lr 0.00050286 rank 6
2023-02-21 22:47:38,207 DEBUG TRAIN Batch 11/7100 loss 22.416716 loss_att 28.359116 loss_ctc 28.612675 loss_rnnt 20.319963 hw_loss 0.154019 lr 0.00050286 rank 0
2023-02-21 22:47:38,208 DEBUG TRAIN Batch 11/7100 loss 16.370630 loss_att 19.197378 loss_ctc 15.429411 loss_rnnt 15.814548 hw_loss 0.217931 lr 0.00050286 rank 2
2023-02-21 22:47:38,211 DEBUG TRAIN Batch 11/7100 loss 15.301676 loss_att 24.150890 loss_ctc 17.328552 loss_rnnt 13.080317 hw_loss 0.339872 lr 0.00050286 rank 4
2023-02-21 22:47:38,212 DEBUG TRAIN Batch 11/7100 loss 28.976185 loss_att 35.675602 loss_ctc 30.875822 loss_rnnt 27.286926 hw_loss 0.180166 lr 0.00050286 rank 3
2023-02-21 22:47:38,213 DEBUG TRAIN Batch 11/7100 loss 17.357033 loss_att 27.885763 loss_ctc 23.051525 loss_rnnt 14.427851 hw_loss 0.120317 lr 0.00050286 rank 5
2023-02-21 22:47:38,215 DEBUG TRAIN Batch 11/7100 loss 30.585245 loss_att 45.036766 loss_ctc 29.777336 loss_rnnt 27.633680 hw_loss 0.316842 lr 0.00050286 rank 1
2023-02-21 22:47:38,216 DEBUG TRAIN Batch 11/7100 loss 36.388157 loss_att 46.033466 loss_ctc 39.329880 loss_rnnt 34.011642 hw_loss 0.103537 lr 0.00050286 rank 7
2023-02-21 22:48:51,370 DEBUG TRAIN Batch 11/7200 loss 18.550297 loss_att 26.967169 loss_ctc 16.036770 loss_rnnt 17.078321 hw_loss 0.232011 lr 0.00050261 rank 3
2023-02-21 22:48:51,382 DEBUG TRAIN Batch 11/7200 loss 11.087556 loss_att 20.958462 loss_ctc 9.779513 loss_rnnt 9.164623 hw_loss 0.230918 lr 0.00050261 rank 2
2023-02-21 22:48:51,382 DEBUG TRAIN Batch 11/7200 loss 13.065619 loss_att 19.058689 loss_ctc 14.117401 loss_rnnt 11.658131 hw_loss 0.128693 lr 0.00050261 rank 1
2023-02-21 22:48:51,385 DEBUG TRAIN Batch 11/7200 loss 22.577297 loss_att 29.942600 loss_ctc 26.484806 loss_rnnt 20.509920 hw_loss 0.137461 lr 0.00050261 rank 6
2023-02-21 22:48:51,385 DEBUG TRAIN Batch 11/7200 loss 30.912554 loss_att 40.820953 loss_ctc 42.729584 loss_rnnt 27.257851 hw_loss 0.182661 lr 0.00050261 rank 7
2023-02-21 22:48:51,386 DEBUG TRAIN Batch 11/7200 loss 5.562834 loss_att 11.548483 loss_ctc 8.605877 loss_rnnt 3.763340 hw_loss 0.368672 lr 0.00050261 rank 0
2023-02-21 22:48:51,394 DEBUG TRAIN Batch 11/7200 loss 20.444330 loss_att 21.680115 loss_ctc 23.621288 loss_rnnt 19.676960 hw_loss 0.181159 lr 0.00050261 rank 5
2023-02-21 22:48:51,433 DEBUG TRAIN Batch 11/7200 loss 23.977243 loss_att 30.148022 loss_ctc 25.189009 loss_rnnt 22.321196 hw_loss 0.488109 lr 0.00050261 rank 4
2023-02-21 22:50:04,255 DEBUG TRAIN Batch 11/7300 loss 15.044211 loss_att 20.923054 loss_ctc 16.757574 loss_rnnt 13.520904 hw_loss 0.223295 lr 0.00050235 rank 3
2023-02-21 22:50:04,257 DEBUG TRAIN Batch 11/7300 loss 18.743885 loss_att 22.730015 loss_ctc 21.910023 loss_rnnt 17.338396 hw_loss 0.348960 lr 0.00050235 rank 2
2023-02-21 22:50:04,261 DEBUG TRAIN Batch 11/7300 loss 16.721632 loss_att 21.426022 loss_ctc 17.655748 loss_rnnt 15.454067 hw_loss 0.379007 lr 0.00050235 rank 5
2023-02-21 22:50:04,262 DEBUG TRAIN Batch 11/7300 loss 15.440476 loss_att 22.354172 loss_ctc 15.435780 loss_rnnt 13.959193 hw_loss 0.185946 lr 0.00050235 rank 7
2023-02-21 22:50:04,263 DEBUG TRAIN Batch 11/7300 loss 13.782665 loss_att 18.491169 loss_ctc 16.847044 loss_rnnt 12.313887 hw_loss 0.222177 lr 0.00050235 rank 4
2023-02-21 22:50:04,264 DEBUG TRAIN Batch 11/7300 loss 28.431778 loss_att 30.613522 loss_ctc 33.724781 loss_rnnt 27.086239 hw_loss 0.381478 lr 0.00050235 rank 0
2023-02-21 22:50:04,266 DEBUG TRAIN Batch 11/7300 loss 13.957289 loss_att 18.155689 loss_ctc 18.504627 loss_rnnt 12.360337 hw_loss 0.283048 lr 0.00050235 rank 6
2023-02-21 22:50:04,267 DEBUG TRAIN Batch 11/7300 loss 8.829247 loss_att 16.869774 loss_ctc 11.643698 loss_rnnt 6.759218 hw_loss 0.162495 lr 0.00050235 rank 1
2023-02-21 22:51:17,527 DEBUG TRAIN Batch 11/7400 loss 14.234344 loss_att 21.021646 loss_ctc 16.204361 loss_rnnt 12.524618 hw_loss 0.167993 lr 0.00050210 rank 0
2023-02-21 22:51:17,538 DEBUG TRAIN Batch 11/7400 loss 14.043405 loss_att 19.916351 loss_ctc 15.137639 loss_rnnt 12.517679 hw_loss 0.384821 lr 0.00050210 rank 2
2023-02-21 22:51:17,540 DEBUG TRAIN Batch 11/7400 loss 30.721254 loss_att 31.590092 loss_ctc 34.101616 loss_rnnt 29.866268 hw_loss 0.432195 lr 0.00050210 rank 6
2023-02-21 22:51:17,545 DEBUG TRAIN Batch 11/7400 loss 19.871756 loss_att 21.814304 loss_ctc 22.432762 loss_rnnt 19.077593 hw_loss 0.120344 lr 0.00050210 rank 3
2023-02-21 22:51:17,547 DEBUG TRAIN Batch 11/7400 loss 19.408772 loss_att 24.594753 loss_ctc 21.742569 loss_rnnt 17.905704 hw_loss 0.290057 lr 0.00050210 rank 7
2023-02-21 22:51:17,547 DEBUG TRAIN Batch 11/7400 loss 11.977155 loss_att 14.587933 loss_ctc 12.989405 loss_rnnt 11.178673 hw_loss 0.265048 lr 0.00050210 rank 1
2023-02-21 22:51:17,556 DEBUG TRAIN Batch 11/7400 loss 16.756798 loss_att 24.488850 loss_ctc 20.447504 loss_rnnt 14.530148 hw_loss 0.352776 lr 0.00050210 rank 4
2023-02-21 22:51:17,568 DEBUG TRAIN Batch 11/7400 loss 23.655800 loss_att 28.227221 loss_ctc 27.511051 loss_rnnt 22.062786 hw_loss 0.308811 lr 0.00050210 rank 5
2023-02-21 22:52:32,025 DEBUG TRAIN Batch 11/7500 loss 8.106138 loss_att 13.868750 loss_ctc 10.407202 loss_rnnt 6.471784 hw_loss 0.328169 lr 0.00050185 rank 5
2023-02-21 22:52:32,027 DEBUG TRAIN Batch 11/7500 loss 15.106054 loss_att 22.628599 loss_ctc 14.775066 loss_rnnt 13.534156 hw_loss 0.209104 lr 0.00050185 rank 3
2023-02-21 22:52:32,031 DEBUG TRAIN Batch 11/7500 loss 26.526518 loss_att 29.465326 loss_ctc 34.333130 loss_rnnt 24.695724 hw_loss 0.379028 lr 0.00050185 rank 2
2023-02-21 22:52:32,034 DEBUG TRAIN Batch 11/7500 loss 20.353771 loss_att 29.412323 loss_ctc 24.056852 loss_rnnt 17.918705 hw_loss 0.243018 lr 0.00050185 rank 6
2023-02-21 22:52:32,036 DEBUG TRAIN Batch 11/7500 loss 16.612297 loss_att 23.238426 loss_ctc 20.086258 loss_rnnt 14.627097 hw_loss 0.368964 lr 0.00050185 rank 4
2023-02-21 22:52:32,036 DEBUG TRAIN Batch 11/7500 loss 14.059726 loss_att 17.695665 loss_ctc 15.482685 loss_rnnt 13.004587 hw_loss 0.259168 lr 0.00050185 rank 1
2023-02-21 22:52:32,037 DEBUG TRAIN Batch 11/7500 loss 24.974289 loss_att 28.029057 loss_ctc 28.576237 loss_rnnt 23.722599 hw_loss 0.300890 lr 0.00050185 rank 0
2023-02-21 22:52:32,042 DEBUG TRAIN Batch 11/7500 loss 10.924437 loss_att 16.924559 loss_ctc 12.046175 loss_rnnt 9.363349 hw_loss 0.396560 lr 0.00050185 rank 7
2023-02-21 22:53:47,593 DEBUG TRAIN Batch 11/7600 loss 24.185009 loss_att 27.652563 loss_ctc 31.431671 loss_rnnt 22.430738 hw_loss 0.177258 lr 0.00050160 rank 0
2023-02-21 22:53:47,608 DEBUG TRAIN Batch 11/7600 loss 8.009789 loss_att 9.711103 loss_ctc 9.602254 loss_rnnt 7.217012 hw_loss 0.450345 lr 0.00050160 rank 2
2023-02-21 22:53:47,613 DEBUG TRAIN Batch 11/7600 loss 17.228378 loss_att 21.661770 loss_ctc 23.414791 loss_rnnt 15.377724 hw_loss 0.260849 lr 0.00050160 rank 1
2023-02-21 22:53:47,615 DEBUG TRAIN Batch 11/7600 loss 13.468095 loss_att 17.866138 loss_ctc 18.986715 loss_rnnt 11.694151 hw_loss 0.297225 lr 0.00050160 rank 3
2023-02-21 22:53:47,616 DEBUG TRAIN Batch 11/7600 loss 15.768747 loss_att 24.624310 loss_ctc 16.755091 loss_rnnt 13.699311 hw_loss 0.312770 lr 0.00050160 rank 7
2023-02-21 22:53:47,620 DEBUG TRAIN Batch 11/7600 loss 16.753786 loss_att 22.073765 loss_ctc 21.735937 loss_rnnt 14.866794 hw_loss 0.297578 lr 0.00050160 rank 5
2023-02-21 22:53:47,620 DEBUG TRAIN Batch 11/7600 loss 18.076246 loss_att 24.112297 loss_ctc 20.219339 loss_rnnt 16.429743 hw_loss 0.287898 lr 0.00050160 rank 4
2023-02-21 22:53:47,621 DEBUG TRAIN Batch 11/7600 loss 32.507725 loss_att 34.655693 loss_ctc 34.166401 loss_rnnt 31.722824 hw_loss 0.251531 lr 0.00050160 rank 6
2023-02-21 22:54:59,355 DEBUG TRAIN Batch 11/7700 loss 13.113245 loss_att 12.272328 loss_ctc 14.518386 loss_rnnt 12.625273 hw_loss 0.879008 lr 0.00050134 rank 3
2023-02-21 22:54:59,359 DEBUG TRAIN Batch 11/7700 loss 14.441362 loss_att 23.872471 loss_ctc 17.303091 loss_rnnt 12.028938 hw_loss 0.271196 lr 0.00050134 rank 6
2023-02-21 22:54:59,360 DEBUG TRAIN Batch 11/7700 loss 10.558040 loss_att 17.277315 loss_ctc 10.785757 loss_rnnt 9.103329 hw_loss 0.150927 lr 0.00050134 rank 2
2023-02-21 22:54:59,363 DEBUG TRAIN Batch 11/7700 loss 23.561533 loss_att 22.198444 loss_ctc 25.535130 loss_rnnt 23.321659 hw_loss 0.467518 lr 0.00050134 rank 1
2023-02-21 22:54:59,363 DEBUG TRAIN Batch 11/7700 loss 15.200243 loss_att 17.126377 loss_ctc 17.077322 loss_rnnt 14.321800 hw_loss 0.455510 lr 0.00050134 rank 0
2023-02-21 22:54:59,368 DEBUG TRAIN Batch 11/7700 loss 23.835516 loss_att 27.493690 loss_ctc 27.178715 loss_rnnt 22.584560 hw_loss 0.137930 lr 0.00050134 rank 5
2023-02-21 22:54:59,394 DEBUG TRAIN Batch 11/7700 loss 16.668211 loss_att 13.904060 loss_ctc 18.519522 loss_rnnt 16.823042 hw_loss 0.283421 lr 0.00050134 rank 4
2023-02-21 22:54:59,404 DEBUG TRAIN Batch 11/7700 loss 13.687097 loss_att 17.939022 loss_ctc 17.001846 loss_rnnt 12.278266 hw_loss 0.218399 lr 0.00050134 rank 7
2023-02-21 22:56:13,163 DEBUG TRAIN Batch 11/7800 loss 12.316411 loss_att 20.521770 loss_ctc 18.582941 loss_rnnt 9.698868 hw_loss 0.264251 lr 0.00050109 rank 5
2023-02-21 22:56:13,178 DEBUG TRAIN Batch 11/7800 loss 22.604195 loss_att 25.244598 loss_ctc 28.050320 loss_rnnt 21.168835 hw_loss 0.339616 lr 0.00050109 rank 0
2023-02-21 22:56:13,178 DEBUG TRAIN Batch 11/7800 loss 16.728844 loss_att 24.318935 loss_ctc 17.552818 loss_rnnt 15.038500 hw_loss 0.117118 lr 0.00050109 rank 2
2023-02-21 22:56:13,179 DEBUG TRAIN Batch 11/7800 loss 23.867943 loss_att 30.804054 loss_ctc 24.926411 loss_rnnt 22.255207 hw_loss 0.158214 lr 0.00050109 rank 3
2023-02-21 22:56:13,180 DEBUG TRAIN Batch 11/7800 loss 18.387308 loss_att 26.376467 loss_ctc 25.794006 loss_rnnt 15.689442 hw_loss 0.210888 lr 0.00050109 rank 6
2023-02-21 22:56:13,192 DEBUG TRAIN Batch 11/7800 loss 23.675146 loss_att 32.955738 loss_ctc 27.416496 loss_rnnt 21.250807 hw_loss 0.130077 lr 0.00050109 rank 4
2023-02-21 22:56:13,198 DEBUG TRAIN Batch 11/7800 loss 28.598185 loss_att 31.191105 loss_ctc 37.309803 loss_rnnt 26.806179 hw_loss 0.209766 lr 0.00050109 rank 7
2023-02-21 22:56:13,206 DEBUG TRAIN Batch 11/7800 loss 10.285997 loss_att 15.669399 loss_ctc 9.992139 loss_rnnt 9.009212 hw_loss 0.448663 lr 0.00050109 rank 1
2023-02-21 22:57:27,002 DEBUG TRAIN Batch 11/7900 loss 15.907587 loss_att 21.332811 loss_ctc 17.485735 loss_rnnt 14.512093 hw_loss 0.187556 lr 0.00050084 rank 2
2023-02-21 22:57:27,005 DEBUG TRAIN Batch 11/7900 loss 14.753075 loss_att 20.604504 loss_ctc 14.508601 loss_rnnt 13.482649 hw_loss 0.248883 lr 0.00050084 rank 3
2023-02-21 22:57:27,007 DEBUG TRAIN Batch 11/7900 loss 28.832516 loss_att 32.968796 loss_ctc 36.480759 loss_rnnt 26.849758 hw_loss 0.254507 lr 0.00050084 rank 6
2023-02-21 22:57:27,009 DEBUG TRAIN Batch 11/7900 loss 19.374762 loss_att 25.510912 loss_ctc 24.511440 loss_rnnt 17.326904 hw_loss 0.254509 lr 0.00050084 rank 4
2023-02-21 22:57:27,010 DEBUG TRAIN Batch 11/7900 loss 30.904341 loss_att 38.991817 loss_ctc 39.084610 loss_rnnt 28.062450 hw_loss 0.250679 lr 0.00050084 rank 1
2023-02-21 22:57:27,010 DEBUG TRAIN Batch 11/7900 loss 17.055611 loss_att 22.868189 loss_ctc 17.660213 loss_rnnt 15.657425 hw_loss 0.290726 lr 0.00050084 rank 7
2023-02-21 22:57:27,012 DEBUG TRAIN Batch 11/7900 loss 31.170788 loss_att 33.124958 loss_ctc 30.843365 loss_rnnt 30.754566 hw_loss 0.129450 lr 0.00050084 rank 0
2023-02-21 22:57:27,015 DEBUG TRAIN Batch 11/7900 loss 16.412680 loss_att 27.286453 loss_ctc 18.794046 loss_rnnt 13.765627 hw_loss 0.290217 lr 0.00050084 rank 5
2023-02-21 22:58:39,624 DEBUG TRAIN Batch 11/8000 loss 22.239338 loss_att 26.875095 loss_ctc 24.948040 loss_rnnt 20.770525 hw_loss 0.338442 lr 0.00050059 rank 4
2023-02-21 22:58:39,636 DEBUG TRAIN Batch 11/8000 loss 26.815044 loss_att 32.664162 loss_ctc 31.138420 loss_rnnt 24.993631 hw_loss 0.140887 lr 0.00050059 rank 2
2023-02-21 22:58:39,636 DEBUG TRAIN Batch 11/8000 loss 7.579181 loss_att 13.237947 loss_ctc 12.123675 loss_rnnt 5.716431 hw_loss 0.234496 lr 0.00050059 rank 6
2023-02-21 22:58:39,638 DEBUG TRAIN Batch 11/8000 loss 33.185402 loss_att 44.946564 loss_ctc 37.542782 loss_rnnt 30.143160 hw_loss 0.204417 lr 0.00050059 rank 3
2023-02-21 22:58:39,640 DEBUG TRAIN Batch 11/8000 loss 10.069576 loss_att 13.300602 loss_ctc 10.596916 loss_rnnt 9.239680 hw_loss 0.212587 lr 0.00050059 rank 7
2023-02-21 22:58:39,649 DEBUG TRAIN Batch 11/8000 loss 25.379206 loss_att 33.622864 loss_ctc 29.270947 loss_rnnt 23.082314 hw_loss 0.242361 lr 0.00050059 rank 1
2023-02-21 22:58:39,649 DEBUG TRAIN Batch 11/8000 loss 16.802816 loss_att 20.628145 loss_ctc 18.894665 loss_rnnt 15.613634 hw_loss 0.272255 lr 0.00050059 rank 0
2023-02-21 22:58:39,697 DEBUG TRAIN Batch 11/8000 loss 17.285311 loss_att 20.197393 loss_ctc 22.672337 loss_rnnt 15.822592 hw_loss 0.303812 lr 0.00050059 rank 5
2023-02-21 22:59:52,297 DEBUG TRAIN Batch 11/8100 loss 20.245838 loss_att 25.579538 loss_ctc 19.988632 loss_rnnt 19.079136 hw_loss 0.251725 lr 0.00050034 rank 4
2023-02-21 22:59:52,304 DEBUG TRAIN Batch 11/8100 loss 23.531200 loss_att 24.761723 loss_ctc 29.366970 loss_rnnt 22.306023 hw_loss 0.376819 lr 0.00050034 rank 7
2023-02-21 22:59:52,305 DEBUG TRAIN Batch 11/8100 loss 36.291756 loss_att 34.429623 loss_ctc 38.358505 loss_rnnt 36.287956 hw_loss 0.188739 lr 0.00050034 rank 2
2023-02-21 22:59:52,306 DEBUG TRAIN Batch 11/8100 loss 8.289380 loss_att 15.045485 loss_ctc 11.171978 loss_rnnt 6.418934 hw_loss 0.252899 lr 0.00050034 rank 3
2023-02-21 22:59:52,308 DEBUG TRAIN Batch 11/8100 loss 20.396082 loss_att 21.064396 loss_ctc 24.176580 loss_rnnt 19.560848 hw_loss 0.370315 lr 0.00050034 rank 6
2023-02-21 22:59:52,309 DEBUG TRAIN Batch 11/8100 loss 17.870214 loss_att 20.837124 loss_ctc 23.134193 loss_rnnt 16.389252 hw_loss 0.348222 lr 0.00050034 rank 1
2023-02-21 22:59:52,313 DEBUG TRAIN Batch 11/8100 loss 31.423532 loss_att 38.124802 loss_ctc 35.873196 loss_rnnt 29.279808 hw_loss 0.394094 lr 0.00050034 rank 5
2023-02-21 22:59:52,316 DEBUG TRAIN Batch 11/8100 loss 27.481768 loss_att 33.808743 loss_ctc 35.349689 loss_rnnt 25.025171 hw_loss 0.266516 lr 0.00050034 rank 0
2023-02-21 23:01:05,965 DEBUG TRAIN Batch 11/8200 loss 13.056176 loss_att 13.915411 loss_ctc 17.120678 loss_rnnt 12.055720 hw_loss 0.537517 lr 0.00050009 rank 7
2023-02-21 23:01:05,965 DEBUG TRAIN Batch 11/8200 loss 13.256471 loss_att 14.276426 loss_ctc 13.735623 loss_rnnt 12.784200 hw_loss 0.383237 lr 0.00050009 rank 0
2023-02-21 23:01:05,966 DEBUG TRAIN Batch 11/8200 loss 13.759519 loss_att 13.446112 loss_ctc 15.879189 loss_rnnt 13.343856 hw_loss 0.366977 lr 0.00050009 rank 2
2023-02-21 23:01:05,966 DEBUG TRAIN Batch 11/8200 loss 15.145781 loss_att 21.020491 loss_ctc 15.994237 loss_rnnt 13.669003 hw_loss 0.353827 lr 0.00050009 rank 1
2023-02-21 23:01:05,967 DEBUG TRAIN Batch 11/8200 loss 19.518702 loss_att 22.144018 loss_ctc 27.186575 loss_rnnt 17.834778 hw_loss 0.255893 lr 0.00050009 rank 4
2023-02-21 23:01:05,971 DEBUG TRAIN Batch 11/8200 loss 18.437416 loss_att 22.042162 loss_ctc 25.106003 loss_rnnt 16.627201 hw_loss 0.375229 lr 0.00050009 rank 6
2023-02-21 23:01:05,973 DEBUG TRAIN Batch 11/8200 loss 14.920759 loss_att 20.861383 loss_ctc 18.814917 loss_rnnt 13.083529 hw_loss 0.243532 lr 0.00050009 rank 3
2023-02-21 23:01:05,973 DEBUG TRAIN Batch 11/8200 loss 17.685953 loss_att 19.366066 loss_ctc 24.185440 loss_rnnt 16.359451 hw_loss 0.232277 lr 0.00050009 rank 5
2023-02-21 23:02:18,138 DEBUG TRAIN Batch 11/8300 loss 19.831196 loss_att 26.166424 loss_ctc 25.290302 loss_rnnt 17.683256 hw_loss 0.286904 lr 0.00049984 rank 2
2023-02-21 23:02:18,146 DEBUG TRAIN Batch 11/8300 loss 26.772738 loss_att 31.194599 loss_ctc 33.910477 loss_rnnt 24.813231 hw_loss 0.231441 lr 0.00049984 rank 3
2023-02-21 23:02:18,147 DEBUG TRAIN Batch 11/8300 loss 36.962246 loss_att 42.670536 loss_ctc 41.582165 loss_rnnt 34.986507 hw_loss 0.408924 lr 0.00049984 rank 5
2023-02-21 23:02:18,148 DEBUG TRAIN Batch 11/8300 loss 25.935642 loss_att 27.061787 loss_ctc 34.167923 loss_rnnt 24.481457 hw_loss 0.246231 lr 0.00049984 rank 0
2023-02-21 23:02:18,148 DEBUG TRAIN Batch 11/8300 loss 14.315270 loss_att 18.641676 loss_ctc 17.587194 loss_rnnt 12.945938 hw_loss 0.127116 lr 0.00049984 rank 6
2023-02-21 23:02:18,148 DEBUG TRAIN Batch 11/8300 loss 18.893492 loss_att 19.711996 loss_ctc 16.693314 loss_rnnt 18.903507 hw_loss 0.224330 lr 0.00049984 rank 7
2023-02-21 23:02:18,150 DEBUG TRAIN Batch 11/8300 loss 6.246356 loss_att 7.659132 loss_ctc 7.290756 loss_rnnt 5.664302 hw_loss 0.300462 lr 0.00049984 rank 4
2023-02-21 23:02:18,152 DEBUG TRAIN Batch 11/8300 loss 21.641485 loss_att 28.596512 loss_ctc 21.747993 loss_rnnt 20.069038 hw_loss 0.313575 lr 0.00049984 rank 1
2023-02-21 23:03:02,111 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 1
2023-02-21 23:03:02,113 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 6
2023-02-21 23:03:02,114 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 5
2023-02-21 23:03:02,117 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 7
2023-02-21 23:03:02,122 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 0
2023-02-21 23:03:02,124 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 3
2023-02-21 23:03:02,131 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 2
2023-02-21 23:03:02,145 DEBUG CV Batch 11/0 loss 3.356445 loss_att 3.240644 loss_ctc 4.032449 loss_rnnt 2.989071 hw_loss 0.563250 history loss 3.232132 rank 4
2023-02-21 23:03:13,559 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 1
2023-02-21 23:03:13,669 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 4
2023-02-21 23:03:13,673 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 6
2023-02-21 23:03:13,766 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 2
2023-02-21 23:03:13,874 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 0
2023-02-21 23:03:13,967 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 5
2023-02-21 23:03:13,991 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 3
2023-02-21 23:03:14,153 DEBUG CV Batch 11/100 loss 12.326300 loss_att 13.358508 loss_ctc 14.022796 loss_rnnt 11.682727 hw_loss 0.395496 history loss 5.690021 rank 7
2023-02-21 23:03:27,108 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 6
2023-02-21 23:03:27,135 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 1
2023-02-21 23:03:27,171 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 2
2023-02-21 23:03:27,370 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 3
2023-02-21 23:03:27,546 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 0
2023-02-21 23:03:27,618 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 5
2023-02-21 23:03:27,631 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 4
2023-02-21 23:03:27,705 DEBUG CV Batch 11/200 loss 15.955062 loss_att 32.331390 loss_ctc 14.664669 loss_rnnt 12.772210 hw_loss 0.149321 history loss 6.490493 rank 7
2023-02-21 23:03:39,548 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 6
2023-02-21 23:03:39,770 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 2
2023-02-21 23:03:39,811 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 3
2023-02-21 23:03:39,872 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 1
2023-02-21 23:03:40,106 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 5
2023-02-21 23:03:40,357 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 7
2023-02-21 23:03:40,528 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 0
2023-02-21 23:03:40,929 DEBUG CV Batch 11/300 loss 9.259953 loss_att 10.072000 loss_ctc 12.811136 loss_rnnt 8.393406 hw_loss 0.432464 history loss 6.724046 rank 4
2023-02-21 23:03:51,629 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 6
2023-02-21 23:03:51,933 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 3
2023-02-21 23:03:51,942 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 2
2023-02-21 23:03:52,037 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 1
2023-02-21 23:03:52,680 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 7
2023-02-21 23:03:52,928 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 5
2023-02-21 23:03:53,030 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 0
2023-02-21 23:03:53,616 DEBUG CV Batch 11/400 loss 40.437637 loss_att 174.406738 loss_ctc 20.406414 loss_rnnt 16.224262 hw_loss 0.169468 history loss 7.961502 rank 4
2023-02-21 23:04:02,429 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 6
2023-02-21 23:04:02,685 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 3
2023-02-21 23:04:02,714 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 2
2023-02-21 23:04:03,262 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 1
2023-02-21 23:04:03,522 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 7
2023-02-21 23:04:03,892 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 5
2023-02-21 23:04:04,238 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 0
2023-02-21 23:04:05,144 DEBUG CV Batch 11/500 loss 7.958251 loss_att 9.596942 loss_ctc 10.137685 loss_rnnt 7.185097 hw_loss 0.290296 history loss 8.995163 rank 4
2023-02-21 23:04:14,944 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 6
2023-02-21 23:04:14,945 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 3
2023-02-21 23:04:14,947 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 2
2023-02-21 23:04:15,512 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 1
2023-02-21 23:04:16,298 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 5
2023-02-21 23:04:16,314 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 7
2023-02-21 23:04:16,823 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 0
2023-02-21 23:04:17,981 DEBUG CV Batch 11/600 loss 10.952902 loss_att 10.610954 loss_ctc 12.648253 loss_rnnt 10.589434 hw_loss 0.385894 history loss 10.188088 rank 4
2023-02-21 23:04:26,354 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 6
2023-02-21 23:04:26,400 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 3
2023-02-21 23:04:26,414 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 2
2023-02-21 23:04:26,904 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 1
2023-02-21 23:04:28,262 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 5
2023-02-21 23:04:28,432 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 7
2023-02-21 23:04:28,655 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 0
2023-02-21 23:04:30,149 DEBUG CV Batch 11/700 loss 31.583597 loss_att 99.039505 loss_ctc 28.282526 loss_rnnt 18.362482 hw_loss 0.318892 history loss 11.144326 rank 4
2023-02-21 23:04:37,810 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 3
2023-02-21 23:04:37,814 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 6
2023-02-21 23:04:37,925 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 2
2023-02-21 23:04:38,531 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 1
2023-02-21 23:04:39,937 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 5
2023-02-21 23:04:39,997 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 7
2023-02-21 23:04:40,379 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 0
2023-02-21 23:04:42,260 DEBUG CV Batch 11/800 loss 16.060860 loss_att 15.935497 loss_ctc 19.184608 loss_rnnt 15.496905 hw_loss 0.323488 history loss 10.410617 rank 4
2023-02-21 23:04:51,220 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 3
2023-02-21 23:04:51,233 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 6
2023-02-21 23:04:51,346 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 2
2023-02-21 23:04:51,879 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 1
2023-02-21 23:04:53,457 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 5
2023-02-21 23:04:53,628 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 7
2023-02-21 23:04:54,329 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 0
2023-02-21 23:04:56,097 DEBUG CV Batch 11/900 loss 30.215019 loss_att 48.790794 loss_ctc 29.103062 loss_rnnt 26.607269 hw_loss 0.076602 history loss 10.141658 rank 4
2023-02-21 23:05:03,538 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505167 history loss 9.839399 rank 3
2023-02-21 23:05:03,648 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505167 history loss 9.839399 rank 6
2023-02-21 23:05:03,782 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505166 history loss 9.839399 rank 2
2023-02-21 23:05:04,320 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505166 history loss 9.839399 rank 1
2023-02-21 23:05:06,220 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505166 history loss 9.839399 rank 7
2023-02-21 23:05:06,336 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505166 history loss 9.839399 rank 5
2023-02-21 23:05:07,180 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505166 history loss 9.839399 rank 0
2023-02-21 23:05:08,904 DEBUG CV Batch 11/1000 loss 5.381415 loss_att 6.431523 loss_ctc 5.259339 loss_rnnt 4.918248 hw_loss 0.505167 history loss 9.839399 rank 4
2023-02-21 23:05:15,642 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665310 history loss 9.800324 rank 3
2023-02-21 23:05:15,709 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665309 history loss 9.800324 rank 6
2023-02-21 23:05:15,881 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665309 history loss 9.800324 rank 2
2023-02-21 23:05:16,837 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665309 history loss 9.800324 rank 1
2023-02-21 23:05:18,408 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665309 history loss 9.800324 rank 7
2023-02-21 23:05:18,634 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665309 history loss 9.800324 rank 5
2023-02-21 23:05:19,586 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665309 history loss 9.800324 rank 0
2023-02-21 23:05:21,616 DEBUG CV Batch 11/1100 loss 9.292519 loss_att 8.359642 loss_ctc 11.291113 loss_rnnt 8.857783 hw_loss 0.665309 history loss 9.800324 rank 4
2023-02-21 23:05:26,419 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 3
2023-02-21 23:05:26,602 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 6
2023-02-21 23:05:26,785 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 2
2023-02-21 23:05:27,772 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 1
2023-02-21 23:05:29,300 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 7
2023-02-21 23:05:29,531 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 5
2023-02-21 23:05:30,807 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 0
2023-02-21 23:05:32,850 DEBUG CV Batch 11/1200 loss 9.366932 loss_att 10.793007 loss_ctc 11.391847 loss_rnnt 8.620914 hw_loss 0.357777 history loss 10.247334 rank 4
2023-02-21 23:05:38,509 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 3
2023-02-21 23:05:38,832 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 6
2023-02-21 23:05:38,861 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 2
2023-02-21 23:05:40,038 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 1
2023-02-21 23:05:41,584 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 7
2023-02-21 23:05:41,875 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 5
2023-02-21 23:05:43,667 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 0
2023-02-21 23:05:45,223 DEBUG CV Batch 11/1300 loss 8.038309 loss_att 8.025410 loss_ctc 10.356229 loss_rnnt 7.514606 hw_loss 0.407302 history loss 10.630600 rank 4
2023-02-21 23:05:49,866 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 3
2023-02-21 23:05:50,241 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 2
2023-02-21 23:05:50,266 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 6
2023-02-21 23:05:51,416 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 1
2023-02-21 23:05:53,036 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 7
2023-02-21 23:05:53,397 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 5
2023-02-21 23:05:55,790 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 0
2023-02-21 23:05:56,791 DEBUG CV Batch 11/1400 loss 17.988514 loss_att 62.305367 loss_ctc 7.780491 loss_rnnt 10.362045 hw_loss 0.232811 history loss 11.090992 rank 4
2023-02-21 23:06:01,582 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 3
2023-02-21 23:06:01,852 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 2
2023-02-21 23:06:01,971 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 6
2023-02-21 23:06:03,169 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 1
2023-02-21 23:06:04,886 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 7
2023-02-21 23:06:05,263 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 5
2023-02-21 23:06:07,901 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 0
2023-02-21 23:06:08,881 DEBUG CV Batch 11/1500 loss 10.846780 loss_att 11.916568 loss_ctc 9.571917 loss_rnnt 10.669929 hw_loss 0.249142 history loss 10.842515 rank 4
2023-02-21 23:06:14,781 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 3
2023-02-21 23:06:15,072 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 2
2023-02-21 23:06:15,184 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 6
2023-02-21 23:06:17,044 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 1
2023-02-21 23:06:18,168 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 7
2023-02-21 23:06:18,572 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 5
2023-02-21 23:06:21,517 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 0
2023-02-21 23:06:22,355 DEBUG CV Batch 11/1600 loss 17.613661 loss_att 38.503517 loss_ctc 14.273901 loss_rnnt 13.747348 hw_loss 0.250580 history loss 10.721465 rank 4
2023-02-21 23:06:27,289 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 3
2023-02-21 23:06:27,535 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 2
2023-02-21 23:06:27,643 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 6
2023-02-21 23:06:29,464 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 1
2023-02-21 23:06:30,897 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 7
2023-02-21 23:06:31,204 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 5
2023-02-21 23:06:34,231 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 0
2023-02-21 23:06:34,932 DEBUG CV Batch 11/1700 loss 13.270963 loss_att 13.470355 loss_ctc 16.693399 loss_rnnt 12.632680 hw_loss 0.266396 history loss 10.584775 rank 4
2023-02-21 23:06:36,425 INFO Epoch 11 CV info cv_loss 10.522817959777191
2023-02-21 23:06:36,425 INFO Epoch 12 TRAIN info lr 0.0004997402026243998
2023-02-21 23:06:36,430 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:06:36,723 INFO Epoch 11 CV info cv_loss 10.522817960569737
2023-02-21 23:06:36,723 INFO Epoch 12 TRAIN info lr 0.0004997252266672312
2023-02-21 23:06:36,725 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:06:36,824 INFO Epoch 11 CV info cv_loss 10.52281795982888
2023-02-21 23:06:36,824 INFO Epoch 12 TRAIN info lr 0.0004997277225665945
2023-02-21 23:06:36,826 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:06:38,384 INFO Epoch 11 CV info cv_loss 10.522817959630743
2023-02-21 23:06:38,384 INFO Epoch 12 TRAIN info lr 0.000499780145093602
2023-02-21 23:06:38,386 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:06:40,263 INFO Epoch 11 CV info cv_loss 10.522817958958802
2023-02-21 23:06:40,264 INFO Epoch 12 TRAIN info lr 0.0004997052608185411
2023-02-21 23:06:40,269 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:06:40,469 INFO Epoch 11 CV info cv_loss 10.52281796025961
2023-02-21 23:06:40,469 INFO Epoch 12 TRAIN info lr 0.0004997277225665945
2023-02-21 23:06:40,471 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:06:43,694 INFO Epoch 11 CV info cv_loss 10.522817959501523
2023-02-21 23:06:43,694 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/11.pt
2023-02-21 23:06:44,335 INFO Epoch 11 CV info cv_loss 10.522817962938761
2023-02-21 23:06:44,336 INFO Epoch 12 TRAIN info lr 0.0004997626690848965
2023-02-21 23:06:44,341 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:06:44,777 INFO Epoch 12 TRAIN info lr 0.000499780145093602
2023-02-21 23:06:44,781 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:07:45,538 DEBUG TRAIN Batch 12/0 loss 12.007030 loss_att 11.116482 loss_ctc 13.600728 loss_rnnt 11.620337 hw_loss 0.660578 lr 0.00049974 rank 3
2023-02-21 23:07:45,539 DEBUG TRAIN Batch 12/0 loss 15.815863 loss_att 15.661217 loss_ctc 18.197367 loss_rnnt 15.239785 hw_loss 0.542759 lr 0.00049978 rank 1
2023-02-21 23:07:45,542 DEBUG TRAIN Batch 12/0 loss 16.436457 loss_att 15.352543 loss_ctc 19.876602 loss_rnnt 15.862601 hw_loss 0.622411 lr 0.00049972 rank 2
2023-02-21 23:07:45,542 DEBUG TRAIN Batch 12/0 loss 11.482366 loss_att 10.464329 loss_ctc 13.036084 loss_rnnt 11.148749 hw_loss 0.618864 lr 0.00049973 rank 6
2023-02-21 23:07:45,547 DEBUG TRAIN Batch 12/0 loss 16.609331 loss_att 16.774101 loss_ctc 18.458570 loss_rnnt 15.954049 hw_loss 0.704556 lr 0.00049973 rank 5
2023-02-21 23:07:45,558 DEBUG TRAIN Batch 12/0 loss 16.550648 loss_att 16.030222 loss_ctc 19.372482 loss_rnnt 15.940965 hw_loss 0.632857 lr 0.00049970 rank 7
2023-02-21 23:07:45,567 DEBUG TRAIN Batch 12/0 loss 12.886703 loss_att 13.038574 loss_ctc 14.523913 loss_rnnt 12.289294 hw_loss 0.653888 lr 0.00049978 rank 0
2023-02-21 23:07:45,569 DEBUG TRAIN Batch 12/0 loss 12.565592 loss_att 11.722822 loss_ctc 14.195598 loss_rnnt 12.227200 hw_loss 0.543021 lr 0.00049976 rank 4
2023-02-21 23:08:57,971 DEBUG TRAIN Batch 12/100 loss 12.988795 loss_att 16.003029 loss_ctc 15.125877 loss_rnnt 12.050297 hw_loss 0.095078 lr 0.00049947 rank 2
2023-02-21 23:08:57,975 DEBUG TRAIN Batch 12/100 loss 15.939092 loss_att 15.656517 loss_ctc 16.641367 loss_rnnt 15.798607 hw_loss 0.193807 lr 0.00049949 rank 3
2023-02-21 23:08:57,976 DEBUG TRAIN Batch 12/100 loss 17.688366 loss_att 20.085003 loss_ctc 22.810852 loss_rnnt 16.405476 hw_loss 0.226058 lr 0.00049948 rank 6
2023-02-21 23:08:57,978 DEBUG TRAIN Batch 12/100 loss 20.209137 loss_att 22.271029 loss_ctc 24.370377 loss_rnnt 19.119944 hw_loss 0.228716 lr 0.00049945 rank 7
2023-02-21 23:08:57,978 DEBUG TRAIN Batch 12/100 loss 35.584354 loss_att 32.965084 loss_ctc 45.541893 loss_rnnt 34.671036 hw_loss 0.205313 lr 0.00049948 rank 5
2023-02-21 23:08:57,981 DEBUG TRAIN Batch 12/100 loss 24.694958 loss_att 36.581825 loss_ctc 24.473333 loss_rnnt 22.217545 hw_loss 0.242976 lr 0.00049951 rank 4
2023-02-21 23:08:57,982 DEBUG TRAIN Batch 12/100 loss 21.668564 loss_att 22.989147 loss_ctc 23.924660 loss_rnnt 20.945599 hw_loss 0.296314 lr 0.00049953 rank 1
2023-02-21 23:08:57,982 DEBUG TRAIN Batch 12/100 loss 15.517633 loss_att 17.772949 loss_ctc 18.937893 loss_rnnt 14.454971 hw_loss 0.291683 lr 0.00049953 rank 0
2023-02-21 23:10:09,961 DEBUG TRAIN Batch 12/200 loss 17.773741 loss_att 20.719093 loss_ctc 20.713409 loss_rnnt 16.633987 hw_loss 0.297612 lr 0.00049922 rank 2
2023-02-21 23:10:09,968 DEBUG TRAIN Batch 12/200 loss 15.531718 loss_att 24.021198 loss_ctc 16.737541 loss_rnnt 13.518145 hw_loss 0.290440 lr 0.00049920 rank 7
2023-02-21 23:10:09,968 DEBUG TRAIN Batch 12/200 loss 17.044954 loss_att 23.579556 loss_ctc 21.549084 loss_rnnt 14.938814 hw_loss 0.372507 lr 0.00049928 rank 1
2023-02-21 23:10:09,969 DEBUG TRAIN Batch 12/200 loss 14.564853 loss_att 21.317936 loss_ctc 14.666170 loss_rnnt 13.104824 hw_loss 0.179818 lr 0.00049923 rank 6
2023-02-21 23:10:09,975 DEBUG TRAIN Batch 12/200 loss 7.765635 loss_att 13.645683 loss_ctc 10.855396 loss_rnnt 6.024644 hw_loss 0.286898 lr 0.00049926 rank 4
2023-02-21 23:10:09,975 DEBUG TRAIN Batch 12/200 loss 17.493608 loss_att 19.465710 loss_ctc 20.880156 loss_rnnt 16.499798 hw_loss 0.277217 lr 0.00049924 rank 3
2023-02-21 23:10:09,976 DEBUG TRAIN Batch 12/200 loss 19.712963 loss_att 26.145741 loss_ctc 24.720093 loss_rnnt 17.669762 hw_loss 0.166928 lr 0.00049928 rank 0
2023-02-21 23:10:09,983 DEBUG TRAIN Batch 12/200 loss 17.682121 loss_att 27.327635 loss_ctc 25.436628 loss_rnnt 14.582901 hw_loss 0.255342 lr 0.00049923 rank 5
2023-02-21 23:11:23,099 DEBUG TRAIN Batch 12/300 loss 19.660053 loss_att 26.158890 loss_ctc 20.733948 loss_rnnt 18.140963 hw_loss 0.142754 lr 0.00049901 rank 4
2023-02-21 23:11:23,115 DEBUG TRAIN Batch 12/300 loss 20.648071 loss_att 25.980309 loss_ctc 27.291235 loss_rnnt 18.648903 hw_loss 0.088058 lr 0.00049896 rank 7
2023-02-21 23:11:23,116 DEBUG TRAIN Batch 12/300 loss 20.394880 loss_att 29.067564 loss_ctc 24.532263 loss_rnnt 17.913778 hw_loss 0.365466 lr 0.00049898 rank 2
2023-02-21 23:11:23,116 DEBUG TRAIN Batch 12/300 loss 15.395207 loss_att 14.064621 loss_ctc 15.314224 loss_rnnt 15.421267 hw_loss 0.470352 lr 0.00049899 rank 3
2023-02-21 23:11:23,121 DEBUG TRAIN Batch 12/300 loss 11.857648 loss_att 16.575020 loss_ctc 16.793118 loss_rnnt 10.031876 hw_loss 0.420441 lr 0.00049898 rank 6
2023-02-21 23:11:23,135 DEBUG TRAIN Batch 12/300 loss 19.836142 loss_att 22.153580 loss_ctc 23.498575 loss_rnnt 18.654131 hw_loss 0.431617 lr 0.00049898 rank 5
2023-02-21 23:11:23,140 DEBUG TRAIN Batch 12/300 loss 21.509716 loss_att 31.995735 loss_ctc 26.924206 loss_rnnt 18.566877 hw_loss 0.231945 lr 0.00049903 rank 1
2023-02-21 23:11:23,140 DEBUG TRAIN Batch 12/300 loss 27.808266 loss_att 33.051067 loss_ctc 37.338684 loss_rnnt 25.376657 hw_loss 0.210609 lr 0.00049903 rank 0
2023-02-21 23:12:36,412 DEBUG TRAIN Batch 12/400 loss 14.489547 loss_att 18.926674 loss_ctc 21.081831 loss_rnnt 12.598077 hw_loss 0.234511 lr 0.00049873 rank 6
2023-02-21 23:12:36,414 DEBUG TRAIN Batch 12/400 loss 39.083702 loss_att 47.185421 loss_ctc 57.990822 loss_rnnt 34.775387 hw_loss 0.313172 lr 0.00049873 rank 2
2023-02-21 23:12:36,414 DEBUG TRAIN Batch 12/400 loss 19.428812 loss_att 24.076263 loss_ctc 22.571531 loss_rnnt 17.839016 hw_loss 0.452390 lr 0.00049874 rank 3
2023-02-21 23:12:36,420 DEBUG TRAIN Batch 12/400 loss 21.245768 loss_att 20.129629 loss_ctc 26.598175 loss_rnnt 20.627153 hw_loss 0.240348 lr 0.00049878 rank 0
2023-02-21 23:12:36,420 DEBUG TRAIN Batch 12/400 loss 16.076296 loss_att 25.677031 loss_ctc 16.804909 loss_rnnt 13.907543 hw_loss 0.283981 lr 0.00049878 rank 1
2023-02-21 23:12:36,421 DEBUG TRAIN Batch 12/400 loss 18.109222 loss_att 26.882607 loss_ctc 23.311789 loss_rnnt 15.523634 hw_loss 0.257322 lr 0.00049873 rank 5
2023-02-21 23:12:36,422 DEBUG TRAIN Batch 12/400 loss 25.758533 loss_att 28.482018 loss_ctc 26.710850 loss_rnnt 24.922665 hw_loss 0.307869 lr 0.00049876 rank 4
2023-02-21 23:12:36,467 DEBUG TRAIN Batch 12/400 loss 8.636655 loss_att 15.102486 loss_ctc 8.099680 loss_rnnt 7.229337 hw_loss 0.348278 lr 0.00049871 rank 7
2023-02-21 23:13:49,026 DEBUG TRAIN Batch 12/500 loss 20.636667 loss_att 21.415693 loss_ctc 23.573574 loss_rnnt 19.962971 hw_loss 0.236817 lr 0.00049848 rank 2
2023-02-21 23:13:49,028 DEBUG TRAIN Batch 12/500 loss 18.995386 loss_att 21.358229 loss_ctc 18.952955 loss_rnnt 18.406696 hw_loss 0.228332 lr 0.00049849 rank 3
2023-02-21 23:13:49,029 DEBUG TRAIN Batch 12/500 loss 17.482653 loss_att 20.782095 loss_ctc 22.747677 loss_rnnt 15.991536 hw_loss 0.242297 lr 0.00049848 rank 6
2023-02-21 23:13:49,030 DEBUG TRAIN Batch 12/500 loss 26.177101 loss_att 28.270586 loss_ctc 25.911348 loss_rnnt 25.638727 hw_loss 0.290833 lr 0.00049852 rank 4
2023-02-21 23:13:49,030 DEBUG TRAIN Batch 12/500 loss 17.549137 loss_att 20.721813 loss_ctc 19.754246 loss_rnnt 16.356686 hw_loss 0.494812 lr 0.00049846 rank 7
2023-02-21 23:13:49,031 DEBUG TRAIN Batch 12/500 loss 11.584473 loss_att 16.077984 loss_ctc 14.118953 loss_rnnt 10.252630 hw_loss 0.178518 lr 0.00049848 rank 5
2023-02-21 23:13:49,034 DEBUG TRAIN Batch 12/500 loss 23.622473 loss_att 21.245296 loss_ctc 24.913637 loss_rnnt 23.595089 hw_loss 0.620000 lr 0.00049853 rank 1
2023-02-21 23:13:49,036 DEBUG TRAIN Batch 12/500 loss 17.651342 loss_att 19.254639 loss_ctc 20.500118 loss_rnnt 16.819786 hw_loss 0.245740 lr 0.00049853 rank 0
2023-02-21 23:15:01,981 DEBUG TRAIN Batch 12/600 loss 19.755087 loss_att 18.455526 loss_ctc 18.993668 loss_rnnt 20.014692 hw_loss 0.190930 lr 0.00049825 rank 3
2023-02-21 23:15:01,985 DEBUG TRAIN Batch 12/600 loss 14.153029 loss_att 16.449621 loss_ctc 16.561533 loss_rnnt 13.250338 hw_loss 0.229196 lr 0.00049823 rank 6
2023-02-21 23:15:01,985 DEBUG TRAIN Batch 12/600 loss 18.954626 loss_att 20.561951 loss_ctc 25.795303 loss_rnnt 17.568058 hw_loss 0.286899 lr 0.00049823 rank 2
2023-02-21 23:15:01,987 DEBUG TRAIN Batch 12/600 loss 7.808829 loss_att 9.439560 loss_ctc 7.178797 loss_rnnt 7.426747 hw_loss 0.262387 lr 0.00049829 rank 1
2023-02-21 23:15:01,987 DEBUG TRAIN Batch 12/600 loss 15.194236 loss_att 19.601442 loss_ctc 17.655060 loss_rnnt 13.865161 hw_loss 0.224107 lr 0.00049827 rank 4
2023-02-21 23:15:01,989 DEBUG TRAIN Batch 12/600 loss 15.983586 loss_att 16.327276 loss_ctc 18.990139 loss_rnnt 15.312855 hw_loss 0.377099 lr 0.00049823 rank 5
2023-02-21 23:15:01,994 DEBUG TRAIN Batch 12/600 loss 15.809283 loss_att 18.012566 loss_ctc 21.082237 loss_rnnt 14.431053 hw_loss 0.439710 lr 0.00049829 rank 0
2023-02-21 23:15:02,037 DEBUG TRAIN Batch 12/600 loss 8.258771 loss_att 10.995150 loss_ctc 9.420813 loss_rnnt 7.469445 hw_loss 0.163330 lr 0.00049821 rank 7
2023-02-21 23:16:17,305 DEBUG TRAIN Batch 12/700 loss 9.711651 loss_att 17.198635 loss_ctc 11.634991 loss_rnnt 7.786390 hw_loss 0.321411 lr 0.00049802 rank 4
2023-02-21 23:16:17,309 DEBUG TRAIN Batch 12/700 loss 13.418453 loss_att 16.232845 loss_ctc 13.957445 loss_rnnt 12.597504 hw_loss 0.349136 lr 0.00049800 rank 3
2023-02-21 23:16:17,309 DEBUG TRAIN Batch 12/700 loss 35.187683 loss_att 45.369541 loss_ctc 34.097927 loss_rnnt 33.199505 hw_loss 0.182074 lr 0.00049798 rank 2
2023-02-21 23:16:17,311 DEBUG TRAIN Batch 12/700 loss 25.602133 loss_att 32.365715 loss_ctc 32.136189 loss_rnnt 23.152046 hw_loss 0.424054 lr 0.00049804 rank 0
2023-02-21 23:16:17,311 DEBUG TRAIN Batch 12/700 loss 17.188492 loss_att 23.513716 loss_ctc 18.429924 loss_rnnt 15.553391 hw_loss 0.383495 lr 0.00049799 rank 6
2023-02-21 23:16:17,317 DEBUG TRAIN Batch 12/700 loss 22.987732 loss_att 29.055662 loss_ctc 30.652512 loss_rnnt 20.541462 hw_loss 0.395086 lr 0.00049799 rank 5
2023-02-21 23:16:17,317 DEBUG TRAIN Batch 12/700 loss 42.613121 loss_att 56.834698 loss_ctc 45.361294 loss_rnnt 39.272884 hw_loss 0.242814 lr 0.00049804 rank 1
2023-02-21 23:16:17,363 DEBUG TRAIN Batch 12/700 loss 22.209618 loss_att 32.627640 loss_ctc 31.912100 loss_rnnt 18.710649 hw_loss 0.228184 lr 0.00049796 rank 7
2023-02-21 23:17:30,072 DEBUG TRAIN Batch 12/800 loss 13.915100 loss_att 19.561098 loss_ctc 24.041988 loss_rnnt 11.314173 hw_loss 0.227766 lr 0.00049774 rank 2
2023-02-21 23:17:30,076 DEBUG TRAIN Batch 12/800 loss 15.016941 loss_att 21.110603 loss_ctc 15.517169 loss_rnnt 13.597702 hw_loss 0.250893 lr 0.00049777 rank 4
2023-02-21 23:17:30,076 DEBUG TRAIN Batch 12/800 loss 27.762115 loss_att 29.587498 loss_ctc 22.556273 loss_rnnt 27.984745 hw_loss 0.199511 lr 0.00049779 rank 1
2023-02-21 23:17:30,076 DEBUG TRAIN Batch 12/800 loss 6.734224 loss_att 15.748768 loss_ctc 10.343218 loss_rnnt 4.402035 hw_loss 0.090153 lr 0.00049772 rank 7
2023-02-21 23:17:30,076 DEBUG TRAIN Batch 12/800 loss 11.653520 loss_att 15.755336 loss_ctc 14.110373 loss_rnnt 10.272680 hw_loss 0.436679 lr 0.00049775 rank 3
2023-02-21 23:17:30,080 DEBUG TRAIN Batch 12/800 loss 27.391039 loss_att 30.749081 loss_ctc 41.414894 loss_rnnt 24.736664 hw_loss 0.211727 lr 0.00049774 rank 5
2023-02-21 23:17:30,080 DEBUG TRAIN Batch 12/800 loss 18.197584 loss_att 23.990320 loss_ctc 16.075012 loss_rnnt 17.182768 hw_loss 0.261149 lr 0.00049779 rank 0
2023-02-21 23:17:30,082 DEBUG TRAIN Batch 12/800 loss 13.972127 loss_att 19.027702 loss_ctc 22.596378 loss_rnnt 11.651117 hw_loss 0.299988 lr 0.00049774 rank 6
2023-02-21 23:18:42,296 DEBUG TRAIN Batch 12/900 loss 23.600533 loss_att 26.673744 loss_ctc 29.266220 loss_rnnt 22.042702 hw_loss 0.352054 lr 0.00049749 rank 2
2023-02-21 23:18:42,297 DEBUG TRAIN Batch 12/900 loss 18.242233 loss_att 21.150618 loss_ctc 24.548275 loss_rnnt 16.660372 hw_loss 0.298833 lr 0.00049753 rank 4
2023-02-21 23:18:42,299 DEBUG TRAIN Batch 12/900 loss 16.148453 loss_att 21.122366 loss_ctc 21.426607 loss_rnnt 14.253213 hw_loss 0.368816 lr 0.00049751 rank 3
2023-02-21 23:18:42,300 DEBUG TRAIN Batch 12/900 loss 23.489376 loss_att 34.562782 loss_ctc 30.321669 loss_rnnt 20.301769 hw_loss 0.116161 lr 0.00049749 rank 5
2023-02-21 23:18:42,300 DEBUG TRAIN Batch 12/900 loss 20.708723 loss_att 25.634909 loss_ctc 24.113562 loss_rnnt 19.108313 hw_loss 0.302243 lr 0.00049749 rank 6
2023-02-21 23:18:42,300 DEBUG TRAIN Batch 12/900 loss 18.343966 loss_att 19.155628 loss_ctc 22.008518 loss_rnnt 17.528749 hw_loss 0.308017 lr 0.00049755 rank 1
2023-02-21 23:18:42,304 DEBUG TRAIN Batch 12/900 loss 20.477451 loss_att 28.925472 loss_ctc 25.267859 loss_rnnt 18.007420 hw_loss 0.265699 lr 0.00049747 rank 7
2023-02-21 23:18:42,305 DEBUG TRAIN Batch 12/900 loss 13.888535 loss_att 20.920214 loss_ctc 18.519733 loss_rnnt 11.798048 hw_loss 0.124986 lr 0.00049755 rank 0
2023-02-21 23:19:54,992 DEBUG TRAIN Batch 12/1000 loss 21.811390 loss_att 23.711887 loss_ctc 29.426960 loss_rnnt 20.323387 hw_loss 0.173425 lr 0.00049725 rank 2
2023-02-21 23:19:54,994 DEBUG TRAIN Batch 12/1000 loss 11.910874 loss_att 14.908927 loss_ctc 14.667143 loss_rnnt 10.800816 hw_loss 0.268022 lr 0.00049726 rank 3
2023-02-21 23:19:54,994 DEBUG TRAIN Batch 12/1000 loss 23.424238 loss_att 25.639385 loss_ctc 24.002913 loss_rnnt 22.738144 hw_loss 0.311080 lr 0.00049728 rank 4
2023-02-21 23:19:54,995 DEBUG TRAIN Batch 12/1000 loss 20.694162 loss_att 26.621983 loss_ctc 26.133095 loss_rnnt 18.584497 hw_loss 0.372952 lr 0.00049730 rank 0
2023-02-21 23:19:54,998 DEBUG TRAIN Batch 12/1000 loss 21.550318 loss_att 25.142525 loss_ctc 22.688105 loss_rnnt 20.556967 hw_loss 0.231008 lr 0.00049725 rank 6
2023-02-21 23:19:55,000 DEBUG TRAIN Batch 12/1000 loss 18.347218 loss_att 22.989040 loss_ctc 24.387997 loss_rnnt 16.473568 hw_loss 0.262213 lr 0.00049723 rank 7
2023-02-21 23:19:55,052 DEBUG TRAIN Batch 12/1000 loss 18.640226 loss_att 23.169542 loss_ctc 18.291096 loss_rnnt 17.657616 hw_loss 0.231186 lr 0.00049730 rank 1
2023-02-21 23:19:55,052 DEBUG TRAIN Batch 12/1000 loss 22.302826 loss_att 27.499680 loss_ctc 27.480032 loss_rnnt 20.378532 hw_loss 0.364929 lr 0.00049725 rank 5
2023-02-21 23:21:09,188 DEBUG TRAIN Batch 12/1100 loss 17.539221 loss_att 19.153370 loss_ctc 20.429804 loss_rnnt 16.725719 hw_loss 0.197364 lr 0.00049700 rank 2
2023-02-21 23:21:09,195 DEBUG TRAIN Batch 12/1100 loss 14.314659 loss_att 17.554962 loss_ctc 17.178286 loss_rnnt 13.139486 hw_loss 0.272430 lr 0.00049705 rank 0
2023-02-21 23:21:09,195 DEBUG TRAIN Batch 12/1100 loss 22.527388 loss_att 23.847183 loss_ctc 27.011847 loss_rnnt 21.446190 hw_loss 0.411207 lr 0.00049698 rank 7
2023-02-21 23:21:09,197 DEBUG TRAIN Batch 12/1100 loss 13.375173 loss_att 18.876808 loss_ctc 16.582285 loss_rnnt 11.673236 hw_loss 0.326241 lr 0.00049704 rank 4
2023-02-21 23:21:09,199 DEBUG TRAIN Batch 12/1100 loss 19.643467 loss_att 21.800863 loss_ctc 23.829865 loss_rnnt 18.492363 hw_loss 0.302695 lr 0.00049701 rank 3
2023-02-21 23:21:09,200 DEBUG TRAIN Batch 12/1100 loss 15.663649 loss_att 18.650322 loss_ctc 19.794399 loss_rnnt 14.331702 hw_loss 0.344711 lr 0.00049700 rank 6
2023-02-21 23:21:09,229 DEBUG TRAIN Batch 12/1100 loss 24.129473 loss_att 25.763519 loss_ctc 29.375076 loss_rnnt 22.917213 hw_loss 0.348817 lr 0.00049705 rank 1
2023-02-21 23:21:09,232 DEBUG TRAIN Batch 12/1100 loss 18.441633 loss_att 20.846170 loss_ctc 23.273865 loss_rnnt 17.222752 hw_loss 0.175642 lr 0.00049700 rank 5
2023-02-21 23:22:21,561 DEBUG TRAIN Batch 12/1200 loss 15.315195 loss_att 17.076279 loss_ctc 16.516094 loss_rnnt 14.664553 hw_loss 0.259322 lr 0.00049675 rank 2
2023-02-21 23:22:21,564 DEBUG TRAIN Batch 12/1200 loss 14.134335 loss_att 18.459652 loss_ctc 16.658653 loss_rnnt 12.855754 hw_loss 0.144267 lr 0.00049676 rank 5
2023-02-21 23:22:21,565 DEBUG TRAIN Batch 12/1200 loss 18.522388 loss_att 19.965418 loss_ctc 21.343985 loss_rnnt 17.707890 hw_loss 0.280650 lr 0.00049679 rank 4
2023-02-21 23:22:21,566 DEBUG TRAIN Batch 12/1200 loss 14.745305 loss_att 19.285095 loss_ctc 19.054184 loss_rnnt 13.155313 hw_loss 0.201593 lr 0.00049676 rank 6
2023-02-21 23:22:21,568 DEBUG TRAIN Batch 12/1200 loss 14.636609 loss_att 15.673172 loss_ctc 16.535349 loss_rnnt 14.018263 hw_loss 0.296003 lr 0.00049677 rank 3
2023-02-21 23:22:21,569 DEBUG TRAIN Batch 12/1200 loss 13.916631 loss_att 17.131042 loss_ctc 18.922779 loss_rnnt 12.468008 hw_loss 0.259227 lr 0.00049681 rank 1
2023-02-21 23:22:21,569 DEBUG TRAIN Batch 12/1200 loss 14.114504 loss_att 16.494011 loss_ctc 21.256561 loss_rnnt 12.571209 hw_loss 0.215847 lr 0.00049673 rank 7
2023-02-21 23:22:21,575 DEBUG TRAIN Batch 12/1200 loss 23.692394 loss_att 24.934719 loss_ctc 29.074347 loss_rnnt 22.592670 hw_loss 0.250619 lr 0.00049681 rank 0
2023-02-21 23:23:34,725 DEBUG TRAIN Batch 12/1300 loss 11.890760 loss_att 15.276979 loss_ctc 15.424545 loss_rnnt 10.606331 hw_loss 0.255026 lr 0.00049651 rank 5
2023-02-21 23:23:34,728 DEBUG TRAIN Batch 12/1300 loss 14.757534 loss_att 21.059765 loss_ctc 15.833601 loss_rnnt 13.201404 hw_loss 0.285391 lr 0.00049655 rank 4
2023-02-21 23:23:34,737 DEBUG TRAIN Batch 12/1300 loss 14.408781 loss_att 21.951391 loss_ctc 16.677679 loss_rnnt 12.454410 hw_loss 0.268745 lr 0.00049651 rank 2
2023-02-21 23:23:34,738 DEBUG TRAIN Batch 12/1300 loss 14.397305 loss_att 18.917717 loss_ctc 25.894512 loss_rnnt 11.800085 hw_loss 0.300333 lr 0.00049652 rank 3
2023-02-21 23:23:34,740 DEBUG TRAIN Batch 12/1300 loss 10.501218 loss_att 12.053242 loss_ctc 11.912951 loss_rnnt 9.820143 hw_loss 0.342074 lr 0.00049651 rank 6
2023-02-21 23:23:34,742 DEBUG TRAIN Batch 12/1300 loss 7.480283 loss_att 8.419893 loss_ctc 8.992847 loss_rnnt 6.852979 hw_loss 0.445701 lr 0.00049656 rank 1
2023-02-21 23:23:34,741 DEBUG TRAIN Batch 12/1300 loss 12.959154 loss_att 14.800001 loss_ctc 14.403793 loss_rnnt 12.181622 hw_loss 0.406397 lr 0.00049649 rank 7
2023-02-21 23:23:34,749 DEBUG TRAIN Batch 12/1300 loss 12.932804 loss_att 15.675217 loss_ctc 14.677876 loss_rnnt 11.978702 hw_loss 0.324267 lr 0.00049656 rank 0
2023-02-21 23:24:48,576 DEBUG TRAIN Batch 12/1400 loss 14.884584 loss_att 14.750504 loss_ctc 17.570015 loss_rnnt 14.467311 hw_loss 0.161308 lr 0.00049630 rank 4
2023-02-21 23:24:48,589 DEBUG TRAIN Batch 12/1400 loss 13.351251 loss_att 18.978266 loss_ctc 17.554298 loss_rnnt 11.543029 hw_loss 0.229522 lr 0.00049625 rank 7
2023-02-21 23:24:48,589 DEBUG TRAIN Batch 12/1400 loss 13.260086 loss_att 20.113224 loss_ctc 12.974246 loss_rnnt 11.820429 hw_loss 0.200890 lr 0.00049628 rank 3
2023-02-21 23:24:48,591 DEBUG TRAIN Batch 12/1400 loss 9.413716 loss_att 14.076359 loss_ctc 11.439082 loss_rnnt 8.071308 hw_loss 0.262181 lr 0.00049626 rank 2
2023-02-21 23:24:48,593 DEBUG TRAIN Batch 12/1400 loss 7.713037 loss_att 11.050339 loss_ctc 7.937738 loss_rnnt 6.819129 hw_loss 0.368414 lr 0.00049632 rank 0
2023-02-21 23:24:48,595 DEBUG TRAIN Batch 12/1400 loss 13.664155 loss_att 18.517683 loss_ctc 16.350201 loss_rnnt 12.155876 hw_loss 0.336436 lr 0.00049632 rank 1
2023-02-21 23:24:48,595 DEBUG TRAIN Batch 12/1400 loss 16.214735 loss_att 18.627224 loss_ctc 23.593130 loss_rnnt 14.494174 hw_loss 0.476770 lr 0.00049627 rank 5
2023-02-21 23:24:48,607 DEBUG TRAIN Batch 12/1400 loss 21.701786 loss_att 25.798159 loss_ctc 35.221149 loss_rnnt 18.983955 hw_loss 0.179950 lr 0.00049627 rank 6
2023-02-21 23:26:01,027 DEBUG TRAIN Batch 12/1500 loss 8.263676 loss_att 16.143944 loss_ctc 11.422388 loss_rnnt 6.203289 hw_loss 0.118446 lr 0.00049602 rank 6
2023-02-21 23:26:01,027 DEBUG TRAIN Batch 12/1500 loss 22.227196 loss_att 27.135624 loss_ctc 27.538692 loss_rnnt 20.395012 hw_loss 0.266807 lr 0.00049604 rank 3
2023-02-21 23:26:01,031 DEBUG TRAIN Batch 12/1500 loss 11.251299 loss_att 15.851638 loss_ctc 14.142979 loss_rnnt 9.862149 hw_loss 0.156607 lr 0.00049602 rank 2
2023-02-21 23:26:01,034 DEBUG TRAIN Batch 12/1500 loss 15.520627 loss_att 21.060005 loss_ctc 14.877170 loss_rnnt 14.385977 hw_loss 0.211070 lr 0.00049606 rank 4
2023-02-21 23:26:01,035 DEBUG TRAIN Batch 12/1500 loss 12.530951 loss_att 19.757513 loss_ctc 18.575317 loss_rnnt 10.131820 hw_loss 0.277319 lr 0.00049600 rank 7
2023-02-21 23:26:01,035 DEBUG TRAIN Batch 12/1500 loss 22.705385 loss_att 29.976902 loss_ctc 22.467901 loss_rnnt 21.204353 hw_loss 0.146986 lr 0.00049607 rank 1
2023-02-21 23:26:01,041 DEBUG TRAIN Batch 12/1500 loss 7.038899 loss_att 11.932134 loss_ctc 8.335474 loss_rnnt 5.678693 hw_loss 0.391278 lr 0.00049607 rank 0
2023-02-21 23:26:01,045 DEBUG TRAIN Batch 12/1500 loss 32.911575 loss_att 37.370548 loss_ctc 36.644073 loss_rnnt 31.340595 hw_loss 0.340344 lr 0.00049602 rank 5
2023-02-21 23:27:13,145 DEBUG TRAIN Batch 12/1600 loss 14.085565 loss_att 21.345978 loss_ctc 21.290552 loss_rnnt 11.537096 hw_loss 0.254475 lr 0.00049578 rank 2
2023-02-21 23:27:13,145 DEBUG TRAIN Batch 12/1600 loss 20.385040 loss_att 24.694977 loss_ctc 24.887470 loss_rnnt 18.756443 hw_loss 0.311784 lr 0.00049576 rank 7
2023-02-21 23:27:13,147 DEBUG TRAIN Batch 12/1600 loss 23.288944 loss_att 27.883709 loss_ctc 24.409023 loss_rnnt 22.161552 hw_loss 0.110803 lr 0.00049578 rank 6
2023-02-21 23:27:13,148 DEBUG TRAIN Batch 12/1600 loss 16.809782 loss_att 21.955791 loss_ctc 17.582367 loss_rnnt 15.521812 hw_loss 0.292045 lr 0.00049579 rank 3
2023-02-21 23:27:13,153 DEBUG TRAIN Batch 12/1600 loss 21.392843 loss_att 23.938578 loss_ctc 35.009357 loss_rnnt 18.872299 hw_loss 0.367239 lr 0.00049583 rank 0
2023-02-21 23:27:13,155 DEBUG TRAIN Batch 12/1600 loss 11.136663 loss_att 12.542126 loss_ctc 11.580746 loss_rnnt 10.735001 hw_loss 0.115048 lr 0.00049583 rank 1
2023-02-21 23:27:13,157 DEBUG TRAIN Batch 12/1600 loss 12.331546 loss_att 14.307384 loss_ctc 12.786703 loss_rnnt 11.743475 hw_loss 0.247904 lr 0.00049578 rank 5
2023-02-21 23:27:13,200 DEBUG TRAIN Batch 12/1600 loss 12.116748 loss_att 16.029835 loss_ctc 13.089816 loss_rnnt 11.096932 hw_loss 0.201477 lr 0.00049581 rank 4
2023-02-21 23:28:26,154 DEBUG TRAIN Batch 12/1700 loss 19.653271 loss_att 22.228310 loss_ctc 26.567585 loss_rnnt 17.994953 hw_loss 0.415124 lr 0.00049559 rank 0
2023-02-21 23:28:26,160 DEBUG TRAIN Batch 12/1700 loss 16.223539 loss_att 20.974621 loss_ctc 20.364464 loss_rnnt 14.502739 hw_loss 0.409611 lr 0.00049553 rank 2
2023-02-21 23:28:26,165 DEBUG TRAIN Batch 12/1700 loss 30.128416 loss_att 33.187149 loss_ctc 37.181122 loss_rnnt 28.417332 hw_loss 0.298074 lr 0.00049555 rank 3
2023-02-21 23:28:26,167 DEBUG TRAIN Batch 12/1700 loss 14.378775 loss_att 17.417084 loss_ctc 21.509428 loss_rnnt 12.590837 hw_loss 0.430355 lr 0.00049551 rank 7
2023-02-21 23:28:26,169 DEBUG TRAIN Batch 12/1700 loss 29.518314 loss_att 35.761509 loss_ctc 39.847984 loss_rnnt 26.774532 hw_loss 0.220977 lr 0.00049554 rank 6
2023-02-21 23:28:26,169 DEBUG TRAIN Batch 12/1700 loss 23.891924 loss_att 33.435219 loss_ctc 26.282509 loss_rnnt 21.540396 hw_loss 0.232736 lr 0.00049559 rank 1
2023-02-21 23:28:26,172 DEBUG TRAIN Batch 12/1700 loss 13.184177 loss_att 17.444145 loss_ctc 13.868801 loss_rnnt 12.037716 hw_loss 0.380972 lr 0.00049554 rank 5
2023-02-21 23:28:26,185 DEBUG TRAIN Batch 12/1700 loss 16.298786 loss_att 23.295555 loss_ctc 24.657944 loss_rnnt 13.666477 hw_loss 0.221999 lr 0.00049557 rank 4
2023-02-21 23:29:41,412 DEBUG TRAIN Batch 12/1800 loss 22.934792 loss_att 23.298576 loss_ctc 27.484213 loss_rnnt 22.120369 hw_loss 0.253266 lr 0.00049534 rank 1
2023-02-21 23:29:41,424 DEBUG TRAIN Batch 12/1800 loss 20.758480 loss_att 20.584270 loss_ctc 26.840900 loss_rnnt 19.802296 hw_loss 0.337570 lr 0.00049529 rank 6
2023-02-21 23:29:41,427 DEBUG TRAIN Batch 12/1800 loss 20.237223 loss_att 23.543217 loss_ctc 24.619045 loss_rnnt 18.811775 hw_loss 0.337512 lr 0.00049529 rank 2
2023-02-21 23:29:41,428 DEBUG TRAIN Batch 12/1800 loss 19.720728 loss_att 23.011913 loss_ctc 24.485567 loss_rnnt 18.170837 hw_loss 0.480636 lr 0.00049530 rank 3
2023-02-21 23:29:41,430 DEBUG TRAIN Batch 12/1800 loss 20.710215 loss_att 24.803677 loss_ctc 22.024645 loss_rnnt 19.594667 hw_loss 0.227990 lr 0.00049527 rank 7
2023-02-21 23:29:41,430 DEBUG TRAIN Batch 12/1800 loss 22.069595 loss_att 28.523354 loss_ctc 23.928614 loss_rnnt 20.423492 hw_loss 0.201531 lr 0.00049533 rank 4
2023-02-21 23:29:41,432 DEBUG TRAIN Batch 12/1800 loss 18.475124 loss_att 26.207588 loss_ctc 20.653620 loss_rnnt 16.459862 hw_loss 0.334319 lr 0.00049529 rank 5
2023-02-21 23:29:41,478 DEBUG TRAIN Batch 12/1800 loss 16.477306 loss_att 19.052528 loss_ctc 17.323614 loss_rnnt 15.685125 hw_loss 0.308054 lr 0.00049534 rank 0
2023-02-21 23:30:54,250 DEBUG TRAIN Batch 12/1900 loss 7.455297 loss_att 9.479555 loss_ctc 7.763072 loss_rnnt 6.937858 hw_loss 0.134157 lr 0.00049505 rank 6
2023-02-21 23:30:54,252 DEBUG TRAIN Batch 12/1900 loss 16.985186 loss_att 14.339842 loss_ctc 19.279646 loss_rnnt 17.026310 hw_loss 0.341281 lr 0.00049503 rank 7
2023-02-21 23:30:54,254 DEBUG TRAIN Batch 12/1900 loss 11.662983 loss_att 16.018597 loss_ctc 10.529696 loss_rnnt 10.865820 hw_loss 0.144647 lr 0.00049506 rank 3
2023-02-21 23:30:54,254 DEBUG TRAIN Batch 12/1900 loss 9.007456 loss_att 8.341368 loss_ctc 8.671318 loss_rnnt 8.907784 hw_loss 0.520701 lr 0.00049505 rank 2
2023-02-21 23:30:54,258 DEBUG TRAIN Batch 12/1900 loss 22.114204 loss_att 22.670630 loss_ctc 26.599394 loss_rnnt 21.166237 hw_loss 0.447482 lr 0.00049508 rank 4
2023-02-21 23:30:54,259 DEBUG TRAIN Batch 12/1900 loss 10.778474 loss_att 14.654251 loss_ctc 10.448412 loss_rnnt 9.929402 hw_loss 0.221107 lr 0.00049510 rank 0
2023-02-21 23:30:54,262 DEBUG TRAIN Batch 12/1900 loss 16.090372 loss_att 17.053020 loss_ctc 19.072758 loss_rnnt 15.340175 hw_loss 0.300030 lr 0.00049505 rank 5
2023-02-21 23:30:54,261 DEBUG TRAIN Batch 12/1900 loss 17.296684 loss_att 18.640110 loss_ctc 19.005020 loss_rnnt 16.649790 hw_loss 0.282061 lr 0.00049510 rank 1
2023-02-21 23:32:07,177 DEBUG TRAIN Batch 12/2000 loss 8.790763 loss_att 13.462349 loss_ctc 9.980089 loss_rnnt 7.619241 hw_loss 0.147425 lr 0.00049480 rank 2
2023-02-21 23:32:07,179 DEBUG TRAIN Batch 12/2000 loss 4.581491 loss_att 7.419914 loss_ctc 2.728970 loss_rnnt 4.137884 hw_loss 0.230486 lr 0.00049482 rank 3
2023-02-21 23:32:07,184 DEBUG TRAIN Batch 12/2000 loss 20.508268 loss_att 28.754726 loss_ctc 24.092360 loss_rnnt 18.295671 hw_loss 0.160176 lr 0.00049479 rank 7
2023-02-21 23:32:07,185 DEBUG TRAIN Batch 12/2000 loss 32.434540 loss_att 34.704102 loss_ctc 35.882111 loss_rnnt 31.302414 hw_loss 0.409751 lr 0.00049486 rank 1
2023-02-21 23:32:07,188 DEBUG TRAIN Batch 12/2000 loss 11.916886 loss_att 15.167308 loss_ctc 11.190510 loss_rnnt 11.255348 hw_loss 0.203070 lr 0.00049481 rank 5
2023-02-21 23:32:07,195 DEBUG TRAIN Batch 12/2000 loss 24.547272 loss_att 31.562414 loss_ctc 21.441038 loss_rnnt 23.394720 hw_loss 0.306917 lr 0.00049481 rank 6
2023-02-21 23:32:07,195 DEBUG TRAIN Batch 12/2000 loss 9.688757 loss_att 10.752448 loss_ctc 10.883749 loss_rnnt 9.087695 hw_loss 0.429358 lr 0.00049486 rank 0
2023-02-21 23:32:07,238 DEBUG TRAIN Batch 12/2000 loss 15.889721 loss_att 18.895472 loss_ctc 15.663319 loss_rnnt 15.281998 hw_loss 0.068925 lr 0.00049484 rank 4
2023-02-21 23:33:21,297 DEBUG TRAIN Batch 12/2100 loss 15.566767 loss_att 21.062635 loss_ctc 21.415642 loss_rnnt 13.647372 hw_loss 0.075697 lr 0.00049460 rank 4
2023-02-21 23:33:21,303 DEBUG TRAIN Batch 12/2100 loss 22.289856 loss_att 27.402632 loss_ctc 20.569408 loss_rnnt 21.430166 hw_loss 0.124739 lr 0.00049456 rank 2
2023-02-21 23:33:21,306 DEBUG TRAIN Batch 12/2100 loss 8.163585 loss_att 14.462198 loss_ctc 6.084302 loss_rnnt 7.098224 hw_loss 0.155391 lr 0.00049456 rank 6
2023-02-21 23:33:21,306 DEBUG TRAIN Batch 12/2100 loss 28.843779 loss_att 37.907269 loss_ctc 40.073212 loss_rnnt 25.447781 hw_loss 0.161334 lr 0.00049458 rank 3
2023-02-21 23:33:21,311 DEBUG TRAIN Batch 12/2100 loss 7.605442 loss_att 13.223055 loss_ctc 9.090526 loss_rnnt 6.089773 hw_loss 0.364005 lr 0.00049462 rank 1
2023-02-21 23:33:21,311 DEBUG TRAIN Batch 12/2100 loss 12.264050 loss_att 16.436520 loss_ctc 14.045035 loss_rnnt 11.096374 hw_loss 0.179471 lr 0.00049462 rank 0
2023-02-21 23:33:21,315 DEBUG TRAIN Batch 12/2100 loss 12.745203 loss_att 15.718073 loss_ctc 16.765892 loss_rnnt 11.531662 hw_loss 0.155392 lr 0.00049456 rank 5
2023-02-21 23:33:21,361 DEBUG TRAIN Batch 12/2100 loss 19.938158 loss_att 23.060970 loss_ctc 29.444990 loss_rnnt 17.937645 hw_loss 0.203201 lr 0.00049454 rank 7
2023-02-21 23:34:34,638 DEBUG TRAIN Batch 12/2200 loss 22.689896 loss_att 27.069126 loss_ctc 23.929319 loss_rnnt 21.547331 hw_loss 0.190244 lr 0.00049432 rank 2
2023-02-21 23:34:34,642 DEBUG TRAIN Batch 12/2200 loss 15.205818 loss_att 20.221489 loss_ctc 16.674101 loss_rnnt 13.932846 hw_loss 0.138876 lr 0.00049430 rank 7
2023-02-21 23:34:34,643 DEBUG TRAIN Batch 12/2200 loss 12.683537 loss_att 14.954401 loss_ctc 16.175060 loss_rnnt 11.566277 hw_loss 0.370410 lr 0.00049432 rank 6
2023-02-21 23:34:34,645 DEBUG TRAIN Batch 12/2200 loss 13.699630 loss_att 16.960766 loss_ctc 13.801264 loss_rnnt 12.901884 hw_loss 0.247441 lr 0.00049432 rank 5
2023-02-21 23:34:34,645 DEBUG TRAIN Batch 12/2200 loss 26.723480 loss_att 33.175995 loss_ctc 30.063406 loss_rnnt 24.913383 hw_loss 0.139258 lr 0.00049434 rank 3
2023-02-21 23:34:34,652 DEBUG TRAIN Batch 12/2200 loss 17.138605 loss_att 22.334251 loss_ctc 21.617176 loss_rnnt 15.374189 hw_loss 0.240270 lr 0.00049437 rank 1
2023-02-21 23:34:34,652 DEBUG TRAIN Batch 12/2200 loss 34.243423 loss_att 32.358479 loss_ctc 45.054962 loss_rnnt 33.087921 hw_loss 0.170533 lr 0.00049437 rank 0
2023-02-21 23:34:34,654 DEBUG TRAIN Batch 12/2200 loss 13.308365 loss_att 17.503508 loss_ctc 15.304335 loss_rnnt 12.006686 hw_loss 0.368477 lr 0.00049436 rank 4
2023-02-21 23:35:46,391 DEBUG TRAIN Batch 12/2300 loss 15.805167 loss_att 16.501675 loss_ctc 19.530312 loss_rnnt 15.049627 hw_loss 0.224161 lr 0.00049408 rank 2
2023-02-21 23:35:46,391 DEBUG TRAIN Batch 12/2300 loss 21.004612 loss_att 25.142897 loss_ctc 28.897385 loss_rnnt 19.035597 hw_loss 0.166853 lr 0.00049409 rank 3
2023-02-21 23:35:46,393 DEBUG TRAIN Batch 12/2300 loss 17.774778 loss_att 19.597582 loss_ctc 22.571495 loss_rnnt 16.565851 hw_loss 0.384009 lr 0.00049408 rank 6
2023-02-21 23:35:46,393 DEBUG TRAIN Batch 12/2300 loss 13.638244 loss_att 15.989031 loss_ctc 18.011948 loss_rnnt 12.491121 hw_loss 0.175882 lr 0.00049412 rank 4
2023-02-21 23:35:46,397 DEBUG TRAIN Batch 12/2300 loss 4.812158 loss_att 9.453578 loss_ctc 5.399096 loss_rnnt 3.663453 hw_loss 0.266555 lr 0.00049413 rank 1
2023-02-21 23:35:46,404 DEBUG TRAIN Batch 12/2300 loss 11.795053 loss_att 16.977602 loss_ctc 14.965895 loss_rnnt 10.197688 hw_loss 0.258893 lr 0.00049413 rank 0
2023-02-21 23:35:46,404 DEBUG TRAIN Batch 12/2300 loss 11.849971 loss_att 15.969084 loss_ctc 13.034543 loss_rnnt 10.754125 hw_loss 0.213901 lr 0.00049408 rank 5
2023-02-21 23:35:46,446 DEBUG TRAIN Batch 12/2300 loss 15.593688 loss_att 16.001974 loss_ctc 18.348507 loss_rnnt 14.974633 hw_loss 0.318916 lr 0.00049406 rank 7
2023-02-21 23:36:58,703 DEBUG TRAIN Batch 12/2400 loss 10.599492 loss_att 14.772798 loss_ctc 11.450783 loss_rnnt 9.538688 hw_loss 0.211196 lr 0.00049385 rank 3
2023-02-21 23:36:58,703 DEBUG TRAIN Batch 12/2400 loss 13.974227 loss_att 16.548216 loss_ctc 17.713284 loss_rnnt 12.865266 hw_loss 0.179294 lr 0.00049384 rank 2
2023-02-21 23:36:58,704 DEBUG TRAIN Batch 12/2400 loss 16.188473 loss_att 19.671848 loss_ctc 19.463638 loss_rnnt 14.939997 hw_loss 0.215837 lr 0.00049384 rank 6
2023-02-21 23:36:58,704 DEBUG TRAIN Batch 12/2400 loss 30.188612 loss_att 35.033100 loss_ctc 45.411835 loss_rnnt 27.016380 hw_loss 0.325447 lr 0.00049389 rank 0
2023-02-21 23:36:58,704 DEBUG TRAIN Batch 12/2400 loss 14.465569 loss_att 16.940868 loss_ctc 14.434311 loss_rnnt 13.813324 hw_loss 0.302538 lr 0.00049382 rank 7
2023-02-21 23:36:58,709 DEBUG TRAIN Batch 12/2400 loss 12.997380 loss_att 14.769876 loss_ctc 16.350883 loss_rnnt 11.998565 hw_loss 0.369719 lr 0.00049387 rank 4
2023-02-21 23:36:58,723 DEBUG TRAIN Batch 12/2400 loss 16.008492 loss_att 20.338238 loss_ctc 22.022259 loss_rnnt 14.104099 hw_loss 0.443639 lr 0.00049384 rank 5
2023-02-21 23:36:58,724 DEBUG TRAIN Batch 12/2400 loss 9.648773 loss_att 14.717312 loss_ctc 11.652461 loss_rnnt 8.137530 hw_loss 0.431958 lr 0.00049389 rank 1
2023-02-21 23:38:13,784 DEBUG TRAIN Batch 12/2500 loss 14.488788 loss_att 17.115421 loss_ctc 16.762762 loss_rnnt 13.382812 hw_loss 0.520223 lr 0.00049360 rank 2
2023-02-21 23:38:13,788 DEBUG TRAIN Batch 12/2500 loss 22.125959 loss_att 28.578060 loss_ctc 22.802132 loss_rnnt 20.554159 hw_loss 0.358550 lr 0.00049365 rank 0
2023-02-21 23:38:13,788 DEBUG TRAIN Batch 12/2500 loss 14.381338 loss_att 14.719373 loss_ctc 14.822837 loss_rnnt 14.127481 hw_loss 0.238843 lr 0.00049358 rank 7
2023-02-21 23:38:13,789 DEBUG TRAIN Batch 12/2500 loss 28.274797 loss_att 26.736364 loss_ctc 28.301535 loss_rnnt 28.359228 hw_loss 0.411921 lr 0.00049363 rank 4
2023-02-21 23:38:13,791 DEBUG TRAIN Batch 12/2500 loss 12.505119 loss_att 14.401290 loss_ctc 15.098900 loss_rnnt 11.541127 hw_loss 0.447977 lr 0.00049360 rank 6
2023-02-21 23:38:13,792 DEBUG TRAIN Batch 12/2500 loss 16.409012 loss_att 20.625740 loss_ctc 19.463598 loss_rnnt 15.058603 hw_loss 0.187096 lr 0.00049360 rank 5
2023-02-21 23:38:13,796 DEBUG TRAIN Batch 12/2500 loss 12.843498 loss_att 19.588799 loss_ctc 19.865852 loss_rnnt 10.418061 hw_loss 0.262616 lr 0.00049361 rank 3
2023-02-21 23:38:13,801 DEBUG TRAIN Batch 12/2500 loss 14.077611 loss_att 16.235868 loss_ctc 15.693021 loss_rnnt 13.248733 hw_loss 0.340946 lr 0.00049365 rank 1
2023-02-21 23:39:26,171 DEBUG TRAIN Batch 12/2600 loss 15.217611 loss_att 15.460543 loss_ctc 18.997114 loss_rnnt 14.548245 hw_loss 0.219085 lr 0.00049336 rank 6
2023-02-21 23:39:26,172 DEBUG TRAIN Batch 12/2600 loss 14.944573 loss_att 23.122126 loss_ctc 17.631241 loss_rnnt 12.757007 hw_loss 0.363439 lr 0.00049336 rank 2
2023-02-21 23:39:26,174 DEBUG TRAIN Batch 12/2600 loss 23.211740 loss_att 28.190237 loss_ctc 28.386688 loss_rnnt 21.395245 hw_loss 0.245263 lr 0.00049339 rank 4
2023-02-21 23:39:26,174 DEBUG TRAIN Batch 12/2600 loss 18.206785 loss_att 24.206572 loss_ctc 23.079359 loss_rnnt 16.267513 hw_loss 0.168073 lr 0.00049337 rank 3
2023-02-21 23:39:26,177 DEBUG TRAIN Batch 12/2600 loss 8.761103 loss_att 17.910194 loss_ctc 7.953625 loss_rnnt 6.922264 hw_loss 0.218781 lr 0.00049334 rank 7
2023-02-21 23:39:26,184 DEBUG TRAIN Batch 12/2600 loss 14.974628 loss_att 25.940990 loss_ctc 15.457458 loss_rnnt 12.502367 hw_loss 0.402396 lr 0.00049341 rank 1
2023-02-21 23:39:26,185 DEBUG TRAIN Batch 12/2600 loss 11.470341 loss_att 17.966431 loss_ctc 14.165816 loss_rnnt 9.667599 hw_loss 0.270240 lr 0.00049336 rank 5
2023-02-21 23:39:26,188 DEBUG TRAIN Batch 12/2600 loss 13.116813 loss_att 15.010197 loss_ctc 16.210569 loss_rnnt 12.058601 hw_loss 0.500689 lr 0.00049341 rank 0
2023-02-21 23:40:37,983 DEBUG TRAIN Batch 12/2700 loss 8.573487 loss_att 11.645430 loss_ctc 8.342002 loss_rnnt 7.904140 hw_loss 0.160918 lr 0.00049312 rank 6
2023-02-21 23:40:37,985 DEBUG TRAIN Batch 12/2700 loss 8.889087 loss_att 12.587543 loss_ctc 9.611506 loss_rnnt 7.962621 hw_loss 0.169597 lr 0.00049313 rank 3
2023-02-21 23:40:37,986 DEBUG TRAIN Batch 12/2700 loss 20.016438 loss_att 21.545885 loss_ctc 27.295300 loss_rnnt 18.699043 hw_loss 0.076858 lr 0.00049312 rank 2
2023-02-21 23:40:37,986 DEBUG TRAIN Batch 12/2700 loss 15.055749 loss_att 18.269264 loss_ctc 19.337711 loss_rnnt 13.731384 hw_loss 0.207624 lr 0.00049315 rank 4
2023-02-21 23:40:37,991 DEBUG TRAIN Batch 12/2700 loss 11.483692 loss_att 11.992755 loss_ctc 10.953456 loss_rnnt 11.274616 hw_loss 0.333680 lr 0.00049317 rank 1
2023-02-21 23:40:37,993 DEBUG TRAIN Batch 12/2700 loss 14.418478 loss_att 19.513536 loss_ctc 18.626957 loss_rnnt 12.548160 hw_loss 0.544080 lr 0.00049310 rank 7
2023-02-21 23:40:38,013 DEBUG TRAIN Batch 12/2700 loss 6.532733 loss_att 11.147164 loss_ctc 10.495825 loss_rnnt 4.867923 hw_loss 0.400335 lr 0.00049317 rank 0
2023-02-21 23:40:38,030 DEBUG TRAIN Batch 12/2700 loss 16.815987 loss_att 19.912354 loss_ctc 21.647223 loss_rnnt 15.429903 hw_loss 0.229959 lr 0.00049312 rank 5
2023-02-21 23:41:51,914 DEBUG TRAIN Batch 12/2800 loss 16.515556 loss_att 18.853636 loss_ctc 20.920254 loss_rnnt 15.317701 hw_loss 0.268027 lr 0.00049286 rank 7
2023-02-21 23:41:51,920 DEBUG TRAIN Batch 12/2800 loss 9.330132 loss_att 13.794989 loss_ctc 11.849289 loss_rnnt 7.952464 hw_loss 0.279019 lr 0.00049289 rank 3
2023-02-21 23:41:51,922 DEBUG TRAIN Batch 12/2800 loss 29.450321 loss_att 29.073963 loss_ctc 39.708275 loss_rnnt 27.992552 hw_loss 0.309962 lr 0.00049288 rank 6
2023-02-21 23:41:51,923 DEBUG TRAIN Batch 12/2800 loss 12.739321 loss_att 19.852503 loss_ctc 18.192139 loss_rnnt 10.500522 hw_loss 0.167099 lr 0.00049288 rank 2
2023-02-21 23:41:51,926 DEBUG TRAIN Batch 12/2800 loss 15.810826 loss_att 17.103346 loss_ctc 22.649136 loss_rnnt 14.465446 hw_loss 0.328316 lr 0.00049293 rank 1
2023-02-21 23:41:51,930 DEBUG TRAIN Batch 12/2800 loss 8.358128 loss_att 14.450809 loss_ctc 16.990772 loss_rnnt 5.865552 hw_loss 0.230659 lr 0.00049288 rank 5
2023-02-21 23:41:51,933 DEBUG TRAIN Batch 12/2800 loss 18.245497 loss_att 22.988880 loss_ctc 25.231911 loss_rnnt 16.259068 hw_loss 0.199178 lr 0.00049293 rank 0
2023-02-21 23:41:51,973 DEBUG TRAIN Batch 12/2800 loss 13.825701 loss_att 18.721458 loss_ctc 20.113445 loss_rnnt 11.914432 hw_loss 0.175783 lr 0.00049291 rank 4
2023-02-21 23:43:04,890 DEBUG TRAIN Batch 12/2900 loss 8.655390 loss_att 12.042096 loss_ctc 10.903238 loss_rnnt 7.542003 hw_loss 0.255623 lr 0.00049265 rank 3
2023-02-21 23:43:04,891 DEBUG TRAIN Batch 12/2900 loss 13.383905 loss_att 17.302902 loss_ctc 19.525154 loss_rnnt 11.706495 hw_loss 0.140210 lr 0.00049262 rank 7
2023-02-21 23:43:04,892 DEBUG TRAIN Batch 12/2900 loss 20.235806 loss_att 25.196495 loss_ctc 28.977142 loss_rnnt 17.928299 hw_loss 0.280981 lr 0.00049264 rank 2
2023-02-21 23:43:04,893 DEBUG TRAIN Batch 12/2900 loss 20.123938 loss_att 22.576105 loss_ctc 26.026779 loss_rnnt 18.648090 hw_loss 0.371941 lr 0.00049264 rank 6
2023-02-21 23:43:04,894 DEBUG TRAIN Batch 12/2900 loss 17.063671 loss_att 20.869976 loss_ctc 22.744190 loss_rnnt 15.421185 hw_loss 0.232166 lr 0.00049269 rank 0
2023-02-21 23:43:04,895 DEBUG TRAIN Batch 12/2900 loss 16.761177 loss_att 22.375912 loss_ctc 22.380590 loss_rnnt 14.749710 hw_loss 0.261119 lr 0.00049269 rank 1
2023-02-21 23:43:04,896 DEBUG TRAIN Batch 12/2900 loss 34.839947 loss_att 38.825027 loss_ctc 46.472366 loss_rnnt 32.415203 hw_loss 0.143888 lr 0.00049267 rank 4
2023-02-21 23:43:04,904 DEBUG TRAIN Batch 12/2900 loss 9.681769 loss_att 14.843683 loss_ctc 12.373116 loss_rnnt 8.113596 hw_loss 0.331770 lr 0.00049264 rank 5
2023-02-21 23:44:16,584 DEBUG TRAIN Batch 12/3000 loss 7.152142 loss_att 13.556211 loss_ctc 9.128159 loss_rnnt 5.472748 hw_loss 0.253333 lr 0.00049240 rank 2
2023-02-21 23:44:16,587 DEBUG TRAIN Batch 12/3000 loss 16.345724 loss_att 18.884300 loss_ctc 20.046665 loss_rnnt 15.157308 hw_loss 0.351082 lr 0.00049245 rank 1
2023-02-21 23:44:16,587 DEBUG TRAIN Batch 12/3000 loss 6.075742 loss_att 10.904410 loss_ctc 9.792718 loss_rnnt 4.444392 hw_loss 0.318786 lr 0.00049244 rank 4
2023-02-21 23:44:16,589 DEBUG TRAIN Batch 12/3000 loss 17.173025 loss_att 21.580730 loss_ctc 22.477736 loss_rnnt 15.405734 hw_loss 0.334602 lr 0.00049240 rank 5
2023-02-21 23:44:16,591 DEBUG TRAIN Batch 12/3000 loss 10.357953 loss_att 14.230141 loss_ctc 12.351114 loss_rnnt 9.119534 hw_loss 0.371673 lr 0.00049245 rank 0
2023-02-21 23:44:16,592 DEBUG TRAIN Batch 12/3000 loss 13.742388 loss_att 13.141472 loss_ctc 15.278707 loss_rnnt 13.435538 hw_loss 0.416606 lr 0.00049241 rank 3
2023-02-21 23:44:16,593 DEBUG TRAIN Batch 12/3000 loss 23.876820 loss_att 31.690449 loss_ctc 35.702454 loss_rnnt 20.657915 hw_loss 0.148925 lr 0.00049238 rank 7
2023-02-21 23:44:17,009 DEBUG TRAIN Batch 12/3000 loss 15.829229 loss_att 20.871212 loss_ctc 22.161127 loss_rnnt 13.750792 hw_loss 0.423352 lr 0.00049240 rank 6
2023-02-21 23:45:32,016 DEBUG TRAIN Batch 12/3100 loss 11.056840 loss_att 15.457763 loss_ctc 16.945713 loss_rnnt 9.272360 hw_loss 0.223336 lr 0.00049216 rank 2
2023-02-21 23:45:32,026 DEBUG TRAIN Batch 12/3100 loss 20.422689 loss_att 25.602917 loss_ctc 26.671232 loss_rnnt 18.347666 hw_loss 0.385947 lr 0.00049216 rank 5
2023-02-21 23:45:32,028 DEBUG TRAIN Batch 12/3100 loss 11.910610 loss_att 16.916895 loss_ctc 13.540394 loss_rnnt 10.566033 hw_loss 0.236278 lr 0.00049221 rank 0
2023-02-21 23:45:32,032 DEBUG TRAIN Batch 12/3100 loss 18.540247 loss_att 25.622698 loss_ctc 21.387602 loss_rnnt 16.579128 hw_loss 0.309340 lr 0.00049216 rank 6
2023-02-21 23:45:32,037 DEBUG TRAIN Batch 12/3100 loss 8.701639 loss_att 9.382814 loss_ctc 9.594774 loss_rnnt 8.230480 hw_loss 0.404699 lr 0.00049218 rank 3
2023-02-21 23:45:32,041 DEBUG TRAIN Batch 12/3100 loss 17.144096 loss_att 20.684484 loss_ctc 21.591429 loss_rnnt 15.743850 hw_loss 0.185984 lr 0.00049214 rank 7
2023-02-21 23:45:32,044 DEBUG TRAIN Batch 12/3100 loss 12.772269 loss_att 17.093346 loss_ctc 18.046736 loss_rnnt 11.124090 hw_loss 0.151317 lr 0.00049221 rank 1
2023-02-21 23:45:32,057 DEBUG TRAIN Batch 12/3100 loss 15.479342 loss_att 17.868555 loss_ctc 19.427395 loss_rnnt 14.297248 hw_loss 0.333459 lr 0.00049220 rank 4
2023-02-21 23:46:47,404 DEBUG TRAIN Batch 12/3200 loss 13.254661 loss_att 12.320796 loss_ctc 15.437712 loss_rnnt 12.970978 hw_loss 0.336342 lr 0.00049192 rank 2
2023-02-21 23:46:47,409 DEBUG TRAIN Batch 12/3200 loss 12.128675 loss_att 11.534302 loss_ctc 14.238497 loss_rnnt 11.556937 hw_loss 0.767441 lr 0.00049196 rank 4
2023-02-21 23:46:47,409 DEBUG TRAIN Batch 12/3200 loss 12.021847 loss_att 13.403583 loss_ctc 13.707407 loss_rnnt 11.295074 hw_loss 0.423156 lr 0.00049197 rank 0
2023-02-21 23:46:47,409 DEBUG TRAIN Batch 12/3200 loss 13.194504 loss_att 13.059709 loss_ctc 14.367055 loss_rnnt 12.789552 hw_loss 0.516693 lr 0.00049192 rank 5
2023-02-21 23:46:47,410 DEBUG TRAIN Batch 12/3200 loss 17.580721 loss_att 17.278774 loss_ctc 18.853708 loss_rnnt 17.219299 hw_loss 0.472648 lr 0.00049190 rank 7
2023-02-21 23:46:47,413 DEBUG TRAIN Batch 12/3200 loss 19.398396 loss_att 22.719711 loss_ctc 22.918280 loss_rnnt 18.156193 hw_loss 0.203669 lr 0.00049192 rank 6
2023-02-21 23:46:47,452 DEBUG TRAIN Batch 12/3200 loss 13.867595 loss_att 17.729427 loss_ctc 16.502483 loss_rnnt 12.596489 hw_loss 0.276413 lr 0.00049194 rank 3
2023-02-21 23:46:47,460 DEBUG TRAIN Batch 12/3200 loss 13.655975 loss_att 14.211639 loss_ctc 16.878183 loss_rnnt 12.843587 hw_loss 0.509299 lr 0.00049197 rank 1
2023-02-21 23:48:00,298 DEBUG TRAIN Batch 12/3300 loss 19.336891 loss_att 21.776829 loss_ctc 18.769501 loss_rnnt 18.779804 hw_loss 0.271404 lr 0.00049170 rank 3
2023-02-21 23:48:00,302 DEBUG TRAIN Batch 12/3300 loss 17.340878 loss_att 25.279652 loss_ctc 25.478817 loss_rnnt 14.608573 hw_loss 0.111544 lr 0.00049168 rank 2
2023-02-21 23:48:00,306 DEBUG TRAIN Batch 12/3300 loss 18.206060 loss_att 26.353775 loss_ctc 21.370861 loss_rnnt 16.033506 hw_loss 0.226947 lr 0.00049167 rank 7
2023-02-21 23:48:00,307 DEBUG TRAIN Batch 12/3300 loss 13.177438 loss_att 15.910240 loss_ctc 15.100433 loss_rnnt 12.283301 hw_loss 0.170959 lr 0.00049169 rank 5
2023-02-21 23:48:00,310 DEBUG TRAIN Batch 12/3300 loss 14.613302 loss_att 16.842175 loss_ctc 18.164227 loss_rnnt 13.588104 hw_loss 0.198688 lr 0.00049169 rank 6
2023-02-21 23:48:00,329 DEBUG TRAIN Batch 12/3300 loss 8.663354 loss_att 15.635969 loss_ctc 10.947075 loss_rnnt 6.810802 hw_loss 0.287875 lr 0.00049174 rank 1
2023-02-21 23:48:00,331 DEBUG TRAIN Batch 12/3300 loss 14.010265 loss_att 20.264442 loss_ctc 21.035051 loss_rnnt 11.665714 hw_loss 0.294522 lr 0.00049172 rank 4
2023-02-21 23:48:00,355 DEBUG TRAIN Batch 12/3300 loss 18.090517 loss_att 26.861679 loss_ctc 25.892635 loss_rnnt 15.217209 hw_loss 0.147739 lr 0.00049174 rank 0
2023-02-21 23:49:12,387 DEBUG TRAIN Batch 12/3400 loss 20.748621 loss_att 25.070210 loss_ctc 26.256893 loss_rnnt 19.027149 hw_loss 0.230095 lr 0.00049145 rank 2
2023-02-21 23:49:12,389 DEBUG TRAIN Batch 12/3400 loss 23.202522 loss_att 30.275433 loss_ctc 36.194153 loss_rnnt 19.916265 hw_loss 0.261482 lr 0.00049150 rank 1
2023-02-21 23:49:12,390 DEBUG TRAIN Batch 12/3400 loss 21.948645 loss_att 24.779264 loss_ctc 24.525906 loss_rnnt 20.889359 hw_loss 0.280359 lr 0.00049146 rank 3
2023-02-21 23:49:12,394 DEBUG TRAIN Batch 12/3400 loss 7.037463 loss_att 11.357209 loss_ctc 9.836142 loss_rnnt 5.689281 hw_loss 0.208267 lr 0.00049143 rank 7
2023-02-21 23:49:12,395 DEBUG TRAIN Batch 12/3400 loss 18.212534 loss_att 24.956457 loss_ctc 24.720848 loss_rnnt 15.855993 hw_loss 0.262464 lr 0.00049150 rank 0
2023-02-21 23:49:12,395 DEBUG TRAIN Batch 12/3400 loss 6.185243 loss_att 8.232316 loss_ctc 6.513696 loss_rnnt 5.604049 hw_loss 0.239973 lr 0.00049148 rank 4
2023-02-21 23:49:12,396 DEBUG TRAIN Batch 12/3400 loss 18.956156 loss_att 22.322475 loss_ctc 23.699728 loss_rnnt 17.395897 hw_loss 0.477225 lr 0.00049145 rank 6
2023-02-21 23:49:12,400 DEBUG TRAIN Batch 12/3400 loss 17.103525 loss_att 20.470015 loss_ctc 23.092316 loss_rnnt 15.513259 hw_loss 0.222116 lr 0.00049145 rank 5
2023-02-21 23:50:25,918 DEBUG TRAIN Batch 12/3500 loss 10.285501 loss_att 12.332815 loss_ctc 15.554895 loss_rnnt 8.974069 hw_loss 0.373845 lr 0.00049125 rank 4
2023-02-21 23:50:25,930 DEBUG TRAIN Batch 12/3500 loss 9.218935 loss_att 12.737082 loss_ctc 11.622039 loss_rnnt 8.081091 hw_loss 0.213377 lr 0.00049122 rank 3
2023-02-21 23:50:25,931 DEBUG TRAIN Batch 12/3500 loss 15.880171 loss_att 17.694458 loss_ctc 17.099586 loss_rnnt 15.269665 hw_loss 0.159486 lr 0.00049126 rank 1
2023-02-21 23:50:25,931 DEBUG TRAIN Batch 12/3500 loss 13.565415 loss_att 16.649189 loss_ctc 17.078308 loss_rnnt 12.355376 hw_loss 0.234186 lr 0.00049121 rank 2
2023-02-21 23:50:25,933 DEBUG TRAIN Batch 12/3500 loss 25.031788 loss_att 32.395210 loss_ctc 22.210598 loss_rnnt 23.852989 hw_loss 0.154262 lr 0.00049119 rank 7
2023-02-21 23:50:25,935 DEBUG TRAIN Batch 12/3500 loss 20.329847 loss_att 27.883432 loss_ctc 26.637547 loss_rnnt 17.844433 hw_loss 0.250631 lr 0.00049121 rank 6
2023-02-21 23:50:25,934 DEBUG TRAIN Batch 12/3500 loss 24.316521 loss_att 30.889038 loss_ctc 33.499142 loss_rnnt 21.661291 hw_loss 0.218207 lr 0.00049126 rank 0
2023-02-21 23:50:25,939 DEBUG TRAIN Batch 12/3500 loss 17.150127 loss_att 20.286537 loss_ctc 22.001617 loss_rnnt 15.755821 hw_loss 0.225296 lr 0.00049121 rank 5
2023-02-21 23:51:38,796 DEBUG TRAIN Batch 12/3600 loss 19.936371 loss_att 22.941723 loss_ctc 27.019884 loss_rnnt 18.338703 hw_loss 0.097738 lr 0.00049099 rank 3
2023-02-21 23:51:38,796 DEBUG TRAIN Batch 12/3600 loss 13.539186 loss_att 14.267060 loss_ctc 16.049385 loss_rnnt 12.938171 hw_loss 0.226397 lr 0.00049097 rank 2
2023-02-21 23:51:38,797 DEBUG TRAIN Batch 12/3600 loss 18.135782 loss_att 21.068066 loss_ctc 22.317486 loss_rnnt 16.832911 hw_loss 0.297851 lr 0.00049101 rank 4
2023-02-21 23:51:38,797 DEBUG TRAIN Batch 12/3600 loss 14.571892 loss_att 17.692562 loss_ctc 20.410963 loss_rnnt 13.105102 hw_loss 0.120212 lr 0.00049098 rank 6
2023-02-21 23:51:38,798 DEBUG TRAIN Batch 12/3600 loss 26.960171 loss_att 31.345917 loss_ctc 29.515120 loss_rnnt 25.655758 hw_loss 0.162385 lr 0.00049103 rank 0
2023-02-21 23:51:38,804 DEBUG TRAIN Batch 12/3600 loss 11.015720 loss_att 13.711537 loss_ctc 12.601465 loss_rnnt 10.214413 hw_loss 0.095086 lr 0.00049095 rank 7
2023-02-21 23:51:38,805 DEBUG TRAIN Batch 12/3600 loss 17.430141 loss_att 24.468275 loss_ctc 25.990467 loss_rnnt 14.768791 hw_loss 0.210649 lr 0.00049098 rank 5
2023-02-21 23:51:38,814 DEBUG TRAIN Batch 12/3600 loss 23.168264 loss_att 29.913557 loss_ctc 24.968903 loss_rnnt 21.432707 hw_loss 0.274526 lr 0.00049103 rank 1
2023-02-21 23:52:50,962 DEBUG TRAIN Batch 12/3700 loss 15.600809 loss_att 21.455093 loss_ctc 18.776133 loss_rnnt 13.853523 hw_loss 0.286974 lr 0.00049079 rank 1
2023-02-21 23:52:50,962 DEBUG TRAIN Batch 12/3700 loss 9.154926 loss_att 9.947217 loss_ctc 10.953361 loss_rnnt 8.528147 hw_loss 0.428495 lr 0.00049075 rank 3
2023-02-21 23:52:50,965 DEBUG TRAIN Batch 12/3700 loss 3.959118 loss_att 8.838521 loss_ctc 4.222617 loss_rnnt 2.826738 hw_loss 0.227562 lr 0.00049077 rank 4
2023-02-21 23:52:50,968 DEBUG TRAIN Batch 12/3700 loss 14.302045 loss_att 17.272411 loss_ctc 17.474167 loss_rnnt 13.135166 hw_loss 0.280979 lr 0.00049079 rank 0
2023-02-21 23:52:50,967 DEBUG TRAIN Batch 12/3700 loss 14.142509 loss_att 18.314026 loss_ctc 19.671022 loss_rnnt 12.377055 hw_loss 0.363782 lr 0.00049074 rank 2
2023-02-21 23:52:50,970 DEBUG TRAIN Batch 12/3700 loss 5.183233 loss_att 9.633539 loss_ctc 5.567466 loss_rnnt 4.078838 hw_loss 0.305819 lr 0.00049072 rank 7
2023-02-21 23:52:50,978 DEBUG TRAIN Batch 12/3700 loss 23.367725 loss_att 30.682407 loss_ctc 26.723883 loss_rnnt 21.302464 hw_loss 0.290317 lr 0.00049074 rank 6
2023-02-21 23:52:51,017 DEBUG TRAIN Batch 12/3700 loss 21.040262 loss_att 21.293198 loss_ctc 24.052858 loss_rnnt 20.485653 hw_loss 0.191891 lr 0.00049074 rank 5
2023-02-21 23:54:03,378 DEBUG TRAIN Batch 12/3800 loss 17.575274 loss_att 18.214413 loss_ctc 25.210960 loss_rnnt 16.259787 hw_loss 0.317939 lr 0.00049050 rank 2
2023-02-21 23:54:03,382 DEBUG TRAIN Batch 12/3800 loss 10.901505 loss_att 16.145845 loss_ctc 11.959785 loss_rnnt 9.586020 hw_loss 0.235339 lr 0.00049051 rank 3
2023-02-21 23:54:03,382 DEBUG TRAIN Batch 12/3800 loss 12.802843 loss_att 15.649318 loss_ctc 14.937528 loss_rnnt 11.829735 hw_loss 0.223478 lr 0.00049055 rank 0
2023-02-21 23:54:03,386 DEBUG TRAIN Batch 12/3800 loss 22.657358 loss_att 23.699144 loss_ctc 30.122467 loss_rnnt 21.316141 hw_loss 0.257831 lr 0.00049050 rank 6
2023-02-21 23:54:03,386 DEBUG TRAIN Batch 12/3800 loss 16.217241 loss_att 18.032150 loss_ctc 21.595303 loss_rnnt 15.014080 hw_loss 0.230824 lr 0.00049050 rank 5
2023-02-21 23:54:03,389 DEBUG TRAIN Batch 12/3800 loss 21.622414 loss_att 28.185186 loss_ctc 26.891754 loss_rnnt 19.444799 hw_loss 0.304655 lr 0.00049048 rank 7
2023-02-21 23:54:03,392 DEBUG TRAIN Batch 12/3800 loss 17.442261 loss_att 18.212833 loss_ctc 18.323519 loss_rnnt 17.033331 hw_loss 0.257462 lr 0.00049054 rank 4
2023-02-21 23:54:03,430 DEBUG TRAIN Batch 12/3800 loss 9.044762 loss_att 14.140317 loss_ctc 11.120123 loss_rnnt 7.569458 hw_loss 0.336520 lr 0.00049055 rank 1
2023-02-21 23:55:19,240 DEBUG TRAIN Batch 12/3900 loss 8.778926 loss_att 12.002414 loss_ctc 7.934256 loss_rnnt 8.039375 hw_loss 0.389016 lr 0.00049026 rank 2
2023-02-21 23:55:19,242 DEBUG TRAIN Batch 12/3900 loss 9.501873 loss_att 11.088737 loss_ctc 10.495859 loss_rnnt 8.928720 hw_loss 0.231090 lr 0.00049028 rank 3
2023-02-21 23:55:19,245 DEBUG TRAIN Batch 12/3900 loss 30.296242 loss_att 30.121557 loss_ctc 34.888390 loss_rnnt 29.538189 hw_loss 0.338822 lr 0.00049027 rank 6
2023-02-21 23:55:19,247 DEBUG TRAIN Batch 12/3900 loss 24.688183 loss_att 26.473684 loss_ctc 25.573086 loss_rnnt 24.069557 hw_loss 0.269135 lr 0.00049025 rank 7
2023-02-21 23:55:19,249 DEBUG TRAIN Batch 12/3900 loss 13.595719 loss_att 11.269714 loss_ctc 15.785704 loss_rnnt 13.577796 hw_loss 0.358361 lr 0.00049032 rank 1
2023-02-21 23:55:19,250 DEBUG TRAIN Batch 12/3900 loss 22.174223 loss_att 20.725716 loss_ctc 25.979559 loss_rnnt 21.679693 hw_loss 0.519098 lr 0.00049032 rank 0
2023-02-21 23:55:19,257 DEBUG TRAIN Batch 12/3900 loss 10.913770 loss_att 15.882059 loss_ctc 17.657724 loss_rnnt 8.973185 hw_loss 0.089501 lr 0.00049027 rank 5
2023-02-21 23:55:19,268 DEBUG TRAIN Batch 12/3900 loss 22.069307 loss_att 28.804726 loss_ctc 30.756771 loss_rnnt 19.399178 hw_loss 0.308842 lr 0.00049030 rank 4
2023-02-21 23:56:31,147 DEBUG TRAIN Batch 12/4000 loss 12.849312 loss_att 16.427147 loss_ctc 15.259939 loss_rnnt 11.684429 hw_loss 0.239808 lr 0.00049004 rank 3
2023-02-21 23:56:31,165 DEBUG TRAIN Batch 12/4000 loss 10.901961 loss_att 16.898170 loss_ctc 11.039577 loss_rnnt 9.637630 hw_loss 0.087636 lr 0.00049003 rank 2
2023-02-21 23:56:31,166 DEBUG TRAIN Batch 12/4000 loss 17.010164 loss_att 23.002911 loss_ctc 21.395964 loss_rnnt 15.167026 hw_loss 0.112151 lr 0.00049008 rank 1
2023-02-21 23:56:31,169 DEBUG TRAIN Batch 12/4000 loss 13.170076 loss_att 21.058296 loss_ctc 18.217892 loss_rnnt 10.829477 hw_loss 0.168585 lr 0.00049003 rank 6
2023-02-21 23:56:31,170 DEBUG TRAIN Batch 12/4000 loss 7.435798 loss_att 12.355474 loss_ctc 7.263577 loss_rnnt 6.279674 hw_loss 0.365909 lr 0.00049008 rank 0
2023-02-21 23:56:31,172 DEBUG TRAIN Batch 12/4000 loss 11.993917 loss_att 20.163855 loss_ctc 13.739818 loss_rnnt 9.930433 hw_loss 0.368830 lr 0.00049006 rank 4
2023-02-21 23:56:31,171 DEBUG TRAIN Batch 12/4000 loss 13.697333 loss_att 14.719252 loss_ctc 17.654442 loss_rnnt 12.809626 hw_loss 0.291954 lr 0.00049003 rank 5
2023-02-21 23:56:31,173 DEBUG TRAIN Batch 12/4000 loss 19.448214 loss_att 21.475941 loss_ctc 18.890776 loss_rnnt 19.003956 hw_loss 0.211945 lr 0.00049001 rank 7
2023-02-21 23:57:44,004 DEBUG TRAIN Batch 12/4100 loss 6.647474 loss_att 11.776666 loss_ctc 8.847198 loss_rnnt 5.219448 hw_loss 0.204173 lr 0.00048979 rank 2
2023-02-21 23:57:44,005 DEBUG TRAIN Batch 12/4100 loss 11.280175 loss_att 17.342417 loss_ctc 14.150934 loss_rnnt 9.491310 hw_loss 0.363090 lr 0.00048980 rank 6
2023-02-21 23:57:44,009 DEBUG TRAIN Batch 12/4100 loss 15.204940 loss_att 16.115505 loss_ctc 21.765850 loss_rnnt 14.015377 hw_loss 0.248740 lr 0.00048977 rank 7
2023-02-21 23:57:44,008 DEBUG TRAIN Batch 12/4100 loss 12.603057 loss_att 15.987093 loss_ctc 13.947914 loss_rnnt 11.606651 hw_loss 0.263031 lr 0.00048981 rank 3
2023-02-21 23:57:44,009 DEBUG TRAIN Batch 12/4100 loss 10.703629 loss_att 15.492464 loss_ctc 12.935088 loss_rnnt 9.320021 hw_loss 0.240586 lr 0.00048985 rank 1
2023-02-21 23:57:44,010 DEBUG TRAIN Batch 12/4100 loss 20.584173 loss_att 25.329765 loss_ctc 20.273785 loss_rnnt 19.460289 hw_loss 0.405285 lr 0.00048983 rank 4
2023-02-21 23:57:44,014 DEBUG TRAIN Batch 12/4100 loss 38.785450 loss_att 43.971077 loss_ctc 53.773384 loss_rnnt 35.623577 hw_loss 0.236921 lr 0.00048980 rank 5
2023-02-21 23:57:44,015 DEBUG TRAIN Batch 12/4100 loss 8.528798 loss_att 15.122965 loss_ctc 9.913361 loss_rnnt 6.945129 hw_loss 0.150425 lr 0.00048985 rank 0
2023-02-21 23:58:57,445 DEBUG TRAIN Batch 12/4200 loss 14.778694 loss_att 16.351387 loss_ctc 22.737818 loss_rnnt 13.366536 hw_loss 0.068254 lr 0.00048957 rank 3
2023-02-21 23:58:57,461 DEBUG TRAIN Batch 12/4200 loss 27.202497 loss_att 31.505161 loss_ctc 33.993496 loss_rnnt 25.251326 hw_loss 0.347201 lr 0.00048954 rank 7
2023-02-21 23:58:57,462 DEBUG TRAIN Batch 12/4200 loss 16.584017 loss_att 22.091413 loss_ctc 19.312111 loss_rnnt 15.024451 hw_loss 0.176889 lr 0.00048956 rank 6
2023-02-21 23:58:57,462 DEBUG TRAIN Batch 12/4200 loss 10.262205 loss_att 15.113533 loss_ctc 13.382240 loss_rnnt 8.805911 hw_loss 0.131294 lr 0.00048956 rank 2
2023-02-21 23:58:57,464 DEBUG TRAIN Batch 12/4200 loss 7.915052 loss_att 12.163893 loss_ctc 10.632475 loss_rnnt 6.576709 hw_loss 0.236722 lr 0.00048956 rank 5
2023-02-21 23:58:57,468 DEBUG TRAIN Batch 12/4200 loss 20.456501 loss_att 23.386782 loss_ctc 23.636536 loss_rnnt 19.339392 hw_loss 0.200719 lr 0.00048961 rank 0
2023-02-21 23:58:57,499 DEBUG TRAIN Batch 12/4200 loss 20.319332 loss_att 23.085785 loss_ctc 24.293316 loss_rnnt 19.075615 hw_loss 0.301055 lr 0.00048959 rank 4
2023-02-21 23:58:57,501 DEBUG TRAIN Batch 12/4200 loss 16.523090 loss_att 15.937260 loss_ctc 17.199406 loss_rnnt 16.457386 hw_loss 0.173803 lr 0.00048961 rank 1
2023-02-22 00:00:11,655 DEBUG TRAIN Batch 12/4300 loss 15.484016 loss_att 19.146544 loss_ctc 19.783566 loss_rnnt 14.041033 hw_loss 0.257258 lr 0.00048932 rank 2
2023-02-22 00:00:11,658 DEBUG TRAIN Batch 12/4300 loss 12.491085 loss_att 14.467325 loss_ctc 15.648133 loss_rnnt 11.561725 hw_loss 0.212198 lr 0.00048933 rank 6
2023-02-22 00:00:11,658 DEBUG TRAIN Batch 12/4300 loss 18.309082 loss_att 20.752411 loss_ctc 20.641737 loss_rnnt 17.373779 hw_loss 0.254279 lr 0.00048938 rank 0
2023-02-22 00:00:11,660 DEBUG TRAIN Batch 12/4300 loss 41.405296 loss_att 41.803314 loss_ctc 49.586906 loss_rnnt 40.097126 hw_loss 0.258159 lr 0.00048931 rank 7
2023-02-22 00:00:11,660 DEBUG TRAIN Batch 12/4300 loss 15.320893 loss_att 19.522707 loss_ctc 18.721333 loss_rnnt 13.939087 hw_loss 0.165098 lr 0.00048938 rank 1
2023-02-22 00:00:11,662 DEBUG TRAIN Batch 12/4300 loss 13.511973 loss_att 17.350573 loss_ctc 16.180643 loss_rnnt 12.271427 hw_loss 0.219382 lr 0.00048934 rank 3
2023-02-22 00:00:11,663 DEBUG TRAIN Batch 12/4300 loss 19.629810 loss_att 27.805901 loss_ctc 26.966179 loss_rnnt 16.911814 hw_loss 0.196113 lr 0.00048936 rank 4
2023-02-22 00:00:11,665 DEBUG TRAIN Batch 12/4300 loss 5.143614 loss_att 8.573847 loss_ctc 6.423273 loss_rnnt 4.146370 hw_loss 0.263582 lr 0.00048933 rank 5
2023-02-22 00:01:24,200 DEBUG TRAIN Batch 12/4400 loss 16.648815 loss_att 18.787411 loss_ctc 17.851776 loss_rnnt 15.820271 hw_loss 0.450808 lr 0.00048909 rank 2
2023-02-22 00:01:24,203 DEBUG TRAIN Batch 12/4400 loss 11.321835 loss_att 14.120445 loss_ctc 14.999430 loss_rnnt 10.174009 hw_loss 0.183294 lr 0.00048909 rank 6
2023-02-22 00:01:24,203 DEBUG TRAIN Batch 12/4400 loss 20.264132 loss_att 21.758579 loss_ctc 29.076416 loss_rnnt 18.638519 hw_loss 0.284532 lr 0.00048914 rank 1
2023-02-22 00:01:24,204 DEBUG TRAIN Batch 12/4400 loss 19.530922 loss_att 22.786911 loss_ctc 20.835913 loss_rnnt 18.608082 hw_loss 0.183084 lr 0.00048914 rank 0
2023-02-22 00:01:24,205 DEBUG TRAIN Batch 12/4400 loss 14.267857 loss_att 14.128619 loss_ctc 16.592413 loss_rnnt 13.712321 hw_loss 0.512702 lr 0.00048910 rank 3
2023-02-22 00:01:24,210 DEBUG TRAIN Batch 12/4400 loss 15.733440 loss_att 20.493877 loss_ctc 22.811056 loss_rnnt 13.700709 hw_loss 0.256803 lr 0.00048907 rank 7
2023-02-22 00:01:24,214 DEBUG TRAIN Batch 12/4400 loss 12.894898 loss_att 14.831548 loss_ctc 16.047642 loss_rnnt 11.985706 hw_loss 0.190305 lr 0.00048909 rank 5
2023-02-22 00:01:24,254 DEBUG TRAIN Batch 12/4400 loss 22.720833 loss_att 23.751762 loss_ctc 29.689228 loss_rnnt 21.373419 hw_loss 0.397703 lr 0.00048913 rank 4
2023-02-22 00:02:36,832 DEBUG TRAIN Batch 12/4500 loss 7.603919 loss_att 13.573843 loss_ctc 9.883698 loss_rnnt 6.048337 hw_loss 0.108049 lr 0.00048887 rank 3
2023-02-22 00:02:36,833 DEBUG TRAIN Batch 12/4500 loss 14.254885 loss_att 16.661865 loss_ctc 20.226130 loss_rnnt 12.801114 hw_loss 0.330389 lr 0.00048891 rank 0
2023-02-22 00:02:36,837 DEBUG TRAIN Batch 12/4500 loss 15.236033 loss_att 23.824778 loss_ctc 19.357361 loss_rnnt 12.815723 hw_loss 0.286970 lr 0.00048889 rank 4
2023-02-22 00:02:36,839 DEBUG TRAIN Batch 12/4500 loss 15.769421 loss_att 15.764292 loss_ctc 18.531635 loss_rnnt 15.267833 hw_loss 0.251847 lr 0.00048884 rank 7
2023-02-22 00:02:36,842 DEBUG TRAIN Batch 12/4500 loss 9.276934 loss_att 9.038917 loss_ctc 11.818244 loss_rnnt 8.787830 hw_loss 0.370996 lr 0.00048886 rank 5
2023-02-22 00:02:36,844 DEBUG TRAIN Batch 12/4500 loss 19.111479 loss_att 19.648468 loss_ctc 25.887650 loss_rnnt 17.921303 hw_loss 0.336167 lr 0.00048891 rank 1
2023-02-22 00:02:36,858 DEBUG TRAIN Batch 12/4500 loss 14.772997 loss_att 18.790659 loss_ctc 23.116255 loss_rnnt 12.692200 hw_loss 0.309058 lr 0.00048886 rank 2
2023-02-22 00:02:36,872 DEBUG TRAIN Batch 12/4500 loss 12.272043 loss_att 14.302677 loss_ctc 14.680766 loss_rnnt 11.351867 hw_loss 0.361663 lr 0.00048886 rank 6
2023-02-22 00:03:51,304 DEBUG TRAIN Batch 12/4600 loss 21.486822 loss_att 25.052584 loss_ctc 29.304892 loss_rnnt 19.644203 hw_loss 0.163235 lr 0.00048867 rank 0
2023-02-22 00:03:51,311 DEBUG TRAIN Batch 12/4600 loss 12.916520 loss_att 20.151094 loss_ctc 15.845783 loss_rnnt 10.973831 hw_loss 0.197259 lr 0.00048862 rank 2
2023-02-22 00:03:51,312 DEBUG TRAIN Batch 12/4600 loss 16.645655 loss_att 16.862717 loss_ctc 16.720575 loss_rnnt 16.420536 hw_loss 0.321972 lr 0.00048860 rank 7
2023-02-22 00:03:51,312 DEBUG TRAIN Batch 12/4600 loss 7.307778 loss_att 12.636524 loss_ctc 8.822532 loss_rnnt 5.893837 hw_loss 0.274171 lr 0.00048864 rank 3
2023-02-22 00:03:51,313 DEBUG TRAIN Batch 12/4600 loss 8.135235 loss_att 16.012386 loss_ctc 13.750298 loss_rnnt 5.683131 hw_loss 0.239997 lr 0.00048867 rank 1
2023-02-22 00:03:51,314 DEBUG TRAIN Batch 12/4600 loss 10.150029 loss_att 14.028275 loss_ctc 12.635352 loss_rnnt 8.943603 hw_loss 0.186376 lr 0.00048866 rank 4
2023-02-22 00:03:51,318 DEBUG TRAIN Batch 12/4600 loss 20.888144 loss_att 26.556126 loss_ctc 22.260471 loss_rnnt 19.355892 hw_loss 0.404398 lr 0.00048863 rank 6
2023-02-22 00:03:51,363 DEBUG TRAIN Batch 12/4600 loss 12.703734 loss_att 16.563381 loss_ctc 13.848144 loss_rnnt 11.626146 hw_loss 0.287006 lr 0.00048863 rank 5
2023-02-22 00:05:04,701 DEBUG TRAIN Batch 12/4700 loss 16.189436 loss_att 23.375381 loss_ctc 18.157419 loss_rnnt 14.414416 hw_loss 0.141438 lr 0.00048837 rank 7
2023-02-22 00:05:04,712 DEBUG TRAIN Batch 12/4700 loss 16.937923 loss_att 22.218868 loss_ctc 20.265697 loss_rnnt 15.237883 hw_loss 0.375282 lr 0.00048839 rank 2
2023-02-22 00:05:04,712 DEBUG TRAIN Batch 12/4700 loss 28.145945 loss_att 28.755474 loss_ctc 35.116051 loss_rnnt 27.018780 hw_loss 0.142342 lr 0.00048844 rank 0
2023-02-22 00:05:04,713 DEBUG TRAIN Batch 12/4700 loss 22.924721 loss_att 23.018389 loss_ctc 29.026693 loss_rnnt 21.938030 hw_loss 0.289425 lr 0.00048840 rank 3
2023-02-22 00:05:04,714 DEBUG TRAIN Batch 12/4700 loss 23.342012 loss_att 24.846609 loss_ctc 20.506660 loss_rnnt 23.354681 hw_loss 0.120857 lr 0.00048844 rank 1
2023-02-22 00:05:04,714 DEBUG TRAIN Batch 12/4700 loss 7.700609 loss_att 13.154438 loss_ctc 13.598211 loss_rnnt 5.699271 hw_loss 0.232923 lr 0.00048839 rank 6
2023-02-22 00:05:04,716 DEBUG TRAIN Batch 12/4700 loss 15.576428 loss_att 16.950279 loss_ctc 20.469336 loss_rnnt 14.474696 hw_loss 0.327328 lr 0.00048842 rank 4
2023-02-22 00:05:04,764 DEBUG TRAIN Batch 12/4700 loss 9.128181 loss_att 13.076539 loss_ctc 12.285345 loss_rnnt 7.785168 hw_loss 0.248225 lr 0.00048839 rank 5
2023-02-22 00:06:17,332 DEBUG TRAIN Batch 12/4800 loss 15.346958 loss_att 19.505032 loss_ctc 19.740047 loss_rnnt 13.828503 hw_loss 0.189554 lr 0.00048819 rank 4
2023-02-22 00:06:17,334 DEBUG TRAIN Batch 12/4800 loss 24.258236 loss_att 26.551189 loss_ctc 28.201115 loss_rnnt 23.197287 hw_loss 0.143702 lr 0.00048816 rank 5
2023-02-22 00:06:17,335 DEBUG TRAIN Batch 12/4800 loss 11.428512 loss_att 17.031174 loss_ctc 14.212955 loss_rnnt 9.871502 hw_loss 0.122286 lr 0.00048816 rank 2
2023-02-22 00:06:17,337 DEBUG TRAIN Batch 12/4800 loss 12.324324 loss_att 17.154655 loss_ctc 15.681875 loss_rnnt 10.735027 hw_loss 0.329168 lr 0.00048814 rank 7
2023-02-22 00:06:17,339 DEBUG TRAIN Batch 12/4800 loss 12.380723 loss_att 15.854511 loss_ctc 14.139842 loss_rnnt 11.371046 hw_loss 0.150695 lr 0.00048816 rank 6
2023-02-22 00:06:17,341 DEBUG TRAIN Batch 12/4800 loss 17.082563 loss_att 23.490274 loss_ctc 15.151897 loss_rnnt 15.941556 hw_loss 0.219166 lr 0.00048817 rank 3
2023-02-22 00:06:17,341 DEBUG TRAIN Batch 12/4800 loss 16.207932 loss_att 22.965782 loss_ctc 15.696559 loss_rnnt 14.756920 hw_loss 0.314293 lr 0.00048821 rank 0
2023-02-22 00:06:17,391 DEBUG TRAIN Batch 12/4800 loss 9.156310 loss_att 14.360415 loss_ctc 10.894842 loss_rnnt 7.691346 hw_loss 0.360633 lr 0.00048821 rank 1
2023-02-22 00:07:29,935 DEBUG TRAIN Batch 12/4900 loss 14.222399 loss_att 18.173323 loss_ctc 18.418190 loss_rnnt 12.800868 hw_loss 0.134825 lr 0.00048796 rank 4
2023-02-22 00:07:29,942 DEBUG TRAIN Batch 12/4900 loss 15.142306 loss_att 16.888264 loss_ctc 18.436659 loss_rnnt 14.249075 hw_loss 0.196488 lr 0.00048792 rank 2
2023-02-22 00:07:29,945 DEBUG TRAIN Batch 12/4900 loss 16.065331 loss_att 16.838360 loss_ctc 16.142824 loss_rnnt 15.666817 hw_loss 0.437954 lr 0.00048794 rank 3
2023-02-22 00:07:29,947 DEBUG TRAIN Batch 12/4900 loss 14.708799 loss_att 20.547285 loss_ctc 18.623259 loss_rnnt 12.934302 hw_loss 0.159134 lr 0.00048798 rank 1
2023-02-22 00:07:29,949 DEBUG TRAIN Batch 12/4900 loss 14.124671 loss_att 18.723225 loss_ctc 18.739193 loss_rnnt 12.492485 hw_loss 0.182259 lr 0.00048793 rank 6
2023-02-22 00:07:29,951 DEBUG TRAIN Batch 12/4900 loss 13.345900 loss_att 16.374826 loss_ctc 16.302916 loss_rnnt 12.105946 hw_loss 0.449809 lr 0.00048798 rank 0
2023-02-22 00:07:29,952 DEBUG TRAIN Batch 12/4900 loss 30.239992 loss_att 34.913021 loss_ctc 38.769062 loss_rnnt 28.016809 hw_loss 0.283813 lr 0.00048793 rank 5
2023-02-22 00:07:29,997 DEBUG TRAIN Batch 12/4900 loss 26.423140 loss_att 31.480576 loss_ctc 31.455387 loss_rnnt 24.667496 hw_loss 0.137236 lr 0.00048791 rank 7
2023-02-22 00:08:44,803 DEBUG TRAIN Batch 12/5000 loss 18.178286 loss_att 21.122070 loss_ctc 21.607731 loss_rnnt 16.926653 hw_loss 0.385528 lr 0.00048769 rank 5
2023-02-22 00:08:44,803 DEBUG TRAIN Batch 12/5000 loss 6.449146 loss_att 7.880779 loss_ctc 7.302411 loss_rnnt 5.964725 hw_loss 0.158113 lr 0.00048774 rank 0
2023-02-22 00:08:44,803 DEBUG TRAIN Batch 12/5000 loss 11.588417 loss_att 14.236182 loss_ctc 12.273197 loss_rnnt 10.760159 hw_loss 0.388877 lr 0.00048767 rank 7
2023-02-22 00:08:44,804 DEBUG TRAIN Batch 12/5000 loss 9.317316 loss_att 10.342138 loss_ctc 10.658229 loss_rnnt 8.859088 hw_loss 0.139642 lr 0.00048771 rank 3
2023-02-22 00:08:44,805 DEBUG TRAIN Batch 12/5000 loss 13.645419 loss_att 15.552694 loss_ctc 16.139486 loss_rnnt 12.796873 hw_loss 0.252279 lr 0.00048774 rank 1
2023-02-22 00:08:44,805 DEBUG TRAIN Batch 12/5000 loss 11.379966 loss_att 13.421446 loss_ctc 14.019248 loss_rnnt 10.488420 hw_loss 0.246271 lr 0.00048769 rank 2
2023-02-22 00:08:44,811 DEBUG TRAIN Batch 12/5000 loss 11.358683 loss_att 15.894878 loss_ctc 17.085396 loss_rnnt 9.403500 hw_loss 0.533217 lr 0.00048773 rank 4
2023-02-22 00:08:44,813 DEBUG TRAIN Batch 12/5000 loss 30.689322 loss_att 35.473598 loss_ctc 34.979340 loss_rnnt 29.037783 hw_loss 0.230020 lr 0.00048769 rank 6
2023-02-22 00:09:57,461 DEBUG TRAIN Batch 12/5100 loss 7.727152 loss_att 9.796963 loss_ctc 11.631094 loss_rnnt 6.711359 hw_loss 0.152449 lr 0.00048746 rank 2
2023-02-22 00:09:57,465 DEBUG TRAIN Batch 12/5100 loss 16.339710 loss_att 15.048611 loss_ctc 17.439297 loss_rnnt 16.299858 hw_loss 0.283986 lr 0.00048747 rank 3
2023-02-22 00:09:57,468 DEBUG TRAIN Batch 12/5100 loss 15.933056 loss_att 16.303612 loss_ctc 19.568287 loss_rnnt 15.130024 hw_loss 0.457916 lr 0.00048744 rank 7
2023-02-22 00:09:57,473 DEBUG TRAIN Batch 12/5100 loss 15.802596 loss_att 18.131252 loss_ctc 21.189241 loss_rnnt 14.450098 hw_loss 0.316026 lr 0.00048751 rank 0
2023-02-22 00:09:57,472 DEBUG TRAIN Batch 12/5100 loss 13.283668 loss_att 14.138014 loss_ctc 13.852077 loss_rnnt 12.873607 hw_loss 0.306381 lr 0.00048746 rank 5
2023-02-22 00:09:57,472 DEBUG TRAIN Batch 12/5100 loss 12.593562 loss_att 13.454597 loss_ctc 16.311121 loss_rnnt 11.755003 hw_loss 0.320021 lr 0.00048751 rank 1
2023-02-22 00:09:57,473 DEBUG TRAIN Batch 12/5100 loss 20.099615 loss_att 20.109165 loss_ctc 23.443325 loss_rnnt 19.492411 hw_loss 0.299001 lr 0.00048746 rank 6
2023-02-22 00:09:57,519 DEBUG TRAIN Batch 12/5100 loss 14.386590 loss_att 12.954226 loss_ctc 16.910793 loss_rnnt 14.111017 hw_loss 0.422782 lr 0.00048750 rank 4
2023-02-22 00:11:09,609 DEBUG TRAIN Batch 12/5200 loss 13.969327 loss_att 19.625219 loss_ctc 17.838280 loss_rnnt 12.192879 hw_loss 0.242642 lr 0.00048724 rank 3
2023-02-22 00:11:09,610 DEBUG TRAIN Batch 12/5200 loss 11.949814 loss_att 16.572819 loss_ctc 14.478068 loss_rnnt 10.589684 hw_loss 0.184552 lr 0.00048726 rank 4
2023-02-22 00:11:09,611 DEBUG TRAIN Batch 12/5200 loss 6.369832 loss_att 8.451300 loss_ctc 5.677066 loss_rnnt 5.826190 hw_loss 0.411969 lr 0.00048723 rank 2
2023-02-22 00:11:09,612 DEBUG TRAIN Batch 12/5200 loss 19.503994 loss_att 29.942997 loss_ctc 27.677618 loss_rnnt 16.230427 hw_loss 0.179908 lr 0.00048721 rank 7
2023-02-22 00:11:09,612 DEBUG TRAIN Batch 12/5200 loss 10.726688 loss_att 14.503418 loss_ctc 13.169353 loss_rnnt 9.606209 hw_loss 0.073958 lr 0.00048723 rank 5
2023-02-22 00:11:09,617 DEBUG TRAIN Batch 12/5200 loss 13.284506 loss_att 14.439525 loss_ctc 15.838999 loss_rnnt 12.459167 hw_loss 0.475758 lr 0.00048723 rank 6
2023-02-22 00:11:09,620 DEBUG TRAIN Batch 12/5200 loss 9.072613 loss_att 13.911291 loss_ctc 9.865406 loss_rnnt 7.951953 hw_loss 0.088534 lr 0.00048728 rank 1
2023-02-22 00:11:09,629 DEBUG TRAIN Batch 12/5200 loss 9.584220 loss_att 10.788242 loss_ctc 11.745848 loss_rnnt 8.919216 hw_loss 0.254967 lr 0.00048728 rank 0
2023-02-22 00:12:23,534 DEBUG TRAIN Batch 12/5300 loss 24.507067 loss_att 30.136253 loss_ctc 33.891338 loss_rnnt 21.987560 hw_loss 0.267060 lr 0.00048700 rank 5
2023-02-22 00:12:23,538 DEBUG TRAIN Batch 12/5300 loss 14.411868 loss_att 19.784897 loss_ctc 22.287594 loss_rnnt 12.185780 hw_loss 0.190098 lr 0.00048703 rank 4
2023-02-22 00:12:23,548 DEBUG TRAIN Batch 12/5300 loss 19.556391 loss_att 23.277170 loss_ctc 24.283888 loss_rnnt 18.089863 hw_loss 0.172571 lr 0.00048701 rank 3
2023-02-22 00:12:23,549 DEBUG TRAIN Batch 12/5300 loss 30.688139 loss_att 30.858898 loss_ctc 25.913137 loss_rnnt 31.118277 hw_loss 0.323204 lr 0.00048700 rank 6
2023-02-22 00:12:23,549 DEBUG TRAIN Batch 12/5300 loss 10.674204 loss_att 12.572371 loss_ctc 13.262024 loss_rnnt 9.787097 hw_loss 0.304559 lr 0.00048700 rank 2
2023-02-22 00:12:23,551 DEBUG TRAIN Batch 12/5300 loss 21.961123 loss_att 27.135475 loss_ctc 25.496923 loss_rnnt 20.280012 hw_loss 0.327749 lr 0.00048705 rank 1
2023-02-22 00:12:23,556 DEBUG TRAIN Batch 12/5300 loss 19.426403 loss_att 27.929153 loss_ctc 25.966167 loss_rnnt 16.699017 hw_loss 0.290373 lr 0.00048698 rank 7
2023-02-22 00:12:23,577 DEBUG TRAIN Batch 12/5300 loss 4.589859 loss_att 11.060196 loss_ctc 8.077885 loss_rnnt 2.718634 hw_loss 0.210165 lr 0.00048705 rank 0
2023-02-22 00:13:36,930 DEBUG TRAIN Batch 12/5400 loss 10.327206 loss_att 15.399052 loss_ctc 14.377094 loss_rnnt 8.566071 hw_loss 0.387714 lr 0.00048677 rank 2
2023-02-22 00:13:36,933 DEBUG TRAIN Batch 12/5400 loss 28.830387 loss_att 31.164213 loss_ctc 34.650669 loss_rnnt 27.459042 hw_loss 0.241021 lr 0.00048678 rank 3
2023-02-22 00:13:36,934 DEBUG TRAIN Batch 12/5400 loss 8.242423 loss_att 15.367439 loss_ctc 9.956763 loss_rnnt 6.442480 hw_loss 0.274428 lr 0.00048677 rank 6
2023-02-22 00:13:36,935 DEBUG TRAIN Batch 12/5400 loss 15.863654 loss_att 21.165159 loss_ctc 18.262915 loss_rnnt 14.376524 hw_loss 0.200491 lr 0.00048677 rank 5
2023-02-22 00:13:36,938 DEBUG TRAIN Batch 12/5400 loss 22.340876 loss_att 23.182419 loss_ctc 26.444738 loss_rnnt 21.499008 hw_loss 0.236953 lr 0.00048682 rank 0
2023-02-22 00:13:36,939 DEBUG TRAIN Batch 12/5400 loss 17.775152 loss_att 24.327229 loss_ctc 21.834326 loss_rnnt 15.752590 hw_loss 0.320480 lr 0.00048682 rank 1
2023-02-22 00:13:36,940 DEBUG TRAIN Batch 12/5400 loss 12.747461 loss_att 16.990383 loss_ctc 16.401920 loss_rnnt 11.346050 hw_loss 0.122937 lr 0.00048675 rank 7
2023-02-22 00:13:36,947 DEBUG TRAIN Batch 12/5400 loss 19.048882 loss_att 21.493101 loss_ctc 20.998978 loss_rnnt 18.121834 hw_loss 0.334113 lr 0.00048680 rank 4
2023-02-22 00:14:48,652 DEBUG TRAIN Batch 12/5500 loss 8.620549 loss_att 13.792786 loss_ctc 8.916474 loss_rnnt 7.384105 hw_loss 0.304764 lr 0.00048654 rank 2
2023-02-22 00:14:48,656 DEBUG TRAIN Batch 12/5500 loss 4.062790 loss_att 8.870640 loss_ctc 5.580214 loss_rnnt 2.789087 hw_loss 0.205893 lr 0.00048655 rank 3
2023-02-22 00:14:48,659 DEBUG TRAIN Batch 12/5500 loss 13.203055 loss_att 15.782116 loss_ctc 14.194018 loss_rnnt 12.435174 hw_loss 0.224889 lr 0.00048654 rank 6
2023-02-22 00:14:48,661 DEBUG TRAIN Batch 12/5500 loss 18.678068 loss_att 22.390757 loss_ctc 22.492390 loss_rnnt 17.317995 hw_loss 0.204295 lr 0.00048657 rank 4
2023-02-22 00:14:48,662 DEBUG TRAIN Batch 12/5500 loss 14.797029 loss_att 21.678030 loss_ctc 18.733541 loss_rnnt 12.744541 hw_loss 0.283914 lr 0.00048654 rank 5
2023-02-22 00:14:48,663 DEBUG TRAIN Batch 12/5500 loss 12.506571 loss_att 17.932432 loss_ctc 14.114639 loss_rnnt 11.051813 hw_loss 0.290954 lr 0.00048659 rank 0
2023-02-22 00:14:48,664 DEBUG TRAIN Batch 12/5500 loss 6.807364 loss_att 11.599186 loss_ctc 11.483679 loss_rnnt 5.000181 hw_loss 0.422454 lr 0.00048652 rank 7
2023-02-22 00:14:48,665 DEBUG TRAIN Batch 12/5500 loss 10.410304 loss_att 12.014783 loss_ctc 10.234753 loss_rnnt 10.020450 hw_loss 0.173184 lr 0.00048659 rank 1
2023-02-22 00:16:01,375 DEBUG TRAIN Batch 12/5600 loss 14.479922 loss_att 17.574337 loss_ctc 17.751780 loss_rnnt 13.298447 hw_loss 0.236898 lr 0.00048631 rank 2
2023-02-22 00:16:01,377 DEBUG TRAIN Batch 12/5600 loss 14.086439 loss_att 17.167561 loss_ctc 20.618261 loss_rnnt 12.392361 hw_loss 0.388022 lr 0.00048631 rank 6
2023-02-22 00:16:01,380 DEBUG TRAIN Batch 12/5600 loss 14.193621 loss_att 14.456762 loss_ctc 17.670053 loss_rnnt 13.522394 hw_loss 0.290763 lr 0.00048631 rank 5
2023-02-22 00:16:01,382 DEBUG TRAIN Batch 12/5600 loss 12.328596 loss_att 18.309149 loss_ctc 17.681767 loss_rnnt 10.271680 hw_loss 0.275717 lr 0.00048632 rank 3
2023-02-22 00:16:01,384 DEBUG TRAIN Batch 12/5600 loss 28.428083 loss_att 29.909981 loss_ctc 36.451904 loss_rnnt 26.941053 hw_loss 0.226514 lr 0.00048634 rank 4
2023-02-22 00:16:01,388 DEBUG TRAIN Batch 12/5600 loss 8.199855 loss_att 11.710040 loss_ctc 8.890045 loss_rnnt 7.260203 hw_loss 0.272981 lr 0.00048629 rank 7
2023-02-22 00:16:01,388 DEBUG TRAIN Batch 12/5600 loss 9.251390 loss_att 12.133962 loss_ctc 11.553510 loss_rnnt 8.202686 hw_loss 0.309822 lr 0.00048636 rank 0
2023-02-22 00:16:01,402 DEBUG TRAIN Batch 12/5600 loss 9.924142 loss_att 12.126395 loss_ctc 11.835385 loss_rnnt 8.930114 hw_loss 0.560147 lr 0.00048636 rank 1
2023-02-22 00:17:16,941 DEBUG TRAIN Batch 12/5700 loss 5.377113 loss_att 6.705751 loss_ctc 7.148466 loss_rnnt 4.606063 hw_loss 0.504641 lr 0.00048609 rank 3
2023-02-22 00:17:16,958 DEBUG TRAIN Batch 12/5700 loss 19.604923 loss_att 19.354218 loss_ctc 23.592096 loss_rnnt 18.941471 hw_loss 0.341191 lr 0.00048606 rank 7
2023-02-22 00:17:16,959 DEBUG TRAIN Batch 12/5700 loss 13.163592 loss_att 17.761269 loss_ctc 14.304299 loss_rnnt 11.870590 hw_loss 0.415074 lr 0.00048613 rank 0
2023-02-22 00:17:16,961 DEBUG TRAIN Batch 12/5700 loss 7.570673 loss_att 7.795181 loss_ctc 9.499127 loss_rnnt 6.923531 hw_loss 0.647087 lr 0.00048608 rank 2
2023-02-22 00:17:16,963 DEBUG TRAIN Batch 12/5700 loss 20.485203 loss_att 24.085915 loss_ctc 24.268648 loss_rnnt 19.136074 hw_loss 0.233489 lr 0.00048613 rank 1
2023-02-22 00:17:16,963 DEBUG TRAIN Batch 12/5700 loss 23.099735 loss_att 22.282612 loss_ctc 29.413151 loss_rnnt 22.299490 hw_loss 0.228528 lr 0.00048608 rank 5
2023-02-22 00:17:16,965 DEBUG TRAIN Batch 12/5700 loss 10.969968 loss_att 16.261320 loss_ctc 12.459902 loss_rnnt 9.488726 hw_loss 0.420587 lr 0.00048608 rank 6
2023-02-22 00:17:17,008 DEBUG TRAIN Batch 12/5700 loss 12.001571 loss_att 12.086718 loss_ctc 14.929446 loss_rnnt 11.390128 hw_loss 0.382558 lr 0.00048611 rank 4
2023-02-22 00:18:29,544 DEBUG TRAIN Batch 12/5800 loss 10.496053 loss_att 15.294545 loss_ctc 12.347368 loss_rnnt 9.186951 hw_loss 0.192303 lr 0.00048590 rank 1
2023-02-22 00:18:29,553 DEBUG TRAIN Batch 12/5800 loss 14.325625 loss_att 16.982231 loss_ctc 21.340132 loss_rnnt 12.735020 hw_loss 0.232531 lr 0.00048588 rank 4
2023-02-22 00:18:29,561 DEBUG TRAIN Batch 12/5800 loss 13.271420 loss_att 14.205987 loss_ctc 14.809444 loss_rnnt 12.730505 hw_loss 0.279244 lr 0.00048585 rank 2
2023-02-22 00:18:29,566 DEBUG TRAIN Batch 12/5800 loss 23.048582 loss_att 25.491615 loss_ctc 26.290829 loss_rnnt 21.925732 hw_loss 0.378647 lr 0.00048586 rank 3
2023-02-22 00:18:29,567 DEBUG TRAIN Batch 12/5800 loss 14.933709 loss_att 18.625002 loss_ctc 21.095409 loss_rnnt 13.100039 hw_loss 0.513471 lr 0.00048585 rank 6
2023-02-22 00:18:29,569 DEBUG TRAIN Batch 12/5800 loss 29.023272 loss_att 34.838219 loss_ctc 38.644104 loss_rnnt 26.489914 hw_loss 0.164231 lr 0.00048585 rank 5
2023-02-22 00:18:29,576 DEBUG TRAIN Batch 12/5800 loss 11.753469 loss_att 20.705315 loss_ctc 16.494095 loss_rnnt 9.048294 hw_loss 0.530103 lr 0.00048583 rank 7
2023-02-22 00:18:29,611 DEBUG TRAIN Batch 12/5800 loss 13.887887 loss_att 15.863930 loss_ctc 17.344673 loss_rnnt 12.865500 hw_loss 0.311764 lr 0.00048590 rank 0
2023-02-22 00:19:41,585 DEBUG TRAIN Batch 12/5900 loss 21.689306 loss_att 29.024815 loss_ctc 32.517254 loss_rnnt 18.697788 hw_loss 0.151294 lr 0.00048562 rank 2
2023-02-22 00:19:41,592 DEBUG TRAIN Batch 12/5900 loss 12.617039 loss_att 20.426329 loss_ctc 15.722876 loss_rnnt 10.582174 hw_loss 0.110427 lr 0.00048562 rank 6
2023-02-22 00:19:41,595 DEBUG TRAIN Batch 12/5900 loss 12.369141 loss_att 15.239328 loss_ctc 14.150312 loss_rnnt 11.481787 hw_loss 0.142175 lr 0.00048565 rank 4
2023-02-22 00:19:41,598 DEBUG TRAIN Batch 12/5900 loss 8.165692 loss_att 12.021712 loss_ctc 6.926580 loss_rnnt 7.439198 hw_loss 0.225950 lr 0.00048567 rank 0
2023-02-22 00:19:41,598 DEBUG TRAIN Batch 12/5900 loss 14.818947 loss_att 20.255466 loss_ctc 14.710882 loss_rnnt 13.477363 hw_loss 0.503792 lr 0.00048567 rank 1
2023-02-22 00:19:41,600 DEBUG TRAIN Batch 12/5900 loss 13.624490 loss_att 17.614773 loss_ctc 16.690121 loss_rnnt 12.302919 hw_loss 0.215181 lr 0.00048560 rank 7
2023-02-22 00:19:41,599 DEBUG TRAIN Batch 12/5900 loss 7.275178 loss_att 13.999274 loss_ctc 10.905177 loss_rnnt 5.337456 hw_loss 0.204192 lr 0.00048562 rank 5
2023-02-22 00:19:41,602 DEBUG TRAIN Batch 12/5900 loss 10.626011 loss_att 17.327932 loss_ctc 12.539187 loss_rnnt 8.919785 hw_loss 0.207657 lr 0.00048563 rank 3
2023-02-22 00:20:55,808 DEBUG TRAIN Batch 12/6000 loss 21.809219 loss_att 21.123177 loss_ctc 25.665993 loss_rnnt 21.351887 hw_loss 0.150570 lr 0.00048539 rank 2
2023-02-22 00:20:55,812 DEBUG TRAIN Batch 12/6000 loss 15.259363 loss_att 23.914776 loss_ctc 21.151043 loss_rnnt 12.654026 hw_loss 0.166308 lr 0.00048542 rank 4
2023-02-22 00:20:55,813 DEBUG TRAIN Batch 12/6000 loss 15.254672 loss_att 20.068872 loss_ctc 17.103302 loss_rnnt 13.856783 hw_loss 0.353558 lr 0.00048537 rank 7
2023-02-22 00:20:55,815 DEBUG TRAIN Batch 12/6000 loss 33.043152 loss_att 36.516563 loss_ctc 41.743385 loss_rnnt 31.071453 hw_loss 0.219350 lr 0.00048540 rank 3
2023-02-22 00:20:55,818 DEBUG TRAIN Batch 12/6000 loss 8.909177 loss_att 13.158954 loss_ctc 12.432293 loss_rnnt 7.468747 hw_loss 0.226359 lr 0.00048544 rank 0
2023-02-22 00:20:55,818 DEBUG TRAIN Batch 12/6000 loss 8.489032 loss_att 12.296977 loss_ctc 9.931145 loss_rnnt 7.341709 hw_loss 0.362722 lr 0.00048539 rank 5
2023-02-22 00:20:55,819 DEBUG TRAIN Batch 12/6000 loss 19.399529 loss_att 22.528759 loss_ctc 22.103821 loss_rnnt 18.278206 hw_loss 0.252944 lr 0.00048539 rank 6
2023-02-22 00:20:55,845 DEBUG TRAIN Batch 12/6000 loss 13.537667 loss_att 16.381229 loss_ctc 13.925437 loss_rnnt 12.815733 hw_loss 0.190347 lr 0.00048544 rank 1
2023-02-22 00:22:09,268 DEBUG TRAIN Batch 12/6100 loss 13.269849 loss_att 19.097683 loss_ctc 15.531926 loss_rnnt 11.713119 hw_loss 0.167912 lr 0.00048514 rank 7
2023-02-22 00:22:09,271 DEBUG TRAIN Batch 12/6100 loss 19.501585 loss_att 25.319759 loss_ctc 25.346342 loss_rnnt 17.470213 hw_loss 0.165820 lr 0.00048517 rank 3
2023-02-22 00:22:09,272 DEBUG TRAIN Batch 12/6100 loss 13.091137 loss_att 12.950640 loss_ctc 13.651499 loss_rnnt 12.875212 hw_loss 0.317456 lr 0.00048516 rank 2
2023-02-22 00:22:09,273 DEBUG TRAIN Batch 12/6100 loss 13.129239 loss_att 18.307259 loss_ctc 13.480061 loss_rnnt 11.918848 hw_loss 0.240018 lr 0.00048516 rank 5
2023-02-22 00:22:09,277 DEBUG TRAIN Batch 12/6100 loss 25.649992 loss_att 27.757938 loss_ctc 30.983643 loss_rnnt 24.396570 hw_loss 0.226272 lr 0.00048521 rank 1
2023-02-22 00:22:09,278 DEBUG TRAIN Batch 12/6100 loss 17.571924 loss_att 15.571323 loss_ctc 24.664028 loss_rnnt 16.825146 hw_loss 0.377405 lr 0.00048516 rank 6
2023-02-22 00:22:09,282 DEBUG TRAIN Batch 12/6100 loss 15.252098 loss_att 23.447199 loss_ctc 25.882156 loss_rnnt 12.007590 hw_loss 0.352772 lr 0.00048519 rank 4
2023-02-22 00:22:09,293 DEBUG TRAIN Batch 12/6100 loss 21.364992 loss_att 25.695885 loss_ctc 23.181488 loss_rnnt 20.126560 hw_loss 0.243850 lr 0.00048521 rank 0
2023-02-22 00:23:21,908 DEBUG TRAIN Batch 12/6200 loss 12.115541 loss_att 15.417559 loss_ctc 14.650728 loss_rnnt 11.029093 hw_loss 0.165036 lr 0.00048493 rank 6
2023-02-22 00:23:21,910 DEBUG TRAIN Batch 12/6200 loss 13.946496 loss_att 15.368705 loss_ctc 19.747549 loss_rnnt 12.698293 hw_loss 0.356789 lr 0.00048493 rank 2
2023-02-22 00:23:21,911 DEBUG TRAIN Batch 12/6200 loss 17.745497 loss_att 20.479935 loss_ctc 22.576887 loss_rnnt 16.414333 hw_loss 0.262670 lr 0.00048497 rank 4
2023-02-22 00:23:21,914 DEBUG TRAIN Batch 12/6200 loss 11.822792 loss_att 19.750771 loss_ctc 15.088312 loss_rnnt 9.608630 hw_loss 0.362182 lr 0.00048495 rank 3
2023-02-22 00:23:21,914 DEBUG TRAIN Batch 12/6200 loss 21.865555 loss_att 24.109005 loss_ctc 29.007137 loss_rnnt 20.317530 hw_loss 0.275860 lr 0.00048491 rank 7
2023-02-22 00:23:21,919 DEBUG TRAIN Batch 12/6200 loss 17.272978 loss_att 22.509697 loss_ctc 18.645336 loss_rnnt 15.863998 hw_loss 0.334978 lr 0.00048498 rank 0
2023-02-22 00:23:21,920 DEBUG TRAIN Batch 12/6200 loss 31.734154 loss_att 32.713829 loss_ctc 36.680298 loss_rnnt 30.666233 hw_loss 0.398437 lr 0.00048493 rank 5
2023-02-22 00:23:21,922 DEBUG TRAIN Batch 12/6200 loss 12.003754 loss_att 16.007532 loss_ctc 13.525423 loss_rnnt 10.928780 hw_loss 0.133743 lr 0.00048498 rank 1
2023-02-22 00:24:34,775 DEBUG TRAIN Batch 12/6300 loss 15.063677 loss_att 16.450932 loss_ctc 19.508970 loss_rnnt 13.907466 hw_loss 0.536351 lr 0.00048469 rank 7
2023-02-22 00:24:34,776 DEBUG TRAIN Batch 12/6300 loss 13.589886 loss_att 17.562845 loss_ctc 18.398268 loss_rnnt 11.956590 hw_loss 0.370475 lr 0.00048472 rank 3
2023-02-22 00:24:34,777 DEBUG TRAIN Batch 12/6300 loss 8.317122 loss_att 7.225667 loss_ctc 8.964637 loss_rnnt 8.204485 hw_loss 0.458613 lr 0.00048470 rank 2
2023-02-22 00:24:34,779 DEBUG TRAIN Batch 12/6300 loss 18.175793 loss_att 20.158024 loss_ctc 21.040499 loss_rnnt 17.245867 hw_loss 0.284094 lr 0.00048471 rank 6
2023-02-22 00:24:34,800 DEBUG TRAIN Batch 12/6300 loss 19.397463 loss_att 24.344509 loss_ctc 27.388464 loss_rnnt 17.261812 hw_loss 0.151447 lr 0.00048475 rank 0
2023-02-22 00:24:34,801 DEBUG TRAIN Batch 12/6300 loss 12.264545 loss_att 15.432769 loss_ctc 16.111879 loss_rnnt 10.976511 hw_loss 0.265146 lr 0.00048474 rank 4
2023-02-22 00:24:34,806 DEBUG TRAIN Batch 12/6300 loss 16.033041 loss_att 18.358919 loss_ctc 19.862297 loss_rnnt 14.924556 hw_loss 0.248891 lr 0.00048475 rank 1
2023-02-22 00:24:34,827 DEBUG TRAIN Batch 12/6300 loss 7.996768 loss_att 12.010147 loss_ctc 10.681459 loss_rnnt 6.647235 hw_loss 0.354184 lr 0.00048471 rank 5
2023-02-22 00:25:50,132 DEBUG TRAIN Batch 12/6400 loss 19.212402 loss_att 18.973965 loss_ctc 23.270016 loss_rnnt 18.570515 hw_loss 0.278552 lr 0.00048453 rank 0
2023-02-22 00:25:50,133 DEBUG TRAIN Batch 12/6400 loss 18.738876 loss_att 21.723314 loss_ctc 22.818584 loss_rnnt 17.502468 hw_loss 0.179178 lr 0.00048451 rank 4
2023-02-22 00:25:50,134 DEBUG TRAIN Batch 12/6400 loss 22.609003 loss_att 25.395185 loss_ctc 27.430401 loss_rnnt 21.220329 hw_loss 0.353593 lr 0.00048453 rank 1
2023-02-22 00:25:50,136 DEBUG TRAIN Batch 12/6400 loss 8.851247 loss_att 14.056261 loss_ctc 11.312582 loss_rnnt 7.380994 hw_loss 0.189509 lr 0.00048449 rank 3
2023-02-22 00:25:50,138 DEBUG TRAIN Batch 12/6400 loss 16.543713 loss_att 21.718666 loss_ctc 22.204388 loss_rnnt 14.612215 hw_loss 0.265778 lr 0.00048448 rank 6
2023-02-22 00:25:50,139 DEBUG TRAIN Batch 12/6400 loss 17.698942 loss_att 22.069784 loss_ctc 23.428932 loss_rnnt 15.927422 hw_loss 0.250039 lr 0.00048448 rank 5
2023-02-22 00:25:50,143 DEBUG TRAIN Batch 12/6400 loss 21.081005 loss_att 22.888912 loss_ctc 27.224972 loss_rnnt 19.833080 hw_loss 0.125902 lr 0.00048446 rank 7
2023-02-22 00:25:50,157 DEBUG TRAIN Batch 12/6400 loss 15.947388 loss_att 23.575293 loss_ctc 19.292788 loss_rnnt 13.860390 hw_loss 0.216308 lr 0.00048448 rank 2
2023-02-22 00:27:02,006 DEBUG TRAIN Batch 12/6500 loss 14.862669 loss_att 18.015631 loss_ctc 22.564728 loss_rnnt 13.103480 hw_loss 0.190603 lr 0.00048423 rank 7
2023-02-22 00:27:02,011 DEBUG TRAIN Batch 12/6500 loss 16.249105 loss_att 19.596170 loss_ctc 19.091829 loss_rnnt 15.032882 hw_loss 0.314588 lr 0.00048425 rank 2
2023-02-22 00:27:02,011 DEBUG TRAIN Batch 12/6500 loss 21.606689 loss_att 22.012276 loss_ctc 22.426205 loss_rnnt 21.182920 hw_loss 0.437593 lr 0.00048426 rank 3
2023-02-22 00:27:02,012 DEBUG TRAIN Batch 12/6500 loss 10.212529 loss_att 9.218001 loss_ctc 11.591469 loss_rnnt 9.887002 hw_loss 0.638575 lr 0.00048425 rank 5
2023-02-22 00:27:02,012 DEBUG TRAIN Batch 12/6500 loss 7.457922 loss_att 9.870479 loss_ctc 9.873777 loss_rnnt 6.610214 hw_loss 0.080780 lr 0.00048428 rank 4
2023-02-22 00:27:02,017 DEBUG TRAIN Batch 12/6500 loss 17.583662 loss_att 22.654879 loss_ctc 18.193310 loss_rnnt 16.312262 hw_loss 0.329757 lr 0.00048425 rank 6
2023-02-22 00:27:02,018 DEBUG TRAIN Batch 12/6500 loss 13.861990 loss_att 17.219101 loss_ctc 18.436514 loss_rnnt 12.442676 hw_loss 0.258666 lr 0.00048430 rank 0
2023-02-22 00:27:02,021 DEBUG TRAIN Batch 12/6500 loss 12.661386 loss_att 18.259562 loss_ctc 17.805353 loss_rnnt 10.774379 hw_loss 0.152829 lr 0.00048430 rank 1
2023-02-22 00:28:13,713 DEBUG TRAIN Batch 12/6600 loss 6.950418 loss_att 12.381350 loss_ctc 9.609800 loss_rnnt 5.309011 hw_loss 0.376191 lr 0.00048402 rank 5
2023-02-22 00:28:13,728 DEBUG TRAIN Batch 12/6600 loss 10.258429 loss_att 15.652653 loss_ctc 15.339300 loss_rnnt 8.373013 hw_loss 0.242105 lr 0.00048402 rank 6
2023-02-22 00:28:13,732 DEBUG TRAIN Batch 12/6600 loss 15.776198 loss_att 19.458063 loss_ctc 17.618240 loss_rnnt 14.707170 hw_loss 0.163216 lr 0.00048402 rank 2
2023-02-22 00:28:13,732 DEBUG TRAIN Batch 12/6600 loss 11.279754 loss_att 12.816304 loss_ctc 11.299922 loss_rnnt 10.750732 hw_loss 0.410667 lr 0.00048407 rank 1
2023-02-22 00:28:13,734 DEBUG TRAIN Batch 12/6600 loss 51.160992 loss_att 55.984673 loss_ctc 59.416862 loss_rnnt 49.029034 hw_loss 0.124576 lr 0.00048404 rank 3
2023-02-22 00:28:13,734 DEBUG TRAIN Batch 12/6600 loss 12.679232 loss_att 14.887083 loss_ctc 12.111460 loss_rnnt 12.270834 hw_loss 0.079744 lr 0.00048407 rank 0
2023-02-22 00:28:13,738 DEBUG TRAIN Batch 12/6600 loss 15.025496 loss_att 23.903372 loss_ctc 18.436104 loss_rnnt 12.716653 hw_loss 0.147223 lr 0.00048400 rank 7
2023-02-22 00:28:13,779 DEBUG TRAIN Batch 12/6600 loss 12.168961 loss_att 16.191433 loss_ctc 15.689079 loss_rnnt 10.799463 hw_loss 0.179349 lr 0.00048406 rank 4
2023-02-22 00:29:27,903 DEBUG TRAIN Batch 12/6700 loss 28.149200 loss_att 31.662548 loss_ctc 35.703117 loss_rnnt 26.171043 hw_loss 0.503059 lr 0.00048385 rank 1
2023-02-22 00:29:27,905 DEBUG TRAIN Batch 12/6700 loss 14.634820 loss_att 18.190596 loss_ctc 18.828032 loss_rnnt 13.238193 hw_loss 0.236956 lr 0.00048380 rank 5
2023-02-22 00:29:27,912 DEBUG TRAIN Batch 12/6700 loss 7.960278 loss_att 12.317611 loss_ctc 10.858302 loss_rnnt 6.617661 hw_loss 0.158903 lr 0.00048380 rank 2
2023-02-22 00:29:27,915 DEBUG TRAIN Batch 12/6700 loss 8.716337 loss_att 13.449182 loss_ctc 13.102842 loss_rnnt 7.013214 hw_loss 0.321913 lr 0.00048380 rank 6
2023-02-22 00:29:27,917 DEBUG TRAIN Batch 12/6700 loss 14.594489 loss_att 17.796402 loss_ctc 18.171209 loss_rnnt 13.277723 hw_loss 0.374040 lr 0.00048383 rank 4
2023-02-22 00:29:27,918 DEBUG TRAIN Batch 12/6700 loss 15.468354 loss_att 17.377048 loss_ctc 16.780291 loss_rnnt 14.820561 hw_loss 0.170867 lr 0.00048381 rank 3
2023-02-22 00:29:27,919 DEBUG TRAIN Batch 12/6700 loss 13.015272 loss_att 18.379408 loss_ctc 15.357185 loss_rnnt 11.539827 hw_loss 0.169428 lr 0.00048385 rank 0
2023-02-22 00:29:27,920 DEBUG TRAIN Batch 12/6700 loss 23.895288 loss_att 28.586124 loss_ctc 29.338509 loss_rnnt 22.074806 hw_loss 0.293537 lr 0.00048378 rank 7
2023-02-22 00:30:42,252 DEBUG TRAIN Batch 12/6800 loss 7.341298 loss_att 10.709584 loss_ctc 8.428432 loss_rnnt 6.392962 hw_loss 0.243240 lr 0.00048357 rank 2
2023-02-22 00:30:42,252 DEBUG TRAIN Batch 12/6800 loss 18.596851 loss_att 17.769295 loss_ctc 22.197433 loss_rnnt 18.118553 hw_loss 0.306995 lr 0.00048355 rank 7
2023-02-22 00:30:42,254 DEBUG TRAIN Batch 12/6800 loss 23.319342 loss_att 23.914202 loss_ctc 27.742466 loss_rnnt 22.453247 hw_loss 0.295074 lr 0.00048358 rank 3
2023-02-22 00:30:42,256 DEBUG TRAIN Batch 12/6800 loss 11.268007 loss_att 15.992554 loss_ctc 14.378068 loss_rnnt 9.733732 hw_loss 0.327546 lr 0.00048362 rank 0
2023-02-22 00:30:42,257 DEBUG TRAIN Batch 12/6800 loss 12.678582 loss_att 17.002466 loss_ctc 17.555271 loss_rnnt 11.033013 hw_loss 0.244810 lr 0.00048360 rank 4
2023-02-22 00:30:42,264 DEBUG TRAIN Batch 12/6800 loss 12.187812 loss_att 15.153968 loss_ctc 14.307523 loss_rnnt 11.175472 hw_loss 0.255899 lr 0.00048357 rank 6
2023-02-22 00:30:42,264 DEBUG TRAIN Batch 12/6800 loss 15.427685 loss_att 19.031216 loss_ctc 19.557302 loss_rnnt 13.999609 hw_loss 0.293913 lr 0.00048357 rank 5
2023-02-22 00:30:42,308 DEBUG TRAIN Batch 12/6800 loss 8.336764 loss_att 15.486605 loss_ctc 7.928628 loss_rnnt 6.748184 hw_loss 0.399431 lr 0.00048362 rank 1
2023-02-22 00:31:56,726 DEBUG TRAIN Batch 12/6900 loss 16.642677 loss_att 17.602676 loss_ctc 20.172119 loss_rnnt 15.885402 hw_loss 0.177533 lr 0.00048334 rank 2
2023-02-22 00:31:56,726 DEBUG TRAIN Batch 12/6900 loss 8.267877 loss_att 12.152840 loss_ctc 12.763425 loss_rnnt 6.741348 hw_loss 0.281493 lr 0.00048338 rank 4
2023-02-22 00:31:56,728 DEBUG TRAIN Batch 12/6900 loss 10.535245 loss_att 12.459583 loss_ctc 13.529834 loss_rnnt 9.484086 hw_loss 0.500649 lr 0.00048336 rank 3
2023-02-22 00:31:56,728 DEBUG TRAIN Batch 12/6900 loss 13.148125 loss_att 17.415968 loss_ctc 12.688869 loss_rnnt 12.193913 hw_loss 0.303521 lr 0.00048335 rank 5
2023-02-22 00:31:56,731 DEBUG TRAIN Batch 12/6900 loss 21.642408 loss_att 26.838732 loss_ctc 24.304296 loss_rnnt 20.117622 hw_loss 0.244878 lr 0.00048335 rank 6
2023-02-22 00:31:56,735 DEBUG TRAIN Batch 12/6900 loss 14.752233 loss_att 18.242968 loss_ctc 19.271320 loss_rnnt 13.369427 hw_loss 0.153964 lr 0.00048339 rank 1
2023-02-22 00:31:56,737 DEBUG TRAIN Batch 12/6900 loss 6.422911 loss_att 8.313818 loss_ctc 6.987733 loss_rnnt 5.822358 hw_loss 0.275740 lr 0.00048339 rank 0
2023-02-22 00:31:56,780 DEBUG TRAIN Batch 12/6900 loss 8.776371 loss_att 14.057438 loss_ctc 15.414958 loss_rnnt 6.743573 hw_loss 0.171448 lr 0.00048333 rank 7
2023-02-22 00:33:11,291 DEBUG TRAIN Batch 12/7000 loss 24.506145 loss_att 33.040951 loss_ctc 32.021828 loss_rnnt 21.651625 hw_loss 0.272753 lr 0.00048315 rank 4
2023-02-22 00:33:11,295 DEBUG TRAIN Batch 12/7000 loss 10.964522 loss_att 11.720024 loss_ctc 11.762219 loss_rnnt 10.477378 hw_loss 0.430657 lr 0.00048313 rank 3
2023-02-22 00:33:11,295 DEBUG TRAIN Batch 12/7000 loss 21.649540 loss_att 21.750261 loss_ctc 23.050991 loss_rnnt 21.346775 hw_loss 0.179546 lr 0.00048312 rank 2
2023-02-22 00:33:11,299 DEBUG TRAIN Batch 12/7000 loss 18.514214 loss_att 18.783754 loss_ctc 22.029278 loss_rnnt 17.870947 hw_loss 0.226281 lr 0.00048317 rank 0
2023-02-22 00:33:11,302 DEBUG TRAIN Batch 12/7000 loss 8.023191 loss_att 10.964223 loss_ctc 7.547953 loss_rnnt 7.414578 hw_loss 0.157071 lr 0.00048317 rank 1
2023-02-22 00:33:11,301 DEBUG TRAIN Batch 12/7000 loss 9.548373 loss_att 17.455021 loss_ctc 12.447017 loss_rnnt 7.423735 hw_loss 0.294044 lr 0.00048312 rank 5
2023-02-22 00:33:11,301 DEBUG TRAIN Batch 12/7000 loss 10.770957 loss_att 15.547428 loss_ctc 11.801702 loss_rnnt 9.573469 hw_loss 0.196426 lr 0.00048310 rank 7
2023-02-22 00:33:11,305 DEBUG TRAIN Batch 12/7000 loss 9.947986 loss_att 11.975704 loss_ctc 12.017769 loss_rnnt 9.097760 hw_loss 0.316332 lr 0.00048312 rank 6
2023-02-22 00:34:26,790 DEBUG TRAIN Batch 12/7100 loss 13.704041 loss_att 15.285631 loss_ctc 17.775314 loss_rnnt 12.683750 hw_loss 0.302130 lr 0.00048293 rank 4
2023-02-22 00:34:26,794 DEBUG TRAIN Batch 12/7100 loss 20.379759 loss_att 25.778168 loss_ctc 25.094524 loss_rnnt 18.497108 hw_loss 0.326873 lr 0.00048294 rank 1
2023-02-22 00:34:26,796 DEBUG TRAIN Batch 12/7100 loss 6.837261 loss_att 8.472313 loss_ctc 6.396096 loss_rnnt 6.429225 hw_loss 0.262214 lr 0.00048289 rank 2
2023-02-22 00:34:26,796 DEBUG TRAIN Batch 12/7100 loss 24.135023 loss_att 23.916771 loss_ctc 29.530706 loss_rnnt 23.315687 hw_loss 0.269177 lr 0.00048291 rank 3
2023-02-22 00:34:26,800 DEBUG TRAIN Batch 12/7100 loss 19.504412 loss_att 26.425144 loss_ctc 24.862320 loss_rnnt 17.294043 hw_loss 0.209688 lr 0.00048289 rank 6
2023-02-22 00:34:26,801 DEBUG TRAIN Batch 12/7100 loss 21.062769 loss_att 21.517611 loss_ctc 22.464855 loss_rnnt 20.639673 hw_loss 0.272217 lr 0.00048289 rank 5
2023-02-22 00:34:26,831 DEBUG TRAIN Batch 12/7100 loss 15.278996 loss_att 15.844831 loss_ctc 18.644453 loss_rnnt 14.404978 hw_loss 0.585228 lr 0.00048294 rank 0
2023-02-22 00:34:26,836 DEBUG TRAIN Batch 12/7100 loss 18.409718 loss_att 23.529541 loss_ctc 28.492170 loss_rnnt 15.870155 hw_loss 0.321130 lr 0.00048287 rank 7
2023-02-22 00:35:40,070 DEBUG TRAIN Batch 12/7200 loss 15.161244 loss_att 16.232468 loss_ctc 19.279327 loss_rnnt 14.300591 hw_loss 0.182497 lr 0.00048267 rank 2
2023-02-22 00:35:40,071 DEBUG TRAIN Batch 12/7200 loss 10.701689 loss_att 18.015026 loss_ctc 13.681724 loss_rnnt 8.595394 hw_loss 0.461791 lr 0.00048268 rank 3
2023-02-22 00:35:40,072 DEBUG TRAIN Batch 12/7200 loss 19.229313 loss_att 22.646441 loss_ctc 23.422554 loss_rnnt 17.856094 hw_loss 0.245049 lr 0.00048270 rank 4
2023-02-22 00:35:40,072 DEBUG TRAIN Batch 12/7200 loss 14.511179 loss_att 18.616528 loss_ctc 22.415627 loss_rnnt 12.530493 hw_loss 0.198169 lr 0.00048272 rank 0
2023-02-22 00:35:40,076 DEBUG TRAIN Batch 12/7200 loss 15.737159 loss_att 18.928959 loss_ctc 21.213356 loss_rnnt 14.262161 hw_loss 0.199643 lr 0.00048272 rank 1
2023-02-22 00:35:40,077 DEBUG TRAIN Batch 12/7200 loss 22.043648 loss_att 25.402437 loss_ctc 27.439405 loss_rnnt 20.592438 hw_loss 0.112532 lr 0.00048267 rank 6
2023-02-22 00:35:40,078 DEBUG TRAIN Batch 12/7200 loss 6.357413 loss_att 9.414893 loss_ctc 8.568034 loss_rnnt 5.310279 hw_loss 0.264166 lr 0.00048267 rank 5
2023-02-22 00:35:40,086 DEBUG TRAIN Batch 12/7200 loss 12.248546 loss_att 15.054674 loss_ctc 11.335020 loss_rnnt 11.667257 hw_loss 0.266001 lr 0.00048265 rank 7
2023-02-22 00:36:52,310 DEBUG TRAIN Batch 12/7300 loss 18.976580 loss_att 22.367878 loss_ctc 27.481773 loss_rnnt 16.896688 hw_loss 0.501761 lr 0.00048246 rank 3
2023-02-22 00:36:52,313 DEBUG TRAIN Batch 12/7300 loss 22.581200 loss_att 25.500563 loss_ctc 33.902870 loss_rnnt 20.266617 hw_loss 0.414664 lr 0.00048248 rank 4
2023-02-22 00:36:52,313 DEBUG TRAIN Batch 12/7300 loss 18.770298 loss_att 22.990080 loss_ctc 18.814857 loss_rnnt 17.726349 hw_loss 0.363845 lr 0.00048244 rank 6
2023-02-22 00:36:52,316 DEBUG TRAIN Batch 12/7300 loss 19.028769 loss_att 23.302969 loss_ctc 21.409687 loss_rnnt 17.765764 hw_loss 0.170077 lr 0.00048244 rank 2
2023-02-22 00:36:52,318 DEBUG TRAIN Batch 12/7300 loss 22.449701 loss_att 24.111942 loss_ctc 26.192265 loss_rnnt 21.451096 hw_loss 0.313407 lr 0.00048249 rank 1
2023-02-22 00:36:52,319 DEBUG TRAIN Batch 12/7300 loss 16.693258 loss_att 22.748137 loss_ctc 23.450573 loss_rnnt 14.442039 hw_loss 0.261125 lr 0.00048242 rank 7
2023-02-22 00:36:52,319 DEBUG TRAIN Batch 12/7300 loss 16.733770 loss_att 23.436089 loss_ctc 20.422333 loss_rnnt 14.715911 hw_loss 0.347975 lr 0.00048244 rank 5
2023-02-22 00:36:52,366 DEBUG TRAIN Batch 12/7300 loss 6.979313 loss_att 11.550896 loss_ctc 7.995920 loss_rnnt 5.816305 hw_loss 0.212143 lr 0.00048249 rank 0
2023-02-22 00:38:05,634 DEBUG TRAIN Batch 12/7400 loss 16.585901 loss_att 23.704945 loss_ctc 26.900856 loss_rnnt 13.674370 hw_loss 0.210743 lr 0.00048222 rank 2
2023-02-22 00:38:05,636 DEBUG TRAIN Batch 12/7400 loss 15.383917 loss_att 20.940701 loss_ctc 18.425161 loss_rnnt 13.703106 hw_loss 0.307417 lr 0.00048220 rank 7
2023-02-22 00:38:05,641 DEBUG TRAIN Batch 12/7400 loss 17.593987 loss_att 20.855104 loss_ctc 24.973789 loss_rnnt 15.842611 hw_loss 0.215960 lr 0.00048225 rank 4
2023-02-22 00:38:05,641 DEBUG TRAIN Batch 12/7400 loss 8.068158 loss_att 13.014006 loss_ctc 7.841523 loss_rnnt 6.937341 hw_loss 0.322249 lr 0.00048223 rank 3
2023-02-22 00:38:05,641 DEBUG TRAIN Batch 12/7400 loss 13.857230 loss_att 18.569426 loss_ctc 17.451200 loss_rnnt 12.313416 hw_loss 0.229084 lr 0.00048227 rank 0
2023-02-22 00:38:05,642 DEBUG TRAIN Batch 12/7400 loss 16.902822 loss_att 23.079079 loss_ctc 22.608049 loss_rnnt 14.718745 hw_loss 0.352739 lr 0.00048227 rank 1
2023-02-22 00:38:05,644 DEBUG TRAIN Batch 12/7400 loss 13.879294 loss_att 18.149897 loss_ctc 15.391306 loss_rnnt 12.652853 hw_loss 0.320101 lr 0.00048222 rank 6
2023-02-22 00:38:05,654 DEBUG TRAIN Batch 12/7400 loss 20.214802 loss_att 28.726608 loss_ctc 23.252739 loss_rnnt 18.007458 hw_loss 0.187361 lr 0.00048222 rank 5
2023-02-22 00:39:19,551 DEBUG TRAIN Batch 12/7500 loss 24.975695 loss_att 25.166471 loss_ctc 27.553516 loss_rnnt 24.505840 hw_loss 0.164981 lr 0.00048198 rank 7
2023-02-22 00:39:19,554 DEBUG TRAIN Batch 12/7500 loss 25.297453 loss_att 26.648777 loss_ctc 31.462826 loss_rnnt 24.043253 hw_loss 0.303534 lr 0.00048201 rank 3
2023-02-22 00:39:19,556 DEBUG TRAIN Batch 12/7500 loss 24.276306 loss_att 29.310238 loss_ctc 30.252401 loss_rnnt 22.297235 hw_loss 0.329007 lr 0.00048199 rank 2
2023-02-22 00:39:19,559 DEBUG TRAIN Batch 12/7500 loss 11.061230 loss_att 14.114092 loss_ctc 12.333050 loss_rnnt 10.170767 hw_loss 0.206839 lr 0.00048200 rank 6
2023-02-22 00:39:19,563 DEBUG TRAIN Batch 12/7500 loss 10.897594 loss_att 13.909317 loss_ctc 11.547420 loss_rnnt 10.075574 hw_loss 0.249433 lr 0.00048203 rank 4
2023-02-22 00:39:19,563 DEBUG TRAIN Batch 12/7500 loss 7.497212 loss_att 10.441845 loss_ctc 8.853641 loss_rnnt 6.515188 hw_loss 0.397951 lr 0.00048204 rank 1
2023-02-22 00:39:19,565 DEBUG TRAIN Batch 12/7500 loss 15.048442 loss_att 15.536615 loss_ctc 15.766270 loss_rnnt 14.761868 hw_loss 0.174807 lr 0.00048204 rank 0
2023-02-22 00:39:19,568 DEBUG TRAIN Batch 12/7500 loss 22.782663 loss_att 23.620350 loss_ctc 31.644773 loss_rnnt 21.219011 hw_loss 0.402187 lr 0.00048200 rank 5
2023-02-22 00:40:31,977 DEBUG TRAIN Batch 12/7600 loss 20.963028 loss_att 22.066936 loss_ctc 22.686453 loss_rnnt 20.386938 hw_loss 0.235342 lr 0.00048178 rank 3
2023-02-22 00:40:31,979 DEBUG TRAIN Batch 12/7600 loss 12.972385 loss_att 14.087603 loss_ctc 14.327094 loss_rnnt 12.286292 hw_loss 0.529541 lr 0.00048177 rank 2
2023-02-22 00:40:31,983 DEBUG TRAIN Batch 12/7600 loss 17.726187 loss_att 22.749668 loss_ctc 20.372074 loss_rnnt 16.146482 hw_loss 0.416668 lr 0.00048177 rank 6
2023-02-22 00:40:31,986 DEBUG TRAIN Batch 12/7600 loss 6.951498 loss_att 9.440521 loss_ctc 7.257097 loss_rnnt 6.308907 hw_loss 0.195075 lr 0.00048182 rank 1
2023-02-22 00:40:31,987 DEBUG TRAIN Batch 12/7600 loss 15.339793 loss_att 16.058475 loss_ctc 17.475342 loss_rnnt 14.642414 hw_loss 0.504192 lr 0.00048180 rank 4
2023-02-22 00:40:31,991 DEBUG TRAIN Batch 12/7600 loss 23.226210 loss_att 25.216969 loss_ctc 28.867817 loss_rnnt 21.949562 hw_loss 0.236780 lr 0.00048177 rank 5
2023-02-22 00:40:31,991 DEBUG TRAIN Batch 12/7600 loss 12.680923 loss_att 18.547115 loss_ctc 16.940182 loss_rnnt 10.791307 hw_loss 0.278389 lr 0.00048182 rank 0
2023-02-22 00:40:32,032 DEBUG TRAIN Batch 12/7600 loss 9.311531 loss_att 9.838011 loss_ctc 10.844111 loss_rnnt 8.764903 hw_loss 0.444353 lr 0.00048175 rank 7
2023-02-22 00:41:44,668 DEBUG TRAIN Batch 12/7700 loss 12.939374 loss_att 23.548725 loss_ctc 20.422758 loss_rnnt 9.668141 hw_loss 0.284207 lr 0.00048156 rank 3
2023-02-22 00:41:44,673 DEBUG TRAIN Batch 12/7700 loss 18.989513 loss_att 20.541616 loss_ctc 20.579191 loss_rnnt 18.307035 hw_loss 0.300189 lr 0.00048160 rank 0
2023-02-22 00:41:44,673 DEBUG TRAIN Batch 12/7700 loss 15.468180 loss_att 17.899120 loss_ctc 24.257322 loss_rnnt 13.595932 hw_loss 0.401576 lr 0.00048155 rank 2
2023-02-22 00:41:44,675 DEBUG TRAIN Batch 12/7700 loss 9.647335 loss_att 8.779445 loss_ctc 11.048820 loss_rnnt 9.435723 hw_loss 0.371858 lr 0.00048160 rank 1
2023-02-22 00:41:44,676 DEBUG TRAIN Batch 12/7700 loss 12.253771 loss_att 16.741228 loss_ctc 17.134735 loss_rnnt 10.603069 hw_loss 0.192027 lr 0.00048153 rank 7
2023-02-22 00:41:44,676 DEBUG TRAIN Batch 12/7700 loss 13.779301 loss_att 18.092308 loss_ctc 18.145521 loss_rnnt 12.283150 hw_loss 0.096349 lr 0.00048158 rank 4
2023-02-22 00:41:44,678 DEBUG TRAIN Batch 12/7700 loss 20.209745 loss_att 22.742573 loss_ctc 27.030970 loss_rnnt 18.647917 hw_loss 0.273312 lr 0.00048155 rank 5
2023-02-22 00:41:44,680 DEBUG TRAIN Batch 12/7700 loss 13.709045 loss_att 14.776773 loss_ctc 14.668502 loss_rnnt 13.068895 hw_loss 0.560018 lr 0.00048155 rank 6
2023-02-22 00:42:59,505 DEBUG TRAIN Batch 12/7800 loss 13.543815 loss_att 12.989204 loss_ctc 15.900140 loss_rnnt 13.090969 hw_loss 0.467983 lr 0.00048137 rank 0
2023-02-22 00:42:59,506 DEBUG TRAIN Batch 12/7800 loss 15.631226 loss_att 21.678841 loss_ctc 23.573278 loss_rnnt 13.196203 hw_loss 0.312298 lr 0.00048134 rank 3
2023-02-22 00:42:59,514 DEBUG TRAIN Batch 12/7800 loss 16.658953 loss_att 23.561308 loss_ctc 22.335861 loss_rnnt 14.401033 hw_loss 0.225988 lr 0.00048132 rank 2
2023-02-22 00:42:59,518 DEBUG TRAIN Batch 12/7800 loss 13.176981 loss_att 18.511532 loss_ctc 21.364447 loss_rnnt 10.868704 hw_loss 0.280697 lr 0.00048131 rank 7
2023-02-22 00:42:59,521 DEBUG TRAIN Batch 12/7800 loss 18.967344 loss_att 26.820700 loss_ctc 24.019955 loss_rnnt 16.578815 hw_loss 0.270328 lr 0.00048137 rank 1
2023-02-22 00:42:59,524 DEBUG TRAIN Batch 12/7800 loss 39.406013 loss_att 41.986694 loss_ctc 45.958233 loss_rnnt 37.929333 hw_loss 0.162967 lr 0.00048133 rank 6
2023-02-22 00:42:59,524 DEBUG TRAIN Batch 12/7800 loss 23.181614 loss_att 29.230915 loss_ctc 30.676268 loss_rnnt 20.834728 hw_loss 0.258261 lr 0.00048136 rank 4
2023-02-22 00:42:59,543 DEBUG TRAIN Batch 12/7800 loss 11.067827 loss_att 15.989632 loss_ctc 14.815023 loss_rnnt 9.434928 hw_loss 0.279209 lr 0.00048133 rank 5
2023-02-22 00:44:12,568 DEBUG TRAIN Batch 12/7900 loss 9.397961 loss_att 12.300920 loss_ctc 11.988655 loss_rnnt 8.327305 hw_loss 0.271196 lr 0.00048113 rank 4
2023-02-22 00:44:12,569 DEBUG TRAIN Batch 12/7900 loss 15.118273 loss_att 21.311115 loss_ctc 19.137138 loss_rnnt 13.092447 hw_loss 0.471389 lr 0.00048110 rank 5
2023-02-22 00:44:12,577 DEBUG TRAIN Batch 12/7900 loss 26.423088 loss_att 27.151043 loss_ctc 31.995831 loss_rnnt 25.406368 hw_loss 0.240181 lr 0.00048110 rank 2
2023-02-22 00:44:12,576 DEBUG TRAIN Batch 12/7900 loss 13.679098 loss_att 16.339718 loss_ctc 11.391155 loss_rnnt 13.325743 hw_loss 0.236798 lr 0.00048111 rank 3
2023-02-22 00:44:12,581 DEBUG TRAIN Batch 12/7900 loss 12.238524 loss_att 17.372559 loss_ctc 15.827830 loss_rnnt 10.599407 hw_loss 0.250756 lr 0.00048115 rank 1
2023-02-22 00:44:12,583 DEBUG TRAIN Batch 12/7900 loss 8.643235 loss_att 13.718045 loss_ctc 14.826774 loss_rnnt 6.653971 hw_loss 0.280930 lr 0.00048110 rank 6
2023-02-22 00:44:12,590 DEBUG TRAIN Batch 12/7900 loss 15.561803 loss_att 16.934217 loss_ctc 22.756111 loss_rnnt 14.187248 hw_loss 0.264057 lr 0.00048115 rank 0
2023-02-22 00:44:12,624 DEBUG TRAIN Batch 12/7900 loss 25.912523 loss_att 35.386833 loss_ctc 28.255692 loss_rnnt 23.564407 hw_loss 0.264056 lr 0.00048108 rank 7
2023-02-22 00:45:24,175 DEBUG TRAIN Batch 12/8000 loss 11.499716 loss_att 13.281065 loss_ctc 12.393340 loss_rnnt 10.951591 hw_loss 0.136320 lr 0.00048088 rank 2
2023-02-22 00:45:24,179 DEBUG TRAIN Batch 12/8000 loss 6.598289 loss_att 8.347206 loss_ctc 7.102971 loss_rnnt 5.872947 hw_loss 0.578002 lr 0.00048088 rank 6
2023-02-22 00:45:24,181 DEBUG TRAIN Batch 12/8000 loss 12.243438 loss_att 13.875259 loss_ctc 13.999531 loss_rnnt 11.536573 hw_loss 0.274415 lr 0.00048091 rank 4
2023-02-22 00:45:24,182 DEBUG TRAIN Batch 12/8000 loss 16.925428 loss_att 19.609432 loss_ctc 19.670006 loss_rnnt 15.927214 hw_loss 0.179010 lr 0.00048093 rank 0
2023-02-22 00:45:24,183 DEBUG TRAIN Batch 12/8000 loss 13.379896 loss_att 18.126236 loss_ctc 21.380682 loss_rnnt 11.155375 hw_loss 0.390901 lr 0.00048088 rank 5
2023-02-22 00:45:24,183 DEBUG TRAIN Batch 12/8000 loss 11.604126 loss_att 14.330563 loss_ctc 14.081617 loss_rnnt 10.582844 hw_loss 0.273115 lr 0.00048089 rank 3
2023-02-22 00:45:24,188 DEBUG TRAIN Batch 12/8000 loss 17.902935 loss_att 20.707373 loss_ctc 20.057968 loss_rnnt 16.943090 hw_loss 0.209291 lr 0.00048086 rank 7
2023-02-22 00:45:24,241 DEBUG TRAIN Batch 12/8000 loss 9.991127 loss_att 13.413898 loss_ctc 16.185120 loss_rnnt 8.375454 hw_loss 0.197350 lr 0.00048093 rank 1
2023-02-22 00:46:37,242 DEBUG TRAIN Batch 12/8100 loss 8.518699 loss_att 12.455866 loss_ctc 11.128048 loss_rnnt 7.218846 hw_loss 0.308448 lr 0.00048069 rank 4
2023-02-22 00:46:37,253 DEBUG TRAIN Batch 12/8100 loss 15.642325 loss_att 18.320921 loss_ctc 20.826630 loss_rnnt 14.304729 hw_loss 0.207445 lr 0.00048066 rank 2
2023-02-22 00:46:37,254 DEBUG TRAIN Batch 12/8100 loss 10.708098 loss_att 14.181831 loss_ctc 12.557850 loss_rnnt 9.674348 hw_loss 0.173195 lr 0.00048066 rank 6
2023-02-22 00:46:37,256 DEBUG TRAIN Batch 12/8100 loss 9.963250 loss_att 13.147795 loss_ctc 12.639179 loss_rnnt 8.856863 hw_loss 0.211288 lr 0.00048070 rank 0
2023-02-22 00:46:37,257 DEBUG TRAIN Batch 12/8100 loss 22.121658 loss_att 24.271414 loss_ctc 31.136616 loss_rnnt 20.367069 hw_loss 0.229957 lr 0.00048067 rank 3
2023-02-22 00:46:37,260 DEBUG TRAIN Batch 12/8100 loss 10.637697 loss_att 14.572233 loss_ctc 13.837194 loss_rnnt 9.307547 hw_loss 0.218705 lr 0.00048066 rank 5
2023-02-22 00:46:37,267 DEBUG TRAIN Batch 12/8100 loss 11.926874 loss_att 16.478285 loss_ctc 18.122814 loss_rnnt 10.092955 hw_loss 0.182837 lr 0.00048070 rank 1
2023-02-22 00:46:37,274 DEBUG TRAIN Batch 12/8100 loss 12.828201 loss_att 18.028063 loss_ctc 15.684378 loss_rnnt 11.227017 hw_loss 0.338227 lr 0.00048064 rank 7
2023-02-22 00:47:49,736 DEBUG TRAIN Batch 12/8200 loss 10.486808 loss_att 10.951301 loss_ctc 10.969225 loss_rnnt 10.182553 hw_loss 0.275686 lr 0.00048045 rank 3
2023-02-22 00:47:49,756 DEBUG TRAIN Batch 12/8200 loss 10.029267 loss_att 14.721536 loss_ctc 11.363857 loss_rnnt 8.739334 hw_loss 0.325376 lr 0.00048043 rank 2
2023-02-22 00:47:49,760 DEBUG TRAIN Batch 12/8200 loss 7.766208 loss_att 10.776556 loss_ctc 11.451557 loss_rnnt 6.452243 hw_loss 0.413467 lr 0.00048048 rank 1
2023-02-22 00:47:49,760 DEBUG TRAIN Batch 12/8200 loss 8.303317 loss_att 13.525581 loss_ctc 9.990530 loss_rnnt 6.929862 hw_loss 0.195077 lr 0.00048048 rank 0
2023-02-22 00:47:49,761 DEBUG TRAIN Batch 12/8200 loss 5.789706 loss_att 8.912444 loss_ctc 8.884837 loss_rnnt 4.682024 hw_loss 0.132096 lr 0.00048044 rank 5
2023-02-22 00:47:49,761 DEBUG TRAIN Batch 12/8200 loss 13.220135 loss_att 15.190957 loss_ctc 21.746548 loss_rnnt 11.552734 hw_loss 0.255713 lr 0.00048042 rank 7
2023-02-22 00:47:49,762 DEBUG TRAIN Batch 12/8200 loss 11.937286 loss_att 14.980314 loss_ctc 13.706870 loss_rnnt 10.972013 hw_loss 0.226354 lr 0.00048044 rank 6
2023-02-22 00:47:49,808 DEBUG TRAIN Batch 12/8200 loss 14.323325 loss_att 17.048828 loss_ctc 18.721481 loss_rnnt 12.942782 hw_loss 0.466914 lr 0.00048047 rank 4
2023-02-22 00:49:01,696 DEBUG TRAIN Batch 12/8300 loss 13.035589 loss_att 15.117329 loss_ctc 16.923307 loss_rnnt 11.963639 hw_loss 0.257326 lr 0.00048023 rank 3
2023-02-22 00:49:01,703 DEBUG TRAIN Batch 12/8300 loss 21.367687 loss_att 23.900936 loss_ctc 25.817232 loss_rnnt 20.126740 hw_loss 0.264427 lr 0.00048021 rank 5
2023-02-22 00:49:01,703 DEBUG TRAIN Batch 12/8300 loss 12.217721 loss_att 13.232059 loss_ctc 14.809412 loss_rnnt 11.509092 hw_loss 0.300382 lr 0.00048021 rank 6
2023-02-22 00:49:01,704 DEBUG TRAIN Batch 12/8300 loss 12.067376 loss_att 14.174616 loss_ctc 16.603603 loss_rnnt 10.864673 hw_loss 0.330798 lr 0.00048021 rank 2
2023-02-22 00:49:01,706 DEBUG TRAIN Batch 12/8300 loss 18.111404 loss_att 16.378033 loss_ctc 19.220293 loss_rnnt 18.174244 hw_loss 0.254964 lr 0.00048019 rank 7
2023-02-22 00:49:01,707 DEBUG TRAIN Batch 12/8300 loss 12.144148 loss_att 16.545401 loss_ctc 14.989137 loss_rnnt 10.747326 hw_loss 0.257326 lr 0.00048026 rank 1
2023-02-22 00:49:01,708 DEBUG TRAIN Batch 12/8300 loss 15.372296 loss_att 17.275053 loss_ctc 17.269119 loss_rnnt 14.621902 hw_loss 0.219249 lr 0.00048026 rank 0
2023-02-22 00:49:01,745 DEBUG TRAIN Batch 12/8300 loss 16.231077 loss_att 17.107210 loss_ctc 11.827315 loss_rnnt 16.513680 hw_loss 0.242510 lr 0.00048025 rank 4
2023-02-22 00:49:42,852 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 6
2023-02-22 00:49:42,855 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 0
2023-02-22 00:49:42,860 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 1
2023-02-22 00:49:42,861 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 2
2023-02-22 00:49:42,864 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 7
2023-02-22 00:49:42,867 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 3
2023-02-22 00:49:42,873 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 4
2023-02-22 00:49:42,899 DEBUG CV Batch 12/0 loss 2.936858 loss_att 2.810569 loss_ctc 3.734824 loss_rnnt 2.500314 hw_loss 0.666387 history loss 2.828086 rank 5
2023-02-22 00:49:54,238 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 6
2023-02-22 00:49:54,313 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 3
2023-02-22 00:49:54,331 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 7
2023-02-22 00:49:54,338 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 2
2023-02-22 00:49:54,464 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 0
2023-02-22 00:49:54,485 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 1
2023-02-22 00:49:54,519 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 5
2023-02-22 00:49:54,660 DEBUG CV Batch 12/100 loss 9.576499 loss_att 10.528259 loss_ctc 11.637287 loss_rnnt 8.920307 hw_loss 0.358252 history loss 5.014376 rank 4
2023-02-22 00:50:07,809 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 6
2023-02-22 00:50:07,878 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 7
2023-02-22 00:50:07,890 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 1
2023-02-22 00:50:07,900 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 3
2023-02-22 00:50:08,009 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 2
2023-02-22 00:50:08,119 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 0
2023-02-22 00:50:08,214 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 4
2023-02-22 00:50:08,441 DEBUG CV Batch 12/200 loss 13.978982 loss_att 26.588507 loss_ctc 15.808693 loss_rnnt 11.135687 hw_loss 0.145179 history loss 5.622924 rank 5
2023-02-22 00:50:20,077 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 2
2023-02-22 00:50:20,129 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 7
2023-02-22 00:50:20,153 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 6
2023-02-22 00:50:20,181 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 1
2023-02-22 00:50:20,181 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 3
2023-02-22 00:50:20,672 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 0
2023-02-22 00:50:20,735 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 4
2023-02-22 00:50:21,309 DEBUG CV Batch 12/300 loss 6.142620 loss_att 6.805151 loss_ctc 8.140083 loss_rnnt 5.503942 hw_loss 0.449707 history loss 5.908734 rank 5
2023-02-22 00:50:32,264 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 3
2023-02-22 00:50:32,289 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 6
2023-02-22 00:50:32,386 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 2
2023-02-22 00:50:32,491 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 7
2023-02-22 00:50:32,572 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 1
2023-02-22 00:50:32,979 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 4
2023-02-22 00:50:33,284 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 0
2023-02-22 00:50:33,853 DEBUG CV Batch 12/400 loss 28.744820 loss_att 118.786530 loss_ctc 15.497242 loss_rnnt 12.375621 hw_loss 0.238499 history loss 7.129356 rank 5
2023-02-22 00:50:43,069 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 3
2023-02-22 00:50:43,211 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 2
2023-02-22 00:50:43,228 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 6
2023-02-22 00:50:43,452 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 7
2023-02-22 00:50:43,465 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 1
2023-02-22 00:50:44,079 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 4
2023-02-22 00:50:44,912 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 0
2023-02-22 00:50:45,105 DEBUG CV Batch 12/500 loss 7.595559 loss_att 8.553394 loss_ctc 11.004146 loss_rnnt 6.781480 hw_loss 0.315063 history loss 8.165502 rank 5
2023-02-22 00:50:55,249 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 3
2023-02-22 00:50:55,356 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 6
2023-02-22 00:50:55,471 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 2
2023-02-22 00:50:55,756 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 1
2023-02-22 00:50:56,100 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 7
2023-02-22 00:50:56,541 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 4
2023-02-22 00:50:57,691 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 0
2023-02-22 00:50:57,801 DEBUG CV Batch 12/600 loss 9.864085 loss_att 8.945803 loss_ctc 10.655980 loss_rnnt 9.614121 hw_loss 0.615063 history loss 9.288316 rank 5
2023-02-22 00:51:06,720 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 3
2023-02-22 00:51:06,821 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 6
2023-02-22 00:51:07,154 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 1
2023-02-22 00:51:07,177 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 2
2023-02-22 00:51:07,629 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 7
2023-02-22 00:51:08,105 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 4
2023-02-22 00:51:09,525 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 0
2023-02-22 00:51:09,640 DEBUG CV Batch 12/700 loss 19.727575 loss_att 75.998734 loss_ctc 19.953098 loss_rnnt 8.286779 hw_loss 0.293427 history loss 10.249596 rank 5
2023-02-22 00:51:18,204 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 3
2023-02-22 00:51:18,383 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 6
2023-02-22 00:51:18,521 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 2
2023-02-22 00:51:18,621 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 1
2023-02-22 00:51:19,175 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 7
2023-02-22 00:51:19,899 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 4
2023-02-22 00:51:21,436 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 0
2023-02-22 00:51:21,682 DEBUG CV Batch 12/800 loss 13.979630 loss_att 13.459923 loss_ctc 15.610773 loss_rnnt 13.657913 hw_loss 0.390324 history loss 9.543794 rank 5
2023-02-22 00:51:31,602 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 3
2023-02-22 00:51:31,868 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 6
2023-02-22 00:51:32,104 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 2
2023-02-22 00:51:32,350 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 1
2023-02-22 00:51:32,686 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 7
2023-02-22 00:51:33,492 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 4
2023-02-22 00:51:35,291 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 0
2023-02-22 00:51:35,393 DEBUG CV Batch 12/900 loss 20.095680 loss_att 42.532810 loss_ctc 22.211422 loss_rnnt 15.161522 hw_loss 0.308687 history loss 9.253788 rank 5
2023-02-22 00:51:44,043 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 3
2023-02-22 00:51:44,262 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 6
2023-02-22 00:51:44,663 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 2
2023-02-22 00:51:44,701 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 1
2023-02-22 00:51:45,228 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 7
2023-02-22 00:51:46,120 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 4
2023-02-22 00:51:48,345 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 0
2023-02-22 00:51:48,522 DEBUG CV Batch 12/1000 loss 5.662674 loss_att 7.201186 loss_ctc 5.652783 loss_rnnt 5.121218 hw_loss 0.440759 history loss 8.970403 rank 5
2023-02-22 00:51:56,117 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 3
2023-02-22 00:51:56,337 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 6
2023-02-22 00:51:56,640 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 1
2023-02-22 00:51:56,711 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 2
2023-02-22 00:51:57,488 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 7
2023-02-22 00:51:58,443 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 4
2023-02-22 00:52:00,798 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 0
2023-02-22 00:52:01,164 DEBUG CV Batch 12/1100 loss 8.202933 loss_att 6.649773 loss_ctc 10.305659 loss_rnnt 7.855167 hw_loss 0.708813 history loss 8.942265 rank 5
2023-02-22 00:52:06,962 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 3
2023-02-22 00:52:07,298 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 6
2023-02-22 00:52:07,439 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 1
2023-02-22 00:52:07,636 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 2
2023-02-22 00:52:08,425 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 7
2023-02-22 00:52:09,738 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 4
2023-02-22 00:52:12,084 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 0
2023-02-22 00:52:12,314 DEBUG CV Batch 12/1200 loss 11.937500 loss_att 12.687776 loss_ctc 14.055219 loss_rnnt 11.312113 hw_loss 0.361816 history loss 9.376914 rank 5
2023-02-22 00:52:19,107 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 3
2023-02-22 00:52:19,599 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 6
2023-02-22 00:52:19,616 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 1
2023-02-22 00:52:19,879 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 2
2023-02-22 00:52:20,943 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 7
2023-02-22 00:52:22,260 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 4
2023-02-22 00:52:24,701 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 0
2023-02-22 00:52:24,864 DEBUG CV Batch 12/1300 loss 9.326923 loss_att 7.015902 loss_ctc 10.130032 loss_rnnt 9.421781 hw_loss 0.487997 history loss 9.732443 rank 5
2023-02-22 00:52:30,505 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 3
2023-02-22 00:52:30,923 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 1
2023-02-22 00:52:31,134 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 6
2023-02-22 00:52:31,457 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 2
2023-02-22 00:52:32,589 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 7
2023-02-22 00:52:34,023 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 4
2023-02-22 00:52:36,710 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 5
2023-02-22 00:52:36,764 DEBUG CV Batch 12/1400 loss 15.086024 loss_att 46.518623 loss_ctc 9.075093 loss_rnnt 9.485916 hw_loss 0.215712 history loss 10.201135 rank 0
2023-02-22 00:52:42,293 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 3
2023-02-22 00:52:42,531 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 1
2023-02-22 00:52:42,969 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 6
2023-02-22 00:52:43,250 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 2
2023-02-22 00:52:44,392 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 7
2023-02-22 00:52:45,990 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 4
2023-02-22 00:52:48,815 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 5
2023-02-22 00:52:48,929 DEBUG CV Batch 12/1500 loss 8.456400 loss_att 9.303423 loss_ctc 6.005543 loss_rnnt 8.481021 hw_loss 0.248917 history loss 9.941426 rank 0
2023-02-22 00:52:55,543 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 1
2023-02-22 00:52:55,592 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 3
2023-02-22 00:52:56,266 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 6
2023-02-22 00:52:56,667 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 2
2023-02-22 00:52:57,756 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 7
2023-02-22 00:52:59,491 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 4
2023-02-22 00:53:02,393 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 0
2023-02-22 00:53:02,452 DEBUG CV Batch 12/1600 loss 10.286215 loss_att 19.520912 loss_ctc 15.642342 loss_rnnt 7.626637 hw_loss 0.184665 history loss 9.815797 rank 5
2023-02-22 00:53:07,979 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 1
2023-02-22 00:53:08,228 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 3
2023-02-22 00:53:08,909 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 6
2023-02-22 00:53:09,397 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 2
2023-02-22 00:53:10,685 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 7
2023-02-22 00:53:12,049 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 4
2023-02-22 00:53:15,039 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 5
2023-02-22 00:53:15,051 DEBUG CV Batch 12/1700 loss 13.917921 loss_att 14.063947 loss_ctc 18.384680 loss_rnnt 13.140810 hw_loss 0.285633 history loss 9.676691 rank 0
2023-02-22 00:53:17,017 INFO Epoch 12 CV info cv_loss 9.608033166948745
2023-02-22 00:53:17,018 INFO Epoch 13 TRAIN info lr 0.0004802123545971549
2023-02-22 00:53:17,019 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:53:17,388 INFO Epoch 12 CV info cv_loss 9.608033166793682
2023-02-22 00:53:17,389 INFO Epoch 13 TRAIN info lr 0.00048014371123461703
2023-02-22 00:53:17,391 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:53:18,048 INFO Epoch 12 CV info cv_loss 9.608033165966678
2023-02-22 00:53:18,049 INFO Epoch 13 TRAIN info lr 0.00048014813895038046
2023-02-22 00:53:18,051 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:53:18,535 INFO Epoch 12 CV info cv_loss 9.608033167543155
2023-02-22 00:53:18,536 INFO Epoch 13 TRAIN info lr 0.00048013706989063717
2023-02-22 00:53:18,538 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:53:20,013 INFO Epoch 12 CV info cv_loss 9.60803316543257
2023-02-22 00:53:20,013 INFO Epoch 13 TRAIN info lr 0.0004801016540432105
2023-02-22 00:53:20,017 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:53:21,666 INFO Epoch 12 CV info cv_loss 9.60803316554456
2023-02-22 00:53:21,666 INFO Epoch 13 TRAIN info lr 0.00048013928364134265
2023-02-22 00:53:21,668 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:53:24,299 INFO Epoch 12 CV info cv_loss 9.608033165906374
2023-02-22 00:53:24,299 INFO Epoch 13 TRAIN info lr 0.00048017249357682455
2023-02-22 00:53:24,308 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:53:24,464 INFO Epoch 12 CV info cv_loss 9.608033165182745
2023-02-22 00:53:24,464 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/12.pt
2023-02-22 00:53:25,051 INFO Epoch 13 TRAIN info lr 0.0004802300737929397
2023-02-22 00:53:25,057 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 00:54:27,931 DEBUG TRAIN Batch 13/0 loss 10.900364 loss_att 10.363119 loss_ctc 13.344893 loss_rnnt 10.464270 hw_loss 0.408011 lr 0.00048010 rank 7
2023-02-22 00:54:27,933 DEBUG TRAIN Batch 13/0 loss 11.202410 loss_att 11.035460 loss_ctc 13.345890 loss_rnnt 10.640151 hw_loss 0.580972 lr 0.00048013 rank 2
2023-02-22 00:54:27,933 DEBUG TRAIN Batch 13/0 loss 10.506279 loss_att 9.235300 loss_ctc 12.528820 loss_rnnt 10.221670 hw_loss 0.504624 lr 0.00048015 rank 6
2023-02-22 00:54:27,939 DEBUG TRAIN Batch 13/0 loss 9.195755 loss_att 8.663982 loss_ctc 11.063811 loss_rnnt 8.808119 hw_loss 0.459219 lr 0.00048014 rank 4
2023-02-22 00:54:27,940 DEBUG TRAIN Batch 13/0 loss 6.925437 loss_att 7.540205 loss_ctc 8.227293 loss_rnnt 6.334036 hw_loss 0.552875 lr 0.00048014 rank 3
2023-02-22 00:54:27,943 DEBUG TRAIN Batch 13/0 loss 10.385701 loss_att 9.360174 loss_ctc 12.039306 loss_rnnt 10.105280 hw_loss 0.496962 lr 0.00048017 rank 5
2023-02-22 00:54:27,964 DEBUG TRAIN Batch 13/0 loss 13.916974 loss_att 13.037211 loss_ctc 16.235199 loss_rnnt 13.512939 hw_loss 0.507920 lr 0.00048021 rank 1
2023-02-22 00:54:27,994 DEBUG TRAIN Batch 13/0 loss 13.216230 loss_att 11.929309 loss_ctc 15.366466 loss_rnnt 12.942000 hw_loss 0.459219 lr 0.00048023 rank 0
2023-02-22 00:55:39,212 DEBUG TRAIN Batch 13/100 loss 21.692337 loss_att 29.129642 loss_ctc 31.010565 loss_rnnt 18.756855 hw_loss 0.385486 lr 0.00047992 rank 3
2023-02-22 00:55:39,212 DEBUG TRAIN Batch 13/100 loss 17.323240 loss_att 21.187113 loss_ctc 22.120382 loss_rnnt 15.818373 hw_loss 0.173392 lr 0.00047992 rank 4
2023-02-22 00:55:39,213 DEBUG TRAIN Batch 13/100 loss 7.422780 loss_att 10.386734 loss_ctc 9.017244 loss_rnnt 6.575416 hw_loss 0.078709 lr 0.00047991 rank 2
2023-02-22 00:55:39,214 DEBUG TRAIN Batch 13/100 loss 10.529519 loss_att 18.201815 loss_ctc 12.159457 loss_rnnt 8.642769 hw_loss 0.253059 lr 0.00047992 rank 6
2023-02-22 00:55:39,216 DEBUG TRAIN Batch 13/100 loss 13.848971 loss_att 19.829590 loss_ctc 16.248878 loss_rnnt 12.267028 hw_loss 0.123437 lr 0.00047999 rank 1
2023-02-22 00:55:39,219 DEBUG TRAIN Batch 13/100 loss 11.466746 loss_att 15.837354 loss_ctc 14.834514 loss_rnnt 10.003008 hw_loss 0.263589 lr 0.00047995 rank 5
2023-02-22 00:55:39,222 DEBUG TRAIN Batch 13/100 loss 19.270350 loss_att 22.780851 loss_ctc 26.129818 loss_rnnt 17.584120 hw_loss 0.130377 lr 0.00047988 rank 7
2023-02-22 00:55:39,269 DEBUG TRAIN Batch 13/100 loss 11.454961 loss_att 14.337688 loss_ctc 11.278071 loss_rnnt 10.706126 hw_loss 0.367263 lr 0.00048001 rank 0
2023-02-22 00:56:51,330 DEBUG TRAIN Batch 13/200 loss 11.111489 loss_att 15.570101 loss_ctc 12.626563 loss_rnnt 9.879866 hw_loss 0.258545 lr 0.00047970 rank 3
2023-02-22 00:56:51,333 DEBUG TRAIN Batch 13/200 loss 19.194956 loss_att 22.070951 loss_ctc 22.174604 loss_rnnt 18.123402 hw_loss 0.185750 lr 0.00047969 rank 4
2023-02-22 00:56:51,335 DEBUG TRAIN Batch 13/200 loss 29.697540 loss_att 31.354643 loss_ctc 41.190643 loss_rnnt 27.688299 hw_loss 0.272638 lr 0.00047970 rank 6
2023-02-22 00:56:51,340 DEBUG TRAIN Batch 13/200 loss 17.471069 loss_att 23.028244 loss_ctc 20.810253 loss_rnnt 15.807838 hw_loss 0.199826 lr 0.00047969 rank 2
2023-02-22 00:56:51,340 DEBUG TRAIN Batch 13/200 loss 10.029439 loss_att 13.620660 loss_ctc 12.463141 loss_rnnt 8.894121 hw_loss 0.173587 lr 0.00047977 rank 1
2023-02-22 00:56:51,340 DEBUG TRAIN Batch 13/200 loss 10.049735 loss_att 13.108609 loss_ctc 14.029444 loss_rnnt 8.801060 hw_loss 0.199261 lr 0.00047966 rank 7
2023-02-22 00:56:51,342 DEBUG TRAIN Batch 13/200 loss 27.056448 loss_att 30.016056 loss_ctc 32.887753 loss_rnnt 25.619595 hw_loss 0.126425 lr 0.00047979 rank 0
2023-02-22 00:56:51,343 DEBUG TRAIN Batch 13/200 loss 10.825957 loss_att 16.400719 loss_ctc 13.972545 loss_rnnt 9.109446 hw_loss 0.341277 lr 0.00047973 rank 5
2023-02-22 00:58:04,857 DEBUG TRAIN Batch 13/300 loss 16.508293 loss_att 23.723923 loss_ctc 24.174574 loss_rnnt 13.893190 hw_loss 0.280884 lr 0.00047948 rank 3
2023-02-22 00:58:04,859 DEBUG TRAIN Batch 13/300 loss 10.555418 loss_att 15.085844 loss_ctc 12.022133 loss_rnnt 9.357368 hw_loss 0.180754 lr 0.00047951 rank 5
2023-02-22 00:58:04,860 DEBUG TRAIN Batch 13/300 loss 19.225775 loss_att 24.374424 loss_ctc 19.419159 loss_rnnt 18.052212 hw_loss 0.221345 lr 0.00047948 rank 6
2023-02-22 00:58:04,861 DEBUG TRAIN Batch 13/300 loss 10.128525 loss_att 12.334562 loss_ctc 10.697161 loss_rnnt 9.508660 hw_loss 0.192820 lr 0.00047947 rank 4
2023-02-22 00:58:04,862 DEBUG TRAIN Batch 13/300 loss 17.201595 loss_att 19.892017 loss_ctc 21.977543 loss_rnnt 15.802555 hw_loss 0.420302 lr 0.00047955 rank 1
2023-02-22 00:58:04,864 DEBUG TRAIN Batch 13/300 loss 11.692036 loss_att 15.777927 loss_ctc 14.736830 loss_rnnt 10.304678 hw_loss 0.307888 lr 0.00047944 rank 7
2023-02-22 00:58:04,881 DEBUG TRAIN Batch 13/300 loss 11.334461 loss_att 13.510632 loss_ctc 17.605940 loss_rnnt 9.868202 hw_loss 0.365301 lr 0.00047947 rank 2
2023-02-22 00:58:04,894 DEBUG TRAIN Batch 13/300 loss 16.531790 loss_att 21.826195 loss_ctc 21.115814 loss_rnnt 14.650243 hw_loss 0.396488 lr 0.00047956 rank 0
2023-02-22 00:59:18,302 DEBUG TRAIN Batch 13/400 loss 11.694509 loss_att 13.879053 loss_ctc 16.552048 loss_rnnt 10.519498 hw_loss 0.169555 lr 0.00047926 rank 3
2023-02-22 00:59:18,304 DEBUG TRAIN Batch 13/400 loss 8.743568 loss_att 12.059057 loss_ctc 9.077816 loss_rnnt 7.895736 hw_loss 0.262816 lr 0.00047925 rank 4
2023-02-22 00:59:18,305 DEBUG TRAIN Batch 13/400 loss 16.863562 loss_att 17.643557 loss_ctc 21.390327 loss_rnnt 15.982784 hw_loss 0.227267 lr 0.00047926 rank 6
2023-02-22 00:59:18,306 DEBUG TRAIN Batch 13/400 loss 17.595402 loss_att 22.233793 loss_ctc 21.964706 loss_rnnt 15.902761 hw_loss 0.341977 lr 0.00047922 rank 7
2023-02-22 00:59:18,309 DEBUG TRAIN Batch 13/400 loss 14.048212 loss_att 19.151161 loss_ctc 17.311092 loss_rnnt 12.440850 hw_loss 0.284475 lr 0.00047925 rank 2
2023-02-22 00:59:18,308 DEBUG TRAIN Batch 13/400 loss 10.486236 loss_att 12.344637 loss_ctc 14.691600 loss_rnnt 9.392475 hw_loss 0.302557 lr 0.00047934 rank 0
2023-02-22 00:59:18,313 DEBUG TRAIN Batch 13/400 loss 10.897994 loss_att 11.347377 loss_ctc 12.564358 loss_rnnt 10.462591 hw_loss 0.231270 lr 0.00047933 rank 1
2023-02-22 00:59:18,315 DEBUG TRAIN Batch 13/400 loss 15.144084 loss_att 19.234104 loss_ctc 18.996861 loss_rnnt 13.704930 hw_loss 0.201460 lr 0.00047929 rank 5
2023-02-22 01:00:31,001 DEBUG TRAIN Batch 13/500 loss 12.380312 loss_att 17.204971 loss_ctc 15.105839 loss_rnnt 10.914886 hw_loss 0.257044 lr 0.00047904 rank 6
2023-02-22 01:00:31,004 DEBUG TRAIN Batch 13/500 loss 8.025763 loss_att 11.301034 loss_ctc 11.625155 loss_rnnt 6.696746 hw_loss 0.363830 lr 0.00047903 rank 2
2023-02-22 01:00:31,004 DEBUG TRAIN Batch 13/500 loss 15.421241 loss_att 18.015469 loss_ctc 19.454557 loss_rnnt 14.219095 hw_loss 0.272858 lr 0.00047911 rank 1
2023-02-22 01:00:31,005 DEBUG TRAIN Batch 13/500 loss 7.917676 loss_att 9.227246 loss_ctc 10.722737 loss_rnnt 7.146355 hw_loss 0.253874 lr 0.00047900 rank 7
2023-02-22 01:00:31,008 DEBUG TRAIN Batch 13/500 loss 13.927090 loss_att 20.061569 loss_ctc 17.993498 loss_rnnt 12.052166 hw_loss 0.198451 lr 0.00047903 rank 4
2023-02-22 01:00:31,011 DEBUG TRAIN Batch 13/500 loss 8.127455 loss_att 11.592131 loss_ctc 9.427189 loss_rnnt 7.104120 hw_loss 0.294565 lr 0.00047904 rank 3
2023-02-22 01:00:31,013 DEBUG TRAIN Batch 13/500 loss 12.789793 loss_att 18.794422 loss_ctc 20.193531 loss_rnnt 10.460398 hw_loss 0.264945 lr 0.00047907 rank 5
2023-02-22 01:00:31,055 DEBUG TRAIN Batch 13/500 loss 12.671388 loss_att 14.559845 loss_ctc 13.302368 loss_rnnt 12.028329 hw_loss 0.339817 lr 0.00047912 rank 0
2023-02-22 01:01:44,037 DEBUG TRAIN Batch 13/600 loss 19.128752 loss_att 21.447704 loss_ctc 24.814236 loss_rnnt 17.742208 hw_loss 0.308791 lr 0.00047882 rank 3
2023-02-22 01:01:44,039 DEBUG TRAIN Batch 13/600 loss 15.729544 loss_att 16.916073 loss_ctc 19.413437 loss_rnnt 14.835439 hw_loss 0.310527 lr 0.00047889 rank 1
2023-02-22 01:01:44,040 DEBUG TRAIN Batch 13/600 loss 18.392447 loss_att 17.048191 loss_ctc 21.510273 loss_rnnt 17.943092 hw_loss 0.567179 lr 0.00047881 rank 2
2023-02-22 01:01:44,040 DEBUG TRAIN Batch 13/600 loss 6.410310 loss_att 6.651190 loss_ctc 7.224126 loss_rnnt 6.063136 hw_loss 0.357167 lr 0.00047882 rank 6
2023-02-22 01:01:44,040 DEBUG TRAIN Batch 13/600 loss 17.189739 loss_att 20.232485 loss_ctc 19.628031 loss_rnnt 16.179928 hw_loss 0.142793 lr 0.00047885 rank 5
2023-02-22 01:01:44,044 DEBUG TRAIN Batch 13/600 loss 10.798296 loss_att 9.860586 loss_ctc 12.960669 loss_rnnt 10.570852 hw_loss 0.237505 lr 0.00047878 rank 7
2023-02-22 01:01:44,043 DEBUG TRAIN Batch 13/600 loss 6.098032 loss_att 8.870214 loss_ctc 7.968429 loss_rnnt 5.177673 hw_loss 0.218506 lr 0.00047881 rank 4
2023-02-22 01:01:44,049 DEBUG TRAIN Batch 13/600 loss 18.421078 loss_att 18.169855 loss_ctc 24.832857 loss_rnnt 17.410376 hw_loss 0.386328 lr 0.00047890 rank 0
2023-02-22 01:02:58,980 DEBUG TRAIN Batch 13/700 loss 6.585252 loss_att 9.805180 loss_ctc 6.701404 loss_rnnt 5.724632 hw_loss 0.377152 lr 0.00047856 rank 7
2023-02-22 01:02:58,982 DEBUG TRAIN Batch 13/700 loss 22.206593 loss_att 27.278358 loss_ctc 24.089109 loss_rnnt 20.835964 hw_loss 0.197382 lr 0.00047867 rank 1
2023-02-22 01:02:58,992 DEBUG TRAIN Batch 13/700 loss 20.495388 loss_att 26.231037 loss_ctc 22.365738 loss_rnnt 18.955933 hw_loss 0.268018 lr 0.00047860 rank 3
2023-02-22 01:02:58,992 DEBUG TRAIN Batch 13/700 loss 8.091084 loss_att 14.275345 loss_ctc 9.995534 loss_rnnt 6.438562 hw_loss 0.303270 lr 0.00047859 rank 2
2023-02-22 01:02:58,992 DEBUG TRAIN Batch 13/700 loss 23.874754 loss_att 21.187885 loss_ctc 23.540823 loss_rnnt 24.300848 hw_loss 0.292133 lr 0.00047863 rank 5
2023-02-22 01:02:58,996 DEBUG TRAIN Batch 13/700 loss 13.863615 loss_att 17.444471 loss_ctc 17.477402 loss_rnnt 12.482252 hw_loss 0.343791 lr 0.00047859 rank 4
2023-02-22 01:02:58,998 DEBUG TRAIN Batch 13/700 loss 13.275650 loss_att 19.420105 loss_ctc 15.210914 loss_rnnt 11.673823 hw_loss 0.215440 lr 0.00047868 rank 0
2023-02-22 01:02:59,000 DEBUG TRAIN Batch 13/700 loss 13.174441 loss_att 19.320057 loss_ctc 15.639510 loss_rnnt 11.513803 hw_loss 0.192820 lr 0.00047860 rank 6
2023-02-22 01:04:11,713 DEBUG TRAIN Batch 13/800 loss 19.368868 loss_att 21.146372 loss_ctc 26.398239 loss_rnnt 17.986610 hw_loss 0.167830 lr 0.00047837 rank 2
2023-02-22 01:04:11,720 DEBUG TRAIN Batch 13/800 loss 6.878304 loss_att 12.258140 loss_ctc 10.174292 loss_rnnt 5.268809 hw_loss 0.176367 lr 0.00047838 rank 3
2023-02-22 01:04:11,722 DEBUG TRAIN Batch 13/800 loss 10.730982 loss_att 13.537792 loss_ctc 11.141796 loss_rnnt 10.011663 hw_loss 0.193465 lr 0.00047838 rank 6
2023-02-22 01:04:11,727 DEBUG TRAIN Batch 13/800 loss 3.597126 loss_att 8.382708 loss_ctc 5.177236 loss_rnnt 2.300379 hw_loss 0.241780 lr 0.00047834 rank 7
2023-02-22 01:04:11,727 DEBUG TRAIN Batch 13/800 loss 22.348513 loss_att 23.377605 loss_ctc 31.240597 loss_rnnt 20.806793 hw_loss 0.281790 lr 0.00047841 rank 5
2023-02-22 01:04:11,728 DEBUG TRAIN Batch 13/800 loss 12.481632 loss_att 15.716934 loss_ctc 19.219582 loss_rnnt 10.792274 hw_loss 0.269820 lr 0.00047838 rank 4
2023-02-22 01:04:11,741 DEBUG TRAIN Batch 13/800 loss 14.216043 loss_att 15.341612 loss_ctc 13.842329 loss_rnnt 13.846998 hw_loss 0.363301 lr 0.00047845 rank 1
2023-02-22 01:04:11,746 DEBUG TRAIN Batch 13/800 loss 14.529832 loss_att 19.437660 loss_ctc 17.024017 loss_rnnt 13.078999 hw_loss 0.256329 lr 0.00047847 rank 0
2023-02-22 01:05:24,522 DEBUG TRAIN Batch 13/900 loss 12.261210 loss_att 14.255946 loss_ctc 16.572235 loss_rnnt 11.207705 hw_loss 0.149540 lr 0.00047812 rank 7
2023-02-22 01:05:24,529 DEBUG TRAIN Batch 13/900 loss 13.585265 loss_att 17.132517 loss_ctc 17.479065 loss_rnnt 12.171299 hw_loss 0.347517 lr 0.00047815 rank 2
2023-02-22 01:05:24,529 DEBUG TRAIN Batch 13/900 loss 7.644258 loss_att 10.031511 loss_ctc 12.345080 loss_rnnt 6.416447 hw_loss 0.231719 lr 0.00047817 rank 6
2023-02-22 01:05:24,533 DEBUG TRAIN Batch 13/900 loss 8.230325 loss_att 10.643047 loss_ctc 7.896106 loss_rnnt 7.702024 hw_loss 0.169346 lr 0.00047816 rank 3
2023-02-22 01:05:24,536 DEBUG TRAIN Batch 13/900 loss 7.990325 loss_att 10.043853 loss_ctc 8.618315 loss_rnnt 7.370909 hw_loss 0.234333 lr 0.00047825 rank 0
2023-02-22 01:05:24,538 DEBUG TRAIN Batch 13/900 loss 14.345584 loss_att 16.513468 loss_ctc 15.527706 loss_rnnt 13.515919 hw_loss 0.447135 lr 0.00047819 rank 5
2023-02-22 01:05:24,585 DEBUG TRAIN Batch 13/900 loss 11.828589 loss_att 20.866314 loss_ctc 11.421558 loss_rnnt 9.990682 hw_loss 0.158690 lr 0.00047823 rank 1
2023-02-22 01:05:24,604 DEBUG TRAIN Batch 13/900 loss 10.804982 loss_att 15.868597 loss_ctc 16.016035 loss_rnnt 9.037271 hw_loss 0.112841 lr 0.00047816 rank 4
2023-02-22 01:06:37,653 DEBUG TRAIN Batch 13/1000 loss 21.643650 loss_att 22.000031 loss_ctc 21.887791 loss_rnnt 21.379284 hw_loss 0.301007 lr 0.00047803 rank 0
2023-02-22 01:06:37,654 DEBUG TRAIN Batch 13/1000 loss 9.362085 loss_att 12.511930 loss_ctc 13.247585 loss_rnnt 8.055597 hw_loss 0.297099 lr 0.00047794 rank 4
2023-02-22 01:06:37,655 DEBUG TRAIN Batch 13/1000 loss 3.478216 loss_att 6.867439 loss_ctc 4.144138 loss_rnnt 2.635589 hw_loss 0.142488 lr 0.00047797 rank 5
2023-02-22 01:06:37,659 DEBUG TRAIN Batch 13/1000 loss 23.796288 loss_att 32.120979 loss_ctc 29.691982 loss_rnnt 21.223970 hw_loss 0.227409 lr 0.00047794 rank 2
2023-02-22 01:06:37,661 DEBUG TRAIN Batch 13/1000 loss 20.882278 loss_att 20.879272 loss_ctc 24.778358 loss_rnnt 20.174744 hw_loss 0.353730 lr 0.00047794 rank 3
2023-02-22 01:06:37,666 DEBUG TRAIN Batch 13/1000 loss 7.384031 loss_att 10.971059 loss_ctc 8.672490 loss_rnnt 6.277780 hw_loss 0.406970 lr 0.00047801 rank 1
2023-02-22 01:06:37,666 DEBUG TRAIN Batch 13/1000 loss 10.736297 loss_att 16.326313 loss_ctc 15.669682 loss_rnnt 8.812623 hw_loss 0.277286 lr 0.00047795 rank 6
2023-02-22 01:06:37,689 DEBUG TRAIN Batch 13/1000 loss 8.700599 loss_att 14.127140 loss_ctc 11.427082 loss_rnnt 7.053446 hw_loss 0.371837 lr 0.00047790 rank 7
2023-02-22 01:07:51,772 DEBUG TRAIN Batch 13/1100 loss 16.524164 loss_att 19.464792 loss_ctc 24.224543 loss_rnnt 14.753906 hw_loss 0.291401 lr 0.00047772 rank 2
2023-02-22 01:07:51,772 DEBUG TRAIN Batch 13/1100 loss 9.228250 loss_att 12.882368 loss_ctc 11.169117 loss_rnnt 8.093144 hw_loss 0.272811 lr 0.00047772 rank 3
2023-02-22 01:07:51,774 DEBUG TRAIN Batch 13/1100 loss 13.291775 loss_att 18.560200 loss_ctc 15.748907 loss_rnnt 11.797502 hw_loss 0.211817 lr 0.00047772 rank 4
2023-02-22 01:07:51,776 DEBUG TRAIN Batch 13/1100 loss 13.772167 loss_att 14.988754 loss_ctc 16.190033 loss_rnnt 13.035585 hw_loss 0.320403 lr 0.00047779 rank 1
2023-02-22 01:07:51,779 DEBUG TRAIN Batch 13/1100 loss 8.767646 loss_att 14.022512 loss_ctc 10.112240 loss_rnnt 7.341160 hw_loss 0.367939 lr 0.00047773 rank 6
2023-02-22 01:07:51,780 DEBUG TRAIN Batch 13/1100 loss 11.629437 loss_att 13.101732 loss_ctc 13.207995 loss_rnnt 10.965000 hw_loss 0.299070 lr 0.00047775 rank 5
2023-02-22 01:07:51,781 DEBUG TRAIN Batch 13/1100 loss 12.242023 loss_att 15.414620 loss_ctc 15.358526 loss_rnnt 11.088004 hw_loss 0.194936 lr 0.00047781 rank 0
2023-02-22 01:07:51,819 DEBUG TRAIN Batch 13/1100 loss 9.466183 loss_att 12.058137 loss_ctc 11.980201 loss_rnnt 8.518918 hw_loss 0.175634 lr 0.00047768 rank 7
2023-02-22 01:09:04,912 DEBUG TRAIN Batch 13/1200 loss 18.284760 loss_att 21.316441 loss_ctc 23.674751 loss_rnnt 16.781908 hw_loss 0.333465 lr 0.00047759 rank 0
2023-02-22 01:09:04,915 DEBUG TRAIN Batch 13/1200 loss 8.098672 loss_att 10.926867 loss_ctc 8.883732 loss_rnnt 7.241336 hw_loss 0.350667 lr 0.00047750 rank 2
2023-02-22 01:09:04,918 DEBUG TRAIN Batch 13/1200 loss 14.434942 loss_att 17.359854 loss_ctc 18.341780 loss_rnnt 13.143394 hw_loss 0.348103 lr 0.00047747 rank 7
2023-02-22 01:09:04,919 DEBUG TRAIN Batch 13/1200 loss 14.494489 loss_att 16.281292 loss_ctc 21.011381 loss_rnnt 13.077065 hw_loss 0.358397 lr 0.00047751 rank 3
2023-02-22 01:09:04,920 DEBUG TRAIN Batch 13/1200 loss 10.850686 loss_att 13.997313 loss_ctc 13.388439 loss_rnnt 9.612198 hw_loss 0.507741 lr 0.00047757 rank 1
2023-02-22 01:09:04,920 DEBUG TRAIN Batch 13/1200 loss 24.230942 loss_att 23.135578 loss_ctc 25.505196 loss_rnnt 24.135475 hw_loss 0.271197 lr 0.00047751 rank 6
2023-02-22 01:09:04,923 DEBUG TRAIN Batch 13/1200 loss 12.624135 loss_att 14.561640 loss_ctc 15.451206 loss_rnnt 11.648734 hw_loss 0.395547 lr 0.00047754 rank 5
2023-02-22 01:09:04,926 DEBUG TRAIN Batch 13/1200 loss 22.508104 loss_att 22.873152 loss_ctc 27.019773 loss_rnnt 21.577595 hw_loss 0.479891 lr 0.00047750 rank 4
2023-02-22 01:10:17,605 DEBUG TRAIN Batch 13/1300 loss 12.267078 loss_att 11.321161 loss_ctc 13.779647 loss_rnnt 12.017708 hw_loss 0.444144 lr 0.00047728 rank 4
2023-02-22 01:10:17,611 DEBUG TRAIN Batch 13/1300 loss 33.421093 loss_att 43.187641 loss_ctc 47.151318 loss_rnnt 29.548412 hw_loss 0.166265 lr 0.00047732 rank 5
2023-02-22 01:10:17,616 DEBUG TRAIN Batch 13/1300 loss 11.319548 loss_att 16.192993 loss_ctc 15.665535 loss_rnnt 9.665567 hw_loss 0.187173 lr 0.00047736 rank 1
2023-02-22 01:10:17,619 DEBUG TRAIN Batch 13/1300 loss 10.366019 loss_att 9.363930 loss_ctc 12.056710 loss_rnnt 10.077675 hw_loss 0.493755 lr 0.00047729 rank 3
2023-02-22 01:10:17,621 DEBUG TRAIN Batch 13/1300 loss 11.515913 loss_att 12.682861 loss_ctc 11.213534 loss_rnnt 11.175513 hw_loss 0.276239 lr 0.00047728 rank 2
2023-02-22 01:10:17,620 DEBUG TRAIN Batch 13/1300 loss 7.817973 loss_att 8.983413 loss_ctc 10.456369 loss_rnnt 6.985747 hw_loss 0.463784 lr 0.00047729 rank 6
2023-02-22 01:10:17,621 DEBUG TRAIN Batch 13/1300 loss 21.102978 loss_att 25.836756 loss_ctc 24.666969 loss_rnnt 19.567909 hw_loss 0.212086 lr 0.00047737 rank 0
2023-02-22 01:10:17,669 DEBUG TRAIN Batch 13/1300 loss 17.064701 loss_att 22.294708 loss_ctc 20.711998 loss_rnnt 15.420206 hw_loss 0.210351 lr 0.00047725 rank 7
2023-02-22 01:11:31,540 DEBUG TRAIN Batch 13/1400 loss 25.681984 loss_att 35.802032 loss_ctc 37.722816 loss_rnnt 21.913183 hw_loss 0.261278 lr 0.00047707 rank 4
2023-02-22 01:11:31,547 DEBUG TRAIN Batch 13/1400 loss 14.181504 loss_att 19.678818 loss_ctc 20.864616 loss_rnnt 12.068221 hw_loss 0.230134 lr 0.00047707 rank 2
2023-02-22 01:11:31,548 DEBUG TRAIN Batch 13/1400 loss 16.853931 loss_att 25.354076 loss_ctc 23.464401 loss_rnnt 14.231459 hw_loss 0.076967 lr 0.00047708 rank 6
2023-02-22 01:11:31,548 DEBUG TRAIN Batch 13/1400 loss 20.175970 loss_att 24.897594 loss_ctc 29.912275 loss_rnnt 17.781948 hw_loss 0.284103 lr 0.00047707 rank 3
2023-02-22 01:11:31,555 DEBUG TRAIN Batch 13/1400 loss 10.793281 loss_att 13.511413 loss_ctc 12.885093 loss_rnnt 9.788242 hw_loss 0.342195 lr 0.00047714 rank 1
2023-02-22 01:11:31,557 DEBUG TRAIN Batch 13/1400 loss 13.771824 loss_att 17.983665 loss_ctc 16.954079 loss_rnnt 12.410904 hw_loss 0.176720 lr 0.00047716 rank 0
2023-02-22 01:11:31,581 DEBUG TRAIN Batch 13/1400 loss 4.993230 loss_att 7.553526 loss_ctc 5.945228 loss_rnnt 4.224644 hw_loss 0.242988 lr 0.00047703 rank 7
2023-02-22 01:11:31,584 DEBUG TRAIN Batch 13/1400 loss 7.712001 loss_att 9.742293 loss_ctc 7.059892 loss_rnnt 7.289319 hw_loss 0.194195 lr 0.00047710 rank 5
2023-02-22 01:12:44,982 DEBUG TRAIN Batch 13/1500 loss 15.933955 loss_att 21.760017 loss_ctc 26.796780 loss_rnnt 13.194038 hw_loss 0.236863 lr 0.00047685 rank 2
2023-02-22 01:12:44,986 DEBUG TRAIN Batch 13/1500 loss 7.283302 loss_att 11.509533 loss_ctc 7.882774 loss_rnnt 6.149683 hw_loss 0.390831 lr 0.00047686 rank 6
2023-02-22 01:12:44,988 DEBUG TRAIN Batch 13/1500 loss 17.516914 loss_att 27.516457 loss_ctc 22.992737 loss_rnnt 14.720405 hw_loss 0.124676 lr 0.00047681 rank 7
2023-02-22 01:12:44,988 DEBUG TRAIN Batch 13/1500 loss 12.917213 loss_att 18.394367 loss_ctc 17.224443 loss_rnnt 11.162154 hw_loss 0.159995 lr 0.00047694 rank 0
2023-02-22 01:12:44,989 DEBUG TRAIN Batch 13/1500 loss 12.648334 loss_att 16.936247 loss_ctc 13.216243 loss_rnnt 11.609247 hw_loss 0.198338 lr 0.00047688 rank 5
2023-02-22 01:12:44,991 DEBUG TRAIN Batch 13/1500 loss 19.078272 loss_att 19.741869 loss_ctc 24.606483 loss_rnnt 18.072861 hw_loss 0.254246 lr 0.00047685 rank 4
2023-02-22 01:12:44,992 DEBUG TRAIN Batch 13/1500 loss 16.760946 loss_att 18.363766 loss_ctc 18.158724 loss_rnnt 16.186447 hw_loss 0.126686 lr 0.00047685 rank 3
2023-02-22 01:12:44,995 DEBUG TRAIN Batch 13/1500 loss 24.848619 loss_att 27.149462 loss_ctc 26.055349 loss_rnnt 24.165188 hw_loss 0.116936 lr 0.00047692 rank 1
2023-02-22 01:13:57,717 DEBUG TRAIN Batch 13/1600 loss 17.027239 loss_att 19.730263 loss_ctc 22.670307 loss_rnnt 15.601162 hw_loss 0.249498 lr 0.00047663 rank 2
2023-02-22 01:13:57,718 DEBUG TRAIN Batch 13/1600 loss 20.457258 loss_att 21.131752 loss_ctc 22.154144 loss_rnnt 19.876225 hw_loss 0.412280 lr 0.00047664 rank 6
2023-02-22 01:13:57,722 DEBUG TRAIN Batch 13/1600 loss 11.246661 loss_att 14.351510 loss_ctc 12.733212 loss_rnnt 10.274455 hw_loss 0.286930 lr 0.00047660 rank 7
2023-02-22 01:13:57,722 DEBUG TRAIN Batch 13/1600 loss 16.440357 loss_att 22.359943 loss_ctc 18.277010 loss_rnnt 14.865836 hw_loss 0.273217 lr 0.00047672 rank 0
2023-02-22 01:13:57,724 DEBUG TRAIN Batch 13/1600 loss 15.441843 loss_att 25.465462 loss_ctc 20.452587 loss_rnnt 12.632715 hw_loss 0.255569 lr 0.00047664 rank 3
2023-02-22 01:13:57,723 DEBUG TRAIN Batch 13/1600 loss 9.841953 loss_att 14.036833 loss_ctc 12.824583 loss_rnnt 8.487780 hw_loss 0.220336 lr 0.00047663 rank 4
2023-02-22 01:13:57,724 DEBUG TRAIN Batch 13/1600 loss 9.911005 loss_att 14.137810 loss_ctc 12.148399 loss_rnnt 8.605575 hw_loss 0.303283 lr 0.00047667 rank 5
2023-02-22 01:13:57,774 DEBUG TRAIN Batch 13/1600 loss 11.375824 loss_att 14.111007 loss_ctc 16.384277 loss_rnnt 10.013402 hw_loss 0.276733 lr 0.00047671 rank 1
2023-02-22 01:15:10,564 DEBUG TRAIN Batch 13/1700 loss 7.580957 loss_att 9.922770 loss_ctc 8.329201 loss_rnnt 6.840197 hw_loss 0.323684 lr 0.00047642 rank 2
2023-02-22 01:15:10,564 DEBUG TRAIN Batch 13/1700 loss 15.777256 loss_att 22.345901 loss_ctc 19.843197 loss_rnnt 13.844673 hw_loss 0.143866 lr 0.00047642 rank 3
2023-02-22 01:15:10,569 DEBUG TRAIN Batch 13/1700 loss 18.407412 loss_att 21.975525 loss_ctc 27.652662 loss_rnnt 16.276894 hw_loss 0.345364 lr 0.00047649 rank 1
2023-02-22 01:15:10,569 DEBUG TRAIN Batch 13/1700 loss 16.406681 loss_att 22.158781 loss_ctc 21.317970 loss_rnnt 14.441958 hw_loss 0.298995 lr 0.00047643 rank 6
2023-02-22 01:15:10,571 DEBUG TRAIN Batch 13/1700 loss 11.255540 loss_att 15.266659 loss_ctc 14.501902 loss_rnnt 9.844444 hw_loss 0.330043 lr 0.00047638 rank 7
2023-02-22 01:15:10,572 DEBUG TRAIN Batch 13/1700 loss 13.321421 loss_att 16.422396 loss_ctc 15.457561 loss_rnnt 12.256306 hw_loss 0.300188 lr 0.00047642 rank 4
2023-02-22 01:15:10,572 DEBUG TRAIN Batch 13/1700 loss 17.241518 loss_att 18.335714 loss_ctc 19.354437 loss_rnnt 16.562550 hw_loss 0.334513 lr 0.00047645 rank 5
2023-02-22 01:15:10,577 DEBUG TRAIN Batch 13/1700 loss 18.392420 loss_att 20.207317 loss_ctc 20.649612 loss_rnnt 17.636776 hw_loss 0.171949 lr 0.00047651 rank 0
2023-02-22 01:16:25,522 DEBUG TRAIN Batch 13/1800 loss 8.056736 loss_att 10.643753 loss_ctc 9.980800 loss_rnnt 7.132238 hw_loss 0.282287 lr 0.00047627 rank 1
2023-02-22 01:16:25,524 DEBUG TRAIN Batch 13/1800 loss 7.459363 loss_att 10.537370 loss_ctc 13.171178 loss_rnnt 5.905782 hw_loss 0.330759 lr 0.00047620 rank 2
2023-02-22 01:16:25,525 DEBUG TRAIN Batch 13/1800 loss 11.711796 loss_att 14.307659 loss_ctc 14.644972 loss_rnnt 10.646792 hw_loss 0.290140 lr 0.00047621 rank 3
2023-02-22 01:16:25,528 DEBUG TRAIN Batch 13/1800 loss 18.540382 loss_att 25.190990 loss_ctc 23.418167 loss_rnnt 16.398294 hw_loss 0.302987 lr 0.00047621 rank 6
2023-02-22 01:16:25,530 DEBUG TRAIN Batch 13/1800 loss 7.447841 loss_att 13.120258 loss_ctc 11.327077 loss_rnnt 5.624233 hw_loss 0.322299 lr 0.00047629 rank 0
2023-02-22 01:16:25,531 DEBUG TRAIN Batch 13/1800 loss 19.257593 loss_att 20.036179 loss_ctc 27.227009 loss_rnnt 17.923954 hw_loss 0.216250 lr 0.00047620 rank 4
2023-02-22 01:16:25,535 DEBUG TRAIN Batch 13/1800 loss 9.681041 loss_att 13.389274 loss_ctc 13.461919 loss_rnnt 8.292524 hw_loss 0.267661 lr 0.00047616 rank 7
2023-02-22 01:16:25,576 DEBUG TRAIN Batch 13/1800 loss 18.757591 loss_att 20.916861 loss_ctc 26.516941 loss_rnnt 17.166077 hw_loss 0.234526 lr 0.00047623 rank 5
2023-02-22 01:17:38,566 DEBUG TRAIN Batch 13/1900 loss 7.522986 loss_att 8.166351 loss_ctc 10.113373 loss_rnnt 6.791417 hw_loss 0.482833 lr 0.00047598 rank 2
2023-02-22 01:17:38,567 DEBUG TRAIN Batch 13/1900 loss 18.086620 loss_att 19.584541 loss_ctc 23.967165 loss_rnnt 16.777111 hw_loss 0.423473 lr 0.00047599 rank 4
2023-02-22 01:17:38,569 DEBUG TRAIN Batch 13/1900 loss 13.808405 loss_att 14.356173 loss_ctc 17.631025 loss_rnnt 12.974829 hw_loss 0.401888 lr 0.00047599 rank 6
2023-02-22 01:17:38,575 DEBUG TRAIN Batch 13/1900 loss 9.911699 loss_att 11.694900 loss_ctc 12.131459 loss_rnnt 9.120024 hw_loss 0.260750 lr 0.00047607 rank 0
2023-02-22 01:17:38,576 DEBUG TRAIN Batch 13/1900 loss 9.349319 loss_att 10.079897 loss_ctc 12.076785 loss_rnnt 8.644117 hw_loss 0.366421 lr 0.00047595 rank 7
2023-02-22 01:17:38,576 DEBUG TRAIN Batch 13/1900 loss 19.788910 loss_att 16.764275 loss_ctc 23.487083 loss_rnnt 19.812538 hw_loss 0.165389 lr 0.00047599 rank 3
2023-02-22 01:17:38,585 DEBUG TRAIN Batch 13/1900 loss 38.512199 loss_att 33.302467 loss_ctc 45.664352 loss_rnnt 38.519241 hw_loss 0.152406 lr 0.00047606 rank 1
2023-02-22 01:17:38,626 DEBUG TRAIN Batch 13/1900 loss 6.525990 loss_att 9.204014 loss_ctc 5.962742 loss_rnnt 5.966165 hw_loss 0.186225 lr 0.00047602 rank 5
2023-02-22 01:18:51,966 DEBUG TRAIN Batch 13/2000 loss 16.423376 loss_att 18.635437 loss_ctc 15.343738 loss_rnnt 15.899426 hw_loss 0.422798 lr 0.00047584 rank 1
2023-02-22 01:18:51,969 DEBUG TRAIN Batch 13/2000 loss 25.173834 loss_att 26.646282 loss_ctc 33.360813 loss_rnnt 23.646879 hw_loss 0.264128 lr 0.00047577 rank 3
2023-02-22 01:18:51,970 DEBUG TRAIN Batch 13/2000 loss 28.038166 loss_att 31.104294 loss_ctc 32.290825 loss_rnnt 26.764935 hw_loss 0.174353 lr 0.00047573 rank 7
2023-02-22 01:18:51,972 DEBUG TRAIN Batch 13/2000 loss 4.675743 loss_att 10.803012 loss_ctc 6.004560 loss_rnnt 3.186391 hw_loss 0.162604 lr 0.00047577 rank 2
2023-02-22 01:18:51,972 DEBUG TRAIN Batch 13/2000 loss 10.788494 loss_att 10.184757 loss_ctc 13.497681 loss_rnnt 10.434528 hw_loss 0.212790 lr 0.00047586 rank 0
2023-02-22 01:18:51,972 DEBUG TRAIN Batch 13/2000 loss 9.922583 loss_att 14.510867 loss_ctc 9.050101 loss_rnnt 8.914541 hw_loss 0.387591 lr 0.00047578 rank 6
2023-02-22 01:18:51,975 DEBUG TRAIN Batch 13/2000 loss 8.005616 loss_att 14.167932 loss_ctc 7.568220 loss_rnnt 6.662882 hw_loss 0.316107 lr 0.00047577 rank 4
2023-02-22 01:18:52,026 DEBUG TRAIN Batch 13/2000 loss 14.634661 loss_att 16.269070 loss_ctc 15.940189 loss_rnnt 14.008201 hw_loss 0.235328 lr 0.00047580 rank 5
2023-02-22 01:20:06,136 DEBUG TRAIN Batch 13/2100 loss 9.845695 loss_att 12.747074 loss_ctc 9.246710 loss_rnnt 9.142881 hw_loss 0.379503 lr 0.00047555 rank 2
2023-02-22 01:20:06,135 DEBUG TRAIN Batch 13/2100 loss 17.863306 loss_att 28.502350 loss_ctc 21.420004 loss_rnnt 15.164301 hw_loss 0.181817 lr 0.00047556 rank 6
2023-02-22 01:20:06,136 DEBUG TRAIN Batch 13/2100 loss 17.078133 loss_att 20.094116 loss_ctc 28.002468 loss_rnnt 14.837473 hw_loss 0.339157 lr 0.00047552 rank 7
2023-02-22 01:20:06,140 DEBUG TRAIN Batch 13/2100 loss 3.282186 loss_att 5.867825 loss_ctc 2.602417 loss_rnnt 2.632223 hw_loss 0.419007 lr 0.00047556 rank 3
2023-02-22 01:20:06,143 DEBUG TRAIN Batch 13/2100 loss 6.328241 loss_att 11.424935 loss_ctc 6.101566 loss_rnnt 5.163114 hw_loss 0.330023 lr 0.00047564 rank 0
2023-02-22 01:20:06,143 DEBUG TRAIN Batch 13/2100 loss 5.694715 loss_att 8.055968 loss_ctc 8.689836 loss_rnnt 4.673703 hw_loss 0.280147 lr 0.00047559 rank 5
2023-02-22 01:20:06,143 DEBUG TRAIN Batch 13/2100 loss 14.393502 loss_att 17.517088 loss_ctc 21.550207 loss_rnnt 12.774311 hw_loss 0.075463 lr 0.00047555 rank 4
2023-02-22 01:20:06,145 DEBUG TRAIN Batch 13/2100 loss 2.868516 loss_att 7.999362 loss_ctc 3.115891 loss_rnnt 1.769300 hw_loss 0.075120 lr 0.00047563 rank 1
2023-02-22 01:21:19,784 DEBUG TRAIN Batch 13/2200 loss 12.797928 loss_att 16.181644 loss_ctc 16.093300 loss_rnnt 11.538027 hw_loss 0.269576 lr 0.00047534 rank 3
2023-02-22 01:21:19,786 DEBUG TRAIN Batch 13/2200 loss 12.379407 loss_att 15.460710 loss_ctc 17.033131 loss_rnnt 10.941538 hw_loss 0.377086 lr 0.00047534 rank 2
2023-02-22 01:21:19,786 DEBUG TRAIN Batch 13/2200 loss 13.821016 loss_att 18.270670 loss_ctc 17.785515 loss_rnnt 12.287105 hw_loss 0.216342 lr 0.00047543 rank 0
2023-02-22 01:21:19,788 DEBUG TRAIN Batch 13/2200 loss 34.545753 loss_att 36.414627 loss_ctc 45.032341 loss_rnnt 32.493958 hw_loss 0.524634 lr 0.00047534 rank 4
2023-02-22 01:21:19,788 DEBUG TRAIN Batch 13/2200 loss 9.468553 loss_att 15.166625 loss_ctc 14.123146 loss_rnnt 7.573171 hw_loss 0.253416 lr 0.00047535 rank 6
2023-02-22 01:21:19,790 DEBUG TRAIN Batch 13/2200 loss 7.726115 loss_att 12.597032 loss_ctc 10.790073 loss_rnnt 6.161249 hw_loss 0.341541 lr 0.00047537 rank 5
2023-02-22 01:21:19,792 DEBUG TRAIN Batch 13/2200 loss 13.423892 loss_att 21.444738 loss_ctc 16.860802 loss_rnnt 11.234517 hw_loss 0.238031 lr 0.00047530 rank 7
2023-02-22 01:21:19,833 DEBUG TRAIN Batch 13/2200 loss 30.011047 loss_att 34.340092 loss_ctc 39.180367 loss_rnnt 27.799736 hw_loss 0.230484 lr 0.00047541 rank 1
2023-02-22 01:22:32,186 DEBUG TRAIN Batch 13/2300 loss 18.436674 loss_att 22.617001 loss_ctc 25.082502 loss_rnnt 16.563105 hw_loss 0.283863 lr 0.00047512 rank 2
2023-02-22 01:22:32,187 DEBUG TRAIN Batch 13/2300 loss 8.184680 loss_att 13.656527 loss_ctc 13.326331 loss_rnnt 6.218073 hw_loss 0.350033 lr 0.00047513 rank 4
2023-02-22 01:22:32,191 DEBUG TRAIN Batch 13/2300 loss 11.952496 loss_att 15.069611 loss_ctc 13.244595 loss_rnnt 11.009750 hw_loss 0.275705 lr 0.00047513 rank 6
2023-02-22 01:22:32,191 DEBUG TRAIN Batch 13/2300 loss 10.143745 loss_att 14.511621 loss_ctc 12.186357 loss_rnnt 8.820280 hw_loss 0.332889 lr 0.00047513 rank 3
2023-02-22 01:22:32,193 DEBUG TRAIN Batch 13/2300 loss 18.046747 loss_att 18.410597 loss_ctc 19.772497 loss_rnnt 17.624664 hw_loss 0.223523 lr 0.00047516 rank 5
2023-02-22 01:22:32,195 DEBUG TRAIN Batch 13/2300 loss 15.243495 loss_att 18.635792 loss_ctc 17.910269 loss_rnnt 14.013198 hw_loss 0.368002 lr 0.00047520 rank 1
2023-02-22 01:22:32,196 DEBUG TRAIN Batch 13/2300 loss 11.206324 loss_att 14.577873 loss_ctc 15.358363 loss_rnnt 9.891796 hw_loss 0.162399 lr 0.00047509 rank 7
2023-02-22 01:22:32,239 DEBUG TRAIN Batch 13/2300 loss 12.744942 loss_att 15.497931 loss_ctc 15.515986 loss_rnnt 11.668702 hw_loss 0.292816 lr 0.00047521 rank 0
2023-02-22 01:23:45,723 DEBUG TRAIN Batch 13/2400 loss 9.435090 loss_att 10.309403 loss_ctc 12.447543 loss_rnnt 8.621089 hw_loss 0.445273 lr 0.00047494 rank 5
2023-02-22 01:23:45,731 DEBUG TRAIN Batch 13/2400 loss 4.000647 loss_att 8.112661 loss_ctc 6.707243 loss_rnnt 2.663060 hw_loss 0.289320 lr 0.00047491 rank 4
2023-02-22 01:23:45,732 DEBUG TRAIN Batch 13/2400 loss 11.111458 loss_att 14.880466 loss_ctc 16.772202 loss_rnnt 9.446216 hw_loss 0.293765 lr 0.00047491 rank 2
2023-02-22 01:23:45,732 DEBUG TRAIN Batch 13/2400 loss 7.473955 loss_att 11.493544 loss_ctc 9.772627 loss_rnnt 6.241746 hw_loss 0.228378 lr 0.00047492 rank 6
2023-02-22 01:23:45,734 DEBUG TRAIN Batch 13/2400 loss 19.534145 loss_att 27.628063 loss_ctc 25.944614 loss_rnnt 16.921597 hw_loss 0.260694 lr 0.00047487 rank 7
2023-02-22 01:23:45,735 DEBUG TRAIN Batch 13/2400 loss 8.900265 loss_att 12.582867 loss_ctc 11.421431 loss_rnnt 7.599706 hw_loss 0.427279 lr 0.00047491 rank 3
2023-02-22 01:23:45,735 DEBUG TRAIN Batch 13/2400 loss 9.401918 loss_att 11.510602 loss_ctc 10.104671 loss_rnnt 8.721292 hw_loss 0.309729 lr 0.00047500 rank 0
2023-02-22 01:23:45,760 DEBUG TRAIN Batch 13/2400 loss 16.475405 loss_att 16.445320 loss_ctc 19.196192 loss_rnnt 15.944008 hw_loss 0.327454 lr 0.00047498 rank 1
2023-02-22 01:25:02,626 DEBUG TRAIN Batch 13/2500 loss 9.299628 loss_att 11.572403 loss_ctc 11.304683 loss_rnnt 8.349987 hw_loss 0.427023 lr 0.00047470 rank 3
2023-02-22 01:25:02,632 DEBUG TRAIN Batch 13/2500 loss 13.954421 loss_att 15.418704 loss_ctc 17.444023 loss_rnnt 12.986284 hw_loss 0.393750 lr 0.00047478 rank 0
2023-02-22 01:25:02,633 DEBUG TRAIN Batch 13/2500 loss 13.395442 loss_att 15.239889 loss_ctc 17.908173 loss_rnnt 12.313196 hw_loss 0.209357 lr 0.00047469 rank 2
2023-02-22 01:25:02,634 DEBUG TRAIN Batch 13/2500 loss 12.944478 loss_att 12.295382 loss_ctc 14.530190 loss_rnnt 12.532076 hw_loss 0.620234 lr 0.00047473 rank 5
2023-02-22 01:25:02,634 DEBUG TRAIN Batch 13/2500 loss 10.481963 loss_att 10.917030 loss_ctc 10.981467 loss_rnnt 10.160357 hw_loss 0.314986 lr 0.00047466 rank 7
2023-02-22 01:25:02,636 DEBUG TRAIN Batch 13/2500 loss 23.155645 loss_att 22.644613 loss_ctc 26.142164 loss_rnnt 22.642256 hw_loss 0.407616 lr 0.00047471 rank 6
2023-02-22 01:25:02,641 DEBUG TRAIN Batch 13/2500 loss 12.066601 loss_att 12.072422 loss_ctc 16.327230 loss_rnnt 11.256985 hw_loss 0.450690 lr 0.00047477 rank 1
2023-02-22 01:25:02,685 DEBUG TRAIN Batch 13/2500 loss 11.343684 loss_att 15.320763 loss_ctc 15.077105 loss_rnnt 9.907469 hw_loss 0.268142 lr 0.00047470 rank 4
2023-02-22 01:26:15,166 DEBUG TRAIN Batch 13/2600 loss 8.483004 loss_att 13.251945 loss_ctc 10.724653 loss_rnnt 7.114828 hw_loss 0.216565 lr 0.00047448 rank 2
2023-02-22 01:26:15,172 DEBUG TRAIN Batch 13/2600 loss 5.122218 loss_att 11.567776 loss_ctc 4.682214 loss_rnnt 3.777188 hw_loss 0.214848 lr 0.00047449 rank 3
2023-02-22 01:26:15,172 DEBUG TRAIN Batch 13/2600 loss 6.764228 loss_att 12.390709 loss_ctc 9.423021 loss_rnnt 5.230952 hw_loss 0.100264 lr 0.00047449 rank 6
2023-02-22 01:26:15,178 DEBUG TRAIN Batch 13/2600 loss 7.428000 loss_att 17.028816 loss_ctc 13.171550 loss_rnnt 4.649851 hw_loss 0.172835 lr 0.00047445 rank 7
2023-02-22 01:26:15,179 DEBUG TRAIN Batch 13/2600 loss 12.264294 loss_att 13.600450 loss_ctc 13.532431 loss_rnnt 11.603676 hw_loss 0.420566 lr 0.00047448 rank 4
2023-02-22 01:26:15,182 DEBUG TRAIN Batch 13/2600 loss 10.394884 loss_att 13.994158 loss_ctc 11.029854 loss_rnnt 9.437005 hw_loss 0.287551 lr 0.00047451 rank 5
2023-02-22 01:26:15,182 DEBUG TRAIN Batch 13/2600 loss 21.242579 loss_att 22.308762 loss_ctc 25.378620 loss_rnnt 20.293839 hw_loss 0.345055 lr 0.00047457 rank 0
2023-02-22 01:26:15,226 DEBUG TRAIN Batch 13/2600 loss 14.274098 loss_att 13.287556 loss_ctc 18.546879 loss_rnnt 13.753267 hw_loss 0.278314 lr 0.00047455 rank 1
2023-02-22 01:27:28,333 DEBUG TRAIN Batch 13/2700 loss 9.546964 loss_att 13.883673 loss_ctc 15.601837 loss_rnnt 7.742813 hw_loss 0.242797 lr 0.00047423 rank 7
2023-02-22 01:27:28,334 DEBUG TRAIN Batch 13/2700 loss 3.921649 loss_att 8.145464 loss_ctc 5.699541 loss_rnnt 2.780348 hw_loss 0.111535 lr 0.00047427 rank 2
2023-02-22 01:27:28,337 DEBUG TRAIN Batch 13/2700 loss 14.301991 loss_att 15.326250 loss_ctc 18.048149 loss_rnnt 13.417612 hw_loss 0.337573 lr 0.00047427 rank 4
2023-02-22 01:27:28,339 DEBUG TRAIN Batch 13/2700 loss 4.248673 loss_att 9.572534 loss_ctc 6.143067 loss_rnnt 2.799083 hw_loss 0.247936 lr 0.00047428 rank 6
2023-02-22 01:27:28,339 DEBUG TRAIN Batch 13/2700 loss 5.531554 loss_att 9.858836 loss_ctc 8.373909 loss_rnnt 4.128226 hw_loss 0.297921 lr 0.00047436 rank 0
2023-02-22 01:27:28,342 DEBUG TRAIN Batch 13/2700 loss 10.809251 loss_att 14.232788 loss_ctc 14.427161 loss_rnnt 9.542854 hw_loss 0.186187 lr 0.00047427 rank 3
2023-02-22 01:27:28,345 DEBUG TRAIN Batch 13/2700 loss 9.391864 loss_att 14.385364 loss_ctc 9.586855 loss_rnnt 8.213734 hw_loss 0.287682 lr 0.00047430 rank 5
2023-02-22 01:27:28,346 DEBUG TRAIN Batch 13/2700 loss 15.344385 loss_att 20.757816 loss_ctc 20.953342 loss_rnnt 13.400561 hw_loss 0.212396 lr 0.00047434 rank 1
2023-02-22 01:28:42,364 DEBUG TRAIN Batch 13/2800 loss 12.871586 loss_att 13.894397 loss_ctc 14.863398 loss_rnnt 12.282734 hw_loss 0.222589 lr 0.00047406 rank 4
2023-02-22 01:28:42,368 DEBUG TRAIN Batch 13/2800 loss 13.877742 loss_att 14.689516 loss_ctc 16.802101 loss_rnnt 13.230106 hw_loss 0.178812 lr 0.00047405 rank 2
2023-02-22 01:28:42,372 DEBUG TRAIN Batch 13/2800 loss 18.806103 loss_att 27.045433 loss_ctc 27.737150 loss_rnnt 15.862947 hw_loss 0.195903 lr 0.00047406 rank 6
2023-02-22 01:28:42,376 DEBUG TRAIN Batch 13/2800 loss 17.084820 loss_att 21.178658 loss_ctc 19.591478 loss_rnnt 15.830694 hw_loss 0.189631 lr 0.00047402 rank 7
2023-02-22 01:28:42,377 DEBUG TRAIN Batch 13/2800 loss 9.678061 loss_att 11.015058 loss_ctc 12.226935 loss_rnnt 8.883165 hw_loss 0.351836 lr 0.00047413 rank 1
2023-02-22 01:28:42,378 DEBUG TRAIN Batch 13/2800 loss 14.022010 loss_att 16.863758 loss_ctc 16.806677 loss_rnnt 12.950699 hw_loss 0.246884 lr 0.00047406 rank 3
2023-02-22 01:28:42,384 DEBUG TRAIN Batch 13/2800 loss 15.939574 loss_att 21.680223 loss_ctc 21.828112 loss_rnnt 13.898700 hw_loss 0.201763 lr 0.00047414 rank 0
2023-02-22 01:28:42,385 DEBUG TRAIN Batch 13/2800 loss 13.884766 loss_att 16.181139 loss_ctc 15.277398 loss_rnnt 13.150099 hw_loss 0.168205 lr 0.00047409 rank 5
2023-02-22 01:29:56,005 DEBUG TRAIN Batch 13/2900 loss 11.500072 loss_att 14.144588 loss_ctc 19.052799 loss_rnnt 9.835834 hw_loss 0.240572 lr 0.00047384 rank 4
2023-02-22 01:29:56,005 DEBUG TRAIN Batch 13/2900 loss 9.962701 loss_att 12.017188 loss_ctc 12.685070 loss_rnnt 9.094002 hw_loss 0.177786 lr 0.00047385 rank 6
2023-02-22 01:29:56,006 DEBUG TRAIN Batch 13/2900 loss 17.406572 loss_att 21.533075 loss_ctc 21.191948 loss_rnnt 15.919500 hw_loss 0.294483 lr 0.00047384 rank 2
2023-02-22 01:29:56,008 DEBUG TRAIN Batch 13/2900 loss 13.630179 loss_att 19.570770 loss_ctc 17.715954 loss_rnnt 11.674372 hw_loss 0.417974 lr 0.00047391 rank 1
2023-02-22 01:29:56,009 DEBUG TRAIN Batch 13/2900 loss 5.127557 loss_att 9.694921 loss_ctc 5.723357 loss_rnnt 3.979556 hw_loss 0.290791 lr 0.00047385 rank 3
2023-02-22 01:29:56,009 DEBUG TRAIN Batch 13/2900 loss 7.363301 loss_att 8.674635 loss_ctc 9.176572 loss_rnnt 6.609456 hw_loss 0.468391 lr 0.00047388 rank 5
2023-02-22 01:29:56,010 DEBUG TRAIN Batch 13/2900 loss 11.153723 loss_att 12.913311 loss_ctc 14.032774 loss_rnnt 10.242035 hw_loss 0.329806 lr 0.00047393 rank 0
2023-02-22 01:29:56,012 DEBUG TRAIN Batch 13/2900 loss 12.463223 loss_att 17.247744 loss_ctc 14.463555 loss_rnnt 11.066313 hw_loss 0.324929 lr 0.00047381 rank 7
2023-02-22 01:31:09,189 DEBUG TRAIN Batch 13/3000 loss 12.418963 loss_att 16.132362 loss_ctc 17.067448 loss_rnnt 10.937954 hw_loss 0.222246 lr 0.00047363 rank 2
2023-02-22 01:31:09,190 DEBUG TRAIN Batch 13/3000 loss 11.747640 loss_att 14.382448 loss_ctc 12.384739 loss_rnnt 11.045038 hw_loss 0.170047 lr 0.00047364 rank 6
2023-02-22 01:31:09,194 DEBUG TRAIN Batch 13/3000 loss 20.480135 loss_att 24.879841 loss_ctc 27.702560 loss_rnnt 18.494905 hw_loss 0.266810 lr 0.00047359 rank 7
2023-02-22 01:31:09,198 DEBUG TRAIN Batch 13/3000 loss 9.592044 loss_att 15.962571 loss_ctc 12.916047 loss_rnnt 7.714908 hw_loss 0.299681 lr 0.00047363 rank 3
2023-02-22 01:31:09,200 DEBUG TRAIN Batch 13/3000 loss 12.443793 loss_att 13.839714 loss_ctc 13.049548 loss_rnnt 11.948120 hw_loss 0.254479 lr 0.00047370 rank 1
2023-02-22 01:31:09,201 DEBUG TRAIN Batch 13/3000 loss 5.481526 loss_att 9.870872 loss_ctc 7.640876 loss_rnnt 4.068942 hw_loss 0.462754 lr 0.00047363 rank 4
2023-02-22 01:31:09,202 DEBUG TRAIN Batch 13/3000 loss 14.546005 loss_att 16.586765 loss_ctc 17.546038 loss_rnnt 13.557070 hw_loss 0.338960 lr 0.00047366 rank 5
2023-02-22 01:31:09,202 DEBUG TRAIN Batch 13/3000 loss 12.891754 loss_att 13.592346 loss_ctc 15.624156 loss_rnnt 12.234488 hw_loss 0.286553 lr 0.00047372 rank 0
2023-02-22 01:32:22,785 DEBUG TRAIN Batch 13/3100 loss 9.059101 loss_att 12.513338 loss_ctc 12.291900 loss_rnnt 7.768413 hw_loss 0.316500 lr 0.00047343 rank 6
2023-02-22 01:32:22,785 DEBUG TRAIN Batch 13/3100 loss 15.522083 loss_att 21.503380 loss_ctc 18.161785 loss_rnnt 13.806541 hw_loss 0.313731 lr 0.00047342 rank 2
2023-02-22 01:32:22,786 DEBUG TRAIN Batch 13/3100 loss 12.618529 loss_att 14.843525 loss_ctc 17.767597 loss_rnnt 11.278637 hw_loss 0.390657 lr 0.00047349 rank 1
2023-02-22 01:32:22,787 DEBUG TRAIN Batch 13/3100 loss 16.711081 loss_att 19.088045 loss_ctc 18.041203 loss_rnnt 15.882697 hw_loss 0.329327 lr 0.00047338 rank 7
2023-02-22 01:32:22,787 DEBUG TRAIN Batch 13/3100 loss 18.788836 loss_att 20.049793 loss_ctc 25.879047 loss_rnnt 17.282318 hw_loss 0.579305 lr 0.00047342 rank 3
2023-02-22 01:32:22,792 DEBUG TRAIN Batch 13/3100 loss 9.582911 loss_att 9.559752 loss_ctc 10.843689 loss_rnnt 9.289845 hw_loss 0.242988 lr 0.00047351 rank 0
2023-02-22 01:32:22,810 DEBUG TRAIN Batch 13/3100 loss 8.976122 loss_att 14.646500 loss_ctc 10.020681 loss_rnnt 7.536827 hw_loss 0.311148 lr 0.00047345 rank 5
2023-02-22 01:32:22,837 DEBUG TRAIN Batch 13/3100 loss 10.686246 loss_att 14.108840 loss_ctc 13.374967 loss_rnnt 9.474871 hw_loss 0.315677 lr 0.00047342 rank 4
2023-02-22 01:33:37,616 DEBUG TRAIN Batch 13/3200 loss 17.735559 loss_att 16.370806 loss_ctc 21.065161 loss_rnnt 17.279474 hw_loss 0.534539 lr 0.00047321 rank 3
2023-02-22 01:33:37,618 DEBUG TRAIN Batch 13/3200 loss 16.489380 loss_att 14.867321 loss_ctc 21.375589 loss_rnnt 15.945004 hw_loss 0.407422 lr 0.00047320 rank 2
2023-02-22 01:33:37,619 DEBUG TRAIN Batch 13/3200 loss 9.459044 loss_att 11.443504 loss_ctc 11.250618 loss_rnnt 8.722506 hw_loss 0.188944 lr 0.00047321 rank 4
2023-02-22 01:33:37,621 DEBUG TRAIN Batch 13/3200 loss 5.833972 loss_att 7.786846 loss_ctc 10.759036 loss_rnnt 4.667333 hw_loss 0.223854 lr 0.00047328 rank 1
2023-02-22 01:33:37,621 DEBUG TRAIN Batch 13/3200 loss 12.661191 loss_att 16.050983 loss_ctc 16.060173 loss_rnnt 11.441184 hw_loss 0.166595 lr 0.00047329 rank 0
2023-02-22 01:33:37,622 DEBUG TRAIN Batch 13/3200 loss 13.873588 loss_att 15.105946 loss_ctc 19.065779 loss_rnnt 12.811764 hw_loss 0.230738 lr 0.00047321 rank 6
2023-02-22 01:33:37,623 DEBUG TRAIN Batch 13/3200 loss 20.492926 loss_att 18.126492 loss_ctc 28.131424 loss_rnnt 19.860182 hw_loss 0.164182 lr 0.00047317 rank 7
2023-02-22 01:33:37,625 DEBUG TRAIN Batch 13/3200 loss 6.378366 loss_att 12.066282 loss_ctc 5.953894 loss_rnnt 5.049656 hw_loss 0.464481 lr 0.00047324 rank 5
2023-02-22 01:34:50,537 DEBUG TRAIN Batch 13/3300 loss 17.320456 loss_att 18.801304 loss_ctc 22.061062 loss_rnnt 16.271381 hw_loss 0.226545 lr 0.00047300 rank 6
2023-02-22 01:34:50,540 DEBUG TRAIN Batch 13/3300 loss 23.462236 loss_att 24.163122 loss_ctc 26.127615 loss_rnnt 22.890976 hw_loss 0.141934 lr 0.00047299 rank 2
2023-02-22 01:34:50,541 DEBUG TRAIN Batch 13/3300 loss 19.979540 loss_att 23.050211 loss_ctc 24.354809 loss_rnnt 18.635292 hw_loss 0.275150 lr 0.00047300 rank 3
2023-02-22 01:34:50,545 DEBUG TRAIN Batch 13/3300 loss 11.292293 loss_att 16.464809 loss_ctc 16.320120 loss_rnnt 9.410706 hw_loss 0.331322 lr 0.00047306 rank 1
2023-02-22 01:34:50,546 DEBUG TRAIN Batch 13/3300 loss 9.052619 loss_att 11.179832 loss_ctc 11.403109 loss_rnnt 8.192072 hw_loss 0.228199 lr 0.00047303 rank 5
2023-02-22 01:34:50,546 DEBUG TRAIN Batch 13/3300 loss 7.120490 loss_att 14.049990 loss_ctc 10.443626 loss_rnnt 5.155329 hw_loss 0.255330 lr 0.00047308 rank 0
2023-02-22 01:34:50,548 DEBUG TRAIN Batch 13/3300 loss 20.034533 loss_att 22.029032 loss_ctc 24.895758 loss_rnnt 18.886421 hw_loss 0.189459 lr 0.00047296 rank 7
2023-02-22 01:34:50,594 DEBUG TRAIN Batch 13/3300 loss 10.892602 loss_att 13.440131 loss_ctc 16.676838 loss_rnnt 9.511685 hw_loss 0.187835 lr 0.00047299 rank 4
2023-02-22 01:36:03,500 DEBUG TRAIN Batch 13/3400 loss 16.247795 loss_att 19.253679 loss_ctc 19.527422 loss_rnnt 15.069483 hw_loss 0.262221 lr 0.00047287 rank 0
2023-02-22 01:36:03,507 DEBUG TRAIN Batch 13/3400 loss 12.207685 loss_att 12.569495 loss_ctc 16.652626 loss_rnnt 11.474662 hw_loss 0.127504 lr 0.00047278 rank 2
2023-02-22 01:36:03,507 DEBUG TRAIN Batch 13/3400 loss 6.751908 loss_att 9.788594 loss_ctc 8.629572 loss_rnnt 5.704637 hw_loss 0.355460 lr 0.00047279 rank 6
2023-02-22 01:36:03,509 DEBUG TRAIN Batch 13/3400 loss 6.200953 loss_att 14.623674 loss_ctc 10.094186 loss_rnnt 3.835338 hw_loss 0.303699 lr 0.00047279 rank 3
2023-02-22 01:36:03,517 DEBUG TRAIN Batch 13/3400 loss 25.075356 loss_att 28.332321 loss_ctc 37.930893 loss_rnnt 22.610580 hw_loss 0.186203 lr 0.00047275 rank 7
2023-02-22 01:36:03,518 DEBUG TRAIN Batch 13/3400 loss 12.419547 loss_att 14.863358 loss_ctc 14.590740 loss_rnnt 11.521385 hw_loss 0.224827 lr 0.00047278 rank 4
2023-02-22 01:36:03,518 DEBUG TRAIN Batch 13/3400 loss 22.507029 loss_att 27.715666 loss_ctc 28.879528 loss_rnnt 20.508806 hw_loss 0.200299 lr 0.00047285 rank 1
2023-02-22 01:36:03,560 DEBUG TRAIN Batch 13/3400 loss 14.800320 loss_att 17.603998 loss_ctc 19.525917 loss_rnnt 13.541314 hw_loss 0.127854 lr 0.00047281 rank 5
2023-02-22 01:37:17,255 DEBUG TRAIN Batch 13/3500 loss 10.136310 loss_att 11.758681 loss_ctc 12.552935 loss_rnnt 9.295784 hw_loss 0.363437 lr 0.00047260 rank 5
2023-02-22 01:37:17,257 DEBUG TRAIN Batch 13/3500 loss 11.371279 loss_att 16.155605 loss_ctc 16.224993 loss_rnnt 9.632418 hw_loss 0.252815 lr 0.00047257 rank 4
2023-02-22 01:37:17,260 DEBUG TRAIN Batch 13/3500 loss 23.779867 loss_att 25.433594 loss_ctc 29.754532 loss_rnnt 22.549946 hw_loss 0.192290 lr 0.00047257 rank 2
2023-02-22 01:37:17,264 DEBUG TRAIN Batch 13/3500 loss 15.374668 loss_att 19.985188 loss_ctc 23.508087 loss_rnnt 13.215696 hw_loss 0.285774 lr 0.00047258 rank 6
2023-02-22 01:37:17,268 DEBUG TRAIN Batch 13/3500 loss 9.893988 loss_att 12.193066 loss_ctc 10.409882 loss_rnnt 9.232120 hw_loss 0.249877 lr 0.00047258 rank 3
2023-02-22 01:37:17,269 DEBUG TRAIN Batch 13/3500 loss 8.244637 loss_att 12.392980 loss_ctc 12.258413 loss_rnnt 6.812008 hw_loss 0.127109 lr 0.00047254 rank 7
2023-02-22 01:37:17,271 DEBUG TRAIN Batch 13/3500 loss 23.123663 loss_att 27.219566 loss_ctc 26.477690 loss_rnnt 21.693260 hw_loss 0.307534 lr 0.00047264 rank 1
2023-02-22 01:37:17,280 DEBUG TRAIN Batch 13/3500 loss 17.211874 loss_att 20.997160 loss_ctc 20.118362 loss_rnnt 15.975471 hw_loss 0.172151 lr 0.00047266 rank 0
2023-02-22 01:38:32,163 DEBUG TRAIN Batch 13/3600 loss 7.061926 loss_att 12.269458 loss_ctc 11.484131 loss_rnnt 5.265140 hw_loss 0.310599 lr 0.00047236 rank 2
2023-02-22 01:38:32,165 DEBUG TRAIN Batch 13/3600 loss 6.946728 loss_att 11.602760 loss_ctc 8.449734 loss_rnnt 5.715035 hw_loss 0.187659 lr 0.00047236 rank 4
2023-02-22 01:38:32,166 DEBUG TRAIN Batch 13/3600 loss 9.106382 loss_att 12.842400 loss_ctc 9.139235 loss_rnnt 8.169546 hw_loss 0.347350 lr 0.00047243 rank 1
2023-02-22 01:38:32,170 DEBUG TRAIN Batch 13/3600 loss 7.284444 loss_att 10.346264 loss_ctc 9.154553 loss_rnnt 6.256740 hw_loss 0.311237 lr 0.00047245 rank 0
2023-02-22 01:38:32,170 DEBUG TRAIN Batch 13/3600 loss 12.799281 loss_att 15.339167 loss_ctc 17.525715 loss_rnnt 11.493276 hw_loss 0.314696 lr 0.00047236 rank 3
2023-02-22 01:38:32,174 DEBUG TRAIN Batch 13/3600 loss 18.629858 loss_att 19.883915 loss_ctc 23.487953 loss_rnnt 17.550236 hw_loss 0.339492 lr 0.00047237 rank 6
2023-02-22 01:38:32,175 DEBUG TRAIN Batch 13/3600 loss 8.309131 loss_att 12.343466 loss_ctc 12.643751 loss_rnnt 6.776645 hw_loss 0.276881 lr 0.00047232 rank 7
2023-02-22 01:38:32,226 DEBUG TRAIN Batch 13/3600 loss 19.543087 loss_att 22.549286 loss_ctc 24.420631 loss_rnnt 18.160425 hw_loss 0.245783 lr 0.00047239 rank 5
2023-02-22 01:39:45,535 DEBUG TRAIN Batch 13/3700 loss 10.418101 loss_att 12.653419 loss_ctc 13.253510 loss_rnnt 9.493669 hw_loss 0.186214 lr 0.00047211 rank 7
2023-02-22 01:39:45,541 DEBUG TRAIN Batch 13/3700 loss 10.486370 loss_att 12.499935 loss_ctc 15.756111 loss_rnnt 9.296642 hw_loss 0.158218 lr 0.00047218 rank 5
2023-02-22 01:39:45,542 DEBUG TRAIN Batch 13/3700 loss 9.985379 loss_att 14.454835 loss_ctc 11.253916 loss_rnnt 8.780562 hw_loss 0.265853 lr 0.00047215 rank 2
2023-02-22 01:39:45,544 DEBUG TRAIN Batch 13/3700 loss 14.083980 loss_att 15.913387 loss_ctc 16.812592 loss_rnnt 13.224598 hw_loss 0.243160 lr 0.00047215 rank 4
2023-02-22 01:39:45,548 DEBUG TRAIN Batch 13/3700 loss 8.492502 loss_att 11.095448 loss_ctc 10.621651 loss_rnnt 7.568576 hw_loss 0.223968 lr 0.00047222 rank 1
2023-02-22 01:39:45,548 DEBUG TRAIN Batch 13/3700 loss 8.884637 loss_att 9.318274 loss_ctc 10.828392 loss_rnnt 8.369154 hw_loss 0.317978 lr 0.00047224 rank 0
2023-02-22 01:39:45,549 DEBUG TRAIN Batch 13/3700 loss 15.678910 loss_att 20.728136 loss_ctc 23.427109 loss_rnnt 13.479898 hw_loss 0.292637 lr 0.00047216 rank 6
2023-02-22 01:39:45,562 DEBUG TRAIN Batch 13/3700 loss 14.177290 loss_att 17.213638 loss_ctc 19.670599 loss_rnnt 12.659591 hw_loss 0.333730 lr 0.00047215 rank 3
2023-02-22 01:40:57,841 DEBUG TRAIN Batch 13/3800 loss 14.945820 loss_att 14.565610 loss_ctc 17.622234 loss_rnnt 14.533976 hw_loss 0.245680 lr 0.00047194 rank 2
2023-02-22 01:40:57,842 DEBUG TRAIN Batch 13/3800 loss 17.067017 loss_att 19.552776 loss_ctc 19.883787 loss_rnnt 16.026417 hw_loss 0.314770 lr 0.00047201 rank 1
2023-02-22 01:40:57,843 DEBUG TRAIN Batch 13/3800 loss 10.793778 loss_att 13.357058 loss_ctc 13.067221 loss_rnnt 9.695232 hw_loss 0.530183 lr 0.00047194 rank 3
2023-02-22 01:40:57,843 DEBUG TRAIN Batch 13/3800 loss 26.444078 loss_att 30.410351 loss_ctc 36.041412 loss_rnnt 24.244572 hw_loss 0.237383 lr 0.00047195 rank 6
2023-02-22 01:40:57,844 DEBUG TRAIN Batch 13/3800 loss 9.647079 loss_att 8.591082 loss_ctc 11.236781 loss_rnnt 9.476308 hw_loss 0.318770 lr 0.00047194 rank 4
2023-02-22 01:40:57,844 DEBUG TRAIN Batch 13/3800 loss 16.430532 loss_att 17.825808 loss_ctc 23.432926 loss_rnnt 15.073291 hw_loss 0.270999 lr 0.00047197 rank 5
2023-02-22 01:40:57,846 DEBUG TRAIN Batch 13/3800 loss 16.191309 loss_att 16.417456 loss_ctc 20.781185 loss_rnnt 15.359171 hw_loss 0.327982 lr 0.00047190 rank 7
2023-02-22 01:40:57,849 DEBUG TRAIN Batch 13/3800 loss 8.540564 loss_att 16.670635 loss_ctc 9.670900 loss_rnnt 6.629267 hw_loss 0.252321 lr 0.00047203 rank 0
2023-02-22 01:42:12,666 DEBUG TRAIN Batch 13/3900 loss 8.120907 loss_att 13.142459 loss_ctc 13.607230 loss_rnnt 6.227794 hw_loss 0.294924 lr 0.00047180 rank 1
2023-02-22 01:42:12,677 DEBUG TRAIN Batch 13/3900 loss 8.359753 loss_att 13.558855 loss_ctc 12.070005 loss_rnnt 6.697629 hw_loss 0.239254 lr 0.00047173 rank 2
2023-02-22 01:42:12,681 DEBUG TRAIN Batch 13/3900 loss 15.134130 loss_att 22.976421 loss_ctc 23.531246 loss_rnnt 12.297750 hw_loss 0.278075 lr 0.00047169 rank 7
2023-02-22 01:42:12,681 DEBUG TRAIN Batch 13/3900 loss 8.908199 loss_att 11.456410 loss_ctc 10.355740 loss_rnnt 8.148787 hw_loss 0.106434 lr 0.00047173 rank 4
2023-02-22 01:42:12,682 DEBUG TRAIN Batch 13/3900 loss 9.005375 loss_att 11.505405 loss_ctc 12.886429 loss_rnnt 7.718285 hw_loss 0.505519 lr 0.00047173 rank 3
2023-02-22 01:42:12,683 DEBUG TRAIN Batch 13/3900 loss 15.011417 loss_att 16.366768 loss_ctc 18.531040 loss_rnnt 14.065875 hw_loss 0.384730 lr 0.00047174 rank 6
2023-02-22 01:42:12,686 DEBUG TRAIN Batch 13/3900 loss 4.546934 loss_att 8.591789 loss_ctc 6.322857 loss_rnnt 3.370362 hw_loss 0.245271 lr 0.00047182 rank 0
2023-02-22 01:42:12,702 DEBUG TRAIN Batch 13/3900 loss 11.454553 loss_att 15.174334 loss_ctc 16.150482 loss_rnnt 9.950884 hw_loss 0.250480 lr 0.00047176 rank 5
2023-02-22 01:43:25,599 DEBUG TRAIN Batch 13/4000 loss 11.291266 loss_att 19.939812 loss_ctc 14.010692 loss_rnnt 9.033707 hw_loss 0.309864 lr 0.00047152 rank 2
2023-02-22 01:43:25,607 DEBUG TRAIN Batch 13/4000 loss 7.197307 loss_att 10.105618 loss_ctc 7.660253 loss_rnnt 6.473702 hw_loss 0.150404 lr 0.00047159 rank 1
2023-02-22 01:43:25,607 DEBUG TRAIN Batch 13/4000 loss 34.083851 loss_att 41.573387 loss_ctc 40.634304 loss_rnnt 31.656048 hw_loss 0.105947 lr 0.00047152 rank 3
2023-02-22 01:43:25,609 DEBUG TRAIN Batch 13/4000 loss 18.198057 loss_att 22.287270 loss_ctc 22.054289 loss_rnnt 16.743258 hw_loss 0.230235 lr 0.00047148 rank 7
2023-02-22 01:43:25,610 DEBUG TRAIN Batch 13/4000 loss 9.081217 loss_att 12.150794 loss_ctc 10.364771 loss_rnnt 8.194283 hw_loss 0.191022 lr 0.00047155 rank 5
2023-02-22 01:43:25,613 DEBUG TRAIN Batch 13/4000 loss 20.926521 loss_att 30.054428 loss_ctc 30.198858 loss_rnnt 17.737316 hw_loss 0.238714 lr 0.00047153 rank 6
2023-02-22 01:43:25,615 DEBUG TRAIN Batch 13/4000 loss 13.667907 loss_att 14.335491 loss_ctc 10.513453 loss_rnnt 13.851120 hw_loss 0.194743 lr 0.00047152 rank 4
2023-02-22 01:43:25,666 DEBUG TRAIN Batch 13/4000 loss 13.496193 loss_att 16.385572 loss_ctc 15.598289 loss_rnnt 12.522573 hw_loss 0.216496 lr 0.00047161 rank 0
2023-02-22 01:44:38,494 DEBUG TRAIN Batch 13/4100 loss 5.975786 loss_att 8.989723 loss_ctc 6.690635 loss_rnnt 5.201838 hw_loss 0.142215 lr 0.00047131 rank 2
2023-02-22 01:44:38,500 DEBUG TRAIN Batch 13/4100 loss 13.079165 loss_att 15.420808 loss_ctc 12.627192 loss_rnnt 12.536633 hw_loss 0.252122 lr 0.00047127 rank 7
2023-02-22 01:44:38,501 DEBUG TRAIN Batch 13/4100 loss 11.292333 loss_att 15.717743 loss_ctc 14.787338 loss_rnnt 9.798020 hw_loss 0.268555 lr 0.00047131 rank 3
2023-02-22 01:44:38,502 DEBUG TRAIN Batch 13/4100 loss 24.686777 loss_att 27.362831 loss_ctc 34.190697 loss_rnnt 22.705666 hw_loss 0.335083 lr 0.00047132 rank 6
2023-02-22 01:44:38,503 DEBUG TRAIN Batch 13/4100 loss 15.069622 loss_att 22.963110 loss_ctc 19.778534 loss_rnnt 12.668402 hw_loss 0.365002 lr 0.00047138 rank 1
2023-02-22 01:44:38,505 DEBUG TRAIN Batch 13/4100 loss 3.421461 loss_att 8.450717 loss_ctc 4.076386 loss_rnnt 2.175306 hw_loss 0.286839 lr 0.00047131 rank 4
2023-02-22 01:44:38,511 DEBUG TRAIN Batch 13/4100 loss 12.743790 loss_att 15.737085 loss_ctc 15.507623 loss_rnnt 11.555449 hw_loss 0.414697 lr 0.00047140 rank 0
2023-02-22 01:44:38,514 DEBUG TRAIN Batch 13/4100 loss 7.712247 loss_att 10.714719 loss_ctc 11.511509 loss_rnnt 6.429574 hw_loss 0.329270 lr 0.00047134 rank 5
2023-02-22 01:45:51,517 DEBUG TRAIN Batch 13/4200 loss 12.567205 loss_att 13.976512 loss_ctc 12.754292 loss_rnnt 12.117121 hw_loss 0.268647 lr 0.00047117 rank 1
2023-02-22 01:45:51,523 DEBUG TRAIN Batch 13/4200 loss 8.810291 loss_att 13.078302 loss_ctc 13.669016 loss_rnnt 7.171623 hw_loss 0.257319 lr 0.00047110 rank 2
2023-02-22 01:45:51,526 DEBUG TRAIN Batch 13/4200 loss 10.730248 loss_att 14.358496 loss_ctc 13.874675 loss_rnnt 9.370206 hw_loss 0.403381 lr 0.00047110 rank 4
2023-02-22 01:45:51,528 DEBUG TRAIN Batch 13/4200 loss 10.526113 loss_att 13.932808 loss_ctc 11.524083 loss_rnnt 9.545000 hw_loss 0.312584 lr 0.00047119 rank 0
2023-02-22 01:45:51,530 DEBUG TRAIN Batch 13/4200 loss 16.459681 loss_att 21.126488 loss_ctc 16.998016 loss_rnnt 15.346668 hw_loss 0.202261 lr 0.00047111 rank 6
2023-02-22 01:45:51,534 DEBUG TRAIN Batch 13/4200 loss 26.707792 loss_att 26.064671 loss_ctc 31.108913 loss_rnnt 26.131290 hw_loss 0.221831 lr 0.00047111 rank 3
2023-02-22 01:45:51,539 DEBUG TRAIN Batch 13/4200 loss 25.974842 loss_att 26.830971 loss_ctc 31.819099 loss_rnnt 24.881096 hw_loss 0.268657 lr 0.00047107 rank 7
2023-02-22 01:45:51,543 DEBUG TRAIN Batch 13/4200 loss 16.348761 loss_att 18.021635 loss_ctc 19.916763 loss_rnnt 15.315868 hw_loss 0.417341 lr 0.00047113 rank 5
2023-02-22 01:47:06,328 DEBUG TRAIN Batch 13/4300 loss 15.543495 loss_att 19.719963 loss_ctc 21.772558 loss_rnnt 13.669001 hw_loss 0.391236 lr 0.00047089 rank 2
2023-02-22 01:47:06,329 DEBUG TRAIN Batch 13/4300 loss 6.355431 loss_att 12.970665 loss_ctc 10.278400 loss_rnnt 4.392704 hw_loss 0.218658 lr 0.00047090 rank 3
2023-02-22 01:47:06,329 DEBUG TRAIN Batch 13/4300 loss 25.263083 loss_att 27.165329 loss_ctc 30.999683 loss_rnnt 23.941143 hw_loss 0.331150 lr 0.00047090 rank 6
2023-02-22 01:47:06,331 DEBUG TRAIN Batch 13/4300 loss 16.428478 loss_att 17.327724 loss_ctc 20.019094 loss_rnnt 15.586060 hw_loss 0.344661 lr 0.00047098 rank 0
2023-02-22 01:47:06,336 DEBUG TRAIN Batch 13/4300 loss 7.720460 loss_att 12.141815 loss_ctc 12.471689 loss_rnnt 6.082666 hw_loss 0.225047 lr 0.00047086 rank 7
2023-02-22 01:47:06,337 DEBUG TRAIN Batch 13/4300 loss 11.400349 loss_att 15.140202 loss_ctc 13.507030 loss_rnnt 10.157351 hw_loss 0.401503 lr 0.00047092 rank 5
2023-02-22 01:47:06,337 DEBUG TRAIN Batch 13/4300 loss 28.393732 loss_att 28.797840 loss_ctc 30.683926 loss_rnnt 27.858521 hw_loss 0.279430 lr 0.00047089 rank 4
2023-02-22 01:47:06,341 DEBUG TRAIN Batch 13/4300 loss 10.111955 loss_att 14.755362 loss_ctc 13.536830 loss_rnnt 8.535679 hw_loss 0.358022 lr 0.00047096 rank 1
2023-02-22 01:48:19,249 DEBUG TRAIN Batch 13/4400 loss 15.786929 loss_att 13.563829 loss_ctc 20.214918 loss_rnnt 15.496817 hw_loss 0.270626 lr 0.00047077 rank 0
2023-02-22 01:48:19,261 DEBUG TRAIN Batch 13/4400 loss 14.104182 loss_att 18.934875 loss_ctc 16.474911 loss_rnnt 12.669065 hw_loss 0.286653 lr 0.00047069 rank 3
2023-02-22 01:48:19,266 DEBUG TRAIN Batch 13/4400 loss 9.632444 loss_att 12.441429 loss_ctc 12.641574 loss_rnnt 8.451123 hw_loss 0.409324 lr 0.00047068 rank 2
2023-02-22 01:48:19,267 DEBUG TRAIN Batch 13/4400 loss 7.256462 loss_att 9.560315 loss_ctc 9.943858 loss_rnnt 6.278283 hw_loss 0.298290 lr 0.00047069 rank 6
2023-02-22 01:48:19,267 DEBUG TRAIN Batch 13/4400 loss 11.735327 loss_att 16.588243 loss_ctc 15.156032 loss_rnnt 10.203887 hw_loss 0.196431 lr 0.00047068 rank 4
2023-02-22 01:48:19,267 DEBUG TRAIN Batch 13/4400 loss 19.063967 loss_att 23.797298 loss_ctc 19.737225 loss_rnnt 17.850325 hw_loss 0.332265 lr 0.00047071 rank 5
2023-02-22 01:48:19,299 DEBUG TRAIN Batch 13/4400 loss 16.170292 loss_att 16.899014 loss_ctc 19.905378 loss_rnnt 15.360132 hw_loss 0.312006 lr 0.00047075 rank 1
2023-02-22 01:48:19,334 DEBUG TRAIN Batch 13/4400 loss 9.066133 loss_att 11.834433 loss_ctc 12.091303 loss_rnnt 7.898838 hw_loss 0.394272 lr 0.00047065 rank 7
2023-02-22 01:49:32,515 DEBUG TRAIN Batch 13/4500 loss 13.250003 loss_att 12.194687 loss_ctc 14.465957 loss_rnnt 13.203147 hw_loss 0.179612 lr 0.00047048 rank 6
2023-02-22 01:49:32,525 DEBUG TRAIN Batch 13/4500 loss 13.976381 loss_att 15.421371 loss_ctc 12.740824 loss_rnnt 13.705126 hw_loss 0.275623 lr 0.00047047 rank 2
2023-02-22 01:49:32,526 DEBUG TRAIN Batch 13/4500 loss 7.883201 loss_att 7.985957 loss_ctc 9.523767 loss_rnnt 7.375976 hw_loss 0.502373 lr 0.00047048 rank 3
2023-02-22 01:49:32,531 DEBUG TRAIN Batch 13/4500 loss 7.410984 loss_att 8.068154 loss_ctc 8.499884 loss_rnnt 6.792694 hw_loss 0.640629 lr 0.00047044 rank 7
2023-02-22 01:49:32,533 DEBUG TRAIN Batch 13/4500 loss 15.421727 loss_att 17.776033 loss_ctc 16.767635 loss_rnnt 14.622084 hw_loss 0.279991 lr 0.00047054 rank 1
2023-02-22 01:49:32,535 DEBUG TRAIN Batch 13/4500 loss 16.774456 loss_att 18.728651 loss_ctc 21.157597 loss_rnnt 15.635189 hw_loss 0.307516 lr 0.00047051 rank 5
2023-02-22 01:49:32,538 DEBUG TRAIN Batch 13/4500 loss 5.570503 loss_att 9.214652 loss_ctc 5.671731 loss_rnnt 4.658363 hw_loss 0.318400 lr 0.00047047 rank 4
2023-02-22 01:49:32,588 DEBUG TRAIN Batch 13/4500 loss 12.350722 loss_att 18.070297 loss_ctc 16.062361 loss_rnnt 10.645298 hw_loss 0.124919 lr 0.00047056 rank 0
2023-02-22 01:50:46,738 DEBUG TRAIN Batch 13/4600 loss 17.520020 loss_att 21.336561 loss_ctc 18.220343 loss_rnnt 16.617748 hw_loss 0.085478 lr 0.00047027 rank 3
2023-02-22 01:50:46,749 DEBUG TRAIN Batch 13/4600 loss 21.402487 loss_att 22.353498 loss_ctc 36.393364 loss_rnnt 19.092037 hw_loss 0.227741 lr 0.00047026 rank 2
2023-02-22 01:50:46,749 DEBUG TRAIN Batch 13/4600 loss 10.690259 loss_att 11.624799 loss_ctc 16.309507 loss_rnnt 9.642768 hw_loss 0.208780 lr 0.00047027 rank 4
2023-02-22 01:50:46,751 DEBUG TRAIN Batch 13/4600 loss 14.607029 loss_att 14.219697 loss_ctc 13.706303 loss_rnnt 14.622955 hw_loss 0.340570 lr 0.00047028 rank 6
2023-02-22 01:50:46,754 DEBUG TRAIN Batch 13/4600 loss 8.486382 loss_att 10.733706 loss_ctc 10.524896 loss_rnnt 7.658521 hw_loss 0.199865 lr 0.00047035 rank 0
2023-02-22 01:50:46,757 DEBUG TRAIN Batch 13/4600 loss 16.322723 loss_att 19.837181 loss_ctc 22.050756 loss_rnnt 14.657008 hw_loss 0.373285 lr 0.00047023 rank 7
2023-02-22 01:50:46,758 DEBUG TRAIN Batch 13/4600 loss 16.488810 loss_att 21.743351 loss_ctc 24.344763 loss_rnnt 14.253729 hw_loss 0.256333 lr 0.00047030 rank 5
2023-02-22 01:50:46,758 DEBUG TRAIN Batch 13/4600 loss 15.063007 loss_att 17.808470 loss_ctc 15.601572 loss_rnnt 14.252739 hw_loss 0.355066 lr 0.00047034 rank 1
2023-02-22 01:52:00,225 DEBUG TRAIN Batch 13/4700 loss 14.906215 loss_att 15.629570 loss_ctc 12.970114 loss_rnnt 14.831207 hw_loss 0.353406 lr 0.00047006 rank 2
2023-02-22 01:52:00,225 DEBUG TRAIN Batch 13/4700 loss 10.528005 loss_att 15.137373 loss_ctc 18.547560 loss_rnnt 8.435284 hw_loss 0.190450 lr 0.00047006 rank 3
2023-02-22 01:52:00,227 DEBUG TRAIN Batch 13/4700 loss 14.309291 loss_att 16.239944 loss_ctc 18.569881 loss_rnnt 13.202007 hw_loss 0.287016 lr 0.00047014 rank 0
2023-02-22 01:52:00,229 DEBUG TRAIN Batch 13/4700 loss 13.309427 loss_att 18.313566 loss_ctc 14.249600 loss_rnnt 12.050995 hw_loss 0.247966 lr 0.00047007 rank 6
2023-02-22 01:52:00,230 DEBUG TRAIN Batch 13/4700 loss 9.150373 loss_att 14.610950 loss_ctc 10.057306 loss_rnnt 7.740440 hw_loss 0.369174 lr 0.00047006 rank 4
2023-02-22 01:52:00,234 DEBUG TRAIN Batch 13/4700 loss 14.698932 loss_att 18.248589 loss_ctc 19.122473 loss_rnnt 13.265268 hw_loss 0.251110 lr 0.00047013 rank 1
2023-02-22 01:52:00,238 DEBUG TRAIN Batch 13/4700 loss 4.073837 loss_att 9.551051 loss_ctc 3.305999 loss_rnnt 2.874763 hw_loss 0.386268 lr 0.00047002 rank 7
2023-02-22 01:52:00,283 DEBUG TRAIN Batch 13/4700 loss 17.467157 loss_att 18.735338 loss_ctc 24.923731 loss_rnnt 16.150116 hw_loss 0.129744 lr 0.00047009 rank 5
2023-02-22 01:53:12,439 DEBUG TRAIN Batch 13/4800 loss 19.233667 loss_att 21.396673 loss_ctc 25.777138 loss_rnnt 17.839470 hw_loss 0.167125 lr 0.00046985 rank 2
2023-02-22 01:53:12,444 DEBUG TRAIN Batch 13/4800 loss 11.148985 loss_att 12.748838 loss_ctc 12.332008 loss_rnnt 10.458488 hw_loss 0.398982 lr 0.00046982 rank 7
2023-02-22 01:53:12,444 DEBUG TRAIN Batch 13/4800 loss 7.813360 loss_att 10.860109 loss_ctc 8.956020 loss_rnnt 6.914094 hw_loss 0.257928 lr 0.00046988 rank 5
2023-02-22 01:53:12,445 DEBUG TRAIN Batch 13/4800 loss 11.886123 loss_att 15.409188 loss_ctc 14.529311 loss_rnnt 10.683524 hw_loss 0.272925 lr 0.00046992 rank 1
2023-02-22 01:53:12,446 DEBUG TRAIN Batch 13/4800 loss 11.478932 loss_att 12.585162 loss_ctc 14.229328 loss_rnnt 10.688852 hw_loss 0.378965 lr 0.00046994 rank 0
2023-02-22 01:53:12,446 DEBUG TRAIN Batch 13/4800 loss 14.502395 loss_att 17.558117 loss_ctc 17.521034 loss_rnnt 13.290541 hw_loss 0.371672 lr 0.00046986 rank 6
2023-02-22 01:53:12,449 DEBUG TRAIN Batch 13/4800 loss 19.344667 loss_att 21.112253 loss_ctc 25.227486 loss_rnnt 18.100983 hw_loss 0.198360 lr 0.00046986 rank 3
2023-02-22 01:53:12,497 DEBUG TRAIN Batch 13/4800 loss 13.006286 loss_att 15.013643 loss_ctc 17.959343 loss_rnnt 11.786036 hw_loss 0.296943 lr 0.00046985 rank 4
2023-02-22 01:54:25,902 DEBUG TRAIN Batch 13/4900 loss 14.067743 loss_att 14.032868 loss_ctc 17.261580 loss_rnnt 13.437744 hw_loss 0.395866 lr 0.00046968 rank 5
2023-02-22 01:54:25,905 DEBUG TRAIN Batch 13/4900 loss 9.430737 loss_att 10.777349 loss_ctc 15.438227 loss_rnnt 8.184336 hw_loss 0.330148 lr 0.00046965 rank 3
2023-02-22 01:54:25,906 DEBUG TRAIN Batch 13/4900 loss 20.429941 loss_att 19.974276 loss_ctc 25.766724 loss_rnnt 19.598650 hw_loss 0.395349 lr 0.00046964 rank 2
2023-02-22 01:54:25,909 DEBUG TRAIN Batch 13/4900 loss 19.620440 loss_att 24.349041 loss_ctc 20.916142 loss_rnnt 18.397800 hw_loss 0.195294 lr 0.00046965 rank 6
2023-02-22 01:54:25,912 DEBUG TRAIN Batch 13/4900 loss 10.290207 loss_att 13.434355 loss_ctc 12.212158 loss_rnnt 9.209638 hw_loss 0.366522 lr 0.00046961 rank 7
2023-02-22 01:54:25,918 DEBUG TRAIN Batch 13/4900 loss 12.960684 loss_att 15.379726 loss_ctc 13.735498 loss_rnnt 12.185791 hw_loss 0.352079 lr 0.00046973 rank 0
2023-02-22 01:54:25,935 DEBUG TRAIN Batch 13/4900 loss 7.170650 loss_att 12.664541 loss_ctc 12.255494 loss_rnnt 5.261629 hw_loss 0.247996 lr 0.00046971 rank 1
2023-02-22 01:54:25,942 DEBUG TRAIN Batch 13/4900 loss 15.403747 loss_att 18.734510 loss_ctc 23.558146 loss_rnnt 13.542101 hw_loss 0.202946 lr 0.00046964 rank 4
2023-02-22 01:55:41,114 DEBUG TRAIN Batch 13/5000 loss 12.770034 loss_att 18.547403 loss_ctc 19.677107 loss_rnnt 10.557721 hw_loss 0.254805 lr 0.00046945 rank 6
2023-02-22 01:55:41,117 DEBUG TRAIN Batch 13/5000 loss 13.292030 loss_att 15.306800 loss_ctc 15.922732 loss_rnnt 12.454676 hw_loss 0.156821 lr 0.00046944 rank 3
2023-02-22 01:55:41,118 DEBUG TRAIN Batch 13/5000 loss 14.864042 loss_att 14.864950 loss_ctc 19.514637 loss_rnnt 13.958380 hw_loss 0.535131 lr 0.00046952 rank 0
2023-02-22 01:55:41,121 DEBUG TRAIN Batch 13/5000 loss 7.321136 loss_att 11.500461 loss_ctc 9.426180 loss_rnnt 6.000643 hw_loss 0.382417 lr 0.00046944 rank 4
2023-02-22 01:55:41,123 DEBUG TRAIN Batch 13/5000 loss 14.599826 loss_att 13.728386 loss_ctc 15.717643 loss_rnnt 14.403659 hw_loss 0.415150 lr 0.00046947 rank 5
2023-02-22 01:55:41,127 DEBUG TRAIN Batch 13/5000 loss 16.311058 loss_att 19.973385 loss_ctc 23.705996 loss_rnnt 14.400854 hw_loss 0.359527 lr 0.00046943 rank 2
2023-02-22 01:55:41,130 DEBUG TRAIN Batch 13/5000 loss 12.764122 loss_att 16.939289 loss_ctc 16.159309 loss_rnnt 11.331737 hw_loss 0.271240 lr 0.00046940 rank 7
2023-02-22 01:55:41,147 DEBUG TRAIN Batch 13/5000 loss 15.024776 loss_att 16.853811 loss_ctc 19.948154 loss_rnnt 13.840482 hw_loss 0.303815 lr 0.00046951 rank 1
2023-02-22 01:56:53,596 DEBUG TRAIN Batch 13/5100 loss 10.191932 loss_att 12.054651 loss_ctc 13.353763 loss_rnnt 9.250208 hw_loss 0.276753 lr 0.00046923 rank 2
2023-02-22 01:56:53,597 DEBUG TRAIN Batch 13/5100 loss 17.603020 loss_att 26.801001 loss_ctc 19.970936 loss_rnnt 15.305901 hw_loss 0.265873 lr 0.00046923 rank 4
2023-02-22 01:56:53,601 DEBUG TRAIN Batch 13/5100 loss 6.587367 loss_att 14.809834 loss_ctc 10.318025 loss_rnnt 4.313554 hw_loss 0.247309 lr 0.00046920 rank 7
2023-02-22 01:56:53,601 DEBUG TRAIN Batch 13/5100 loss 9.549265 loss_att 12.952796 loss_ctc 12.646174 loss_rnnt 8.243025 hw_loss 0.398648 lr 0.00046931 rank 0
2023-02-22 01:56:53,603 DEBUG TRAIN Batch 13/5100 loss 7.343886 loss_att 11.513154 loss_ctc 9.957340 loss_rnnt 6.107151 hw_loss 0.102040 lr 0.00046926 rank 5
2023-02-22 01:56:53,606 DEBUG TRAIN Batch 13/5100 loss 21.379944 loss_att 28.688354 loss_ctc 27.413555 loss_rnnt 19.008135 hw_loss 0.198085 lr 0.00046930 rank 1
2023-02-22 01:56:53,633 DEBUG TRAIN Batch 13/5100 loss 17.504396 loss_att 16.310080 loss_ctc 20.315886 loss_rnnt 17.041910 hw_loss 0.612160 lr 0.00046923 rank 3
2023-02-22 01:56:53,635 DEBUG TRAIN Batch 13/5100 loss 11.240294 loss_att 12.011666 loss_ctc 14.223372 loss_rnnt 10.518337 hw_loss 0.318633 lr 0.00046924 rank 6
2023-02-22 01:58:06,083 DEBUG TRAIN Batch 13/5200 loss 18.161737 loss_att 23.189457 loss_ctc 20.251625 loss_rnnt 16.787670 hw_loss 0.168508 lr 0.00046903 rank 6
2023-02-22 01:58:06,082 DEBUG TRAIN Batch 13/5200 loss 11.990671 loss_att 16.389141 loss_ctc 13.171280 loss_rnnt 10.858947 hw_loss 0.177406 lr 0.00046902 rank 2
2023-02-22 01:58:06,082 DEBUG TRAIN Batch 13/5200 loss 11.168538 loss_att 19.991495 loss_ctc 18.114613 loss_rnnt 8.389853 hw_loss 0.164908 lr 0.00046903 rank 3
2023-02-22 01:58:06,087 DEBUG TRAIN Batch 13/5200 loss 5.829263 loss_att 8.713828 loss_ctc 6.760417 loss_rnnt 4.986493 hw_loss 0.265691 lr 0.00046899 rank 7
2023-02-22 01:58:06,091 DEBUG TRAIN Batch 13/5200 loss 14.341305 loss_att 15.160116 loss_ctc 20.850418 loss_rnnt 13.031816 hw_loss 0.520958 lr 0.00046911 rank 0
2023-02-22 01:58:06,094 DEBUG TRAIN Batch 13/5200 loss 13.972805 loss_att 17.668856 loss_ctc 17.983681 loss_rnnt 12.503086 hw_loss 0.366984 lr 0.00046909 rank 1
2023-02-22 01:58:06,100 DEBUG TRAIN Batch 13/5200 loss 5.025004 loss_att 7.801939 loss_ctc 6.994986 loss_rnnt 4.007415 hw_loss 0.374134 lr 0.00046905 rank 5
2023-02-22 01:58:06,135 DEBUG TRAIN Batch 13/5200 loss 24.661716 loss_att 27.330742 loss_ctc 29.793610 loss_rnnt 23.347542 hw_loss 0.180222 lr 0.00046902 rank 4
2023-02-22 01:59:19,991 DEBUG TRAIN Batch 13/5300 loss 29.180723 loss_att 40.232761 loss_ctc 38.159843 loss_rnnt 25.642189 hw_loss 0.245455 lr 0.00046882 rank 4
2023-02-22 01:59:19,993 DEBUG TRAIN Batch 13/5300 loss 8.010982 loss_att 11.711333 loss_ctc 9.089460 loss_rnnt 6.970222 hw_loss 0.294175 lr 0.00046878 rank 7
2023-02-22 01:59:20,005 DEBUG TRAIN Batch 13/5300 loss 13.629353 loss_att 15.847548 loss_ctc 18.909264 loss_rnnt 12.296211 hw_loss 0.347839 lr 0.00046882 rank 3
2023-02-22 01:59:20,008 DEBUG TRAIN Batch 13/5300 loss 22.209175 loss_att 24.059029 loss_ctc 29.898138 loss_rnnt 20.720150 hw_loss 0.175989 lr 0.00046882 rank 2
2023-02-22 01:59:20,009 DEBUG TRAIN Batch 13/5300 loss 15.443167 loss_att 15.804075 loss_ctc 18.701050 loss_rnnt 14.795753 hw_loss 0.264089 lr 0.00046883 rank 6
2023-02-22 01:59:20,011 DEBUG TRAIN Batch 13/5300 loss 6.220103 loss_att 10.299222 loss_ctc 7.047901 loss_rnnt 5.173593 hw_loss 0.225587 lr 0.00046885 rank 5
2023-02-22 01:59:20,021 DEBUG TRAIN Batch 13/5300 loss 12.648521 loss_att 16.972012 loss_ctc 17.442543 loss_rnnt 11.041576 hw_loss 0.193207 lr 0.00046890 rank 0
2023-02-22 01:59:20,036 DEBUG TRAIN Batch 13/5300 loss 14.750952 loss_att 16.855345 loss_ctc 15.676443 loss_rnnt 13.975696 hw_loss 0.433087 lr 0.00046889 rank 1
2023-02-22 02:00:34,212 DEBUG TRAIN Batch 13/5400 loss 16.701866 loss_att 18.722237 loss_ctc 21.558554 loss_rnnt 15.531428 hw_loss 0.222762 lr 0.00046861 rank 2
2023-02-22 02:00:34,212 DEBUG TRAIN Batch 13/5400 loss 13.278007 loss_att 16.832190 loss_ctc 18.605715 loss_rnnt 11.730192 hw_loss 0.237405 lr 0.00046862 rank 3
2023-02-22 02:00:34,215 DEBUG TRAIN Batch 13/5400 loss 6.248088 loss_att 10.700655 loss_ctc 10.122370 loss_rnnt 4.704553 hw_loss 0.255846 lr 0.00046868 rank 1
2023-02-22 02:00:34,216 DEBUG TRAIN Batch 13/5400 loss 7.528231 loss_att 12.216071 loss_ctc 7.997975 loss_rnnt 6.394088 hw_loss 0.251141 lr 0.00046861 rank 4
2023-02-22 02:00:34,215 DEBUG TRAIN Batch 13/5400 loss 12.315411 loss_att 15.890319 loss_ctc 18.528208 loss_rnnt 10.668816 hw_loss 0.193577 lr 0.00046858 rank 7
2023-02-22 02:00:34,216 DEBUG TRAIN Batch 13/5400 loss 9.471345 loss_att 12.491858 loss_ctc 10.952686 loss_rnnt 8.516140 hw_loss 0.287980 lr 0.00046862 rank 6
2023-02-22 02:00:34,215 DEBUG TRAIN Batch 13/5400 loss 15.983796 loss_att 21.901367 loss_ctc 19.736664 loss_rnnt 14.169582 hw_loss 0.244346 lr 0.00046870 rank 0
2023-02-22 02:00:34,220 DEBUG TRAIN Batch 13/5400 loss 11.190610 loss_att 13.302376 loss_ctc 15.475410 loss_rnnt 10.064619 hw_loss 0.248120 lr 0.00046864 rank 5
2023-02-22 02:01:46,372 DEBUG TRAIN Batch 13/5500 loss 21.002888 loss_att 22.402187 loss_ctc 23.624186 loss_rnnt 20.235512 hw_loss 0.258766 lr 0.00046847 rank 1
2023-02-22 02:01:46,377 DEBUG TRAIN Batch 13/5500 loss 11.277828 loss_att 14.593886 loss_ctc 13.131027 loss_rnnt 10.301703 hw_loss 0.123413 lr 0.00046840 rank 2
2023-02-22 02:01:46,378 DEBUG TRAIN Batch 13/5500 loss 15.138150 loss_att 20.987490 loss_ctc 18.775078 loss_rnnt 13.376328 hw_loss 0.200679 lr 0.00046841 rank 3
2023-02-22 02:01:46,379 DEBUG TRAIN Batch 13/5500 loss 6.076029 loss_att 8.214053 loss_ctc 5.780924 loss_rnnt 5.587376 hw_loss 0.188241 lr 0.00046837 rank 7
2023-02-22 02:01:46,379 DEBUG TRAIN Batch 13/5500 loss 16.494061 loss_att 16.199278 loss_ctc 20.396994 loss_rnnt 15.806498 hw_loss 0.423992 lr 0.00046849 rank 0
2023-02-22 02:01:46,384 DEBUG TRAIN Batch 13/5500 loss 13.828218 loss_att 15.123930 loss_ctc 17.162067 loss_rnnt 12.945848 hw_loss 0.335089 lr 0.00046841 rank 4
2023-02-22 02:01:46,383 DEBUG TRAIN Batch 13/5500 loss 4.923213 loss_att 10.320951 loss_ctc 7.722723 loss_rnnt 3.347335 hw_loss 0.230741 lr 0.00046841 rank 6
2023-02-22 02:01:46,430 DEBUG TRAIN Batch 13/5500 loss 16.166197 loss_att 20.761278 loss_ctc 17.634119 loss_rnnt 14.958640 hw_loss 0.174038 lr 0.00046844 rank 5
2023-02-22 02:02:59,039 DEBUG TRAIN Batch 13/5600 loss 5.606512 loss_att 8.793938 loss_ctc 7.916190 loss_rnnt 4.438268 hw_loss 0.417752 lr 0.00046820 rank 2
2023-02-22 02:02:59,040 DEBUG TRAIN Batch 13/5600 loss 13.800028 loss_att 15.765501 loss_ctc 20.851624 loss_rnnt 12.323605 hw_loss 0.268342 lr 0.00046821 rank 6
2023-02-22 02:02:59,043 DEBUG TRAIN Batch 13/5600 loss 4.904530 loss_att 6.535776 loss_ctc 6.691212 loss_rnnt 4.186592 hw_loss 0.287745 lr 0.00046823 rank 5
2023-02-22 02:02:59,043 DEBUG TRAIN Batch 13/5600 loss 16.857973 loss_att 19.095882 loss_ctc 23.000994 loss_rnnt 15.503503 hw_loss 0.164659 lr 0.00046820 rank 4
2023-02-22 02:02:59,044 DEBUG TRAIN Batch 13/5600 loss 27.801590 loss_att 27.507557 loss_ctc 35.322380 loss_rnnt 26.733181 hw_loss 0.233334 lr 0.00046817 rank 7
2023-02-22 02:02:59,045 DEBUG TRAIN Batch 13/5600 loss 7.184602 loss_att 10.128311 loss_ctc 9.362705 loss_rnnt 6.150418 hw_loss 0.290678 lr 0.00046820 rank 3
2023-02-22 02:02:59,055 DEBUG TRAIN Batch 13/5600 loss 7.782894 loss_att 9.704165 loss_ctc 10.316401 loss_rnnt 6.876394 hw_loss 0.345834 lr 0.00046828 rank 0
2023-02-22 02:02:59,097 DEBUG TRAIN Batch 13/5600 loss 31.188507 loss_att 32.072762 loss_ctc 38.447151 loss_rnnt 29.926723 hw_loss 0.219590 lr 0.00046827 rank 1
2023-02-22 02:04:14,671 DEBUG TRAIN Batch 13/5700 loss 12.602767 loss_att 14.290821 loss_ctc 15.959290 loss_rnnt 11.511894 hw_loss 0.573235 lr 0.00046799 rank 2
2023-02-22 02:04:14,673 DEBUG TRAIN Batch 13/5700 loss 17.462273 loss_att 15.306897 loss_ctc 19.836035 loss_rnnt 17.389606 hw_loss 0.351078 lr 0.00046800 rank 3
2023-02-22 02:04:14,676 DEBUG TRAIN Batch 13/5700 loss 10.288652 loss_att 11.835251 loss_ctc 11.863879 loss_rnnt 9.634640 hw_loss 0.252493 lr 0.00046800 rank 4
2023-02-22 02:04:14,677 DEBUG TRAIN Batch 13/5700 loss 11.675586 loss_att 14.872961 loss_ctc 18.268187 loss_rnnt 10.058753 hw_loss 0.184395 lr 0.00046803 rank 5
2023-02-22 02:04:14,680 DEBUG TRAIN Batch 13/5700 loss 28.063280 loss_att 30.386295 loss_ctc 35.916363 loss_rnnt 26.425562 hw_loss 0.236315 lr 0.00046800 rank 6
2023-02-22 02:04:14,680 DEBUG TRAIN Batch 13/5700 loss 14.837508 loss_att 15.304236 loss_ctc 16.748428 loss_rnnt 14.293251 hw_loss 0.367730 lr 0.00046808 rank 0
2023-02-22 02:04:14,685 DEBUG TRAIN Batch 13/5700 loss 15.480623 loss_att 15.339300 loss_ctc 19.028276 loss_rnnt 14.883903 hw_loss 0.284934 lr 0.00046806 rank 1
2023-02-22 02:04:14,729 DEBUG TRAIN Batch 13/5700 loss 12.772633 loss_att 13.459637 loss_ctc 16.855881 loss_rnnt 11.814830 hw_loss 0.517441 lr 0.00046796 rank 7
2023-02-22 02:05:26,606 DEBUG TRAIN Batch 13/5800 loss 16.458803 loss_att 17.670109 loss_ctc 21.169628 loss_rnnt 15.448263 hw_loss 0.262819 lr 0.00046779 rank 4
2023-02-22 02:05:26,618 DEBUG TRAIN Batch 13/5800 loss 8.892235 loss_att 14.726982 loss_ctc 8.729736 loss_rnnt 7.655506 hw_loss 0.171462 lr 0.00046779 rank 3
2023-02-22 02:05:26,618 DEBUG TRAIN Batch 13/5800 loss 13.019819 loss_att 15.400743 loss_ctc 16.944332 loss_rnnt 11.786549 hw_loss 0.438408 lr 0.00046779 rank 2
2023-02-22 02:05:26,618 DEBUG TRAIN Batch 13/5800 loss 9.264926 loss_att 13.483368 loss_ctc 9.136605 loss_rnnt 8.206489 hw_loss 0.434734 lr 0.00046786 rank 1
2023-02-22 02:05:26,619 DEBUG TRAIN Batch 13/5800 loss 9.976941 loss_att 14.254957 loss_ctc 12.017775 loss_rnnt 8.767942 hw_loss 0.152410 lr 0.00046782 rank 5
2023-02-22 02:05:26,620 DEBUG TRAIN Batch 13/5800 loss 12.370298 loss_att 14.672930 loss_ctc 14.766063 loss_rnnt 11.433466 hw_loss 0.294133 lr 0.00046780 rank 6
2023-02-22 02:05:26,626 DEBUG TRAIN Batch 13/5800 loss 12.891905 loss_att 16.558416 loss_ctc 12.403190 loss_rnnt 12.126762 hw_loss 0.181879 lr 0.00046776 rank 7
2023-02-22 02:05:26,670 DEBUG TRAIN Batch 13/5800 loss 6.215220 loss_att 10.511566 loss_ctc 8.985849 loss_rnnt 4.921557 hw_loss 0.121830 lr 0.00046787 rank 0
2023-02-22 02:06:39,066 DEBUG TRAIN Batch 13/5900 loss 15.132692 loss_att 18.831860 loss_ctc 18.230579 loss_rnnt 13.868246 hw_loss 0.209178 lr 0.00046758 rank 2
2023-02-22 02:06:39,068 DEBUG TRAIN Batch 13/5900 loss 21.627457 loss_att 26.408104 loss_ctc 26.885036 loss_rnnt 19.813559 hw_loss 0.293922 lr 0.00046759 rank 4
2023-02-22 02:06:39,070 DEBUG TRAIN Batch 13/5900 loss 5.901071 loss_att 8.498613 loss_ctc 8.604332 loss_rnnt 4.911494 hw_loss 0.205562 lr 0.00046759 rank 3
2023-02-22 02:06:39,072 DEBUG TRAIN Batch 13/5900 loss 17.552620 loss_att 21.260098 loss_ctc 22.580503 loss_rnnt 16.017044 hw_loss 0.231928 lr 0.00046767 rank 0
2023-02-22 02:06:39,074 DEBUG TRAIN Batch 13/5900 loss 12.097807 loss_att 15.943464 loss_ctc 14.157496 loss_rnnt 10.944400 hw_loss 0.205595 lr 0.00046765 rank 1
2023-02-22 02:06:39,076 DEBUG TRAIN Batch 13/5900 loss 13.589282 loss_att 16.044191 loss_ctc 18.575359 loss_rnnt 12.244720 hw_loss 0.353942 lr 0.00046762 rank 5
2023-02-22 02:06:39,077 DEBUG TRAIN Batch 13/5900 loss 14.764124 loss_att 18.637512 loss_ctc 22.206259 loss_rnnt 12.900747 hw_loss 0.180779 lr 0.00046755 rank 7
2023-02-22 02:06:39,077 DEBUG TRAIN Batch 13/5900 loss 8.739641 loss_att 10.862783 loss_ctc 10.542349 loss_rnnt 7.897632 hw_loss 0.331913 lr 0.00046759 rank 6
2023-02-22 02:07:53,580 DEBUG TRAIN Batch 13/6000 loss 11.114007 loss_att 13.638137 loss_ctc 13.614111 loss_rnnt 10.085990 hw_loss 0.355957 lr 0.00046741 rank 5
2023-02-22 02:07:53,589 DEBUG TRAIN Batch 13/6000 loss 4.829460 loss_att 7.023558 loss_ctc 4.985726 loss_rnnt 4.249362 hw_loss 0.225830 lr 0.00046738 rank 2
2023-02-22 02:07:53,592 DEBUG TRAIN Batch 13/6000 loss 9.349260 loss_att 9.703408 loss_ctc 9.165683 loss_rnnt 9.106192 hw_loss 0.368844 lr 0.00046739 rank 3
2023-02-22 02:07:53,595 DEBUG TRAIN Batch 13/6000 loss 12.520248 loss_att 15.624957 loss_ctc 15.847112 loss_rnnt 11.379236 hw_loss 0.143416 lr 0.00046735 rank 7
2023-02-22 02:07:53,597 DEBUG TRAIN Batch 13/6000 loss 15.957417 loss_att 20.283253 loss_ctc 20.908703 loss_rnnt 14.329184 hw_loss 0.192929 lr 0.00046747 rank 0
2023-02-22 02:07:53,597 DEBUG TRAIN Batch 13/6000 loss 12.203888 loss_att 14.876990 loss_ctc 15.778057 loss_rnnt 11.056089 hw_loss 0.256168 lr 0.00046738 rank 4
2023-02-22 02:07:53,598 DEBUG TRAIN Batch 13/6000 loss 14.286313 loss_att 19.458040 loss_ctc 18.231140 loss_rnnt 12.576595 hw_loss 0.280115 lr 0.00046739 rank 6
2023-02-22 02:07:53,628 DEBUG TRAIN Batch 13/6000 loss 10.876216 loss_att 14.321918 loss_ctc 16.255657 loss_rnnt 9.327095 hw_loss 0.267604 lr 0.00046745 rank 1
2023-02-22 02:09:07,514 DEBUG TRAIN Batch 13/6100 loss 3.495420 loss_att 8.330647 loss_ctc 6.282270 loss_rnnt 2.007856 hw_loss 0.279260 lr 0.00046718 rank 3
2023-02-22 02:09:07,514 DEBUG TRAIN Batch 13/6100 loss 15.433234 loss_att 15.974159 loss_ctc 21.870028 loss_rnnt 14.325972 hw_loss 0.264072 lr 0.00046718 rank 2
2023-02-22 02:09:07,521 DEBUG TRAIN Batch 13/6100 loss 17.824932 loss_att 24.246542 loss_ctc 23.729719 loss_rnnt 15.627600 hw_loss 0.235698 lr 0.00046718 rank 4
2023-02-22 02:09:07,520 DEBUG TRAIN Batch 13/6100 loss 24.741043 loss_att 27.670029 loss_ctc 29.947567 loss_rnnt 23.285522 hw_loss 0.329100 lr 0.00046719 rank 6
2023-02-22 02:09:07,522 DEBUG TRAIN Batch 13/6100 loss 17.308531 loss_att 18.063545 loss_ctc 26.414827 loss_rnnt 15.799089 hw_loss 0.270496 lr 0.00046726 rank 0
2023-02-22 02:09:07,524 DEBUG TRAIN Batch 13/6100 loss 11.388197 loss_att 14.590034 loss_ctc 14.195442 loss_rnnt 10.242018 hw_loss 0.246587 lr 0.00046714 rank 7
2023-02-22 02:09:07,524 DEBUG TRAIN Batch 13/6100 loss 9.218846 loss_att 15.474095 loss_ctc 13.546663 loss_rnnt 7.307616 hw_loss 0.155886 lr 0.00046721 rank 5
2023-02-22 02:09:07,525 DEBUG TRAIN Batch 13/6100 loss 18.657974 loss_att 24.758764 loss_ctc 23.495392 loss_rnnt 16.610027 hw_loss 0.342751 lr 0.00046724 rank 1
2023-02-22 02:10:20,918 DEBUG TRAIN Batch 13/6200 loss 12.581460 loss_att 16.994919 loss_ctc 18.063328 loss_rnnt 10.865577 hw_loss 0.191767 lr 0.00046706 rank 0
2023-02-22 02:10:20,918 DEBUG TRAIN Batch 13/6200 loss 11.337957 loss_att 15.399137 loss_ctc 16.198063 loss_rnnt 9.729139 hw_loss 0.278567 lr 0.00046694 rank 7
2023-02-22 02:10:20,921 DEBUG TRAIN Batch 13/6200 loss 13.973987 loss_att 17.554321 loss_ctc 18.203957 loss_rnnt 12.516912 hw_loss 0.331897 lr 0.00046704 rank 1
2023-02-22 02:10:20,922 DEBUG TRAIN Batch 13/6200 loss 10.889233 loss_att 13.247206 loss_ctc 11.810163 loss_rnnt 10.137119 hw_loss 0.295741 lr 0.00046700 rank 5
2023-02-22 02:10:20,922 DEBUG TRAIN Batch 13/6200 loss 19.582209 loss_att 27.142591 loss_ctc 23.254642 loss_rnnt 17.461250 hw_loss 0.223547 lr 0.00046697 rank 2
2023-02-22 02:10:20,923 DEBUG TRAIN Batch 13/6200 loss 13.128612 loss_att 15.859146 loss_ctc 16.792427 loss_rnnt 11.852682 hw_loss 0.452464 lr 0.00046698 rank 3
2023-02-22 02:10:20,924 DEBUG TRAIN Batch 13/6200 loss 20.231817 loss_att 22.819927 loss_ctc 23.909023 loss_rnnt 19.074190 hw_loss 0.280710 lr 0.00046698 rank 6
2023-02-22 02:10:20,926 DEBUG TRAIN Batch 13/6200 loss 15.260461 loss_att 20.957758 loss_ctc 22.251408 loss_rnnt 13.004753 hw_loss 0.345227 lr 0.00046697 rank 4
2023-02-22 02:11:36,232 DEBUG TRAIN Batch 13/6300 loss 23.379896 loss_att 27.367552 loss_ctc 31.620945 loss_rnnt 21.376133 hw_loss 0.201420 lr 0.00046677 rank 3
2023-02-22 02:11:36,236 DEBUG TRAIN Batch 13/6300 loss 16.429296 loss_att 22.949915 loss_ctc 20.795984 loss_rnnt 14.428055 hw_loss 0.215425 lr 0.00046678 rank 6
2023-02-22 02:11:36,237 DEBUG TRAIN Batch 13/6300 loss 9.007421 loss_att 9.770996 loss_ctc 9.994328 loss_rnnt 8.481855 hw_loss 0.452368 lr 0.00046680 rank 5
2023-02-22 02:11:36,238 DEBUG TRAIN Batch 13/6300 loss 23.000866 loss_att 26.289864 loss_ctc 30.227848 loss_rnnt 21.181723 hw_loss 0.370773 lr 0.00046684 rank 1
2023-02-22 02:11:36,239 DEBUG TRAIN Batch 13/6300 loss 8.627905 loss_att 9.723228 loss_ctc 11.137461 loss_rnnt 7.886568 hw_loss 0.351874 lr 0.00046677 rank 4
2023-02-22 02:11:36,239 DEBUG TRAIN Batch 13/6300 loss 14.812142 loss_att 17.280661 loss_ctc 13.851244 loss_rnnt 14.256630 hw_loss 0.356116 lr 0.00046677 rank 2
2023-02-22 02:11:36,246 DEBUG TRAIN Batch 13/6300 loss 11.361828 loss_att 12.635513 loss_ctc 10.787107 loss_rnnt 11.035894 hw_loss 0.277176 lr 0.00046674 rank 7
2023-02-22 02:11:36,246 DEBUG TRAIN Batch 13/6300 loss 9.665516 loss_att 10.119165 loss_ctc 11.814632 loss_rnnt 9.045054 hw_loss 0.455968 lr 0.00046685 rank 0
2023-02-22 02:12:52,524 DEBUG TRAIN Batch 13/6400 loss 9.749101 loss_att 12.115088 loss_ctc 12.797210 loss_rnnt 8.775201 hw_loss 0.176786 lr 0.00046656 rank 2
2023-02-22 02:12:52,526 DEBUG TRAIN Batch 13/6400 loss 18.413815 loss_att 22.633728 loss_ctc 24.413349 loss_rnnt 16.531610 hw_loss 0.446781 lr 0.00046657 rank 3
2023-02-22 02:12:52,531 DEBUG TRAIN Batch 13/6400 loss 10.343536 loss_att 10.289445 loss_ctc 12.860854 loss_rnnt 9.852149 hw_loss 0.312306 lr 0.00046658 rank 6
2023-02-22 02:12:52,538 DEBUG TRAIN Batch 13/6400 loss 16.995447 loss_att 21.019276 loss_ctc 23.496620 loss_rnnt 15.219966 hw_loss 0.194799 lr 0.00046660 rank 5
2023-02-22 02:12:52,543 DEBUG TRAIN Batch 13/6400 loss 17.375441 loss_att 34.337963 loss_ctc 19.799137 loss_rnnt 13.506714 hw_loss 0.286996 lr 0.00046663 rank 1
2023-02-22 02:12:52,590 DEBUG TRAIN Batch 13/6400 loss 8.913813 loss_att 15.164968 loss_ctc 9.647726 loss_rnnt 7.381465 hw_loss 0.345491 lr 0.00046657 rank 4
2023-02-22 02:12:52,614 DEBUG TRAIN Batch 13/6400 loss 9.755100 loss_att 13.683962 loss_ctc 13.454042 loss_rnnt 8.327693 hw_loss 0.278329 lr 0.00046653 rank 7
2023-02-22 02:12:52,614 DEBUG TRAIN Batch 13/6400 loss 18.271400 loss_att 19.157831 loss_ctc 23.548071 loss_rnnt 17.265209 hw_loss 0.235026 lr 0.00046665 rank 0
2023-02-22 02:14:05,712 DEBUG TRAIN Batch 13/6500 loss 2.693645 loss_att 4.636562 loss_ctc 1.660511 loss_rnnt 2.323334 hw_loss 0.224024 lr 0.00046637 rank 3
2023-02-22 02:14:05,712 DEBUG TRAIN Batch 13/6500 loss 28.587389 loss_att 33.197567 loss_ctc 28.415234 loss_rnnt 27.559235 hw_loss 0.242011 lr 0.00046637 rank 6
2023-02-22 02:14:05,714 DEBUG TRAIN Batch 13/6500 loss 4.980548 loss_att 8.972980 loss_ctc 6.706789 loss_rnnt 3.771062 hw_loss 0.339064 lr 0.00046636 rank 2
2023-02-22 02:14:05,716 DEBUG TRAIN Batch 13/6500 loss 14.975249 loss_att 18.873093 loss_ctc 20.854706 loss_rnnt 13.234996 hw_loss 0.331422 lr 0.00046636 rank 4
2023-02-22 02:14:05,719 DEBUG TRAIN Batch 13/6500 loss 13.775181 loss_att 18.678988 loss_ctc 20.191412 loss_rnnt 11.768871 hw_loss 0.318845 lr 0.00046633 rank 7
2023-02-22 02:14:05,720 DEBUG TRAIN Batch 13/6500 loss 12.070868 loss_att 13.649729 loss_ctc 12.893173 loss_rnnt 11.412130 hw_loss 0.437483 lr 0.00046643 rank 1
2023-02-22 02:14:05,722 DEBUG TRAIN Batch 13/6500 loss 10.848127 loss_att 14.576917 loss_ctc 16.373632 loss_rnnt 9.298190 hw_loss 0.126460 lr 0.00046639 rank 5
2023-02-22 02:14:05,764 DEBUG TRAIN Batch 13/6500 loss 13.315210 loss_att 15.793571 loss_ctc 19.098152 loss_rnnt 11.879066 hw_loss 0.317650 lr 0.00046645 rank 0
2023-02-22 02:15:18,581 DEBUG TRAIN Batch 13/6600 loss 8.224924 loss_att 12.901085 loss_ctc 11.312082 loss_rnnt 6.671012 hw_loss 0.388235 lr 0.00046616 rank 2
2023-02-22 02:15:18,582 DEBUG TRAIN Batch 13/6600 loss 14.645910 loss_att 19.441895 loss_ctc 21.982235 loss_rnnt 12.589434 hw_loss 0.223317 lr 0.00046617 rank 3
2023-02-22 02:15:18,583 DEBUG TRAIN Batch 13/6600 loss 8.589512 loss_att 12.663734 loss_ctc 8.444456 loss_rnnt 7.651998 hw_loss 0.266269 lr 0.00046617 rank 6
2023-02-22 02:15:18,584 DEBUG TRAIN Batch 13/6600 loss 5.386402 loss_att 10.081762 loss_ctc 6.815449 loss_rnnt 4.217610 hw_loss 0.073463 lr 0.00046613 rank 7
2023-02-22 02:15:18,589 DEBUG TRAIN Batch 13/6600 loss 9.707390 loss_att 14.076908 loss_ctc 15.022959 loss_rnnt 7.975246 hw_loss 0.280307 lr 0.00046619 rank 5
2023-02-22 02:15:18,592 DEBUG TRAIN Batch 13/6600 loss 14.966479 loss_att 17.156347 loss_ctc 24.299301 loss_rnnt 13.193115 hw_loss 0.170653 lr 0.00046624 rank 0
2023-02-22 02:15:18,596 DEBUG TRAIN Batch 13/6600 loss 8.094766 loss_att 11.469409 loss_ctc 10.893847 loss_rnnt 6.933861 hw_loss 0.211435 lr 0.00046623 rank 1
2023-02-22 02:15:18,599 DEBUG TRAIN Batch 13/6600 loss 22.526823 loss_att 29.368999 loss_ctc 28.276339 loss_rnnt 20.271111 hw_loss 0.226265 lr 0.00046616 rank 4
2023-02-22 02:16:31,712 DEBUG TRAIN Batch 13/6700 loss 9.618662 loss_att 14.404291 loss_ctc 11.082153 loss_rnnt 8.356458 hw_loss 0.206148 lr 0.00046599 rank 5
2023-02-22 02:16:31,714 DEBUG TRAIN Batch 13/6700 loss 13.514545 loss_att 17.111465 loss_ctc 17.890953 loss_rnnt 12.091284 hw_loss 0.225671 lr 0.00046596 rank 4
2023-02-22 02:16:31,715 DEBUG TRAIN Batch 13/6700 loss 12.675976 loss_att 13.885566 loss_ctc 12.573101 loss_rnnt 12.351408 hw_loss 0.180687 lr 0.00046592 rank 7
2023-02-22 02:16:31,725 DEBUG TRAIN Batch 13/6700 loss 35.884548 loss_att 42.289436 loss_ctc 43.083092 loss_rnnt 33.481354 hw_loss 0.304518 lr 0.00046597 rank 6
2023-02-22 02:16:31,729 DEBUG TRAIN Batch 13/6700 loss 12.576718 loss_att 13.926363 loss_ctc 14.277890 loss_rnnt 11.954565 hw_loss 0.235131 lr 0.00046604 rank 0
2023-02-22 02:16:31,730 DEBUG TRAIN Batch 13/6700 loss 10.957854 loss_att 13.414316 loss_ctc 15.862564 loss_rnnt 9.581764 hw_loss 0.432818 lr 0.00046596 rank 2
2023-02-22 02:16:31,733 DEBUG TRAIN Batch 13/6700 loss 10.778692 loss_att 13.811827 loss_ctc 12.095551 loss_rnnt 9.858152 hw_loss 0.259371 lr 0.00046596 rank 3
2023-02-22 02:16:31,733 DEBUG TRAIN Batch 13/6700 loss 6.346925 loss_att 10.638186 loss_ctc 9.166786 loss_rnnt 4.993614 hw_loss 0.223270 lr 0.00046603 rank 1
2023-02-22 02:17:45,846 DEBUG TRAIN Batch 13/6800 loss 15.524627 loss_att 18.578339 loss_ctc 19.463753 loss_rnnt 14.245002 hw_loss 0.269375 lr 0.00046575 rank 2
2023-02-22 02:17:45,848 DEBUG TRAIN Batch 13/6800 loss 6.841977 loss_att 13.677362 loss_ctc 8.875997 loss_rnnt 5.088943 hw_loss 0.215162 lr 0.00046576 rank 3
2023-02-22 02:17:45,850 DEBUG TRAIN Batch 13/6800 loss 12.494932 loss_att 16.070225 loss_ctc 16.814730 loss_rnnt 11.064329 hw_loss 0.261698 lr 0.00046576 rank 4
2023-02-22 02:17:45,850 DEBUG TRAIN Batch 13/6800 loss 9.485291 loss_att 13.167562 loss_ctc 14.660280 loss_rnnt 7.936640 hw_loss 0.229122 lr 0.00046572 rank 7
2023-02-22 02:17:45,850 DEBUG TRAIN Batch 13/6800 loss 19.263472 loss_att 18.591791 loss_ctc 22.555943 loss_rnnt 18.824783 hw_loss 0.251303 lr 0.00046576 rank 6
2023-02-22 02:17:45,857 DEBUG TRAIN Batch 13/6800 loss 9.106486 loss_att 14.261625 loss_ctc 17.523830 loss_rnnt 6.809720 hw_loss 0.268923 lr 0.00046584 rank 0
2023-02-22 02:17:45,856 DEBUG TRAIN Batch 13/6800 loss 5.723053 loss_att 7.789632 loss_ctc 7.888098 loss_rnnt 4.867588 hw_loss 0.287768 lr 0.00046579 rank 5
2023-02-22 02:17:45,908 DEBUG TRAIN Batch 13/6800 loss 20.934263 loss_att 25.255468 loss_ctc 28.474504 loss_rnnt 18.935349 hw_loss 0.242453 lr 0.00046582 rank 1
2023-02-22 02:18:58,073 DEBUG TRAIN Batch 13/6900 loss 13.863319 loss_att 16.516977 loss_ctc 21.268412 loss_rnnt 12.212341 hw_loss 0.249189 lr 0.00046556 rank 3
2023-02-22 02:18:58,075 DEBUG TRAIN Batch 13/6900 loss 7.427533 loss_att 12.068046 loss_ctc 11.030354 loss_rnnt 5.816253 hw_loss 0.380253 lr 0.00046562 rank 1
2023-02-22 02:18:58,079 DEBUG TRAIN Batch 13/6900 loss 7.706795 loss_att 10.276992 loss_ctc 10.768338 loss_rnnt 6.649812 hw_loss 0.252634 lr 0.00046556 rank 6
2023-02-22 02:18:58,080 DEBUG TRAIN Batch 13/6900 loss 9.217958 loss_att 13.292931 loss_ctc 14.593701 loss_rnnt 7.522545 hw_loss 0.306850 lr 0.00046555 rank 2
2023-02-22 02:18:58,081 DEBUG TRAIN Batch 13/6900 loss 18.424990 loss_att 20.755751 loss_ctc 22.622410 loss_rnnt 17.190512 hw_loss 0.391256 lr 0.00046564 rank 0
2023-02-22 02:18:58,081 DEBUG TRAIN Batch 13/6900 loss 14.909669 loss_att 16.888912 loss_ctc 18.454472 loss_rnnt 13.869865 hw_loss 0.321213 lr 0.00046552 rank 7
2023-02-22 02:18:58,083 DEBUG TRAIN Batch 13/6900 loss 7.855609 loss_att 8.941109 loss_ctc 10.186160 loss_rnnt 7.201956 hw_loss 0.235899 lr 0.00046555 rank 4
2023-02-22 02:18:58,083 DEBUG TRAIN Batch 13/6900 loss 12.229040 loss_att 14.813720 loss_ctc 17.868258 loss_rnnt 10.767916 hw_loss 0.360545 lr 0.00046558 rank 5
2023-02-22 02:20:10,851 DEBUG TRAIN Batch 13/7000 loss 12.143063 loss_att 11.961746 loss_ctc 14.576807 loss_rnnt 11.711985 hw_loss 0.267828 lr 0.00046535 rank 2
2023-02-22 02:20:10,855 DEBUG TRAIN Batch 13/7000 loss 10.351514 loss_att 9.586432 loss_ctc 12.409900 loss_rnnt 9.932485 hw_loss 0.557987 lr 0.00046532 rank 7
2023-02-22 02:20:10,857 DEBUG TRAIN Batch 13/7000 loss 11.851982 loss_att 14.005224 loss_ctc 16.017242 loss_rnnt 10.558901 hw_loss 0.575747 lr 0.00046536 rank 3
2023-02-22 02:20:10,859 DEBUG TRAIN Batch 13/7000 loss 12.951805 loss_att 13.577645 loss_ctc 17.475275 loss_rnnt 12.156569 hw_loss 0.125511 lr 0.00046536 rank 6
2023-02-22 02:20:10,860 DEBUG TRAIN Batch 13/7000 loss 8.205139 loss_att 11.933172 loss_ctc 11.050856 loss_rnnt 7.006245 hw_loss 0.138485 lr 0.00046535 rank 4
2023-02-22 02:20:10,862 DEBUG TRAIN Batch 13/7000 loss 13.789141 loss_att 14.708427 loss_ctc 15.819150 loss_rnnt 13.142550 hw_loss 0.360123 lr 0.00046542 rank 1
2023-02-22 02:20:10,863 DEBUG TRAIN Batch 13/7000 loss 14.818594 loss_att 18.945887 loss_ctc 18.250301 loss_rnnt 13.490939 hw_loss 0.083691 lr 0.00046538 rank 5
2023-02-22 02:20:10,910 DEBUG TRAIN Batch 13/7000 loss 13.168930 loss_att 17.194389 loss_ctc 17.498842 loss_rnnt 11.612460 hw_loss 0.326355 lr 0.00046544 rank 0
2023-02-22 02:21:25,486 DEBUG TRAIN Batch 13/7100 loss 26.315083 loss_att 33.812836 loss_ctc 35.379894 loss_rnnt 23.470577 hw_loss 0.255589 lr 0.00046516 rank 6
2023-02-22 02:21:25,486 DEBUG TRAIN Batch 13/7100 loss 22.623276 loss_att 19.899971 loss_ctc 29.461531 loss_rnnt 22.043730 hw_loss 0.398322 lr 0.00046515 rank 2
2023-02-22 02:21:25,488 DEBUG TRAIN Batch 13/7100 loss 16.000380 loss_att 19.519934 loss_ctc 18.957228 loss_rnnt 14.838744 hw_loss 0.119022 lr 0.00046516 rank 3
2023-02-22 02:21:25,489 DEBUG TRAIN Batch 13/7100 loss 14.718648 loss_att 17.310123 loss_ctc 15.568843 loss_rnnt 13.933220 hw_loss 0.288325 lr 0.00046512 rank 7
2023-02-22 02:21:25,495 DEBUG TRAIN Batch 13/7100 loss 14.900729 loss_att 17.090008 loss_ctc 13.435546 loss_rnnt 14.508730 hw_loss 0.280312 lr 0.00046518 rank 5
2023-02-22 02:21:25,499 DEBUG TRAIN Batch 13/7100 loss 12.834611 loss_att 21.071129 loss_ctc 12.896482 loss_rnnt 11.067790 hw_loss 0.208629 lr 0.00046515 rank 4
2023-02-22 02:21:25,499 DEBUG TRAIN Batch 13/7100 loss 15.658015 loss_att 21.512964 loss_ctc 22.486069 loss_rnnt 13.501857 hw_loss 0.140179 lr 0.00046523 rank 0
2023-02-22 02:21:25,537 DEBUG TRAIN Batch 13/7100 loss 2.531128 loss_att 7.365334 loss_ctc 2.723989 loss_rnnt 1.454836 hw_loss 0.157006 lr 0.00046522 rank 1
2023-02-22 02:22:38,899 DEBUG TRAIN Batch 13/7200 loss 12.749006 loss_att 17.999094 loss_ctc 12.875259 loss_rnnt 11.590776 hw_loss 0.171333 lr 0.00046495 rank 3
2023-02-22 02:22:38,899 DEBUG TRAIN Batch 13/7200 loss 10.735107 loss_att 15.242203 loss_ctc 13.733443 loss_rnnt 9.320560 hw_loss 0.212530 lr 0.00046495 rank 2
2023-02-22 02:22:38,900 DEBUG TRAIN Batch 13/7200 loss 5.197424 loss_att 7.995615 loss_ctc 7.197236 loss_rnnt 4.263606 hw_loss 0.201634 lr 0.00046498 rank 5
2023-02-22 02:22:38,902 DEBUG TRAIN Batch 13/7200 loss 15.579895 loss_att 17.456852 loss_ctc 19.239113 loss_rnnt 14.621326 hw_loss 0.178652 lr 0.00046492 rank 7
2023-02-22 02:22:38,902 DEBUG TRAIN Batch 13/7200 loss 4.885476 loss_att 11.288131 loss_ctc 7.799016 loss_rnnt 2.961140 hw_loss 0.478749 lr 0.00046496 rank 6
2023-02-22 02:22:38,902 DEBUG TRAIN Batch 13/7200 loss 19.103090 loss_att 22.559263 loss_ctc 23.831356 loss_rnnt 17.707655 hw_loss 0.138311 lr 0.00046502 rank 1
2023-02-22 02:22:38,908 DEBUG TRAIN Batch 13/7200 loss 12.863861 loss_att 14.005020 loss_ctc 17.443792 loss_rnnt 11.889697 hw_loss 0.253643 lr 0.00046495 rank 4
2023-02-22 02:22:38,908 DEBUG TRAIN Batch 13/7200 loss 17.363293 loss_att 22.077118 loss_ctc 25.713566 loss_rnnt 15.171673 hw_loss 0.254035 lr 0.00046503 rank 0
2023-02-22 02:23:52,039 DEBUG TRAIN Batch 13/7300 loss 11.638591 loss_att 14.730776 loss_ctc 10.663339 loss_rnnt 10.975096 hw_loss 0.328297 lr 0.00046482 rank 1
2023-02-22 02:23:52,041 DEBUG TRAIN Batch 13/7300 loss 14.660857 loss_att 17.158585 loss_ctc 16.033651 loss_rnnt 13.839997 hw_loss 0.259266 lr 0.00046478 rank 5
2023-02-22 02:23:52,052 DEBUG TRAIN Batch 13/7300 loss 11.912426 loss_att 14.240498 loss_ctc 15.921719 loss_rnnt 10.852262 hw_loss 0.112457 lr 0.00046475 rank 3
2023-02-22 02:23:52,055 DEBUG TRAIN Batch 13/7300 loss 14.150436 loss_att 15.031699 loss_ctc 14.602629 loss_rnnt 13.797904 hw_loss 0.217477 lr 0.00046476 rank 6
2023-02-22 02:23:52,058 DEBUG TRAIN Batch 13/7300 loss 9.684547 loss_att 14.603237 loss_ctc 12.931140 loss_rnnt 8.079752 hw_loss 0.352833 lr 0.00046475 rank 2
2023-02-22 02:23:52,058 DEBUG TRAIN Batch 13/7300 loss 7.159678 loss_att 10.054269 loss_ctc 8.653020 loss_rnnt 6.207233 hw_loss 0.327027 lr 0.00046483 rank 0
2023-02-22 02:23:52,061 DEBUG TRAIN Batch 13/7300 loss 3.982332 loss_att 7.712160 loss_ctc 5.969525 loss_rnnt 2.895949 hw_loss 0.141483 lr 0.00046472 rank 7
2023-02-22 02:23:52,107 DEBUG TRAIN Batch 13/7300 loss 12.065422 loss_att 14.936046 loss_ctc 14.586382 loss_rnnt 10.979147 hw_loss 0.330043 lr 0.00046475 rank 4
2023-02-22 02:25:04,859 DEBUG TRAIN Batch 13/7400 loss 4.715029 loss_att 7.421748 loss_ctc 7.677042 loss_rnnt 3.656354 hw_loss 0.229493 lr 0.00046455 rank 2
2023-02-22 02:25:04,868 DEBUG TRAIN Batch 13/7400 loss 12.880194 loss_att 14.007367 loss_ctc 15.774645 loss_rnnt 12.196838 hw_loss 0.134988 lr 0.00046456 rank 6
2023-02-22 02:25:04,869 DEBUG TRAIN Batch 13/7400 loss 18.301453 loss_att 20.783646 loss_ctc 21.983303 loss_rnnt 17.168129 hw_loss 0.273694 lr 0.00046455 rank 3
2023-02-22 02:25:04,871 DEBUG TRAIN Batch 13/7400 loss 14.784678 loss_att 18.436674 loss_ctc 18.062090 loss_rnnt 13.416718 hw_loss 0.376071 lr 0.00046458 rank 5
2023-02-22 02:25:04,876 DEBUG TRAIN Batch 13/7400 loss 33.776131 loss_att 35.467896 loss_ctc 42.089397 loss_rnnt 32.174618 hw_loss 0.290111 lr 0.00046463 rank 0
2023-02-22 02:25:04,892 DEBUG TRAIN Batch 13/7400 loss 17.958902 loss_att 18.649626 loss_ctc 19.068918 loss_rnnt 17.563675 hw_loss 0.204524 lr 0.00046455 rank 4
2023-02-22 02:25:04,895 DEBUG TRAIN Batch 13/7400 loss 7.870680 loss_att 10.009686 loss_ctc 9.544287 loss_rnnt 7.086819 hw_loss 0.249211 lr 0.00046451 rank 7
2023-02-22 02:25:04,939 DEBUG TRAIN Batch 13/7400 loss 14.308187 loss_att 17.349255 loss_ctc 18.761242 loss_rnnt 12.986519 hw_loss 0.224464 lr 0.00046461 rank 1
2023-02-22 02:26:18,955 DEBUG TRAIN Batch 13/7500 loss 12.559664 loss_att 15.435051 loss_ctc 15.483668 loss_rnnt 11.378404 hw_loss 0.405591 lr 0.00046435 rank 2
2023-02-22 02:26:18,962 DEBUG TRAIN Batch 13/7500 loss 12.713151 loss_att 16.694813 loss_ctc 15.954748 loss_rnnt 11.401607 hw_loss 0.155624 lr 0.00046435 rank 3
2023-02-22 02:26:18,961 DEBUG TRAIN Batch 13/7500 loss 19.576803 loss_att 19.717150 loss_ctc 28.907022 loss_rnnt 18.159664 hw_loss 0.271948 lr 0.00046436 rank 6
2023-02-22 02:26:18,962 DEBUG TRAIN Batch 13/7500 loss 12.698957 loss_att 16.216228 loss_ctc 19.026133 loss_rnnt 10.959610 hw_loss 0.360505 lr 0.00046441 rank 1
2023-02-22 02:26:18,963 DEBUG TRAIN Batch 13/7500 loss 12.856985 loss_att 15.568672 loss_ctc 16.793175 loss_rnnt 11.644698 hw_loss 0.272108 lr 0.00046431 rank 7
2023-02-22 02:26:18,963 DEBUG TRAIN Batch 13/7500 loss 8.907506 loss_att 10.119377 loss_ctc 11.095142 loss_rnnt 8.226839 hw_loss 0.274889 lr 0.00046438 rank 5
2023-02-22 02:26:18,964 DEBUG TRAIN Batch 13/7500 loss 16.928007 loss_att 19.708996 loss_ctc 22.479267 loss_rnnt 15.512815 hw_loss 0.222804 lr 0.00046443 rank 0
2023-02-22 02:26:18,964 DEBUG TRAIN Batch 13/7500 loss 18.837351 loss_att 22.708961 loss_ctc 27.427418 loss_rnnt 16.797089 hw_loss 0.226123 lr 0.00046435 rank 4
2023-02-22 02:27:31,916 DEBUG TRAIN Batch 13/7600 loss 20.137098 loss_att 22.456562 loss_ctc 24.822767 loss_rnnt 18.868244 hw_loss 0.337887 lr 0.00046415 rank 4
2023-02-22 02:27:31,921 DEBUG TRAIN Batch 13/7600 loss 15.377964 loss_att 15.462950 loss_ctc 20.551435 loss_rnnt 14.486139 hw_loss 0.346933 lr 0.00046411 rank 7
2023-02-22 02:27:31,926 DEBUG TRAIN Batch 13/7600 loss 6.786658 loss_att 10.199303 loss_ctc 10.078434 loss_rnnt 5.529778 hw_loss 0.253963 lr 0.00046415 rank 2
2023-02-22 02:27:31,928 DEBUG TRAIN Batch 13/7600 loss 7.470499 loss_att 9.354031 loss_ctc 10.948862 loss_rnnt 6.382539 hw_loss 0.464008 lr 0.00046421 rank 1
2023-02-22 02:27:31,927 DEBUG TRAIN Batch 13/7600 loss 10.533109 loss_att 12.638405 loss_ctc 13.041574 loss_rnnt 9.636073 hw_loss 0.265340 lr 0.00046416 rank 6
2023-02-22 02:27:31,928 DEBUG TRAIN Batch 13/7600 loss 8.481119 loss_att 11.561201 loss_ctc 12.976401 loss_rnnt 7.174757 hw_loss 0.170579 lr 0.00046415 rank 3
2023-02-22 02:27:31,929 DEBUG TRAIN Batch 13/7600 loss 14.213247 loss_att 18.762630 loss_ctc 19.976505 loss_rnnt 12.413234 hw_loss 0.228192 lr 0.00046423 rank 0
2023-02-22 02:27:31,934 DEBUG TRAIN Batch 13/7600 loss 9.183647 loss_att 11.223137 loss_ctc 9.485403 loss_rnnt 8.661965 hw_loss 0.137907 lr 0.00046418 rank 5
2023-02-22 02:28:44,465 DEBUG TRAIN Batch 13/7700 loss 16.112446 loss_att 16.660795 loss_ctc 20.820288 loss_rnnt 15.258401 hw_loss 0.218743 lr 0.00046395 rank 2
2023-02-22 02:28:44,466 DEBUG TRAIN Batch 13/7700 loss 15.476771 loss_att 19.940292 loss_ctc 21.285307 loss_rnnt 13.647822 hw_loss 0.303326 lr 0.00046403 rank 0
2023-02-22 02:28:44,466 DEBUG TRAIN Batch 13/7700 loss 6.914104 loss_att 10.314727 loss_ctc 11.664892 loss_rnnt 5.523784 hw_loss 0.143919 lr 0.00046396 rank 6
2023-02-22 02:28:44,468 DEBUG TRAIN Batch 13/7700 loss 8.992323 loss_att 15.409275 loss_ctc 12.505522 loss_rnnt 7.127977 hw_loss 0.210992 lr 0.00046391 rank 7
2023-02-22 02:28:44,469 DEBUG TRAIN Batch 13/7700 loss 13.767127 loss_att 17.338486 loss_ctc 18.112173 loss_rnnt 12.342665 hw_loss 0.245347 lr 0.00046395 rank 4
2023-02-22 02:28:44,469 DEBUG TRAIN Batch 13/7700 loss 10.842906 loss_att 12.342549 loss_ctc 12.509453 loss_rnnt 10.176094 hw_loss 0.271270 lr 0.00046395 rank 3
2023-02-22 02:28:44,472 DEBUG TRAIN Batch 13/7700 loss 15.733587 loss_att 14.710461 loss_ctc 17.809322 loss_rnnt 15.308214 hw_loss 0.662313 lr 0.00046401 rank 1
2023-02-22 02:28:44,473 DEBUG TRAIN Batch 13/7700 loss 13.823448 loss_att 17.915024 loss_ctc 15.772895 loss_rnnt 12.656268 hw_loss 0.166760 lr 0.00046398 rank 5
2023-02-22 02:29:58,815 DEBUG TRAIN Batch 13/7800 loss 3.665612 loss_att 8.622421 loss_ctc 4.751976 loss_rnnt 2.346385 hw_loss 0.343156 lr 0.00046378 rank 5
2023-02-22 02:29:58,817 DEBUG TRAIN Batch 13/7800 loss 5.878465 loss_att 8.983282 loss_ctc 6.915831 loss_rnnt 4.998365 hw_loss 0.226539 lr 0.00046371 rank 7
2023-02-22 02:29:58,826 DEBUG TRAIN Batch 13/7800 loss 11.759965 loss_att 14.358244 loss_ctc 14.863620 loss_rnnt 10.699127 hw_loss 0.238802 lr 0.00046376 rank 6
2023-02-22 02:29:58,826 DEBUG TRAIN Batch 13/7800 loss 4.807215 loss_att 8.526047 loss_ctc 6.239327 loss_rnnt 3.766058 hw_loss 0.199580 lr 0.00046383 rank 0
2023-02-22 02:29:58,827 DEBUG TRAIN Batch 13/7800 loss 18.570631 loss_att 21.789257 loss_ctc 18.898769 loss_rnnt 17.693317 hw_loss 0.355944 lr 0.00046375 rank 2
2023-02-22 02:29:58,829 DEBUG TRAIN Batch 13/7800 loss 18.414051 loss_att 20.473467 loss_ctc 26.160854 loss_rnnt 16.874662 hw_loss 0.177374 lr 0.00046375 rank 4
2023-02-22 02:29:58,830 DEBUG TRAIN Batch 13/7800 loss 8.422097 loss_att 12.840372 loss_ctc 12.328101 loss_rnnt 6.942386 hw_loss 0.141104 lr 0.00046375 rank 3
2023-02-22 02:29:58,830 DEBUG TRAIN Batch 13/7800 loss 11.368989 loss_att 14.331831 loss_ctc 18.590797 loss_rnnt 9.637717 hw_loss 0.329619 lr 0.00046381 rank 1
2023-02-22 02:31:12,443 DEBUG TRAIN Batch 13/7900 loss 8.428890 loss_att 10.636774 loss_ctc 14.617587 loss_rnnt 7.040353 hw_loss 0.228377 lr 0.00046356 rank 6
2023-02-22 02:31:12,444 DEBUG TRAIN Batch 13/7900 loss 1.407634 loss_att 5.557569 loss_ctc 2.056317 loss_rnnt 0.426920 hw_loss 0.120442 lr 0.00046355 rank 2
2023-02-22 02:31:12,445 DEBUG TRAIN Batch 13/7900 loss 15.682391 loss_att 20.024578 loss_ctc 20.477631 loss_rnnt 13.990389 hw_loss 0.345372 lr 0.00046362 rank 1
2023-02-22 02:31:12,446 DEBUG TRAIN Batch 13/7900 loss 14.439546 loss_att 18.161793 loss_ctc 18.787167 loss_rnnt 12.970267 hw_loss 0.272151 lr 0.00046363 rank 0
2023-02-22 02:31:12,447 DEBUG TRAIN Batch 13/7900 loss 22.190960 loss_att 23.677326 loss_ctc 34.051590 loss_rnnt 20.106209 hw_loss 0.386361 lr 0.00046355 rank 3
2023-02-22 02:31:12,446 DEBUG TRAIN Batch 13/7900 loss 8.511161 loss_att 12.158148 loss_ctc 9.751817 loss_rnnt 7.445638 hw_loss 0.320072 lr 0.00046352 rank 7
2023-02-22 02:31:12,447 DEBUG TRAIN Batch 13/7900 loss 5.704875 loss_att 9.269320 loss_ctc 6.575439 loss_rnnt 4.759642 hw_loss 0.218004 lr 0.00046355 rank 4
2023-02-22 02:31:12,499 DEBUG TRAIN Batch 13/7900 loss 22.994194 loss_att 22.007156 loss_ctc 37.972939 loss_rnnt 21.106377 hw_loss 0.165112 lr 0.00046358 rank 5
2023-02-22 02:32:24,796 DEBUG TRAIN Batch 13/8000 loss 13.371051 loss_att 15.367552 loss_ctc 19.339834 loss_rnnt 12.005987 hw_loss 0.318610 lr 0.00046335 rank 2
2023-02-22 02:32:24,802 DEBUG TRAIN Batch 13/8000 loss 16.314148 loss_att 15.304426 loss_ctc 17.042374 loss_rnnt 16.296566 hw_loss 0.229555 lr 0.00046335 rank 4
2023-02-22 02:32:24,802 DEBUG TRAIN Batch 13/8000 loss 14.570148 loss_att 18.223791 loss_ctc 16.791639 loss_rnnt 13.463266 hw_loss 0.149910 lr 0.00046338 rank 5
2023-02-22 02:32:24,803 DEBUG TRAIN Batch 13/8000 loss 5.637774 loss_att 9.131746 loss_ctc 8.285350 loss_rnnt 4.418709 hw_loss 0.313612 lr 0.00046335 rank 3
2023-02-22 02:32:24,802 DEBUG TRAIN Batch 13/8000 loss 17.756907 loss_att 18.053347 loss_ctc 23.484840 loss_rnnt 16.814648 hw_loss 0.223584 lr 0.00046332 rank 7
2023-02-22 02:32:24,805 DEBUG TRAIN Batch 13/8000 loss 11.716395 loss_att 12.539901 loss_ctc 15.928316 loss_rnnt 10.777721 hw_loss 0.398219 lr 0.00046342 rank 1
2023-02-22 02:32:24,806 DEBUG TRAIN Batch 13/8000 loss 13.778105 loss_att 18.913244 loss_ctc 18.561598 loss_rnnt 12.007683 hw_loss 0.197989 lr 0.00046336 rank 6
2023-02-22 02:32:24,809 DEBUG TRAIN Batch 13/8000 loss 33.465786 loss_att 32.290573 loss_ctc 39.947201 loss_rnnt 32.721775 hw_loss 0.215371 lr 0.00046343 rank 0
2023-02-22 02:33:38,121 DEBUG TRAIN Batch 13/8100 loss 13.006014 loss_att 16.712847 loss_ctc 19.671761 loss_rnnt 11.239243 hw_loss 0.256194 lr 0.00046312 rank 7
2023-02-22 02:33:38,132 DEBUG TRAIN Batch 13/8100 loss 10.725680 loss_att 12.290849 loss_ctc 13.732610 loss_rnnt 9.860535 hw_loss 0.283481 lr 0.00046318 rank 5
2023-02-22 02:33:38,135 DEBUG TRAIN Batch 13/8100 loss 21.845905 loss_att 30.032501 loss_ctc 27.912741 loss_rnnt 19.241333 hw_loss 0.296889 lr 0.00046316 rank 3
2023-02-22 02:33:38,139 DEBUG TRAIN Batch 13/8100 loss 8.808002 loss_att 10.572493 loss_ctc 13.672216 loss_rnnt 7.635255 hw_loss 0.321165 lr 0.00046316 rank 6
2023-02-22 02:33:38,139 DEBUG TRAIN Batch 13/8100 loss 9.010224 loss_att 13.062056 loss_ctc 12.933904 loss_rnnt 7.574892 hw_loss 0.190893 lr 0.00046315 rank 2
2023-02-22 02:33:38,142 DEBUG TRAIN Batch 13/8100 loss 15.115594 loss_att 16.461449 loss_ctc 21.166124 loss_rnnt 13.913025 hw_loss 0.237489 lr 0.00046323 rank 0
2023-02-22 02:33:38,149 DEBUG TRAIN Batch 13/8100 loss 7.438736 loss_att 11.037428 loss_ctc 9.458405 loss_rnnt 6.318686 hw_loss 0.245667 lr 0.00046322 rank 1
2023-02-22 02:33:38,168 DEBUG TRAIN Batch 13/8100 loss 16.870201 loss_att 18.877590 loss_ctc 20.209743 loss_rnnt 15.947823 hw_loss 0.141802 lr 0.00046315 rank 4
2023-02-22 02:34:51,746 DEBUG TRAIN Batch 13/8200 loss 22.659494 loss_att 27.841835 loss_ctc 28.079147 loss_rnnt 20.679184 hw_loss 0.414789 lr 0.00046298 rank 5
2023-02-22 02:34:51,759 DEBUG TRAIN Batch 13/8200 loss 10.959977 loss_att 12.721422 loss_ctc 13.189120 loss_rnnt 10.176715 hw_loss 0.250789 lr 0.00046296 rank 3
2023-02-22 02:34:51,760 DEBUG TRAIN Batch 13/8200 loss 9.937054 loss_att 14.362190 loss_ctc 12.081568 loss_rnnt 8.559100 hw_loss 0.388110 lr 0.00046295 rank 2
2023-02-22 02:34:51,761 DEBUG TRAIN Batch 13/8200 loss 15.327388 loss_att 17.139332 loss_ctc 18.802509 loss_rnnt 14.352869 hw_loss 0.278961 lr 0.00046295 rank 4
2023-02-22 02:34:51,767 DEBUG TRAIN Batch 13/8200 loss 13.144054 loss_att 17.531282 loss_ctc 18.807798 loss_rnnt 11.337940 hw_loss 0.325317 lr 0.00046296 rank 6
2023-02-22 02:34:51,769 DEBUG TRAIN Batch 13/8200 loss 15.086946 loss_att 20.422493 loss_ctc 19.358994 loss_rnnt 13.234837 hw_loss 0.403859 lr 0.00046303 rank 0
2023-02-22 02:34:51,774 DEBUG TRAIN Batch 13/8200 loss 12.572170 loss_att 15.328968 loss_ctc 13.197907 loss_rnnt 11.802995 hw_loss 0.251969 lr 0.00046292 rank 7
2023-02-22 02:34:51,817 DEBUG TRAIN Batch 13/8200 loss 11.757447 loss_att 13.827258 loss_ctc 13.889700 loss_rnnt 10.871981 hw_loss 0.351004 lr 0.00046302 rank 1
2023-02-22 02:36:04,491 DEBUG TRAIN Batch 13/8300 loss 15.086726 loss_att 18.344810 loss_ctc 20.227760 loss_rnnt 13.560286 hw_loss 0.355040 lr 0.00046276 rank 3
2023-02-22 02:36:04,498 DEBUG TRAIN Batch 13/8300 loss 8.332427 loss_att 12.010858 loss_ctc 8.772440 loss_rnnt 7.391975 hw_loss 0.273932 lr 0.00046275 rank 2
2023-02-22 02:36:04,499 DEBUG TRAIN Batch 13/8300 loss 11.297905 loss_att 14.205513 loss_ctc 16.002142 loss_rnnt 9.912699 hw_loss 0.330849 lr 0.00046282 rank 1
2023-02-22 02:36:04,499 DEBUG TRAIN Batch 13/8300 loss 11.545971 loss_att 14.726851 loss_ctc 17.162069 loss_rnnt 10.075235 hw_loss 0.160774 lr 0.00046276 rank 6
2023-02-22 02:36:04,500 DEBUG TRAIN Batch 13/8300 loss 9.649793 loss_att 10.152429 loss_ctc 12.151747 loss_rnnt 9.041357 hw_loss 0.326841 lr 0.00046275 rank 4
2023-02-22 02:36:04,503 DEBUG TRAIN Batch 13/8300 loss 24.530842 loss_att 26.726261 loss_ctc 36.013153 loss_rnnt 22.354408 hw_loss 0.386955 lr 0.00046272 rank 7
2023-02-22 02:36:04,506 DEBUG TRAIN Batch 13/8300 loss 10.324477 loss_att 13.318177 loss_ctc 13.914413 loss_rnnt 9.171751 hw_loss 0.141241 lr 0.00046284 rank 0
2023-02-22 02:36:04,513 DEBUG TRAIN Batch 13/8300 loss 11.598896 loss_att 15.720092 loss_ctc 13.116633 loss_rnnt 10.533351 hw_loss 0.073014 lr 0.00046278 rank 5
2023-02-22 02:36:53,307 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 3
2023-02-22 02:36:53,309 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 1
2023-02-22 02:36:53,312 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 4
2023-02-22 02:36:53,315 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 5
2023-02-22 02:36:53,318 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 2
2023-02-22 02:36:53,319 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 6
2023-02-22 02:36:53,323 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 7
2023-02-22 02:36:53,335 DEBUG CV Batch 13/0 loss 2.452857 loss_att 2.262164 loss_ctc 3.060246 loss_rnnt 1.964688 hw_loss 0.834980 history loss 2.362010 rank 0
2023-02-22 02:37:04,742 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 1
2023-02-22 02:37:04,755 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 7
2023-02-22 02:37:04,759 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 0
2023-02-22 02:37:04,785 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 2
2023-02-22 02:37:04,793 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 3
2023-02-22 02:37:04,864 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 5
2023-02-22 02:37:04,926 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 4
2023-02-22 02:37:04,971 DEBUG CV Batch 13/100 loss 8.980665 loss_att 10.301188 loss_ctc 13.025238 loss_rnnt 8.037504 hw_loss 0.262087 history loss 4.430058 rank 6
2023-02-22 02:37:18,168 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 7
2023-02-22 02:37:18,229 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 1
2023-02-22 02:37:18,375 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 0
2023-02-22 02:37:18,422 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 3
2023-02-22 02:37:18,429 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 2
2023-02-22 02:37:18,440 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 5
2023-02-22 02:37:18,449 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 4
2023-02-22 02:37:18,615 DEBUG CV Batch 13/200 loss 10.507426 loss_att 16.766747 loss_ctc 14.377674 loss_rnnt 8.597740 hw_loss 0.265853 history loss 4.989696 rank 6
2023-02-22 02:37:30,185 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 1
2023-02-22 02:37:30,369 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 7
2023-02-22 02:37:30,579 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 4
2023-02-22 02:37:30,605 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 5
2023-02-22 02:37:30,868 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 3
2023-02-22 02:37:30,879 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 2
2023-02-22 02:37:31,092 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 6
2023-02-22 02:37:31,132 DEBUG CV Batch 13/300 loss 5.656980 loss_att 6.318860 loss_ctc 8.187687 loss_rnnt 5.025674 hw_loss 0.302816 history loss 5.171470 rank 0
2023-02-22 02:37:42,378 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 1
2023-02-22 02:37:42,731 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 7
2023-02-22 02:37:42,827 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 4
2023-02-22 02:37:42,897 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 5
2023-02-22 02:37:43,212 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 3
2023-02-22 02:37:43,247 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 2
2023-02-22 02:37:43,499 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 6
2023-02-22 02:37:43,960 DEBUG CV Batch 13/400 loss 21.360662 loss_att 95.108856 loss_ctc 6.638512 loss_rnnt 8.493670 hw_loss 0.150577 history loss 6.307978 rank 0
2023-02-22 02:37:53,050 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 1
2023-02-22 02:37:53,604 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 4
2023-02-22 02:37:53,748 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 5
2023-02-22 02:37:54,093 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 7
2023-02-22 02:37:54,144 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 3
2023-02-22 02:37:54,195 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 2
2023-02-22 02:37:54,578 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 6
2023-02-22 02:37:55,222 DEBUG CV Batch 13/500 loss 5.874019 loss_att 7.395461 loss_ctc 8.301167 loss_rnnt 5.126385 hw_loss 0.224485 history loss 7.280588 rank 0
2023-02-22 02:38:05,611 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 1
2023-02-22 02:38:05,806 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 4
2023-02-22 02:38:05,946 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 5
2023-02-22 02:38:06,390 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 7
2023-02-22 02:38:06,499 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 3
2023-02-22 02:38:06,571 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 2
2023-02-22 02:38:06,983 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 6
2023-02-22 02:38:07,810 DEBUG CV Batch 13/600 loss 9.377536 loss_att 8.952003 loss_ctc 11.271671 loss_rnnt 8.909899 hw_loss 0.562860 history loss 8.271354 rank 0
2023-02-22 02:38:17,123 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 1
2023-02-22 02:38:17,344 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 5
2023-02-22 02:38:17,477 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 4
2023-02-22 02:38:17,918 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 7
2023-02-22 02:38:18,306 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 2
2023-02-22 02:38:18,350 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 3
2023-02-22 02:38:18,633 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 6
2023-02-22 02:38:19,782 DEBUG CV Batch 13/700 loss 22.955147 loss_att 49.672318 loss_ctc 26.208004 loss_rnnt 17.091970 hw_loss 0.161306 history loss 9.088495 rank 0
2023-02-22 02:38:28,659 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 1
2023-02-22 02:38:28,821 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 5
2023-02-22 02:38:28,826 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 4
2023-02-22 02:38:29,575 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 7
2023-02-22 02:38:29,897 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 2
2023-02-22 02:38:29,924 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 3
2023-02-22 02:38:30,188 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 6
2023-02-22 02:38:31,774 DEBUG CV Batch 13/800 loss 13.637023 loss_att 13.399262 loss_ctc 18.292938 loss_rnnt 12.924006 hw_loss 0.262087 history loss 8.466810 rank 0
2023-02-22 02:38:42,120 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 1
2023-02-22 02:38:42,208 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 4
2023-02-22 02:38:42,384 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 5
2023-02-22 02:38:43,055 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 7
2023-02-22 02:38:43,435 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 2
2023-02-22 02:38:43,539 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 3
2023-02-22 02:38:43,719 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 6
2023-02-22 02:38:45,591 DEBUG CV Batch 13/900 loss 18.052414 loss_att 23.791718 loss_ctc 24.431616 loss_rnnt 15.942922 hw_loss 0.208261 history loss 8.209211 rank 0
2023-02-22 02:38:54,485 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 1
2023-02-22 02:38:54,547 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 4
2023-02-22 02:38:54,702 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 5
2023-02-22 02:38:55,606 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 7
2023-02-22 02:38:55,826 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 2
2023-02-22 02:38:55,923 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 3
2023-02-22 02:38:56,144 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 6
2023-02-22 02:38:58,656 DEBUG CV Batch 13/1000 loss 4.027863 loss_att 5.474242 loss_ctc 5.494055 loss_rnnt 3.398831 hw_loss 0.270495 history loss 7.937504 rank 0
2023-02-22 02:39:06,465 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907026 rank 4
2023-02-22 02:39:06,655 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907027 rank 1
2023-02-22 02:39:06,850 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907026 rank 5
2023-02-22 02:39:07,781 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907026 rank 7
2023-02-22 02:39:08,062 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907026 rank 2
2023-02-22 02:39:08,138 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907026 rank 3
2023-02-22 02:39:08,350 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907026 rank 6
2023-02-22 02:39:11,295 DEBUG CV Batch 13/1100 loss 7.370462 loss_att 6.504265 loss_ctc 8.931038 loss_rnnt 6.938323 hw_loss 0.744940 history loss 7.907026 rank 0
2023-02-22 02:39:17,292 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 4
2023-02-22 02:39:17,338 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 1
2023-02-22 02:39:17,578 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 5
2023-02-22 02:39:18,707 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 7
2023-02-22 02:39:18,997 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 2
2023-02-22 02:39:19,127 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 3
2023-02-22 02:39:19,250 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 6
2023-02-22 02:39:22,695 DEBUG CV Batch 13/1200 loss 8.507012 loss_att 10.937724 loss_ctc 9.560571 loss_rnnt 7.737508 hw_loss 0.267912 history loss 8.333306 rank 0
2023-02-22 02:39:29,422 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 4
2023-02-22 02:39:29,459 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 1
2023-02-22 02:39:29,725 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 5
2023-02-22 02:39:31,120 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 7
2023-02-22 02:39:31,330 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 2
2023-02-22 02:39:31,367 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 3
2023-02-22 02:39:31,590 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 6
2023-02-22 02:39:35,211 DEBUG CV Batch 13/1300 loss 7.415657 loss_att 6.781653 loss_ctc 8.935575 loss_rnnt 7.110290 hw_loss 0.430335 history loss 8.645029 rank 0
2023-02-22 02:39:40,697 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 4
2023-02-22 02:39:41,014 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 5
2023-02-22 02:39:41,029 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 1
2023-02-22 02:39:42,643 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 7
2023-02-22 02:39:42,907 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 2
2023-02-22 02:39:42,928 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 3
2023-02-22 02:39:43,257 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 6
2023-02-22 02:39:46,849 DEBUG CV Batch 13/1400 loss 11.005255 loss_att 34.303123 loss_ctc 6.064179 loss_rnnt 6.799197 hw_loss 0.384926 history loss 9.042499 rank 0
2023-02-22 02:39:52,274 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 4
2023-02-22 02:39:52,538 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 1
2023-02-22 02:39:52,668 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 5
2023-02-22 02:39:54,485 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 7
2023-02-22 02:39:54,761 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 3
2023-02-22 02:39:54,809 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 2
2023-02-22 02:39:54,987 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 6
2023-02-22 02:39:59,022 DEBUG CV Batch 13/1500 loss 8.356819 loss_att 10.313116 loss_ctc 7.854553 loss_rnnt 7.894313 hw_loss 0.259153 history loss 8.837169 rank 0
2023-02-22 02:40:05,327 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 4
2023-02-22 02:40:05,744 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 5
2023-02-22 02:40:05,954 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 1
2023-02-22 02:40:07,876 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 7
2023-02-22 02:40:08,065 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 3
2023-02-22 02:40:08,170 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 2
2023-02-22 02:40:08,291 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 6
2023-02-22 02:40:12,586 DEBUG CV Batch 13/1600 loss 12.652849 loss_att 15.497448 loss_ctc 15.654140 loss_rnnt 11.476452 hw_loss 0.388696 history loss 8.736065 rank 0
2023-02-22 02:40:17,775 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 4
2023-02-22 02:40:18,151 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 5
2023-02-22 02:40:18,409 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 1
2023-02-22 02:40:20,514 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 7
2023-02-22 02:40:20,607 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 3
2023-02-22 02:40:20,675 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 2
2023-02-22 02:40:20,920 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 6
2023-02-22 02:40:25,105 DEBUG CV Batch 13/1700 loss 10.191401 loss_att 10.074729 loss_ctc 14.583433 loss_rnnt 9.496273 hw_loss 0.249107 history loss 8.614379 rank 0
2023-02-22 02:40:26,820 INFO Epoch 13 CV info cv_loss 8.558186915193374
2023-02-22 02:40:26,820 INFO Epoch 14 TRAIN info lr 0.00046268339054285037
2023-02-22 02:40:26,822 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:40:27,265 INFO Epoch 13 CV info cv_loss 8.558186916252973
2023-02-22 02:40:27,266 INFO Epoch 14 TRAIN info lr 0.00046267348592365573
2023-02-22 02:40:27,271 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:40:27,430 INFO Epoch 13 CV info cv_loss 8.55818691648557
2023-02-22 02:40:27,431 INFO Epoch 14 TRAIN info lr 0.000462766614464837
2023-02-22 02:40:27,436 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:40:29,618 INFO Epoch 13 CV info cv_loss 8.558186914900476
2023-02-22 02:40:29,619 INFO Epoch 14 TRAIN info lr 0.0004626239723671385
2023-02-22 02:40:29,624 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:40:29,730 INFO Epoch 13 CV info cv_loss 8.55818691364274
2023-02-22 02:40:29,730 INFO Epoch 14 TRAIN info lr 0.00046268140956812377
2023-02-22 02:40:29,735 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:40:29,796 INFO Epoch 13 CV info cv_loss 8.558186914710955
2023-02-22 02:40:29,796 INFO Epoch 14 TRAIN info lr 0.00046269923925672496
2023-02-22 02:40:29,798 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:40:30,026 INFO Epoch 13 CV info cv_loss 8.558186916011763
2023-02-22 02:40:30,026 INFO Epoch 14 TRAIN info lr 0.00046270320168967534
2023-02-22 02:40:30,031 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:40:34,659 INFO Epoch 13 CV info cv_loss 8.558186913832262
2023-02-22 02:40:34,659 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/13.pt
2023-02-22 02:40:35,241 INFO Epoch 14 TRAIN info lr 0.00046271905243953454
2023-02-22 02:40:35,244 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 02:41:35,139 DEBUG TRAIN Batch 14/0 loss 11.852334 loss_att 11.092166 loss_ctc 14.181053 loss_rnnt 11.435384 hw_loss 0.484664 lr 0.00046268 rank 3
2023-02-22 02:41:35,140 DEBUG TRAIN Batch 14/0 loss 13.532816 loss_att 12.297232 loss_ctc 16.885715 loss_rnnt 13.032971 hw_loss 0.562328 lr 0.00046262 rank 7
2023-02-22 02:41:35,147 DEBUG TRAIN Batch 14/0 loss 10.862163 loss_att 9.054212 loss_ctc 12.596787 loss_rnnt 10.596461 hw_loss 0.742517 lr 0.00046276 rank 1
2023-02-22 02:41:35,149 DEBUG TRAIN Batch 14/0 loss 11.238707 loss_att 11.001646 loss_ctc 13.726123 loss_rnnt 10.618792 hw_loss 0.629385 lr 0.00046267 rank 5
2023-02-22 02:41:35,150 DEBUG TRAIN Batch 14/0 loss 7.829522 loss_att 7.461816 loss_ctc 9.674484 loss_rnnt 7.382705 hw_loss 0.514429 lr 0.00046270 rank 6
2023-02-22 02:41:35,150 DEBUG TRAIN Batch 14/0 loss 9.991425 loss_att 8.899998 loss_ctc 13.047338 loss_rnnt 9.409239 hw_loss 0.736905 lr 0.00046268 rank 4
2023-02-22 02:41:35,153 DEBUG TRAIN Batch 14/0 loss 11.249459 loss_att 10.162155 loss_ctc 12.361617 loss_rnnt 10.931331 hw_loss 0.726191 lr 0.00046270 rank 2
2023-02-22 02:41:35,176 DEBUG TRAIN Batch 14/0 loss 9.745825 loss_att 9.577691 loss_ctc 12.136182 loss_rnnt 9.126767 hw_loss 0.626192 lr 0.00046272 rank 0
2023-02-22 02:42:46,066 DEBUG TRAIN Batch 14/100 loss 10.643146 loss_att 10.922279 loss_ctc 9.163622 loss_rnnt 10.645322 hw_loss 0.261125 lr 0.00046250 rank 6
2023-02-22 02:42:46,067 DEBUG TRAIN Batch 14/100 loss 16.316313 loss_att 18.240932 loss_ctc 23.295637 loss_rnnt 14.868251 hw_loss 0.248550 lr 0.00046250 rank 2
2023-02-22 02:42:46,068 DEBUG TRAIN Batch 14/100 loss 10.741408 loss_att 13.587120 loss_ctc 13.282187 loss_rnnt 9.723247 hw_loss 0.206718 lr 0.00046248 rank 4
2023-02-22 02:42:46,068 DEBUG TRAIN Batch 14/100 loss 8.515716 loss_att 11.560459 loss_ctc 11.845695 loss_rnnt 7.371412 hw_loss 0.171296 lr 0.00046248 rank 3
2023-02-22 02:42:46,069 DEBUG TRAIN Batch 14/100 loss 14.789314 loss_att 17.681631 loss_ctc 18.505512 loss_rnnt 13.507492 hw_loss 0.389748 lr 0.00046257 rank 1
2023-02-22 02:42:46,072 DEBUG TRAIN Batch 14/100 loss 20.900997 loss_att 25.856388 loss_ctc 26.567389 loss_rnnt 18.987503 hw_loss 0.312935 lr 0.00046252 rank 0
2023-02-22 02:42:46,073 DEBUG TRAIN Batch 14/100 loss 14.409154 loss_att 17.234493 loss_ctc 15.675797 loss_rnnt 13.456594 hw_loss 0.409887 lr 0.00046242 rank 7
2023-02-22 02:42:46,074 DEBUG TRAIN Batch 14/100 loss 16.971064 loss_att 17.915161 loss_ctc 18.904552 loss_rnnt 16.305677 hw_loss 0.410188 lr 0.00046247 rank 5
2023-02-22 02:43:57,745 DEBUG TRAIN Batch 14/200 loss 10.458247 loss_att 17.822617 loss_ctc 12.924776 loss_rnnt 8.530317 hw_loss 0.236597 lr 0.00046230 rank 2
2023-02-22 02:43:57,748 DEBUG TRAIN Batch 14/200 loss 13.049623 loss_att 13.456909 loss_ctc 13.815776 loss_rnnt 12.724208 hw_loss 0.265882 lr 0.00046223 rank 7
2023-02-22 02:43:57,751 DEBUG TRAIN Batch 14/200 loss 16.050547 loss_att 17.421650 loss_ctc 16.782726 loss_rnnt 15.569489 hw_loss 0.204774 lr 0.00046231 rank 6
2023-02-22 02:43:57,753 DEBUG TRAIN Batch 14/200 loss 18.725603 loss_att 22.125961 loss_ctc 20.194813 loss_rnnt 17.642328 hw_loss 0.388703 lr 0.00046228 rank 3
2023-02-22 02:43:57,755 DEBUG TRAIN Batch 14/200 loss 22.584726 loss_att 27.423952 loss_ctc 30.845482 loss_rnnt 20.397635 hw_loss 0.220893 lr 0.00046229 rank 4
2023-02-22 02:43:57,758 DEBUG TRAIN Batch 14/200 loss 18.618927 loss_att 22.398054 loss_ctc 24.775679 loss_rnnt 16.976400 hw_loss 0.123379 lr 0.00046228 rank 5
2023-02-22 02:43:57,760 DEBUG TRAIN Batch 14/200 loss 9.148301 loss_att 12.750124 loss_ctc 10.043093 loss_rnnt 8.111186 hw_loss 0.370210 lr 0.00046237 rank 1
2023-02-22 02:43:57,760 DEBUG TRAIN Batch 14/200 loss 14.591585 loss_att 17.788614 loss_ctc 17.664108 loss_rnnt 13.430017 hw_loss 0.210921 lr 0.00046232 rank 0
2023-02-22 02:45:11,669 DEBUG TRAIN Batch 14/300 loss 12.632793 loss_att 17.035172 loss_ctc 14.718846 loss_rnnt 11.293659 hw_loss 0.338470 lr 0.00046209 rank 3
2023-02-22 02:45:11,669 DEBUG TRAIN Batch 14/300 loss 8.980913 loss_att 15.190213 loss_ctc 12.569832 loss_rnnt 7.052831 hw_loss 0.389437 lr 0.00046209 rank 4
2023-02-22 02:45:11,680 DEBUG TRAIN Batch 14/300 loss 24.029575 loss_att 27.653566 loss_ctc 31.700956 loss_rnnt 22.040623 hw_loss 0.452441 lr 0.00046210 rank 2
2023-02-22 02:45:11,684 DEBUG TRAIN Batch 14/300 loss 14.559071 loss_att 20.765427 loss_ctc 17.708344 loss_rnnt 12.710559 hw_loss 0.351260 lr 0.00046208 rank 5
2023-02-22 02:45:11,684 DEBUG TRAIN Batch 14/300 loss 7.665039 loss_att 12.702784 loss_ctc 12.176093 loss_rnnt 5.905670 hw_loss 0.281899 lr 0.00046203 rank 7
2023-02-22 02:45:11,687 DEBUG TRAIN Batch 14/300 loss 7.170375 loss_att 8.744411 loss_ctc 8.693367 loss_rnnt 6.536355 hw_loss 0.217777 lr 0.00046211 rank 6
2023-02-22 02:45:11,717 DEBUG TRAIN Batch 14/300 loss 10.135970 loss_att 16.753843 loss_ctc 14.359077 loss_rnnt 8.110972 hw_loss 0.259392 lr 0.00046217 rank 1
2023-02-22 02:45:11,720 DEBUG TRAIN Batch 14/300 loss 8.681087 loss_att 15.649113 loss_ctc 11.426756 loss_rnnt 6.764403 hw_loss 0.294357 lr 0.00046212 rank 0
2023-02-22 02:46:25,245 DEBUG TRAIN Batch 14/400 loss 12.883470 loss_att 18.148533 loss_ctc 18.160439 loss_rnnt 11.043594 hw_loss 0.156125 lr 0.00046191 rank 2
2023-02-22 02:46:25,249 DEBUG TRAIN Batch 14/400 loss 10.474995 loss_att 13.646940 loss_ctc 13.912786 loss_rnnt 9.263603 hw_loss 0.222432 lr 0.00046189 rank 3
2023-02-22 02:46:25,250 DEBUG TRAIN Batch 14/400 loss 14.827015 loss_att 19.682535 loss_ctc 17.544014 loss_rnnt 13.409268 hw_loss 0.158205 lr 0.00046197 rank 1
2023-02-22 02:46:25,250 DEBUG TRAIN Batch 14/400 loss 8.021974 loss_att 11.117455 loss_ctc 8.283846 loss_rnnt 7.263072 hw_loss 0.196669 lr 0.00046191 rank 6
2023-02-22 02:46:25,255 DEBUG TRAIN Batch 14/400 loss 8.289449 loss_att 10.122330 loss_ctc 10.627429 loss_rnnt 7.431056 hw_loss 0.337660 lr 0.00046193 rank 0
2023-02-22 02:46:25,256 DEBUG TRAIN Batch 14/400 loss 8.355292 loss_att 12.464640 loss_ctc 12.155559 loss_rnnt 6.889160 hw_loss 0.257929 lr 0.00046183 rank 7
2023-02-22 02:46:25,255 DEBUG TRAIN Batch 14/400 loss 8.543951 loss_att 11.066434 loss_ctc 8.858254 loss_rnnt 7.914825 hw_loss 0.155102 lr 0.00046188 rank 5
2023-02-22 02:46:25,306 DEBUG TRAIN Batch 14/400 loss 16.251390 loss_att 17.647429 loss_ctc 22.439510 loss_rnnt 14.942764 hw_loss 0.383129 lr 0.00046189 rank 4
2023-02-22 02:47:37,581 DEBUG TRAIN Batch 14/500 loss 14.389781 loss_att 15.667125 loss_ctc 21.048960 loss_rnnt 13.105263 hw_loss 0.264672 lr 0.00046171 rank 2
2023-02-22 02:47:37,584 DEBUG TRAIN Batch 14/500 loss 15.576852 loss_att 16.509338 loss_ctc 16.604202 loss_rnnt 15.112997 hw_loss 0.263208 lr 0.00046169 rank 3
2023-02-22 02:47:37,589 DEBUG TRAIN Batch 14/500 loss 12.250759 loss_att 14.286175 loss_ctc 16.654900 loss_rnnt 11.078148 hw_loss 0.334330 lr 0.00046178 rank 1
2023-02-22 02:47:37,590 DEBUG TRAIN Batch 14/500 loss 16.145658 loss_att 20.835810 loss_ctc 20.445312 loss_rnnt 14.536221 hw_loss 0.183974 lr 0.00046173 rank 0
2023-02-22 02:47:37,591 DEBUG TRAIN Batch 14/500 loss 11.399770 loss_att 13.735029 loss_ctc 14.709549 loss_rnnt 10.395767 hw_loss 0.179337 lr 0.00046171 rank 6
2023-02-22 02:47:37,595 DEBUG TRAIN Batch 14/500 loss 5.962302 loss_att 9.151666 loss_ctc 8.319399 loss_rnnt 4.843297 hw_loss 0.312848 lr 0.00046164 rank 7
2023-02-22 02:47:37,595 DEBUG TRAIN Batch 14/500 loss 12.995725 loss_att 13.540562 loss_ctc 17.110107 loss_rnnt 12.159285 hw_loss 0.335416 lr 0.00046169 rank 4
2023-02-22 02:47:37,596 DEBUG TRAIN Batch 14/500 loss 9.945507 loss_att 13.916629 loss_ctc 16.201193 loss_rnnt 8.111609 hw_loss 0.385467 lr 0.00046168 rank 5
2023-02-22 02:48:50,666 DEBUG TRAIN Batch 14/600 loss 11.728129 loss_att 12.288507 loss_ctc 16.251982 loss_rnnt 10.862067 hw_loss 0.282761 lr 0.00046150 rank 3
2023-02-22 02:48:50,669 DEBUG TRAIN Batch 14/600 loss 15.260789 loss_att 15.239383 loss_ctc 17.758711 loss_rnnt 14.708362 hw_loss 0.419347 lr 0.00046151 rank 2
2023-02-22 02:48:50,678 DEBUG TRAIN Batch 14/600 loss 11.351705 loss_att 12.093761 loss_ctc 14.144427 loss_rnnt 10.563013 hw_loss 0.502345 lr 0.00046150 rank 4
2023-02-22 02:48:50,677 DEBUG TRAIN Batch 14/600 loss 11.107949 loss_att 29.892574 loss_ctc 13.605534 loss_rnnt 6.847928 hw_loss 0.318911 lr 0.00046152 rank 6
2023-02-22 02:48:50,681 DEBUG TRAIN Batch 14/600 loss 11.594600 loss_att 16.511665 loss_ctc 11.955795 loss_rnnt 10.481871 hw_loss 0.152172 lr 0.00046149 rank 5
2023-02-22 02:48:50,681 DEBUG TRAIN Batch 14/600 loss 9.652806 loss_att 10.231702 loss_ctc 11.952724 loss_rnnt 8.983330 hw_loss 0.463202 lr 0.00046153 rank 0
2023-02-22 02:48:50,681 DEBUG TRAIN Batch 14/600 loss 5.099019 loss_att 5.096561 loss_ctc 6.247219 loss_rnnt 4.705873 hw_loss 0.451020 lr 0.00046144 rank 7
2023-02-22 02:48:50,683 DEBUG TRAIN Batch 14/600 loss 14.391000 loss_att 13.943344 loss_ctc 18.514860 loss_rnnt 13.779786 hw_loss 0.282930 lr 0.00046158 rank 1
2023-02-22 02:50:05,336 DEBUG TRAIN Batch 14/700 loss 13.763554 loss_att 21.218157 loss_ctc 19.998827 loss_rnnt 11.331329 hw_loss 0.206125 lr 0.00046132 rank 6
2023-02-22 02:50:05,339 DEBUG TRAIN Batch 14/700 loss 11.207724 loss_att 14.864057 loss_ctc 18.358868 loss_rnnt 9.422024 hw_loss 0.189276 lr 0.00046129 rank 5
2023-02-22 02:50:05,343 DEBUG TRAIN Batch 14/700 loss 9.979027 loss_att 14.497692 loss_ctc 13.979445 loss_rnnt 8.435683 hw_loss 0.199165 lr 0.00046132 rank 2
2023-02-22 02:50:05,348 DEBUG TRAIN Batch 14/700 loss 8.395844 loss_att 12.764759 loss_ctc 12.157795 loss_rnnt 6.904424 hw_loss 0.217581 lr 0.00046138 rank 1
2023-02-22 02:50:05,348 DEBUG TRAIN Batch 14/700 loss 12.176231 loss_att 12.456718 loss_ctc 16.208960 loss_rnnt 11.364529 hw_loss 0.408578 lr 0.00046130 rank 3
2023-02-22 02:50:05,352 DEBUG TRAIN Batch 14/700 loss 7.214143 loss_att 10.147238 loss_ctc 10.341158 loss_rnnt 6.167333 hw_loss 0.081105 lr 0.00046130 rank 4
2023-02-22 02:50:05,352 DEBUG TRAIN Batch 14/700 loss 10.172308 loss_att 14.983043 loss_ctc 13.898738 loss_rnnt 8.666617 hw_loss 0.087539 lr 0.00046124 rank 7
2023-02-22 02:50:05,395 DEBUG TRAIN Batch 14/700 loss 23.206497 loss_att 27.232010 loss_ctc 32.207664 loss_rnnt 21.049709 hw_loss 0.284119 lr 0.00046134 rank 0
2023-02-22 02:51:17,735 DEBUG TRAIN Batch 14/800 loss 9.742547 loss_att 10.988791 loss_ctc 18.804737 loss_rnnt 8.062610 hw_loss 0.416994 lr 0.00046110 rank 4
2023-02-22 02:51:17,738 DEBUG TRAIN Batch 14/800 loss 10.601640 loss_att 13.125116 loss_ctc 12.641409 loss_rnnt 9.598634 hw_loss 0.424390 lr 0.00046105 rank 7
2023-02-22 02:51:17,742 DEBUG TRAIN Batch 14/800 loss 12.768254 loss_att 15.729055 loss_ctc 12.454285 loss_rnnt 12.058754 hw_loss 0.298507 lr 0.00046119 rank 1
2023-02-22 02:51:17,744 DEBUG TRAIN Batch 14/800 loss 14.320935 loss_att 16.515806 loss_ctc 20.174412 loss_rnnt 12.967550 hw_loss 0.251153 lr 0.00046112 rank 2
2023-02-22 02:51:17,746 DEBUG TRAIN Batch 14/800 loss 16.915495 loss_att 18.660334 loss_ctc 16.613783 loss_rnnt 16.557377 hw_loss 0.092588 lr 0.00046110 rank 3
2023-02-22 02:51:17,753 DEBUG TRAIN Batch 14/800 loss 11.740343 loss_att 14.785942 loss_ctc 19.154064 loss_rnnt 9.923223 hw_loss 0.411567 lr 0.00046112 rank 6
2023-02-22 02:51:17,755 DEBUG TRAIN Batch 14/800 loss 19.232349 loss_att 23.414177 loss_ctc 26.745375 loss_rnnt 17.204519 hw_loss 0.355740 lr 0.00046109 rank 5
2023-02-22 02:51:17,788 DEBUG TRAIN Batch 14/800 loss 12.363515 loss_att 14.940664 loss_ctc 19.415031 loss_rnnt 10.776400 hw_loss 0.246526 lr 0.00046114 rank 0
2023-02-22 02:52:29,599 DEBUG TRAIN Batch 14/900 loss 12.911810 loss_att 16.211349 loss_ctc 16.467056 loss_rnnt 11.574596 hw_loss 0.381135 lr 0.00046091 rank 3
2023-02-22 02:52:29,598 DEBUG TRAIN Batch 14/900 loss 7.360959 loss_att 12.536143 loss_ctc 13.960415 loss_rnnt 5.263040 hw_loss 0.343040 lr 0.00046092 rank 2
2023-02-22 02:52:29,599 DEBUG TRAIN Batch 14/900 loss 6.461596 loss_att 7.734386 loss_ctc 6.338977 loss_rnnt 6.034600 hw_loss 0.353973 lr 0.00046093 rank 6
2023-02-22 02:52:29,602 DEBUG TRAIN Batch 14/900 loss 13.761359 loss_att 16.040688 loss_ctc 18.927994 loss_rnnt 12.473418 hw_loss 0.268483 lr 0.00046094 rank 0
2023-02-22 02:52:29,603 DEBUG TRAIN Batch 14/900 loss 14.477209 loss_att 19.410830 loss_ctc 21.030785 loss_rnnt 12.488848 hw_loss 0.239672 lr 0.00046085 rank 7
2023-02-22 02:52:29,603 DEBUG TRAIN Batch 14/900 loss 10.610703 loss_att 12.970039 loss_ctc 14.634326 loss_rnnt 9.480534 hw_loss 0.228411 lr 0.00046099 rank 1
2023-02-22 02:52:29,603 DEBUG TRAIN Batch 14/900 loss 16.838081 loss_att 21.391663 loss_ctc 25.578232 loss_rnnt 14.648642 hw_loss 0.212571 lr 0.00046091 rank 4
2023-02-22 02:52:29,606 DEBUG TRAIN Batch 14/900 loss 11.866367 loss_att 15.786859 loss_ctc 15.431817 loss_rnnt 10.492491 hw_loss 0.214471 lr 0.00046090 rank 5
2023-02-22 02:53:42,258 DEBUG TRAIN Batch 14/1000 loss 13.458945 loss_att 16.683056 loss_ctc 16.966579 loss_rnnt 12.206010 hw_loss 0.263303 lr 0.00046073 rank 2
2023-02-22 02:53:42,259 DEBUG TRAIN Batch 14/1000 loss 16.195250 loss_att 18.168709 loss_ctc 18.461472 loss_rnnt 15.417799 hw_loss 0.151116 lr 0.00046073 rank 6
2023-02-22 02:53:42,262 DEBUG TRAIN Batch 14/1000 loss 9.622112 loss_att 12.327881 loss_ctc 12.322147 loss_rnnt 8.597558 hw_loss 0.231365 lr 0.00046071 rank 4
2023-02-22 02:53:42,265 DEBUG TRAIN Batch 14/1000 loss 12.008934 loss_att 14.916792 loss_ctc 19.796043 loss_rnnt 10.202644 hw_loss 0.349568 lr 0.00046080 rank 1
2023-02-22 02:53:42,267 DEBUG TRAIN Batch 14/1000 loss 19.617439 loss_att 22.942314 loss_ctc 27.508312 loss_rnnt 17.784716 hw_loss 0.216809 lr 0.00046075 rank 0
2023-02-22 02:53:42,275 DEBUG TRAIN Batch 14/1000 loss 7.926920 loss_att 12.347791 loss_ctc 10.372292 loss_rnnt 6.614744 hw_loss 0.191160 lr 0.00046065 rank 7
2023-02-22 02:53:42,276 DEBUG TRAIN Batch 14/1000 loss 10.348759 loss_att 13.368714 loss_ctc 13.724489 loss_rnnt 9.117149 hw_loss 0.332852 lr 0.00046071 rank 3
2023-02-22 02:53:42,281 DEBUG TRAIN Batch 14/1000 loss 25.648949 loss_att 25.954914 loss_ctc 33.199432 loss_rnnt 24.370865 hw_loss 0.394049 lr 0.00046070 rank 5
2023-02-22 02:54:56,645 DEBUG TRAIN Batch 14/1100 loss 27.212009 loss_att 32.355045 loss_ctc 32.835503 loss_rnnt 25.267197 hw_loss 0.312016 lr 0.00046052 rank 3
2023-02-22 02:54:56,648 DEBUG TRAIN Batch 14/1100 loss 13.067483 loss_att 15.804447 loss_ctc 18.493137 loss_rnnt 11.637116 hw_loss 0.299160 lr 0.00046053 rank 2
2023-02-22 02:54:56,649 DEBUG TRAIN Batch 14/1100 loss 5.537438 loss_att 10.171365 loss_ctc 7.815088 loss_rnnt 4.126226 hw_loss 0.338887 lr 0.00046060 rank 1
2023-02-22 02:54:56,651 DEBUG TRAIN Batch 14/1100 loss 22.653833 loss_att 25.864054 loss_ctc 27.277809 loss_rnnt 21.233898 hw_loss 0.302555 lr 0.00046046 rank 7
2023-02-22 02:54:56,653 DEBUG TRAIN Batch 14/1100 loss 19.590191 loss_att 21.418741 loss_ctc 25.993464 loss_rnnt 18.246613 hw_loss 0.232689 lr 0.00046054 rank 6
2023-02-22 02:54:56,654 DEBUG TRAIN Batch 14/1100 loss 19.446873 loss_att 24.224241 loss_ctc 28.767069 loss_rnnt 17.049755 hw_loss 0.373034 lr 0.00046051 rank 5
2023-02-22 02:54:56,662 DEBUG TRAIN Batch 14/1100 loss 4.801551 loss_att 9.320551 loss_ctc 7.049141 loss_rnnt 3.417198 hw_loss 0.339140 lr 0.00046052 rank 4
2023-02-22 02:54:56,700 DEBUG TRAIN Batch 14/1100 loss 13.981110 loss_att 17.700581 loss_ctc 18.752283 loss_rnnt 12.377942 hw_loss 0.418344 lr 0.00046055 rank 0
2023-02-22 02:56:10,017 DEBUG TRAIN Batch 14/1200 loss 8.033173 loss_att 8.597992 loss_ctc 10.454267 loss_rnnt 7.501641 hw_loss 0.179539 lr 0.00046034 rank 6
2023-02-22 02:56:10,018 DEBUG TRAIN Batch 14/1200 loss 11.821304 loss_att 13.836660 loss_ctc 20.043814 loss_rnnt 10.173100 hw_loss 0.278998 lr 0.00046040 rank 1
2023-02-22 02:56:10,020 DEBUG TRAIN Batch 14/1200 loss 11.423338 loss_att 12.620716 loss_ctc 14.135626 loss_rnnt 10.612799 hw_loss 0.392674 lr 0.00046034 rank 2
2023-02-22 02:56:10,022 DEBUG TRAIN Batch 14/1200 loss 14.097765 loss_att 15.492174 loss_ctc 17.813456 loss_rnnt 13.167885 hw_loss 0.291699 lr 0.00046026 rank 7
2023-02-22 02:56:10,023 DEBUG TRAIN Batch 14/1200 loss 11.311954 loss_att 15.329198 loss_ctc 13.723203 loss_rnnt 9.988413 hw_loss 0.372362 lr 0.00046036 rank 0
2023-02-22 02:56:10,025 DEBUG TRAIN Batch 14/1200 loss 16.290409 loss_att 18.038700 loss_ctc 19.039165 loss_rnnt 15.491796 hw_loss 0.154601 lr 0.00046032 rank 3
2023-02-22 02:56:10,024 DEBUG TRAIN Batch 14/1200 loss 10.623949 loss_att 9.529463 loss_ctc 12.000398 loss_rnnt 10.400292 hw_loss 0.485676 lr 0.00046031 rank 5
2023-02-22 02:56:10,075 DEBUG TRAIN Batch 14/1200 loss 12.580830 loss_att 14.085438 loss_ctc 18.087744 loss_rnnt 11.362597 hw_loss 0.343230 lr 0.00046032 rank 4
2023-02-22 02:57:22,424 DEBUG TRAIN Batch 14/1300 loss 9.426753 loss_att 12.098962 loss_ctc 9.968010 loss_rnnt 8.717031 hw_loss 0.193336 lr 0.00046016 rank 0
2023-02-22 02:57:22,441 DEBUG TRAIN Batch 14/1300 loss 8.065451 loss_att 14.470434 loss_ctc 12.096560 loss_rnnt 6.133180 hw_loss 0.213361 lr 0.00046013 rank 4
2023-02-22 02:57:22,442 DEBUG TRAIN Batch 14/1300 loss 12.804186 loss_att 14.439515 loss_ctc 16.055550 loss_rnnt 11.914107 hw_loss 0.242810 lr 0.00046013 rank 3
2023-02-22 02:57:22,442 DEBUG TRAIN Batch 14/1300 loss 13.713233 loss_att 20.408239 loss_ctc 20.309814 loss_rnnt 11.449004 hw_loss 0.085655 lr 0.00046015 rank 6
2023-02-22 02:57:22,444 DEBUG TRAIN Batch 14/1300 loss 6.975645 loss_att 9.350418 loss_ctc 6.952388 loss_rnnt 6.359394 hw_loss 0.270745 lr 0.00046014 rank 2
2023-02-22 02:57:22,447 DEBUG TRAIN Batch 14/1300 loss 5.774147 loss_att 9.994073 loss_ctc 7.447532 loss_rnnt 4.566924 hw_loss 0.262725 lr 0.00046021 rank 1
2023-02-22 02:57:22,449 DEBUG TRAIN Batch 14/1300 loss 11.929946 loss_att 14.494967 loss_ctc 17.934895 loss_rnnt 10.516062 hw_loss 0.187912 lr 0.00046012 rank 5
2023-02-22 02:57:22,449 DEBUG TRAIN Batch 14/1300 loss 13.240395 loss_att 12.779015 loss_ctc 18.731569 loss_rnnt 12.494207 hw_loss 0.199327 lr 0.00046007 rank 7
2023-02-22 02:58:37,099 DEBUG TRAIN Batch 14/1400 loss 27.685841 loss_att 36.799545 loss_ctc 38.003502 loss_rnnt 24.345718 hw_loss 0.265674 lr 0.00045987 rank 7
2023-02-22 02:58:37,111 DEBUG TRAIN Batch 14/1400 loss 11.391693 loss_att 13.401815 loss_ctc 14.645416 loss_rnnt 10.396616 hw_loss 0.298543 lr 0.00045995 rank 2
2023-02-22 02:58:37,112 DEBUG TRAIN Batch 14/1400 loss 12.104836 loss_att 14.670941 loss_ctc 14.784456 loss_rnnt 11.130771 hw_loss 0.194175 lr 0.00045993 rank 3
2023-02-22 02:58:37,113 DEBUG TRAIN Batch 14/1400 loss 12.134523 loss_att 14.616807 loss_ctc 13.997474 loss_rnnt 11.271608 hw_loss 0.221369 lr 0.00045995 rank 6
2023-02-22 02:58:37,114 DEBUG TRAIN Batch 14/1400 loss 16.892740 loss_att 21.533354 loss_ctc 30.777393 loss_rnnt 13.896898 hw_loss 0.405809 lr 0.00045993 rank 4
2023-02-22 02:58:37,116 DEBUG TRAIN Batch 14/1400 loss 8.039928 loss_att 10.098644 loss_ctc 8.697836 loss_rnnt 7.393326 hw_loss 0.275885 lr 0.00045997 rank 0
2023-02-22 02:58:37,119 DEBUG TRAIN Batch 14/1400 loss 15.817779 loss_att 20.244677 loss_ctc 23.517483 loss_rnnt 13.778702 hw_loss 0.238253 lr 0.00046001 rank 1
2023-02-22 02:58:37,138 DEBUG TRAIN Batch 14/1400 loss 21.765671 loss_att 26.705803 loss_ctc 24.925053 loss_rnnt 20.152508 hw_loss 0.382283 lr 0.00045992 rank 5
2023-02-22 02:59:50,927 DEBUG TRAIN Batch 14/1500 loss 19.872885 loss_att 21.925339 loss_ctc 30.460485 loss_rnnt 17.873526 hw_loss 0.332225 lr 0.00045975 rank 2
2023-02-22 02:59:50,931 DEBUG TRAIN Batch 14/1500 loss 9.132807 loss_att 13.350805 loss_ctc 11.048059 loss_rnnt 7.888074 hw_loss 0.273312 lr 0.00045974 rank 3
2023-02-22 02:59:50,932 DEBUG TRAIN Batch 14/1500 loss 12.567172 loss_att 18.355947 loss_ctc 19.841923 loss_rnnt 10.254821 hw_loss 0.346182 lr 0.00045968 rank 7
2023-02-22 02:59:50,933 DEBUG TRAIN Batch 14/1500 loss 6.054453 loss_att 11.071911 loss_ctc 7.783126 loss_rnnt 4.639110 hw_loss 0.340054 lr 0.00045977 rank 0
2023-02-22 02:59:50,934 DEBUG TRAIN Batch 14/1500 loss 6.052102 loss_att 7.508826 loss_ctc 7.503423 loss_rnnt 5.438632 hw_loss 0.241152 lr 0.00045982 rank 1
2023-02-22 02:59:50,934 DEBUG TRAIN Batch 14/1500 loss 10.477147 loss_att 12.525457 loss_ctc 11.743661 loss_rnnt 9.755879 hw_loss 0.267633 lr 0.00045976 rank 6
2023-02-22 02:59:50,946 DEBUG TRAIN Batch 14/1500 loss 5.526645 loss_att 10.111844 loss_ctc 5.672787 loss_rnnt 4.451954 hw_loss 0.259061 lr 0.00045973 rank 5
2023-02-22 02:59:50,984 DEBUG TRAIN Batch 14/1500 loss 7.174804 loss_att 10.568668 loss_ctc 8.813023 loss_rnnt 6.166244 hw_loss 0.208796 lr 0.00045974 rank 4
2023-02-22 03:01:03,349 DEBUG TRAIN Batch 14/1600 loss 19.002834 loss_att 20.042332 loss_ctc 22.911434 loss_rnnt 18.175337 hw_loss 0.184599 lr 0.00045958 rank 0
2023-02-22 03:01:03,349 DEBUG TRAIN Batch 14/1600 loss 11.745807 loss_att 12.970461 loss_ctc 14.611305 loss_rnnt 10.900098 hw_loss 0.410086 lr 0.00045956 rank 2
2023-02-22 03:01:03,350 DEBUG TRAIN Batch 14/1600 loss 4.738400 loss_att 7.603617 loss_ctc 8.538498 loss_rnnt 3.582841 hw_loss 0.142191 lr 0.00045954 rank 3
2023-02-22 03:01:03,350 DEBUG TRAIN Batch 14/1600 loss 4.450699 loss_att 9.858418 loss_ctc 7.568677 loss_rnnt 2.835626 hw_loss 0.220874 lr 0.00045956 rank 6
2023-02-22 03:01:03,353 DEBUG TRAIN Batch 14/1600 loss 15.845119 loss_att 16.244867 loss_ctc 20.087460 loss_rnnt 15.022590 hw_loss 0.331749 lr 0.00045963 rank 1
2023-02-22 03:01:03,355 DEBUG TRAIN Batch 14/1600 loss 6.484082 loss_att 10.443110 loss_ctc 9.299562 loss_rnnt 5.193318 hw_loss 0.231675 lr 0.00045954 rank 4
2023-02-22 03:01:03,358 DEBUG TRAIN Batch 14/1600 loss 12.195724 loss_att 13.740730 loss_ctc 11.557269 loss_rnnt 11.884164 hw_loss 0.164412 lr 0.00045953 rank 5
2023-02-22 03:01:03,405 DEBUG TRAIN Batch 14/1600 loss 6.787364 loss_att 9.750879 loss_ctc 7.980394 loss_rnnt 5.903794 hw_loss 0.247116 lr 0.00045949 rank 7
2023-02-22 03:02:15,994 DEBUG TRAIN Batch 14/1700 loss 12.799798 loss_att 16.668734 loss_ctc 12.584864 loss_rnnt 11.925831 hw_loss 0.241572 lr 0.00045943 rank 1
2023-02-22 03:02:15,999 DEBUG TRAIN Batch 14/1700 loss 15.303127 loss_att 18.953211 loss_ctc 18.968746 loss_rnnt 13.916273 hw_loss 0.315166 lr 0.00045935 rank 4
2023-02-22 03:02:16,005 DEBUG TRAIN Batch 14/1700 loss 6.576070 loss_att 8.909709 loss_ctc 10.019255 loss_rnnt 5.488898 hw_loss 0.302538 lr 0.00045937 rank 2
2023-02-22 03:02:16,008 DEBUG TRAIN Batch 14/1700 loss 13.231438 loss_att 15.196368 loss_ctc 15.966875 loss_rnnt 12.272312 hw_loss 0.377654 lr 0.00045929 rank 7
2023-02-22 03:02:16,009 DEBUG TRAIN Batch 14/1700 loss 7.736748 loss_att 10.487275 loss_ctc 7.307339 loss_rnnt 7.100022 hw_loss 0.269765 lr 0.00045938 rank 0
2023-02-22 03:02:16,011 DEBUG TRAIN Batch 14/1700 loss 19.192719 loss_att 20.878016 loss_ctc 22.285425 loss_rnnt 18.318977 hw_loss 0.233100 lr 0.00045935 rank 3
2023-02-22 03:02:16,010 DEBUG TRAIN Batch 14/1700 loss 7.850746 loss_att 10.947497 loss_ctc 8.856060 loss_rnnt 6.993396 hw_loss 0.194921 lr 0.00045934 rank 5
2023-02-22 03:02:16,014 DEBUG TRAIN Batch 14/1700 loss 8.629457 loss_att 8.647928 loss_ctc 9.179804 loss_rnnt 8.444515 hw_loss 0.202256 lr 0.00045937 rank 6
2023-02-22 03:03:31,675 DEBUG TRAIN Batch 14/1800 loss 13.039346 loss_att 16.643841 loss_ctc 17.988756 loss_rnnt 11.472074 hw_loss 0.349595 lr 0.00045910 rank 7
2023-02-22 03:03:31,691 DEBUG TRAIN Batch 14/1800 loss 11.161871 loss_att 12.290504 loss_ctc 12.914665 loss_rnnt 10.472023 hw_loss 0.432029 lr 0.00045917 rank 2
2023-02-22 03:03:31,695 DEBUG TRAIN Batch 14/1800 loss 8.665640 loss_att 11.930460 loss_ctc 9.538792 loss_rnnt 7.798910 hw_loss 0.182522 lr 0.00045915 rank 3
2023-02-22 03:03:31,695 DEBUG TRAIN Batch 14/1800 loss 10.416016 loss_att 12.485244 loss_ctc 11.813288 loss_rnnt 9.742696 hw_loss 0.137195 lr 0.00045915 rank 5
2023-02-22 03:03:31,698 DEBUG TRAIN Batch 14/1800 loss 11.085342 loss_att 13.401854 loss_ctc 15.558426 loss_rnnt 9.840573 hw_loss 0.346979 lr 0.00045919 rank 0
2023-02-22 03:03:31,699 DEBUG TRAIN Batch 14/1800 loss 7.235015 loss_att 11.384703 loss_ctc 12.950329 loss_rnnt 5.448455 hw_loss 0.364840 lr 0.00045916 rank 4
2023-02-22 03:03:31,700 DEBUG TRAIN Batch 14/1800 loss 16.684980 loss_att 18.068153 loss_ctc 24.627665 loss_rnnt 15.191192 hw_loss 0.296495 lr 0.00045918 rank 6
2023-02-22 03:03:31,744 DEBUG TRAIN Batch 14/1800 loss 16.600864 loss_att 21.196514 loss_ctc 20.261097 loss_rnnt 15.031921 hw_loss 0.303338 lr 0.00045924 rank 1
2023-02-22 03:04:45,219 DEBUG TRAIN Batch 14/1900 loss 12.732949 loss_att 14.600489 loss_ctc 15.385513 loss_rnnt 11.854284 hw_loss 0.284031 lr 0.00045898 rank 2
2023-02-22 03:04:45,221 DEBUG TRAIN Batch 14/1900 loss 12.116218 loss_att 11.283287 loss_ctc 14.975072 loss_rnnt 11.570304 hw_loss 0.621224 lr 0.00045890 rank 7
2023-02-22 03:04:45,221 DEBUG TRAIN Batch 14/1900 loss 26.397190 loss_att 30.260242 loss_ctc 34.067734 loss_rnnt 24.392134 hw_loss 0.393200 lr 0.00045904 rank 1
2023-02-22 03:04:45,222 DEBUG TRAIN Batch 14/1900 loss 13.176713 loss_att 15.316324 loss_ctc 21.269262 loss_rnnt 11.534995 hw_loss 0.252732 lr 0.00045896 rank 3
2023-02-22 03:04:45,225 DEBUG TRAIN Batch 14/1900 loss 14.672244 loss_att 22.742943 loss_ctc 24.510265 loss_rnnt 11.633929 hw_loss 0.210823 lr 0.00045898 rank 6
2023-02-22 03:04:45,225 DEBUG TRAIN Batch 14/1900 loss 10.269681 loss_att 16.443026 loss_ctc 18.295195 loss_rnnt 7.833702 hw_loss 0.246078 lr 0.00045895 rank 5
2023-02-22 03:04:45,226 DEBUG TRAIN Batch 14/1900 loss 16.207642 loss_att 19.015802 loss_ctc 19.171795 loss_rnnt 15.060492 hw_loss 0.356805 lr 0.00045896 rank 4
2023-02-22 03:04:45,230 DEBUG TRAIN Batch 14/1900 loss 12.914932 loss_att 12.637074 loss_ctc 14.936515 loss_rnnt 12.441354 hw_loss 0.486761 lr 0.00045900 rank 0
2023-02-22 03:05:57,920 DEBUG TRAIN Batch 14/2000 loss 9.573450 loss_att 15.445569 loss_ctc 14.407706 loss_rnnt 7.638551 hw_loss 0.217328 lr 0.00045871 rank 7
2023-02-22 03:05:57,935 DEBUG TRAIN Batch 14/2000 loss 9.427775 loss_att 10.192107 loss_ctc 12.494034 loss_rnnt 8.597820 hw_loss 0.502977 lr 0.00045877 rank 3
2023-02-22 03:05:57,935 DEBUG TRAIN Batch 14/2000 loss 12.859447 loss_att 20.624275 loss_ctc 21.746387 loss_rnnt 9.949401 hw_loss 0.322793 lr 0.00045885 rank 1
2023-02-22 03:05:57,937 DEBUG TRAIN Batch 14/2000 loss 14.499170 loss_att 20.002743 loss_ctc 16.141720 loss_rnnt 13.068520 hw_loss 0.207991 lr 0.00045879 rank 6
2023-02-22 03:05:57,938 DEBUG TRAIN Batch 14/2000 loss 11.827431 loss_att 14.701434 loss_ctc 13.846281 loss_rnnt 10.744475 hw_loss 0.448078 lr 0.00045880 rank 0
2023-02-22 03:05:57,939 DEBUG TRAIN Batch 14/2000 loss 8.685140 loss_att 11.444677 loss_ctc 13.225800 loss_rnnt 7.382570 hw_loss 0.272327 lr 0.00045876 rank 5
2023-02-22 03:05:57,940 DEBUG TRAIN Batch 14/2000 loss 16.651693 loss_att 23.744534 loss_ctc 20.913168 loss_rnnt 14.537289 hw_loss 0.239326 lr 0.00045879 rank 2
2023-02-22 03:05:57,940 DEBUG TRAIN Batch 14/2000 loss 9.171351 loss_att 13.275766 loss_ctc 11.581249 loss_rnnt 7.903021 hw_loss 0.236490 lr 0.00045877 rank 4
2023-02-22 03:07:12,827 DEBUG TRAIN Batch 14/2100 loss 6.398724 loss_att 8.566542 loss_ctc 6.414359 loss_rnnt 5.850845 hw_loss 0.210433 lr 0.00045857 rank 5
2023-02-22 03:07:12,834 DEBUG TRAIN Batch 14/2100 loss 6.860508 loss_att 11.089600 loss_ctc 8.151886 loss_rnnt 5.673751 hw_loss 0.316417 lr 0.00045858 rank 4
2023-02-22 03:07:12,835 DEBUG TRAIN Batch 14/2100 loss 9.023211 loss_att 15.093573 loss_ctc 11.509758 loss_rnnt 7.362322 hw_loss 0.216143 lr 0.00045860 rank 6
2023-02-22 03:07:12,837 DEBUG TRAIN Batch 14/2100 loss 10.316384 loss_att 13.359215 loss_ctc 14.527029 loss_rnnt 8.978594 hw_loss 0.314633 lr 0.00045866 rank 1
2023-02-22 03:07:12,838 DEBUG TRAIN Batch 14/2100 loss 11.871441 loss_att 13.829430 loss_ctc 17.414021 loss_rnnt 10.573377 hw_loss 0.313980 lr 0.00045859 rank 2
2023-02-22 03:07:12,840 DEBUG TRAIN Batch 14/2100 loss 12.285748 loss_att 12.872287 loss_ctc 13.858837 loss_rnnt 11.723510 hw_loss 0.440972 lr 0.00045857 rank 3
2023-02-22 03:07:12,844 DEBUG TRAIN Batch 14/2100 loss 9.909762 loss_att 15.182119 loss_ctc 12.375196 loss_rnnt 8.402236 hw_loss 0.233119 lr 0.00045861 rank 0
2023-02-22 03:07:12,845 DEBUG TRAIN Batch 14/2100 loss 5.362772 loss_att 12.531324 loss_ctc 6.690625 loss_rnnt 3.543411 hw_loss 0.391133 lr 0.00045852 rank 7
2023-02-22 03:08:25,806 DEBUG TRAIN Batch 14/2200 loss 16.542746 loss_att 19.257854 loss_ctc 24.429581 loss_rnnt 14.897280 hw_loss 0.095372 lr 0.00045840 rank 2
2023-02-22 03:08:25,808 DEBUG TRAIN Batch 14/2200 loss 12.283912 loss_att 13.350002 loss_ctc 13.903901 loss_rnnt 11.700473 hw_loss 0.289166 lr 0.00045840 rank 6
2023-02-22 03:08:25,811 DEBUG TRAIN Batch 14/2200 loss 7.264213 loss_att 11.511091 loss_ctc 12.322628 loss_rnnt 5.650619 hw_loss 0.168308 lr 0.00045838 rank 3
2023-02-22 03:08:25,816 DEBUG TRAIN Batch 14/2200 loss 14.625897 loss_att 17.583092 loss_ctc 18.378355 loss_rnnt 13.425535 hw_loss 0.203618 lr 0.00045833 rank 7
2023-02-22 03:08:25,818 DEBUG TRAIN Batch 14/2200 loss 8.734702 loss_att 10.042140 loss_ctc 11.655260 loss_rnnt 7.920248 hw_loss 0.306674 lr 0.00045842 rank 0
2023-02-22 03:08:25,820 DEBUG TRAIN Batch 14/2200 loss 14.064129 loss_att 18.119696 loss_ctc 20.759113 loss_rnnt 12.162018 hw_loss 0.371874 lr 0.00045838 rank 4
2023-02-22 03:08:25,820 DEBUG TRAIN Batch 14/2200 loss 12.941935 loss_att 15.080039 loss_ctc 18.233063 loss_rnnt 11.665428 hw_loss 0.268879 lr 0.00045837 rank 5
2023-02-22 03:08:25,870 DEBUG TRAIN Batch 14/2200 loss 9.326587 loss_att 12.335180 loss_ctc 9.824336 loss_rnnt 8.506544 hw_loss 0.284919 lr 0.00045846 rank 1
2023-02-22 03:09:37,982 DEBUG TRAIN Batch 14/2300 loss 12.269021 loss_att 14.665140 loss_ctc 13.697001 loss_rnnt 11.403488 hw_loss 0.367335 lr 0.00045821 rank 2
2023-02-22 03:09:37,982 DEBUG TRAIN Batch 14/2300 loss 15.368402 loss_att 22.736902 loss_ctc 21.760635 loss_rnnt 12.905464 hw_loss 0.256759 lr 0.00045819 rank 3
2023-02-22 03:09:37,984 DEBUG TRAIN Batch 14/2300 loss 11.251403 loss_att 15.730550 loss_ctc 16.408077 loss_rnnt 9.574957 hw_loss 0.174486 lr 0.00045821 rank 6
2023-02-22 03:09:37,985 DEBUG TRAIN Batch 14/2300 loss 17.558043 loss_att 20.766453 loss_ctc 23.220881 loss_rnnt 16.029703 hw_loss 0.246771 lr 0.00045827 rank 1
2023-02-22 03:09:37,988 DEBUG TRAIN Batch 14/2300 loss 21.631374 loss_att 21.099646 loss_ctc 24.923479 loss_rnnt 21.062920 hw_loss 0.442222 lr 0.00045819 rank 4
2023-02-22 03:09:37,990 DEBUG TRAIN Batch 14/2300 loss 17.387705 loss_att 17.818008 loss_ctc 20.946138 loss_rnnt 16.714689 hw_loss 0.210934 lr 0.00045823 rank 0
2023-02-22 03:09:37,992 DEBUG TRAIN Batch 14/2300 loss 21.927883 loss_att 24.407600 loss_ctc 25.550539 loss_rnnt 20.758026 hw_loss 0.357923 lr 0.00045818 rank 5
2023-02-22 03:09:38,035 DEBUG TRAIN Batch 14/2300 loss 11.492252 loss_att 16.481853 loss_ctc 15.969696 loss_rnnt 9.758325 hw_loss 0.260653 lr 0.00045813 rank 7
2023-02-22 03:10:50,542 DEBUG TRAIN Batch 14/2400 loss 7.889153 loss_att 11.693625 loss_ctc 14.650163 loss_rnnt 6.065468 hw_loss 0.302480 lr 0.00045801 rank 2
2023-02-22 03:10:50,557 DEBUG TRAIN Batch 14/2400 loss 11.110651 loss_att 12.830563 loss_ctc 13.798380 loss_rnnt 10.277580 hw_loss 0.245108 lr 0.00045800 rank 3
2023-02-22 03:10:50,558 DEBUG TRAIN Batch 14/2400 loss 10.047310 loss_att 14.112734 loss_ctc 16.244574 loss_rnnt 8.236930 hw_loss 0.320613 lr 0.00045802 rank 6
2023-02-22 03:10:50,560 DEBUG TRAIN Batch 14/2400 loss 17.255232 loss_att 14.716143 loss_ctc 20.558556 loss_rnnt 17.116201 hw_loss 0.387010 lr 0.00045803 rank 0
2023-02-22 03:10:50,560 DEBUG TRAIN Batch 14/2400 loss 11.748446 loss_att 14.818051 loss_ctc 13.314255 loss_rnnt 10.732179 hw_loss 0.362947 lr 0.00045799 rank 5
2023-02-22 03:10:50,576 DEBUG TRAIN Batch 14/2400 loss 8.083178 loss_att 13.751945 loss_ctc 12.130477 loss_rnnt 6.218940 hw_loss 0.357832 lr 0.00045800 rank 4
2023-02-22 03:10:50,576 DEBUG TRAIN Batch 14/2400 loss 9.652738 loss_att 14.381981 loss_ctc 17.061674 loss_rnnt 7.534430 hw_loss 0.346127 lr 0.00045808 rank 1
2023-02-22 03:10:50,586 DEBUG TRAIN Batch 14/2400 loss 14.969950 loss_att 18.549511 loss_ctc 20.730778 loss_rnnt 13.394545 hw_loss 0.171341 lr 0.00045794 rank 7
2023-02-22 03:12:06,518 DEBUG TRAIN Batch 14/2500 loss 8.852140 loss_att 8.742723 loss_ctc 10.530830 loss_rnnt 8.361119 hw_loss 0.542023 lr 0.00045782 rank 2
2023-02-22 03:12:06,519 DEBUG TRAIN Batch 14/2500 loss 9.988185 loss_att 11.001972 loss_ctc 13.232253 loss_rnnt 9.114828 hw_loss 0.446357 lr 0.00045783 rank 6
2023-02-22 03:12:06,520 DEBUG TRAIN Batch 14/2500 loss 18.977795 loss_att 21.927814 loss_ctc 23.570959 loss_rnnt 17.608931 hw_loss 0.312072 lr 0.00045781 rank 3
2023-02-22 03:12:06,520 DEBUG TRAIN Batch 14/2500 loss 7.748490 loss_att 8.461757 loss_ctc 9.665212 loss_rnnt 7.201793 hw_loss 0.278401 lr 0.00045775 rank 7
2023-02-22 03:12:06,523 DEBUG TRAIN Batch 14/2500 loss 9.590343 loss_att 10.505127 loss_ctc 11.683911 loss_rnnt 8.940174 hw_loss 0.352627 lr 0.00045781 rank 4
2023-02-22 03:12:06,530 DEBUG TRAIN Batch 14/2500 loss 14.391456 loss_att 14.839996 loss_ctc 17.739817 loss_rnnt 13.606904 hw_loss 0.465738 lr 0.00045780 rank 5
2023-02-22 03:12:06,530 DEBUG TRAIN Batch 14/2500 loss 7.537285 loss_att 9.338180 loss_ctc 8.455157 loss_rnnt 6.923087 hw_loss 0.246819 lr 0.00045784 rank 0
2023-02-22 03:12:06,581 DEBUG TRAIN Batch 14/2500 loss 17.130121 loss_att 19.056622 loss_ctc 21.626928 loss_rnnt 15.956114 hw_loss 0.354625 lr 0.00045789 rank 1
2023-02-22 03:13:18,955 DEBUG TRAIN Batch 14/2600 loss 17.448818 loss_att 20.433037 loss_ctc 21.079082 loss_rnnt 16.329563 hw_loss 0.071955 lr 0.00045763 rank 2
2023-02-22 03:13:18,956 DEBUG TRAIN Batch 14/2600 loss 21.963308 loss_att 28.079916 loss_ctc 28.390511 loss_rnnt 19.792774 hw_loss 0.169222 lr 0.00045763 rank 6
2023-02-22 03:13:18,958 DEBUG TRAIN Batch 14/2600 loss 2.855538 loss_att 7.994470 loss_ctc 4.155217 loss_rnnt 1.414735 hw_loss 0.449486 lr 0.00045770 rank 1
2023-02-22 03:13:18,959 DEBUG TRAIN Batch 14/2600 loss 16.046537 loss_att 18.581055 loss_ctc 22.106657 loss_rnnt 14.591001 hw_loss 0.263658 lr 0.00045761 rank 3
2023-02-22 03:13:18,960 DEBUG TRAIN Batch 14/2600 loss 5.939897 loss_att 10.038607 loss_ctc 9.173782 loss_rnnt 4.613026 hw_loss 0.142396 lr 0.00045765 rank 0
2023-02-22 03:13:18,964 DEBUG TRAIN Batch 14/2600 loss 15.937233 loss_att 18.803032 loss_ctc 17.047720 loss_rnnt 15.109743 hw_loss 0.199247 lr 0.00045761 rank 5
2023-02-22 03:13:18,992 DEBUG TRAIN Batch 14/2600 loss 9.106947 loss_att 13.726973 loss_ctc 17.673954 loss_rnnt 6.867900 hw_loss 0.323952 lr 0.00045756 rank 7
2023-02-22 03:13:18,997 DEBUG TRAIN Batch 14/2600 loss 14.045997 loss_att 17.721329 loss_ctc 16.507114 loss_rnnt 12.868789 hw_loss 0.213738 lr 0.00045762 rank 4
2023-02-22 03:14:31,703 DEBUG TRAIN Batch 14/2700 loss 8.430094 loss_att 12.425463 loss_ctc 14.185556 loss_rnnt 6.739623 hw_loss 0.232504 lr 0.00045750 rank 1
2023-02-22 03:14:31,712 DEBUG TRAIN Batch 14/2700 loss 9.200652 loss_att 12.709009 loss_ctc 10.952209 loss_rnnt 8.147691 hw_loss 0.220778 lr 0.00045744 rank 6
2023-02-22 03:14:31,712 DEBUG TRAIN Batch 14/2700 loss 6.259100 loss_att 8.412389 loss_ctc 10.360444 loss_rnnt 5.177508 hw_loss 0.195165 lr 0.00045744 rank 2
2023-02-22 03:14:31,713 DEBUG TRAIN Batch 14/2700 loss 9.022276 loss_att 14.560193 loss_ctc 12.703303 loss_rnnt 7.307062 hw_loss 0.219050 lr 0.00045741 rank 5
2023-02-22 03:14:31,714 DEBUG TRAIN Batch 14/2700 loss 15.268607 loss_att 19.879351 loss_ctc 19.051741 loss_rnnt 13.671535 hw_loss 0.319697 lr 0.00045742 rank 4
2023-02-22 03:14:31,715 DEBUG TRAIN Batch 14/2700 loss 11.175247 loss_att 12.581473 loss_ctc 13.919506 loss_rnnt 10.369319 hw_loss 0.297716 lr 0.00045742 rank 3
2023-02-22 03:14:31,723 DEBUG TRAIN Batch 14/2700 loss 4.663718 loss_att 8.775146 loss_ctc 4.889163 loss_rnnt 3.625783 hw_loss 0.347981 lr 0.00045746 rank 0
2023-02-22 03:14:31,772 DEBUG TRAIN Batch 14/2700 loss 7.172150 loss_att 9.865456 loss_ctc 10.267826 loss_rnnt 6.028444 hw_loss 0.360539 lr 0.00045737 rank 7
2023-02-22 03:15:45,189 DEBUG TRAIN Batch 14/2800 loss 8.202879 loss_att 12.990485 loss_ctc 9.062625 loss_rnnt 6.981286 hw_loss 0.280196 lr 0.00045731 rank 1
2023-02-22 03:15:45,190 DEBUG TRAIN Batch 14/2800 loss 10.293072 loss_att 15.551700 loss_ctc 12.350503 loss_rnnt 8.801954 hw_loss 0.309500 lr 0.00045727 rank 0
2023-02-22 03:15:45,198 DEBUG TRAIN Batch 14/2800 loss 5.753836 loss_att 9.107100 loss_ctc 7.507664 loss_rnnt 4.655917 hw_loss 0.362666 lr 0.00045725 rank 2
2023-02-22 03:15:45,201 DEBUG TRAIN Batch 14/2800 loss 11.124412 loss_att 15.098783 loss_ctc 20.281815 loss_rnnt 8.991686 hw_loss 0.219119 lr 0.00045723 rank 3
2023-02-22 03:15:45,204 DEBUG TRAIN Batch 14/2800 loss 8.902936 loss_att 10.622803 loss_ctc 12.950782 loss_rnnt 7.950996 hw_loss 0.127977 lr 0.00045723 rank 4
2023-02-22 03:15:45,207 DEBUG TRAIN Batch 14/2800 loss 8.425257 loss_att 15.030398 loss_ctc 14.385876 loss_rnnt 6.163180 hw_loss 0.274311 lr 0.00045718 rank 7
2023-02-22 03:15:45,223 DEBUG TRAIN Batch 14/2800 loss 17.984051 loss_att 21.405645 loss_ctc 27.975983 loss_rnnt 15.846759 hw_loss 0.226347 lr 0.00045725 rank 6
2023-02-22 03:15:45,248 DEBUG TRAIN Batch 14/2800 loss 21.902056 loss_att 25.761019 loss_ctc 25.632500 loss_rnnt 20.484615 hw_loss 0.277975 lr 0.00045722 rank 5
2023-02-22 03:16:58,735 DEBUG TRAIN Batch 14/2900 loss 7.705752 loss_att 11.614788 loss_ctc 11.111983 loss_rnnt 6.288095 hw_loss 0.340661 lr 0.00045704 rank 3
2023-02-22 03:16:58,739 DEBUG TRAIN Batch 14/2900 loss 12.262169 loss_att 14.502929 loss_ctc 14.723170 loss_rnnt 11.339998 hw_loss 0.273533 lr 0.00045704 rank 4
2023-02-22 03:16:58,740 DEBUG TRAIN Batch 14/2900 loss 20.423458 loss_att 24.283756 loss_ctc 29.782131 loss_rnnt 18.302746 hw_loss 0.189056 lr 0.00045706 rank 6
2023-02-22 03:16:58,741 DEBUG TRAIN Batch 14/2900 loss 14.513089 loss_att 20.330042 loss_ctc 19.772924 loss_rnnt 12.485318 hw_loss 0.305755 lr 0.00045706 rank 2
2023-02-22 03:16:58,744 DEBUG TRAIN Batch 14/2900 loss 17.265661 loss_att 23.721457 loss_ctc 26.148453 loss_rnnt 14.560881 hw_loss 0.429845 lr 0.00045712 rank 1
2023-02-22 03:16:58,745 DEBUG TRAIN Batch 14/2900 loss 11.297899 loss_att 14.060900 loss_ctc 13.527086 loss_rnnt 10.338699 hw_loss 0.205079 lr 0.00045698 rank 7
2023-02-22 03:16:58,747 DEBUG TRAIN Batch 14/2900 loss 9.446499 loss_att 13.365231 loss_ctc 11.706274 loss_rnnt 8.313635 hw_loss 0.089650 lr 0.00045708 rank 0
2023-02-22 03:16:58,748 DEBUG TRAIN Batch 14/2900 loss 13.426595 loss_att 16.909798 loss_ctc 19.830547 loss_rnnt 11.712036 hw_loss 0.307608 lr 0.00045703 rank 5
2023-02-22 03:18:10,860 DEBUG TRAIN Batch 14/3000 loss 10.618697 loss_att 10.796643 loss_ctc 17.610987 loss_rnnt 9.573334 hw_loss 0.145254 lr 0.00045687 rank 2
2023-02-22 03:18:10,862 DEBUG TRAIN Batch 14/3000 loss 9.629180 loss_att 12.404856 loss_ctc 15.364225 loss_rnnt 8.181601 hw_loss 0.239570 lr 0.00045685 rank 4
2023-02-22 03:18:10,863 DEBUG TRAIN Batch 14/3000 loss 5.717438 loss_att 9.217052 loss_ctc 7.994758 loss_rnnt 4.582494 hw_loss 0.246335 lr 0.00045685 rank 3
2023-02-22 03:18:10,864 DEBUG TRAIN Batch 14/3000 loss 11.637899 loss_att 15.305426 loss_ctc 16.657091 loss_rnnt 10.084898 hw_loss 0.281758 lr 0.00045688 rank 0
2023-02-22 03:18:10,864 DEBUG TRAIN Batch 14/3000 loss 11.571859 loss_att 15.192661 loss_ctc 17.821836 loss_rnnt 9.845490 hw_loss 0.316649 lr 0.00045693 rank 1
2023-02-22 03:18:10,865 DEBUG TRAIN Batch 14/3000 loss 12.964165 loss_att 16.459356 loss_ctc 18.298756 loss_rnnt 11.426254 hw_loss 0.239237 lr 0.00045687 rank 6
2023-02-22 03:18:10,872 DEBUG TRAIN Batch 14/3000 loss 16.293674 loss_att 20.415310 loss_ctc 21.577272 loss_rnnt 14.656689 hw_loss 0.202836 lr 0.00045679 rank 7
2023-02-22 03:18:10,915 DEBUG TRAIN Batch 14/3000 loss 15.325479 loss_att 18.320089 loss_ctc 20.063633 loss_rnnt 13.917871 hw_loss 0.331745 lr 0.00045684 rank 5
2023-02-22 03:19:22,842 DEBUG TRAIN Batch 14/3100 loss 9.998642 loss_att 9.441628 loss_ctc 12.282125 loss_rnnt 9.624045 hw_loss 0.340378 lr 0.00045668 rank 6
2023-02-22 03:19:22,843 DEBUG TRAIN Batch 14/3100 loss 4.093417 loss_att 7.724646 loss_ctc 5.085192 loss_rnnt 3.035002 hw_loss 0.374873 lr 0.00045674 rank 1
2023-02-22 03:19:22,846 DEBUG TRAIN Batch 14/3100 loss 14.542840 loss_att 17.291557 loss_ctc 22.925785 loss_rnnt 12.725530 hw_loss 0.280951 lr 0.00045660 rank 7
2023-02-22 03:19:22,846 DEBUG TRAIN Batch 14/3100 loss 5.999028 loss_att 8.026093 loss_ctc 8.327388 loss_rnnt 5.107628 hw_loss 0.329134 lr 0.00045665 rank 5
2023-02-22 03:19:22,847 DEBUG TRAIN Batch 14/3100 loss 19.196518 loss_att 24.203758 loss_ctc 21.335821 loss_rnnt 17.819103 hw_loss 0.170112 lr 0.00045666 rank 3
2023-02-22 03:19:22,847 DEBUG TRAIN Batch 14/3100 loss 22.185129 loss_att 23.641977 loss_ctc 26.700089 loss_rnnt 21.087368 hw_loss 0.383242 lr 0.00045669 rank 0
2023-02-22 03:19:22,849 DEBUG TRAIN Batch 14/3100 loss 13.947821 loss_att 17.087566 loss_ctc 18.568041 loss_rnnt 12.541965 hw_loss 0.303522 lr 0.00045666 rank 4
2023-02-22 03:19:22,856 DEBUG TRAIN Batch 14/3100 loss 11.236943 loss_att 13.422632 loss_ctc 13.472092 loss_rnnt 10.367816 hw_loss 0.251196 lr 0.00045668 rank 2
2023-02-22 03:20:38,243 DEBUG TRAIN Batch 14/3200 loss 10.936122 loss_att 14.485098 loss_ctc 16.045639 loss_rnnt 9.477289 hw_loss 0.127065 lr 0.00045647 rank 4
2023-02-22 03:20:38,249 DEBUG TRAIN Batch 14/3200 loss 15.053505 loss_att 16.879436 loss_ctc 20.112915 loss_rnnt 13.819007 hw_loss 0.365108 lr 0.00045641 rank 7
2023-02-22 03:20:38,250 DEBUG TRAIN Batch 14/3200 loss 9.264124 loss_att 11.453344 loss_ctc 10.747736 loss_rnnt 8.551475 hw_loss 0.144357 lr 0.00045650 rank 0
2023-02-22 03:20:38,252 DEBUG TRAIN Batch 14/3200 loss 12.143643 loss_att 14.576982 loss_ctc 20.906330 loss_rnnt 10.267399 hw_loss 0.414783 lr 0.00045647 rank 3
2023-02-22 03:20:38,252 DEBUG TRAIN Batch 14/3200 loss 13.340862 loss_att 12.530497 loss_ctc 16.353910 loss_rnnt 12.895718 hw_loss 0.385270 lr 0.00045655 rank 1
2023-02-22 03:20:38,255 DEBUG TRAIN Batch 14/3200 loss 22.295734 loss_att 28.883873 loss_ctc 35.697960 loss_rnnt 19.025211 hw_loss 0.311122 lr 0.00045649 rank 6
2023-02-22 03:20:38,256 DEBUG TRAIN Batch 14/3200 loss 12.570349 loss_att 18.843605 loss_ctc 16.197372 loss_rnnt 10.758662 hw_loss 0.137685 lr 0.00045646 rank 5
2023-02-22 03:20:38,281 DEBUG TRAIN Batch 14/3200 loss 10.344096 loss_att 18.126095 loss_ctc 11.450331 loss_rnnt 8.486888 hw_loss 0.287460 lr 0.00045648 rank 2
2023-02-22 03:21:50,036 DEBUG TRAIN Batch 14/3300 loss 6.120166 loss_att 9.690304 loss_ctc 6.238256 loss_rnnt 5.182811 hw_loss 0.389216 lr 0.00045628 rank 4
2023-02-22 03:21:50,045 DEBUG TRAIN Batch 14/3300 loss 20.229298 loss_att 19.092199 loss_ctc 24.886839 loss_rnnt 19.690527 hw_loss 0.272219 lr 0.00045628 rank 3
2023-02-22 03:21:50,047 DEBUG TRAIN Batch 14/3300 loss 5.701721 loss_att 10.391258 loss_ctc 8.726517 loss_rnnt 4.238461 hw_loss 0.228837 lr 0.00045630 rank 6
2023-02-22 03:21:50,048 DEBUG TRAIN Batch 14/3300 loss 9.842042 loss_att 15.152349 loss_ctc 13.367824 loss_rnnt 8.273187 hw_loss 0.068790 lr 0.00045629 rank 2
2023-02-22 03:21:50,050 DEBUG TRAIN Batch 14/3300 loss 6.626035 loss_att 10.172505 loss_ctc 8.570587 loss_rnnt 5.553678 hw_loss 0.194604 lr 0.00045636 rank 1
2023-02-22 03:21:50,050 DEBUG TRAIN Batch 14/3300 loss 15.511224 loss_att 19.422497 loss_ctc 20.055279 loss_rnnt 13.976771 hw_loss 0.274359 lr 0.00045631 rank 0
2023-02-22 03:21:50,051 DEBUG TRAIN Batch 14/3300 loss 11.764087 loss_att 16.530819 loss_ctc 20.761164 loss_rnnt 9.530860 hw_loss 0.150505 lr 0.00045622 rank 7
2023-02-22 03:21:50,054 DEBUG TRAIN Batch 14/3300 loss 14.634492 loss_att 20.221998 loss_ctc 18.172489 loss_rnnt 12.923664 hw_loss 0.227987 lr 0.00045627 rank 5
2023-02-22 03:23:02,339 DEBUG TRAIN Batch 14/3400 loss 15.209618 loss_att 20.848646 loss_ctc 22.673958 loss_rnnt 13.035636 hw_loss 0.095494 lr 0.00045610 rank 2
2023-02-22 03:23:02,341 DEBUG TRAIN Batch 14/3400 loss 19.522432 loss_att 21.893494 loss_ctc 21.902977 loss_rnnt 18.567345 hw_loss 0.306508 lr 0.00045609 rank 3
2023-02-22 03:23:02,342 DEBUG TRAIN Batch 14/3400 loss 13.674579 loss_att 17.492851 loss_ctc 16.278183 loss_rnnt 12.486842 hw_loss 0.144254 lr 0.00045609 rank 4
2023-02-22 03:23:02,343 DEBUG TRAIN Batch 14/3400 loss 12.052497 loss_att 17.253235 loss_ctc 17.481861 loss_rnnt 10.129725 hw_loss 0.297579 lr 0.00045612 rank 0
2023-02-22 03:23:02,343 DEBUG TRAIN Batch 14/3400 loss 17.874571 loss_att 24.376003 loss_ctc 23.664444 loss_rnnt 15.673484 hw_loss 0.241534 lr 0.00045611 rank 6
2023-02-22 03:23:02,346 DEBUG TRAIN Batch 14/3400 loss 8.236238 loss_att 10.796411 loss_ctc 14.041309 loss_rnnt 6.798295 hw_loss 0.284807 lr 0.00045617 rank 1
2023-02-22 03:23:02,348 DEBUG TRAIN Batch 14/3400 loss 11.566723 loss_att 15.624763 loss_ctc 13.340790 loss_rnnt 10.331538 hw_loss 0.350691 lr 0.00045603 rank 7
2023-02-22 03:23:02,353 DEBUG TRAIN Batch 14/3400 loss 13.310630 loss_att 16.137403 loss_ctc 15.536751 loss_rnnt 12.333775 hw_loss 0.215035 lr 0.00045608 rank 5
2023-02-22 03:24:15,517 DEBUG TRAIN Batch 14/3500 loss 14.141265 loss_att 21.641809 loss_ctc 18.968437 loss_rnnt 11.894709 hw_loss 0.192793 lr 0.00045598 rank 1
2023-02-22 03:24:15,519 DEBUG TRAIN Batch 14/3500 loss 8.162444 loss_att 11.904131 loss_ctc 8.907452 loss_rnnt 7.133000 hw_loss 0.340823 lr 0.00045592 rank 2
2023-02-22 03:24:15,521 DEBUG TRAIN Batch 14/3500 loss 10.263661 loss_att 15.471786 loss_ctc 15.555726 loss_rnnt 8.319462 hw_loss 0.369310 lr 0.00045584 rank 7
2023-02-22 03:24:15,532 DEBUG TRAIN Batch 14/3500 loss 17.678801 loss_att 22.926905 loss_ctc 25.163715 loss_rnnt 15.454380 hw_loss 0.331523 lr 0.00045592 rank 6
2023-02-22 03:24:15,534 DEBUG TRAIN Batch 14/3500 loss 9.258500 loss_att 12.300492 loss_ctc 15.047472 loss_rnnt 7.742723 hw_loss 0.254093 lr 0.00045590 rank 4
2023-02-22 03:24:15,541 DEBUG TRAIN Batch 14/3500 loss 14.498317 loss_att 15.560638 loss_ctc 16.456976 loss_rnnt 13.830406 hw_loss 0.364295 lr 0.00045589 rank 5
2023-02-22 03:24:15,567 DEBUG TRAIN Batch 14/3500 loss 15.884983 loss_att 17.165327 loss_ctc 16.629051 loss_rnnt 15.320041 hw_loss 0.393123 lr 0.00045590 rank 3
2023-02-22 03:24:15,568 DEBUG TRAIN Batch 14/3500 loss 29.750637 loss_att 37.248947 loss_ctc 36.555450 loss_rnnt 27.213263 hw_loss 0.244512 lr 0.00045593 rank 0
2023-02-22 03:25:30,061 DEBUG TRAIN Batch 14/3600 loss 13.168150 loss_att 16.490147 loss_ctc 13.887286 loss_rnnt 12.233147 hw_loss 0.327597 lr 0.00045573 rank 2
2023-02-22 03:25:30,063 DEBUG TRAIN Batch 14/3600 loss 18.641552 loss_att 22.418531 loss_ctc 26.958050 loss_rnnt 16.638327 hw_loss 0.260558 lr 0.00045573 rank 6
2023-02-22 03:25:30,064 DEBUG TRAIN Batch 14/3600 loss 8.229954 loss_att 11.031435 loss_ctc 10.885117 loss_rnnt 7.141370 hw_loss 0.326748 lr 0.00045571 rank 3
2023-02-22 03:25:30,067 DEBUG TRAIN Batch 14/3600 loss 5.610340 loss_att 11.837668 loss_ctc 8.676480 loss_rnnt 3.818480 hw_loss 0.257953 lr 0.00045565 rank 7
2023-02-22 03:25:30,068 DEBUG TRAIN Batch 14/3600 loss 12.063227 loss_att 13.771568 loss_ctc 16.235962 loss_rnnt 11.042316 hw_loss 0.230394 lr 0.00045579 rank 1
2023-02-22 03:25:30,069 DEBUG TRAIN Batch 14/3600 loss 5.434974 loss_att 7.586514 loss_ctc 6.524296 loss_rnnt 4.664310 hw_loss 0.365837 lr 0.00045574 rank 0
2023-02-22 03:25:30,073 DEBUG TRAIN Batch 14/3600 loss 8.431958 loss_att 9.296258 loss_ctc 10.827256 loss_rnnt 7.782121 hw_loss 0.295507 lr 0.00045570 rank 5
2023-02-22 03:25:30,115 DEBUG TRAIN Batch 14/3600 loss 20.078630 loss_att 25.462173 loss_ctc 27.110836 loss_rnnt 17.934135 hw_loss 0.244044 lr 0.00045571 rank 4
2023-02-22 03:26:42,680 DEBUG TRAIN Batch 14/3700 loss 6.968188 loss_att 9.934902 loss_ctc 7.885477 loss_rnnt 6.102912 hw_loss 0.280555 lr 0.00045552 rank 3
2023-02-22 03:26:42,684 DEBUG TRAIN Batch 14/3700 loss 10.059801 loss_att 10.491103 loss_ctc 13.611164 loss_rnnt 9.257303 hw_loss 0.455103 lr 0.00045554 rank 6
2023-02-22 03:26:42,686 DEBUG TRAIN Batch 14/3700 loss 17.618551 loss_att 18.633944 loss_ctc 22.719795 loss_rnnt 16.580084 hw_loss 0.291049 lr 0.00045546 rank 7
2023-02-22 03:26:42,688 DEBUG TRAIN Batch 14/3700 loss 7.521048 loss_att 11.367464 loss_ctc 12.167232 loss_rnnt 5.948354 hw_loss 0.344849 lr 0.00045560 rank 1
2023-02-22 03:26:42,688 DEBUG TRAIN Batch 14/3700 loss 10.946750 loss_att 14.397949 loss_ctc 13.553166 loss_rnnt 9.800745 hw_loss 0.202954 lr 0.00045554 rank 2
2023-02-22 03:26:42,689 DEBUG TRAIN Batch 14/3700 loss 19.255379 loss_att 22.760002 loss_ctc 23.183210 loss_rnnt 17.873285 hw_loss 0.295229 lr 0.00045551 rank 5
2023-02-22 03:26:42,689 DEBUG TRAIN Batch 14/3700 loss 8.247753 loss_att 11.242743 loss_ctc 11.483874 loss_rnnt 7.028192 hw_loss 0.354527 lr 0.00045552 rank 4
2023-02-22 03:26:42,692 DEBUG TRAIN Batch 14/3700 loss 14.744014 loss_att 18.541433 loss_ctc 17.868063 loss_rnnt 13.377042 hw_loss 0.358026 lr 0.00045556 rank 0
2023-02-22 03:27:54,734 DEBUG TRAIN Batch 14/3800 loss 6.939418 loss_att 8.529345 loss_ctc 10.476078 loss_rnnt 5.975458 hw_loss 0.327037 lr 0.00045535 rank 2
2023-02-22 03:27:54,740 DEBUG TRAIN Batch 14/3800 loss 11.258398 loss_att 11.657760 loss_ctc 13.240163 loss_rnnt 10.650116 hw_loss 0.495328 lr 0.00045533 rank 4
2023-02-22 03:27:54,740 DEBUG TRAIN Batch 14/3800 loss 10.031362 loss_att 12.230241 loss_ctc 14.340732 loss_rnnt 8.901070 hw_loss 0.217372 lr 0.00045537 rank 0
2023-02-22 03:27:54,740 DEBUG TRAIN Batch 14/3800 loss 10.994027 loss_att 12.199939 loss_ctc 14.473019 loss_rnnt 10.157394 hw_loss 0.246722 lr 0.00045541 rank 1
2023-02-22 03:27:54,742 DEBUG TRAIN Batch 14/3800 loss 10.132866 loss_att 11.856244 loss_ctc 17.106691 loss_rnnt 8.635252 hw_loss 0.418302 lr 0.00045533 rank 3
2023-02-22 03:27:54,742 DEBUG TRAIN Batch 14/3800 loss 10.876333 loss_att 10.924064 loss_ctc 14.107753 loss_rnnt 10.181959 hw_loss 0.476195 lr 0.00045528 rank 7
2023-02-22 03:27:54,744 DEBUG TRAIN Batch 14/3800 loss 24.310156 loss_att 23.698172 loss_ctc 26.943657 loss_rnnt 23.986267 hw_loss 0.178407 lr 0.00045535 rank 6
2023-02-22 03:27:54,748 DEBUG TRAIN Batch 14/3800 loss 17.234898 loss_att 22.220291 loss_ctc 25.287971 loss_rnnt 15.012652 hw_loss 0.283916 lr 0.00045532 rank 5
2023-02-22 03:29:09,233 DEBUG TRAIN Batch 14/3900 loss 20.691828 loss_att 28.578333 loss_ctc 30.016457 loss_rnnt 17.590858 hw_loss 0.525720 lr 0.00045509 rank 7
2023-02-22 03:29:09,239 DEBUG TRAIN Batch 14/3900 loss 10.843020 loss_att 15.899534 loss_ctc 16.367613 loss_rnnt 8.944862 hw_loss 0.281703 lr 0.00045522 rank 1
2023-02-22 03:29:09,240 DEBUG TRAIN Batch 14/3900 loss 23.532391 loss_att 26.143433 loss_ctc 36.408985 loss_rnnt 20.988613 hw_loss 0.571295 lr 0.00045514 rank 4
2023-02-22 03:29:09,243 DEBUG TRAIN Batch 14/3900 loss 6.579580 loss_att 10.252892 loss_ctc 8.610352 loss_rnnt 5.399320 hw_loss 0.327803 lr 0.00045516 rank 2
2023-02-22 03:29:09,246 DEBUG TRAIN Batch 14/3900 loss 14.126492 loss_att 13.751610 loss_ctc 15.951323 loss_rnnt 13.786080 hw_loss 0.322645 lr 0.00045514 rank 3
2023-02-22 03:29:09,248 DEBUG TRAIN Batch 14/3900 loss 7.637718 loss_att 12.093399 loss_ctc 7.512293 loss_rnnt 6.649246 hw_loss 0.213861 lr 0.00045516 rank 6
2023-02-22 03:29:09,249 DEBUG TRAIN Batch 14/3900 loss 8.198097 loss_att 12.499323 loss_ctc 7.916506 loss_rnnt 7.278817 hw_loss 0.181086 lr 0.00045513 rank 5
2023-02-22 03:29:09,249 DEBUG TRAIN Batch 14/3900 loss 21.975548 loss_att 25.963699 loss_ctc 28.994896 loss_rnnt 20.160721 hw_loss 0.152409 lr 0.00045518 rank 0
2023-02-22 03:30:22,717 DEBUG TRAIN Batch 14/4000 loss 10.446819 loss_att 13.081388 loss_ctc 12.901443 loss_rnnt 9.423715 hw_loss 0.316701 lr 0.00045495 rank 3
2023-02-22 03:30:22,721 DEBUG TRAIN Batch 14/4000 loss 19.476379 loss_att 20.462259 loss_ctc 25.614302 loss_rnnt 18.371901 hw_loss 0.166710 lr 0.00045497 rank 2
2023-02-22 03:30:22,723 DEBUG TRAIN Batch 14/4000 loss 13.815557 loss_att 21.722593 loss_ctc 19.607101 loss_rnnt 11.257564 hw_loss 0.383213 lr 0.00045503 rank 1
2023-02-22 03:30:22,726 DEBUG TRAIN Batch 14/4000 loss 10.596765 loss_att 15.516602 loss_ctc 15.430044 loss_rnnt 8.797783 hw_loss 0.319832 lr 0.00045499 rank 0
2023-02-22 03:30:22,727 DEBUG TRAIN Batch 14/4000 loss 5.478368 loss_att 12.734871 loss_ctc 11.479839 loss_rnnt 3.125703 hw_loss 0.189692 lr 0.00045496 rank 4
2023-02-22 03:30:22,728 DEBUG TRAIN Batch 14/4000 loss 14.510585 loss_att 19.193127 loss_ctc 13.282813 loss_rnnt 13.545015 hw_loss 0.361430 lr 0.00045497 rank 6
2023-02-22 03:30:22,730 DEBUG TRAIN Batch 14/4000 loss 10.721581 loss_att 15.238220 loss_ctc 14.644198 loss_rnnt 9.139593 hw_loss 0.291833 lr 0.00045495 rank 5
2023-02-22 03:30:22,771 DEBUG TRAIN Batch 14/4000 loss 14.860908 loss_att 21.548466 loss_ctc 19.450876 loss_rnnt 12.694579 hw_loss 0.406539 lr 0.00045490 rank 7
2023-02-22 03:31:34,592 DEBUG TRAIN Batch 14/4100 loss 15.672534 loss_att 19.460464 loss_ctc 20.432152 loss_rnnt 14.109537 hw_loss 0.320243 lr 0.00045478 rank 2
2023-02-22 03:31:34,593 DEBUG TRAIN Batch 14/4100 loss 16.815863 loss_att 20.193640 loss_ctc 24.827782 loss_rnnt 14.987885 hw_loss 0.157807 lr 0.00045479 rank 6
2023-02-22 03:31:34,594 DEBUG TRAIN Batch 14/4100 loss 6.390790 loss_att 10.338843 loss_ctc 8.661454 loss_rnnt 5.127179 hw_loss 0.321083 lr 0.00045477 rank 4
2023-02-22 03:31:34,594 DEBUG TRAIN Batch 14/4100 loss 9.841773 loss_att 16.827497 loss_ctc 15.805794 loss_rnnt 7.463512 hw_loss 0.348586 lr 0.00045477 rank 3
2023-02-22 03:31:34,597 DEBUG TRAIN Batch 14/4100 loss 16.575954 loss_att 19.198772 loss_ctc 22.180231 loss_rnnt 15.131344 hw_loss 0.324021 lr 0.00045471 rank 7
2023-02-22 03:31:34,603 DEBUG TRAIN Batch 14/4100 loss 9.168523 loss_att 12.289378 loss_ctc 10.394306 loss_rnnt 8.295386 hw_loss 0.160366 lr 0.00045476 rank 5
2023-02-22 03:31:34,605 DEBUG TRAIN Batch 14/4100 loss 11.838039 loss_att 14.185458 loss_ctc 14.152338 loss_rnnt 10.865673 hw_loss 0.364329 lr 0.00045480 rank 0
2023-02-22 03:31:34,609 DEBUG TRAIN Batch 14/4100 loss 9.099577 loss_att 13.427807 loss_ctc 11.013859 loss_rnnt 7.852273 hw_loss 0.237036 lr 0.00045485 rank 1
2023-02-22 03:32:47,801 DEBUG TRAIN Batch 14/4200 loss 12.174994 loss_att 11.511235 loss_ctc 11.345269 loss_rnnt 12.307707 hw_loss 0.207504 lr 0.00045460 rank 6
2023-02-22 03:32:47,801 DEBUG TRAIN Batch 14/4200 loss 12.698240 loss_att 15.065942 loss_ctc 17.773821 loss_rnnt 11.349166 hw_loss 0.372732 lr 0.00045459 rank 2
2023-02-22 03:32:47,802 DEBUG TRAIN Batch 14/4200 loss 5.998384 loss_att 9.703896 loss_ctc 7.930303 loss_rnnt 4.836866 hw_loss 0.305298 lr 0.00045466 rank 1
2023-02-22 03:32:47,802 DEBUG TRAIN Batch 14/4200 loss 7.888900 loss_att 12.667188 loss_ctc 8.558550 loss_rnnt 6.665378 hw_loss 0.334835 lr 0.00045458 rank 3
2023-02-22 03:32:47,805 DEBUG TRAIN Batch 14/4200 loss 11.025046 loss_att 15.697001 loss_ctc 12.929829 loss_rnnt 9.675791 hw_loss 0.301677 lr 0.00045457 rank 5
2023-02-22 03:32:47,808 DEBUG TRAIN Batch 14/4200 loss 6.344181 loss_att 8.458739 loss_ctc 6.995362 loss_rnnt 5.717306 hw_loss 0.219636 lr 0.00045452 rank 7
2023-02-22 03:32:47,809 DEBUG TRAIN Batch 14/4200 loss 14.346270 loss_att 18.377237 loss_ctc 19.140377 loss_rnnt 12.796339 hw_loss 0.195980 lr 0.00045461 rank 0
2023-02-22 03:32:47,810 DEBUG TRAIN Batch 14/4200 loss 8.343652 loss_att 12.723118 loss_ctc 8.866687 loss_rnnt 7.308657 hw_loss 0.167557 lr 0.00045458 rank 4
2023-02-22 03:34:02,188 DEBUG TRAIN Batch 14/4300 loss 19.455591 loss_att 23.423565 loss_ctc 27.082964 loss_rnnt 17.492649 hw_loss 0.285681 lr 0.00045439 rank 3
2023-02-22 03:34:02,196 DEBUG TRAIN Batch 14/4300 loss 7.358666 loss_att 11.643196 loss_ctc 10.379221 loss_rnnt 5.889285 hw_loss 0.393254 lr 0.00045441 rank 2
2023-02-22 03:34:02,197 DEBUG TRAIN Batch 14/4300 loss 13.204747 loss_att 17.287548 loss_ctc 15.717379 loss_rnnt 11.969446 hw_loss 0.156979 lr 0.00045439 rank 4
2023-02-22 03:34:02,197 DEBUG TRAIN Batch 14/4300 loss 13.245599 loss_att 17.741695 loss_ctc 21.021070 loss_rnnt 11.046900 hw_loss 0.492656 lr 0.00045441 rank 6
2023-02-22 03:34:02,200 DEBUG TRAIN Batch 14/4300 loss 16.791492 loss_att 19.866795 loss_ctc 21.964565 loss_rnnt 15.287724 hw_loss 0.373056 lr 0.00045443 rank 0
2023-02-22 03:34:02,204 DEBUG TRAIN Batch 14/4300 loss 14.015828 loss_att 15.903724 loss_ctc 16.759884 loss_rnnt 13.051838 hw_loss 0.413506 lr 0.00045434 rank 7
2023-02-22 03:34:02,207 DEBUG TRAIN Batch 14/4300 loss 13.972406 loss_att 16.020538 loss_ctc 20.206978 loss_rnnt 12.584045 hw_loss 0.276485 lr 0.00045438 rank 5
2023-02-22 03:34:02,249 DEBUG TRAIN Batch 14/4300 loss 6.616673 loss_att 9.570957 loss_ctc 9.556231 loss_rnnt 5.414423 hw_loss 0.411474 lr 0.00045447 rank 1
2023-02-22 03:35:15,234 DEBUG TRAIN Batch 14/4400 loss 11.455647 loss_att 13.734501 loss_ctc 15.229034 loss_rnnt 10.393372 hw_loss 0.193850 lr 0.00045422 rank 2
2023-02-22 03:35:15,234 DEBUG TRAIN Batch 14/4400 loss 15.671595 loss_att 16.033440 loss_ctc 16.064224 loss_rnnt 15.398521 hw_loss 0.278163 lr 0.00045424 rank 0
2023-02-22 03:35:15,235 DEBUG TRAIN Batch 14/4400 loss 12.127655 loss_att 13.266883 loss_ctc 14.585101 loss_rnnt 11.354220 hw_loss 0.408619 lr 0.00045428 rank 1
2023-02-22 03:35:15,237 DEBUG TRAIN Batch 14/4400 loss 17.850080 loss_att 20.800625 loss_ctc 23.458591 loss_rnnt 16.375101 hw_loss 0.257000 lr 0.00045420 rank 3
2023-02-22 03:35:15,239 DEBUG TRAIN Batch 14/4400 loss 18.728405 loss_att 22.522041 loss_ctc 24.117147 loss_rnnt 17.085220 hw_loss 0.311176 lr 0.00045420 rank 4
2023-02-22 03:35:15,240 DEBUG TRAIN Batch 14/4400 loss 11.112873 loss_att 12.536547 loss_ctc 15.856545 loss_rnnt 10.012523 hw_loss 0.343364 lr 0.00045422 rank 6
2023-02-22 03:35:15,242 DEBUG TRAIN Batch 14/4400 loss 7.865517 loss_att 7.725519 loss_ctc 9.141133 loss_rnnt 7.536049 hw_loss 0.351347 lr 0.00045419 rank 5
2023-02-22 03:35:15,281 DEBUG TRAIN Batch 14/4400 loss 9.665135 loss_att 13.080378 loss_ctc 14.546107 loss_rnnt 8.119533 hw_loss 0.397045 lr 0.00045415 rank 7
2023-02-22 03:36:28,182 DEBUG TRAIN Batch 14/4500 loss 17.012367 loss_att 22.274004 loss_ctc 20.995705 loss_rnnt 15.275623 hw_loss 0.287446 lr 0.00045410 rank 1
2023-02-22 03:36:28,183 DEBUG TRAIN Batch 14/4500 loss 10.476925 loss_att 14.245175 loss_ctc 10.936865 loss_rnnt 9.568541 hw_loss 0.175141 lr 0.00045403 rank 2
2023-02-22 03:36:28,184 DEBUG TRAIN Batch 14/4500 loss 12.433920 loss_att 14.070894 loss_ctc 15.923503 loss_rnnt 11.474012 hw_loss 0.313567 lr 0.00045401 rank 3
2023-02-22 03:36:28,186 DEBUG TRAIN Batch 14/4500 loss 8.536341 loss_att 11.248049 loss_ctc 11.374657 loss_rnnt 7.563428 hw_loss 0.097743 lr 0.00045405 rank 0
2023-02-22 03:36:28,187 DEBUG TRAIN Batch 14/4500 loss 9.308228 loss_att 12.268857 loss_ctc 13.423311 loss_rnnt 8.021574 hw_loss 0.273472 lr 0.00045404 rank 6
2023-02-22 03:36:28,191 DEBUG TRAIN Batch 14/4500 loss 19.359774 loss_att 24.440601 loss_ctc 24.655704 loss_rnnt 17.512739 hw_loss 0.233896 lr 0.00045402 rank 4
2023-02-22 03:36:28,192 DEBUG TRAIN Batch 14/4500 loss 11.096675 loss_att 17.829802 loss_ctc 16.886246 loss_rnnt 8.851466 hw_loss 0.237453 lr 0.00045396 rank 7
2023-02-22 03:36:28,235 DEBUG TRAIN Batch 14/4500 loss 9.682469 loss_att 11.133245 loss_ctc 10.815651 loss_rnnt 9.062712 hw_loss 0.334708 lr 0.00045401 rank 5
2023-02-22 03:37:42,843 DEBUG TRAIN Batch 14/4600 loss 4.609313 loss_att 7.346949 loss_ctc 4.851707 loss_rnnt 3.954934 hw_loss 0.139749 lr 0.00045384 rank 2
2023-02-22 03:37:42,844 DEBUG TRAIN Batch 14/4600 loss 8.145537 loss_att 11.305382 loss_ctc 13.139023 loss_rnnt 6.747320 hw_loss 0.188346 lr 0.00045382 rank 5
2023-02-22 03:37:42,846 DEBUG TRAIN Batch 14/4600 loss 12.659505 loss_att 19.872332 loss_ctc 25.125237 loss_rnnt 9.461298 hw_loss 0.175392 lr 0.00045383 rank 4
2023-02-22 03:37:42,849 DEBUG TRAIN Batch 14/4600 loss 9.303555 loss_att 13.301662 loss_ctc 15.568741 loss_rnnt 7.513521 hw_loss 0.290727 lr 0.00045383 rank 3
2023-02-22 03:37:42,849 DEBUG TRAIN Batch 14/4600 loss 9.367661 loss_att 12.533096 loss_ctc 14.953979 loss_rnnt 7.795260 hw_loss 0.364634 lr 0.00045385 rank 6
2023-02-22 03:37:42,851 DEBUG TRAIN Batch 14/4600 loss 8.538857 loss_att 13.276457 loss_ctc 14.605536 loss_rnnt 6.716220 hw_loss 0.124176 lr 0.00045377 rank 7
2023-02-22 03:37:42,878 DEBUG TRAIN Batch 14/4600 loss 18.682119 loss_att 20.582973 loss_ctc 22.739437 loss_rnnt 17.642546 hw_loss 0.222048 lr 0.00045391 rank 1
2023-02-22 03:37:42,904 DEBUG TRAIN Batch 14/4600 loss 13.294873 loss_att 17.055151 loss_ctc 16.128635 loss_rnnt 12.024092 hw_loss 0.264171 lr 0.00045386 rank 0
2023-02-22 03:38:55,808 DEBUG TRAIN Batch 14/4700 loss 8.547564 loss_att 12.765253 loss_ctc 16.360500 loss_rnnt 6.555429 hw_loss 0.200383 lr 0.00045364 rank 3
2023-02-22 03:38:55,809 DEBUG TRAIN Batch 14/4700 loss 10.357938 loss_att 14.514517 loss_ctc 13.737015 loss_rnnt 8.925613 hw_loss 0.282122 lr 0.00045366 rank 2
2023-02-22 03:38:55,811 DEBUG TRAIN Batch 14/4700 loss 6.966935 loss_att 13.012557 loss_ctc 12.857941 loss_rnnt 4.906271 hw_loss 0.123885 lr 0.00045366 rank 6
2023-02-22 03:38:55,813 DEBUG TRAIN Batch 14/4700 loss 8.086387 loss_att 9.628075 loss_ctc 11.625595 loss_rnnt 7.153190 hw_loss 0.286807 lr 0.00045372 rank 1
2023-02-22 03:38:55,814 DEBUG TRAIN Batch 14/4700 loss 10.666224 loss_att 12.670984 loss_ctc 12.202738 loss_rnnt 9.975565 hw_loss 0.159070 lr 0.00045368 rank 0
2023-02-22 03:38:55,816 DEBUG TRAIN Batch 14/4700 loss 12.067303 loss_att 17.119616 loss_ctc 18.535366 loss_rnnt 10.044893 hw_loss 0.280383 lr 0.00045364 rank 4
2023-02-22 03:38:55,817 DEBUG TRAIN Batch 14/4700 loss 12.146477 loss_att 16.940598 loss_ctc 12.983561 loss_rnnt 10.960545 hw_loss 0.216555 lr 0.00045363 rank 5
2023-02-22 03:38:55,818 DEBUG TRAIN Batch 14/4700 loss 8.859160 loss_att 11.409971 loss_ctc 14.514911 loss_rnnt 7.500319 hw_loss 0.177337 lr 0.00045359 rank 7
2023-02-22 03:40:07,633 DEBUG TRAIN Batch 14/4800 loss 12.129673 loss_att 14.068830 loss_ctc 15.524954 loss_rnnt 11.183558 hw_loss 0.197960 lr 0.00045347 rank 6
2023-02-22 03:40:07,635 DEBUG TRAIN Batch 14/4800 loss 4.187783 loss_att 7.669487 loss_ctc 7.224006 loss_rnnt 2.937253 hw_loss 0.280048 lr 0.00045347 rank 2
2023-02-22 03:40:07,636 DEBUG TRAIN Batch 14/4800 loss 7.651856 loss_att 13.808275 loss_ctc 9.630361 loss_rnnt 6.076787 hw_loss 0.149972 lr 0.00045345 rank 3
2023-02-22 03:40:07,640 DEBUG TRAIN Batch 14/4800 loss 11.069477 loss_att 13.294223 loss_ctc 12.476166 loss_rnnt 10.274427 hw_loss 0.304765 lr 0.00045346 rank 4
2023-02-22 03:40:07,639 DEBUG TRAIN Batch 14/4800 loss 12.012308 loss_att 17.313852 loss_ctc 19.280708 loss_rnnt 9.911957 hw_loss 0.132979 lr 0.00045345 rank 5
2023-02-22 03:40:07,640 DEBUG TRAIN Batch 14/4800 loss 22.092133 loss_att 25.849636 loss_ctc 30.629019 loss_rnnt 20.093124 hw_loss 0.204855 lr 0.00045349 rank 0
2023-02-22 03:40:07,639 DEBUG TRAIN Batch 14/4800 loss 24.582443 loss_att 26.920948 loss_ctc 32.484612 loss_rnnt 22.862879 hw_loss 0.371705 lr 0.00045353 rank 1
2023-02-22 03:40:07,641 DEBUG TRAIN Batch 14/4800 loss 8.182411 loss_att 10.077021 loss_ctc 8.111466 loss_rnnt 7.681076 hw_loss 0.247261 lr 0.00045340 rank 7
2023-02-22 03:41:20,990 DEBUG TRAIN Batch 14/4900 loss 8.887995 loss_att 9.915859 loss_ctc 10.563456 loss_rnnt 8.370257 hw_loss 0.166446 lr 0.00045328 rank 2
2023-02-22 03:41:20,995 DEBUG TRAIN Batch 14/4900 loss 14.317013 loss_att 19.131248 loss_ctc 23.340389 loss_rnnt 12.039968 hw_loss 0.208277 lr 0.00045330 rank 0
2023-02-22 03:41:20,996 DEBUG TRAIN Batch 14/4900 loss 10.436112 loss_att 14.249981 loss_ctc 14.078265 loss_rnnt 8.977776 hw_loss 0.393644 lr 0.00045321 rank 7
2023-02-22 03:41:20,996 DEBUG TRAIN Batch 14/4900 loss 8.458505 loss_att 11.893673 loss_ctc 10.320946 loss_rnnt 7.310737 hw_loss 0.398266 lr 0.00045335 rank 1
2023-02-22 03:41:20,996 DEBUG TRAIN Batch 14/4900 loss 13.943589 loss_att 17.484276 loss_ctc 16.257465 loss_rnnt 12.808193 hw_loss 0.222641 lr 0.00045327 rank 3
2023-02-22 03:41:20,998 DEBUG TRAIN Batch 14/4900 loss 11.390513 loss_att 14.192344 loss_ctc 15.212174 loss_rnnt 10.167604 hw_loss 0.286851 lr 0.00045329 rank 6
2023-02-22 03:41:21,003 DEBUG TRAIN Batch 14/4900 loss 18.022264 loss_att 18.037128 loss_ctc 21.149220 loss_rnnt 17.488455 hw_loss 0.213582 lr 0.00045326 rank 5
2023-02-22 03:41:21,043 DEBUG TRAIN Batch 14/4900 loss 6.642341 loss_att 11.445983 loss_ctc 10.680206 loss_rnnt 5.010891 hw_loss 0.248135 lr 0.00045327 rank 4
2023-02-22 03:42:35,950 DEBUG TRAIN Batch 14/5000 loss 9.416270 loss_att 12.406890 loss_ctc 13.089293 loss_rnnt 8.153343 hw_loss 0.328250 lr 0.00045308 rank 4
2023-02-22 03:42:35,963 DEBUG TRAIN Batch 14/5000 loss 11.070859 loss_att 13.230390 loss_ctc 12.943566 loss_rnnt 10.284655 hw_loss 0.196134 lr 0.00045312 rank 0
2023-02-22 03:42:35,967 DEBUG TRAIN Batch 14/5000 loss 8.663046 loss_att 13.006960 loss_ctc 11.581516 loss_rnnt 7.212617 hw_loss 0.360967 lr 0.00045303 rank 7
2023-02-22 03:42:35,969 DEBUG TRAIN Batch 14/5000 loss 13.115870 loss_att 14.843871 loss_ctc 14.261673 loss_rnnt 12.382535 hw_loss 0.440550 lr 0.00045310 rank 2
2023-02-22 03:42:35,969 DEBUG TRAIN Batch 14/5000 loss 13.565377 loss_att 15.892069 loss_ctc 16.215183 loss_rnnt 12.575461 hw_loss 0.321133 lr 0.00045310 rank 6
2023-02-22 03:42:35,973 DEBUG TRAIN Batch 14/5000 loss 11.635083 loss_att 12.470024 loss_ctc 12.776199 loss_rnnt 11.123996 hw_loss 0.359908 lr 0.00045308 rank 3
2023-02-22 03:42:35,980 DEBUG TRAIN Batch 14/5000 loss 17.527441 loss_att 22.075697 loss_ctc 23.895348 loss_rnnt 15.606260 hw_loss 0.304640 lr 0.00045307 rank 5
2023-02-22 03:42:36,018 DEBUG TRAIN Batch 14/5000 loss 25.345549 loss_att 28.781548 loss_ctc 31.119528 loss_rnnt 23.705709 hw_loss 0.342704 lr 0.00045316 rank 1
2023-02-22 03:43:48,352 DEBUG TRAIN Batch 14/5100 loss 12.219004 loss_att 12.462711 loss_ctc 16.420116 loss_rnnt 11.353745 hw_loss 0.480694 lr 0.00045291 rank 2
2023-02-22 03:43:48,361 DEBUG TRAIN Batch 14/5100 loss 13.376178 loss_att 16.608170 loss_ctc 19.251194 loss_rnnt 11.819002 hw_loss 0.238952 lr 0.00045298 rank 1
2023-02-22 03:43:48,361 DEBUG TRAIN Batch 14/5100 loss 14.303708 loss_att 18.700098 loss_ctc 17.541412 loss_rnnt 12.851313 hw_loss 0.265169 lr 0.00045290 rank 3
2023-02-22 03:43:48,361 DEBUG TRAIN Batch 14/5100 loss 15.244968 loss_att 18.590271 loss_ctc 13.096904 loss_rnnt 14.755653 hw_loss 0.199992 lr 0.00045284 rank 7
2023-02-22 03:43:48,362 DEBUG TRAIN Batch 14/5100 loss 14.208999 loss_att 16.326691 loss_ctc 14.526358 loss_rnnt 13.569426 hw_loss 0.325726 lr 0.00045292 rank 6
2023-02-22 03:43:48,367 DEBUG TRAIN Batch 14/5100 loss 10.904010 loss_att 11.678220 loss_ctc 14.979899 loss_rnnt 9.997284 hw_loss 0.390811 lr 0.00045293 rank 0
2023-02-22 03:43:48,368 DEBUG TRAIN Batch 14/5100 loss 12.649277 loss_att 13.621360 loss_ctc 16.491261 loss_rnnt 11.752055 hw_loss 0.357263 lr 0.00045290 rank 4
2023-02-22 03:43:48,372 DEBUG TRAIN Batch 14/5100 loss 25.169065 loss_att 25.879789 loss_ctc 25.684210 loss_rnnt 24.710464 hw_loss 0.464566 lr 0.00045289 rank 5
2023-02-22 03:45:00,912 DEBUG TRAIN Batch 14/5200 loss 19.776825 loss_att 20.138504 loss_ctc 24.613277 loss_rnnt 18.923414 hw_loss 0.255402 lr 0.00045273 rank 2
2023-02-22 03:45:00,915 DEBUG TRAIN Batch 14/5200 loss 6.378408 loss_att 10.678352 loss_ctc 10.573874 loss_rnnt 4.845369 hw_loss 0.213104 lr 0.00045271 rank 3
2023-02-22 03:45:00,915 DEBUG TRAIN Batch 14/5200 loss 6.799669 loss_att 9.739554 loss_ctc 8.699951 loss_rnnt 5.864655 hw_loss 0.175622 lr 0.00045271 rank 4
2023-02-22 03:45:00,917 DEBUG TRAIN Batch 14/5200 loss 13.346401 loss_att 16.865707 loss_ctc 20.535200 loss_rnnt 11.505999 hw_loss 0.333816 lr 0.00045273 rank 6
2023-02-22 03:45:00,917 DEBUG TRAIN Batch 14/5200 loss 13.632641 loss_att 19.509794 loss_ctc 22.586044 loss_rnnt 11.087622 hw_loss 0.329628 lr 0.00045279 rank 1
2023-02-22 03:45:00,922 DEBUG TRAIN Batch 14/5200 loss 13.113105 loss_att 13.264029 loss_ctc 14.465433 loss_rnnt 12.810755 hw_loss 0.172227 lr 0.00045266 rank 7
2023-02-22 03:45:00,925 DEBUG TRAIN Batch 14/5200 loss 6.221000 loss_att 8.357840 loss_ctc 10.597593 loss_rnnt 5.112834 hw_loss 0.182346 lr 0.00045270 rank 5
2023-02-22 03:45:00,925 DEBUG TRAIN Batch 14/5200 loss 13.252776 loss_att 16.591614 loss_ctc 18.052734 loss_rnnt 11.770525 hw_loss 0.327167 lr 0.00045275 rank 0
2023-02-22 03:46:15,367 DEBUG TRAIN Batch 14/5300 loss 9.570093 loss_att 12.351753 loss_ctc 10.817751 loss_rnnt 8.770786 hw_loss 0.143663 lr 0.00045260 rank 1
2023-02-22 03:46:15,367 DEBUG TRAIN Batch 14/5300 loss 8.811717 loss_att 10.670909 loss_ctc 14.009383 loss_rnnt 7.645694 hw_loss 0.189681 lr 0.00045253 rank 4
2023-02-22 03:46:15,367 DEBUG TRAIN Batch 14/5300 loss 9.763387 loss_att 13.417233 loss_ctc 14.507548 loss_rnnt 8.324364 hw_loss 0.141935 lr 0.00045255 rank 6
2023-02-22 03:46:15,370 DEBUG TRAIN Batch 14/5300 loss 14.402698 loss_att 16.101048 loss_ctc 16.119373 loss_rnnt 13.666874 hw_loss 0.313619 lr 0.00045256 rank 0
2023-02-22 03:46:15,371 DEBUG TRAIN Batch 14/5300 loss 10.565525 loss_att 12.266146 loss_ctc 15.183733 loss_rnnt 9.502305 hw_loss 0.201251 lr 0.00045252 rank 5
2023-02-22 03:46:15,377 DEBUG TRAIN Batch 14/5300 loss 16.017685 loss_att 16.648914 loss_ctc 16.532446 loss_rnnt 15.480612 hw_loss 0.641610 lr 0.00045252 rank 3
2023-02-22 03:46:15,383 DEBUG TRAIN Batch 14/5300 loss 9.503601 loss_att 16.021730 loss_ctc 10.574970 loss_rnnt 7.937201 hw_loss 0.224860 lr 0.00045254 rank 2
2023-02-22 03:46:15,394 DEBUG TRAIN Batch 14/5300 loss 19.909485 loss_att 21.629223 loss_ctc 21.521996 loss_rnnt 19.196281 hw_loss 0.289231 lr 0.00045247 rank 7
2023-02-22 03:47:28,565 DEBUG TRAIN Batch 14/5400 loss 24.209322 loss_att 27.796694 loss_ctc 28.052092 loss_rnnt 22.756865 hw_loss 0.417406 lr 0.00045234 rank 3
2023-02-22 03:47:28,570 DEBUG TRAIN Batch 14/5400 loss 18.186682 loss_att 22.620607 loss_ctc 22.902828 loss_rnnt 16.530659 hw_loss 0.263285 lr 0.00045229 rank 7
2023-02-22 03:47:28,572 DEBUG TRAIN Batch 14/5400 loss 7.739206 loss_att 10.797509 loss_ctc 11.306733 loss_rnnt 6.531334 hw_loss 0.226014 lr 0.00045236 rank 2
2023-02-22 03:47:28,574 DEBUG TRAIN Batch 14/5400 loss 7.642245 loss_att 14.744284 loss_ctc 9.812288 loss_rnnt 5.822269 hw_loss 0.206680 lr 0.00045236 rank 6
2023-02-22 03:47:28,578 DEBUG TRAIN Batch 14/5400 loss 10.150293 loss_att 12.950813 loss_ctc 17.311441 loss_rnnt 8.500500 hw_loss 0.252881 lr 0.00045242 rank 1
2023-02-22 03:47:28,578 DEBUG TRAIN Batch 14/5400 loss 18.347277 loss_att 22.100437 loss_ctc 24.107273 loss_rnnt 16.710602 hw_loss 0.221331 lr 0.00045237 rank 0
2023-02-22 03:47:28,581 DEBUG TRAIN Batch 14/5400 loss 8.618361 loss_att 11.223657 loss_ctc 13.951334 loss_rnnt 7.266289 hw_loss 0.224904 lr 0.00045233 rank 5
2023-02-22 03:47:28,582 DEBUG TRAIN Batch 14/5400 loss 14.057144 loss_att 19.139811 loss_ctc 19.250082 loss_rnnt 12.199753 hw_loss 0.278375 lr 0.00045234 rank 4
2023-02-22 03:48:41,141 DEBUG TRAIN Batch 14/5500 loss 8.929146 loss_att 11.945333 loss_ctc 12.936490 loss_rnnt 7.663359 hw_loss 0.240443 lr 0.00045217 rank 2
2023-02-22 03:48:41,147 DEBUG TRAIN Batch 14/5500 loss 6.289052 loss_att 9.705133 loss_ctc 8.714131 loss_rnnt 5.149301 hw_loss 0.249734 lr 0.00045216 rank 4
2023-02-22 03:48:41,147 DEBUG TRAIN Batch 14/5500 loss 15.462075 loss_att 16.935863 loss_ctc 22.524406 loss_rnnt 14.069636 hw_loss 0.292571 lr 0.00045215 rank 5
2023-02-22 03:48:41,148 DEBUG TRAIN Batch 14/5500 loss 15.044350 loss_att 17.973255 loss_ctc 20.204487 loss_rnnt 13.621393 hw_loss 0.279668 lr 0.00045215 rank 3
2023-02-22 03:48:41,148 DEBUG TRAIN Batch 14/5500 loss 11.399851 loss_att 14.125294 loss_ctc 17.087418 loss_rnnt 9.988113 hw_loss 0.203073 lr 0.00045223 rank 1
2023-02-22 03:48:41,149 DEBUG TRAIN Batch 14/5500 loss 13.043232 loss_att 15.349359 loss_ctc 19.941509 loss_rnnt 11.567621 hw_loss 0.177404 lr 0.00045219 rank 0
2023-02-22 03:48:41,151 DEBUG TRAIN Batch 14/5500 loss 12.548112 loss_att 15.751820 loss_ctc 18.448524 loss_rnnt 10.975119 hw_loss 0.272870 lr 0.00045210 rank 7
2023-02-22 03:48:41,152 DEBUG TRAIN Batch 14/5500 loss 24.010406 loss_att 25.456970 loss_ctc 29.887705 loss_rnnt 22.808968 hw_loss 0.240907 lr 0.00045217 rank 6
2023-02-22 03:49:54,530 DEBUG TRAIN Batch 14/5600 loss 7.611705 loss_att 10.108430 loss_ctc 9.208313 loss_rnnt 6.764641 hw_loss 0.252822 lr 0.00045199 rank 6
2023-02-22 03:49:54,546 DEBUG TRAIN Batch 14/5600 loss 9.947769 loss_att 12.839956 loss_ctc 13.073171 loss_rnnt 8.755626 hw_loss 0.369349 lr 0.00045197 rank 3
2023-02-22 03:49:54,549 DEBUG TRAIN Batch 14/5600 loss 15.005346 loss_att 16.697609 loss_ctc 22.851477 loss_rnnt 13.471563 hw_loss 0.279713 lr 0.00045197 rank 4
2023-02-22 03:49:54,551 DEBUG TRAIN Batch 14/5600 loss 13.529556 loss_att 17.057171 loss_ctc 20.735283 loss_rnnt 11.682976 hw_loss 0.338051 lr 0.00045192 rank 7
2023-02-22 03:49:54,553 DEBUG TRAIN Batch 14/5600 loss 28.451763 loss_att 31.898273 loss_ctc 35.744320 loss_rnnt 26.638498 hw_loss 0.284289 lr 0.00045200 rank 0
2023-02-22 03:49:54,555 DEBUG TRAIN Batch 14/5600 loss 11.219235 loss_att 13.908899 loss_ctc 12.377175 loss_rnnt 10.328046 hw_loss 0.372869 lr 0.00045205 rank 1
2023-02-22 03:49:54,555 DEBUG TRAIN Batch 14/5600 loss 10.707830 loss_att 11.060557 loss_ctc 10.496288 loss_rnnt 10.502771 hw_loss 0.305100 lr 0.00045199 rank 2
2023-02-22 03:49:54,596 DEBUG TRAIN Batch 14/5600 loss 14.754506 loss_att 15.157201 loss_ctc 18.168385 loss_rnnt 14.047309 hw_loss 0.321514 lr 0.00045196 rank 5
2023-02-22 03:51:10,580 DEBUG TRAIN Batch 14/5700 loss 8.534439 loss_att 10.929227 loss_ctc 13.221401 loss_rnnt 7.265252 hw_loss 0.309938 lr 0.00045181 rank 6
2023-02-22 03:51:10,581 DEBUG TRAIN Batch 14/5700 loss 11.508362 loss_att 11.924086 loss_ctc 12.319376 loss_rnnt 11.090787 hw_loss 0.424302 lr 0.00045179 rank 3
2023-02-22 03:51:10,582 DEBUG TRAIN Batch 14/5700 loss 10.028064 loss_att 10.882248 loss_ctc 13.183622 loss_rnnt 9.149757 hw_loss 0.537616 lr 0.00045182 rank 0
2023-02-22 03:51:10,582 DEBUG TRAIN Batch 14/5700 loss 14.298343 loss_att 17.037130 loss_ctc 20.670155 loss_rnnt 12.792743 hw_loss 0.203002 lr 0.00045179 rank 4
2023-02-22 03:51:10,584 DEBUG TRAIN Batch 14/5700 loss 6.969784 loss_att 7.364050 loss_ctc 9.599354 loss_rnnt 6.340746 hw_loss 0.374203 lr 0.00045186 rank 1
2023-02-22 03:51:10,586 DEBUG TRAIN Batch 14/5700 loss 12.015924 loss_att 13.367842 loss_ctc 15.009256 loss_rnnt 11.151634 hw_loss 0.365240 lr 0.00045180 rank 2
2023-02-22 03:51:10,614 DEBUG TRAIN Batch 14/5700 loss 15.523901 loss_att 19.073570 loss_ctc 21.706081 loss_rnnt 13.905897 hw_loss 0.157087 lr 0.00045173 rank 7
2023-02-22 03:51:10,614 DEBUG TRAIN Batch 14/5700 loss 19.772770 loss_att 24.199022 loss_ctc 25.366970 loss_rnnt 18.012657 hw_loss 0.241812 lr 0.00045178 rank 5
2023-02-22 03:52:23,246 DEBUG TRAIN Batch 14/5800 loss 12.086448 loss_att 14.232437 loss_ctc 13.781187 loss_rnnt 11.196983 hw_loss 0.439315 lr 0.00045160 rank 3
2023-02-22 03:52:23,247 DEBUG TRAIN Batch 14/5800 loss 8.680048 loss_att 10.822166 loss_ctc 10.947262 loss_rnnt 7.707855 hw_loss 0.452765 lr 0.00045155 rank 7
2023-02-22 03:52:23,250 DEBUG TRAIN Batch 14/5800 loss 11.868315 loss_att 13.450943 loss_ctc 29.968929 loss_rnnt 9.036421 hw_loss 0.191163 lr 0.00045164 rank 0
2023-02-22 03:52:23,257 DEBUG TRAIN Batch 14/5800 loss 11.994755 loss_att 17.769283 loss_ctc 14.798347 loss_rnnt 10.283052 hw_loss 0.343093 lr 0.00045168 rank 1
2023-02-22 03:52:23,257 DEBUG TRAIN Batch 14/5800 loss 10.071247 loss_att 14.942109 loss_ctc 18.782871 loss_rnnt 7.824882 hw_loss 0.207454 lr 0.00045159 rank 5
2023-02-22 03:52:23,258 DEBUG TRAIN Batch 14/5800 loss 8.878595 loss_att 15.177207 loss_ctc 12.354383 loss_rnnt 7.075860 hw_loss 0.149203 lr 0.00045162 rank 6
2023-02-22 03:52:23,258 DEBUG TRAIN Batch 14/5800 loss 12.982231 loss_att 16.045803 loss_ctc 14.134432 loss_rnnt 12.077236 hw_loss 0.259974 lr 0.00045162 rank 2
2023-02-22 03:52:23,309 DEBUG TRAIN Batch 14/5800 loss 7.314708 loss_att 10.722308 loss_ctc 8.314958 loss_rnnt 6.381444 hw_loss 0.221955 lr 0.00045160 rank 4
2023-02-22 03:53:35,938 DEBUG TRAIN Batch 14/5900 loss 4.010243 loss_att 8.955954 loss_ctc 6.375314 loss_rnnt 2.606699 hw_loss 0.185736 lr 0.00045144 rank 6
2023-02-22 03:53:35,952 DEBUG TRAIN Batch 14/5900 loss 16.434225 loss_att 16.562658 loss_ctc 21.302048 loss_rnnt 15.628841 hw_loss 0.244973 lr 0.00045143 rank 2
2023-02-22 03:53:35,956 DEBUG TRAIN Batch 14/5900 loss 18.085339 loss_att 19.115324 loss_ctc 24.224285 loss_rnnt 16.894894 hw_loss 0.311105 lr 0.00045136 rank 7
2023-02-22 03:53:35,957 DEBUG TRAIN Batch 14/5900 loss 30.986124 loss_att 35.946697 loss_ctc 46.708004 loss_rnnt 27.748154 hw_loss 0.280510 lr 0.00045145 rank 0
2023-02-22 03:53:35,960 DEBUG TRAIN Batch 14/5900 loss 16.404543 loss_att 19.757719 loss_ctc 20.257448 loss_rnnt 15.063487 hw_loss 0.293815 lr 0.00045142 rank 3
2023-02-22 03:53:35,962 DEBUG TRAIN Batch 14/5900 loss 10.998239 loss_att 15.009743 loss_ctc 16.640953 loss_rnnt 9.306336 hw_loss 0.257324 lr 0.00045141 rank 5
2023-02-22 03:53:35,963 DEBUG TRAIN Batch 14/5900 loss 6.752528 loss_att 13.495927 loss_ctc 8.139286 loss_rnnt 5.051896 hw_loss 0.313220 lr 0.00045150 rank 1
2023-02-22 03:53:35,963 DEBUG TRAIN Batch 14/5900 loss 6.879424 loss_att 11.041608 loss_ctc 7.582847 loss_rnnt 5.804915 hw_loss 0.278029 lr 0.00045142 rank 4
2023-02-22 03:54:49,471 DEBUG TRAIN Batch 14/6000 loss 16.919245 loss_att 17.482786 loss_ctc 22.707638 loss_rnnt 15.912836 hw_loss 0.228591 lr 0.00045131 rank 1
2023-02-22 03:54:49,484 DEBUG TRAIN Batch 14/6000 loss 18.204697 loss_att 27.620880 loss_ctc 30.057129 loss_rnnt 14.578041 hw_loss 0.305803 lr 0.00045123 rank 4
2023-02-22 03:54:49,486 DEBUG TRAIN Batch 14/6000 loss 15.362423 loss_att 16.627548 loss_ctc 18.380520 loss_rnnt 14.565945 hw_loss 0.264452 lr 0.00045125 rank 2
2023-02-22 03:54:49,487 DEBUG TRAIN Batch 14/6000 loss 9.262425 loss_att 14.541511 loss_ctc 8.577381 loss_rnnt 8.212494 hw_loss 0.160225 lr 0.00045123 rank 3
2023-02-22 03:54:49,487 DEBUG TRAIN Batch 14/6000 loss 11.031019 loss_att 13.249167 loss_ctc 15.978580 loss_rnnt 9.717086 hw_loss 0.394928 lr 0.00045125 rank 6
2023-02-22 03:54:49,489 DEBUG TRAIN Batch 14/6000 loss 7.297501 loss_att 9.598522 loss_ctc 9.120114 loss_rnnt 6.426767 hw_loss 0.314087 lr 0.00045118 rank 7
2023-02-22 03:54:49,496 DEBUG TRAIN Batch 14/6000 loss 3.353660 loss_att 8.163772 loss_ctc 6.074699 loss_rnnt 1.870589 hw_loss 0.296706 lr 0.00045127 rank 0
2023-02-22 03:54:49,509 DEBUG TRAIN Batch 14/6000 loss 12.332731 loss_att 16.778275 loss_ctc 17.772991 loss_rnnt 10.584246 hw_loss 0.251264 lr 0.00045123 rank 5
2023-02-22 03:56:02,945 DEBUG TRAIN Batch 14/6100 loss 20.140112 loss_att 20.932417 loss_ctc 21.938084 loss_rnnt 19.577482 hw_loss 0.308329 lr 0.00045113 rank 1
2023-02-22 03:56:02,952 DEBUG TRAIN Batch 14/6100 loss 5.074471 loss_att 6.575296 loss_ctc 6.944651 loss_rnnt 4.334294 hw_loss 0.357475 lr 0.00045107 rank 6
2023-02-22 03:56:02,955 DEBUG TRAIN Batch 14/6100 loss 10.523295 loss_att 13.179241 loss_ctc 15.745831 loss_rnnt 9.127779 hw_loss 0.314977 lr 0.00045107 rank 2
2023-02-22 03:56:02,957 DEBUG TRAIN Batch 14/6100 loss 8.295119 loss_att 12.758165 loss_ctc 10.533852 loss_rnnt 6.990638 hw_loss 0.212575 lr 0.00045108 rank 0
2023-02-22 03:56:02,959 DEBUG TRAIN Batch 14/6100 loss 7.226227 loss_att 11.246821 loss_ctc 11.038979 loss_rnnt 5.801221 hw_loss 0.210975 lr 0.00045100 rank 7
2023-02-22 03:56:02,960 DEBUG TRAIN Batch 14/6100 loss 4.630190 loss_att 7.620794 loss_ctc 6.104031 loss_rnnt 3.740294 hw_loss 0.178619 lr 0.00045105 rank 3
2023-02-22 03:56:02,962 DEBUG TRAIN Batch 14/6100 loss 6.982047 loss_att 10.638739 loss_ctc 10.920053 loss_rnnt 5.637050 hw_loss 0.166107 lr 0.00045105 rank 4
2023-02-22 03:56:03,011 DEBUG TRAIN Batch 14/6100 loss 13.332326 loss_att 14.793901 loss_ctc 13.744024 loss_rnnt 12.886419 hw_loss 0.185062 lr 0.00045104 rank 5
2023-02-22 03:57:15,236 DEBUG TRAIN Batch 14/6200 loss 12.356618 loss_att 16.842033 loss_ctc 15.018955 loss_rnnt 10.946402 hw_loss 0.296540 lr 0.00045087 rank 3
2023-02-22 03:57:15,240 DEBUG TRAIN Batch 14/6200 loss 7.192755 loss_att 9.844260 loss_ctc 10.140382 loss_rnnt 6.149211 hw_loss 0.225425 lr 0.00045089 rank 6
2023-02-22 03:57:15,241 DEBUG TRAIN Batch 14/6200 loss 7.391185 loss_att 9.354944 loss_ctc 9.562187 loss_rnnt 6.556822 hw_loss 0.285270 lr 0.00045088 rank 2
2023-02-22 03:57:15,244 DEBUG TRAIN Batch 14/6200 loss 16.095947 loss_att 17.556967 loss_ctc 17.149733 loss_rnnt 15.481944 hw_loss 0.339926 lr 0.00045081 rank 7
2023-02-22 03:57:15,244 DEBUG TRAIN Batch 14/6200 loss 17.335638 loss_att 18.990587 loss_ctc 23.715696 loss_rnnt 16.078751 hw_loss 0.141043 lr 0.00045094 rank 1
2023-02-22 03:57:15,245 DEBUG TRAIN Batch 14/6200 loss 18.041708 loss_att 23.908216 loss_ctc 20.235825 loss_rnnt 16.460432 hw_loss 0.216421 lr 0.00045090 rank 0
2023-02-22 03:57:15,245 DEBUG TRAIN Batch 14/6200 loss 12.468028 loss_att 14.006053 loss_ctc 15.263028 loss_rnnt 11.665923 hw_loss 0.228437 lr 0.00045086 rank 5
2023-02-22 03:57:15,248 DEBUG TRAIN Batch 14/6200 loss 3.176460 loss_att 7.950497 loss_ctc 3.054475 loss_rnnt 2.112432 hw_loss 0.235286 lr 0.00045087 rank 4
2023-02-22 03:58:27,919 DEBUG TRAIN Batch 14/6300 loss 15.761526 loss_att 15.304306 loss_ctc 20.352804 loss_rnnt 14.968408 hw_loss 0.510736 lr 0.00045070 rank 2
2023-02-22 03:58:27,922 DEBUG TRAIN Batch 14/6300 loss 6.187602 loss_att 7.680242 loss_ctc 9.035081 loss_rnnt 5.224050 hw_loss 0.535051 lr 0.00045063 rank 7
2023-02-22 03:58:27,922 DEBUG TRAIN Batch 14/6300 loss 11.259940 loss_att 13.398308 loss_ctc 14.773789 loss_rnnt 10.240207 hw_loss 0.231650 lr 0.00045068 rank 3
2023-02-22 03:58:27,925 DEBUG TRAIN Batch 14/6300 loss 5.860682 loss_att 10.335549 loss_ctc 7.981126 loss_rnnt 4.487507 hw_loss 0.366516 lr 0.00045068 rank 4
2023-02-22 03:58:27,928 DEBUG TRAIN Batch 14/6300 loss 10.688715 loss_att 11.938748 loss_ctc 14.536786 loss_rnnt 9.775023 hw_loss 0.282392 lr 0.00045070 rank 6
2023-02-22 03:58:27,927 DEBUG TRAIN Batch 14/6300 loss 10.431540 loss_att 11.590621 loss_ctc 13.622526 loss_rnnt 9.609879 hw_loss 0.308212 lr 0.00045076 rank 1
2023-02-22 03:58:27,928 DEBUG TRAIN Batch 14/6300 loss 18.644476 loss_att 18.560551 loss_ctc 18.941471 loss_rnnt 18.534704 hw_loss 0.163046 lr 0.00045072 rank 0
2023-02-22 03:58:27,929 DEBUG TRAIN Batch 14/6300 loss 23.501141 loss_att 27.943562 loss_ctc 32.472565 loss_rnnt 21.324783 hw_loss 0.171905 lr 0.00045068 rank 5
2023-02-22 03:59:42,774 DEBUG TRAIN Batch 14/6400 loss 7.371633 loss_att 12.142496 loss_ctc 8.524151 loss_rnnt 6.179065 hw_loss 0.158862 lr 0.00045045 rank 7
2023-02-22 03:59:42,775 DEBUG TRAIN Batch 14/6400 loss 11.016951 loss_att 12.959631 loss_ctc 14.619570 loss_rnnt 9.759093 hw_loss 0.729323 lr 0.00045050 rank 4
2023-02-22 03:59:42,775 DEBUG TRAIN Batch 14/6400 loss 23.122797 loss_att 28.406532 loss_ctc 30.954224 loss_rnnt 20.885036 hw_loss 0.256542 lr 0.00045049 rank 5
2023-02-22 03:59:42,780 DEBUG TRAIN Batch 14/6400 loss 3.324408 loss_att 5.853102 loss_ctc 3.422399 loss_rnnt 2.739929 hw_loss 0.123140 lr 0.00045052 rank 2
2023-02-22 03:59:42,780 DEBUG TRAIN Batch 14/6400 loss 27.173464 loss_att 25.016335 loss_ctc 38.879745 loss_rnnt 25.901974 hw_loss 0.266401 lr 0.00045050 rank 3
2023-02-22 03:59:42,787 DEBUG TRAIN Batch 14/6400 loss 16.942955 loss_att 19.886919 loss_ctc 20.616232 loss_rnnt 15.719172 hw_loss 0.272282 lr 0.00045052 rank 6
2023-02-22 03:59:42,790 DEBUG TRAIN Batch 14/6400 loss 7.588953 loss_att 12.192393 loss_ctc 13.711327 loss_rnnt 5.737401 hw_loss 0.214774 lr 0.00045058 rank 1
2023-02-22 03:59:42,795 DEBUG TRAIN Batch 14/6400 loss 6.297807 loss_att 11.708119 loss_ctc 8.247961 loss_rnnt 4.883121 hw_loss 0.136129 lr 0.00045053 rank 0
2023-02-22 04:00:56,454 DEBUG TRAIN Batch 14/6500 loss 10.254212 loss_att 13.056775 loss_ctc 12.858816 loss_rnnt 9.165587 hw_loss 0.339060 lr 0.00045035 rank 0
2023-02-22 04:00:56,456 DEBUG TRAIN Batch 14/6500 loss 8.400372 loss_att 13.001777 loss_ctc 9.978434 loss_rnnt 7.194954 hw_loss 0.140117 lr 0.00045026 rank 7
2023-02-22 04:00:56,456 DEBUG TRAIN Batch 14/6500 loss 13.199112 loss_att 18.058214 loss_ctc 18.818211 loss_rnnt 11.408644 hw_loss 0.130190 lr 0.00045034 rank 6
2023-02-22 04:00:56,459 DEBUG TRAIN Batch 14/6500 loss 15.553878 loss_att 17.401939 loss_ctc 21.841614 loss_rnnt 14.124599 hw_loss 0.414942 lr 0.00045032 rank 4
2023-02-22 04:00:56,459 DEBUG TRAIN Batch 14/6500 loss 13.953288 loss_att 22.588850 loss_ctc 19.112232 loss_rnnt 11.402064 hw_loss 0.255473 lr 0.00045033 rank 2
2023-02-22 04:00:56,460 DEBUG TRAIN Batch 14/6500 loss 4.261818 loss_att 9.456038 loss_ctc 5.914833 loss_rnnt 2.866569 hw_loss 0.255007 lr 0.00045031 rank 5
2023-02-22 04:00:56,460 DEBUG TRAIN Batch 14/6500 loss 20.843351 loss_att 30.191473 loss_ctc 30.457222 loss_rnnt 17.601318 hw_loss 0.169796 lr 0.00045032 rank 3
2023-02-22 04:00:56,466 DEBUG TRAIN Batch 14/6500 loss 14.317250 loss_att 21.054245 loss_ctc 20.768387 loss_rnnt 11.927188 hw_loss 0.342210 lr 0.00045040 rank 1
2023-02-22 04:02:08,977 DEBUG TRAIN Batch 14/6600 loss 3.983325 loss_att 7.476070 loss_ctc 5.536957 loss_rnnt 2.962759 hw_loss 0.215373 lr 0.00045014 rank 4
2023-02-22 04:02:08,979 DEBUG TRAIN Batch 14/6600 loss 14.853191 loss_att 15.443348 loss_ctc 18.594494 loss_rnnt 14.029533 hw_loss 0.387725 lr 0.00045015 rank 2
2023-02-22 04:02:08,980 DEBUG TRAIN Batch 14/6600 loss 12.245546 loss_att 16.250053 loss_ctc 11.353490 loss_rnnt 11.448705 hw_loss 0.215401 lr 0.00045021 rank 1
2023-02-22 04:02:08,983 DEBUG TRAIN Batch 14/6600 loss 12.254296 loss_att 16.431396 loss_ctc 14.910563 loss_rnnt 10.889761 hw_loss 0.328025 lr 0.00045013 rank 5
2023-02-22 04:02:08,985 DEBUG TRAIN Batch 14/6600 loss 15.992901 loss_att 18.421816 loss_ctc 18.108757 loss_rnnt 15.106419 hw_loss 0.222347 lr 0.00045015 rank 6
2023-02-22 04:02:08,987 DEBUG TRAIN Batch 14/6600 loss 21.972908 loss_att 24.140289 loss_ctc 23.751379 loss_rnnt 21.127743 hw_loss 0.327297 lr 0.00045017 rank 0
2023-02-22 04:02:08,995 DEBUG TRAIN Batch 14/6600 loss 7.528087 loss_att 10.020980 loss_ctc 10.056280 loss_rnnt 6.583202 hw_loss 0.204776 lr 0.00045013 rank 3
2023-02-22 04:02:09,031 DEBUG TRAIN Batch 14/6600 loss 21.082310 loss_att 25.940414 loss_ctc 26.267399 loss_rnnt 19.299082 hw_loss 0.225494 lr 0.00045008 rank 7
2023-02-22 04:03:22,017 DEBUG TRAIN Batch 14/6700 loss 13.321751 loss_att 15.051189 loss_ctc 16.695778 loss_rnnt 12.449832 hw_loss 0.142804 lr 0.00044997 rank 2
2023-02-22 04:03:22,020 DEBUG TRAIN Batch 14/6700 loss 8.770196 loss_att 12.083358 loss_ctc 10.239578 loss_rnnt 7.794072 hw_loss 0.220452 lr 0.00044990 rank 7
2023-02-22 04:03:22,023 DEBUG TRAIN Batch 14/6700 loss 10.155480 loss_att 11.891562 loss_ctc 13.864204 loss_rnnt 9.222706 hw_loss 0.170741 lr 0.00044999 rank 0
2023-02-22 04:03:22,024 DEBUG TRAIN Batch 14/6700 loss 12.394362 loss_att 16.377111 loss_ctc 16.529272 loss_rnnt 10.932640 hw_loss 0.213471 lr 0.00044995 rank 3
2023-02-22 04:03:22,024 DEBUG TRAIN Batch 14/6700 loss 18.057034 loss_att 23.583054 loss_ctc 26.876507 loss_rnnt 15.622459 hw_loss 0.287701 lr 0.00044997 rank 6
2023-02-22 04:03:22,024 DEBUG TRAIN Batch 14/6700 loss 17.322037 loss_att 19.229521 loss_ctc 22.586195 loss_rnnt 16.135004 hw_loss 0.194339 lr 0.00045003 rank 1
2023-02-22 04:03:22,038 DEBUG TRAIN Batch 14/6700 loss 10.427083 loss_att 11.024776 loss_ctc 13.459290 loss_rnnt 9.777776 hw_loss 0.235265 lr 0.00044994 rank 5
2023-02-22 04:03:22,082 DEBUG TRAIN Batch 14/6700 loss 8.973292 loss_att 13.516989 loss_ctc 9.844275 loss_rnnt 7.813867 hw_loss 0.252292 lr 0.00044995 rank 4
2023-02-22 04:04:37,897 DEBUG TRAIN Batch 14/6800 loss 18.796347 loss_att 19.805635 loss_ctc 22.538399 loss_rnnt 17.938917 hw_loss 0.293683 lr 0.00044979 rank 6
2023-02-22 04:04:37,897 DEBUG TRAIN Batch 14/6800 loss 17.858114 loss_att 19.395739 loss_ctc 19.999050 loss_rnnt 17.193287 hw_loss 0.134710 lr 0.00044977 rank 3
2023-02-22 04:04:37,899 DEBUG TRAIN Batch 14/6800 loss 16.452402 loss_att 22.493382 loss_ctc 22.363529 loss_rnnt 14.399986 hw_loss 0.105129 lr 0.00044985 rank 1
2023-02-22 04:04:37,902 DEBUG TRAIN Batch 14/6800 loss 6.751548 loss_att 10.585590 loss_ctc 10.868097 loss_rnnt 5.271482 hw_loss 0.308221 lr 0.00044972 rank 7
2023-02-22 04:04:37,903 DEBUG TRAIN Batch 14/6800 loss 9.990459 loss_att 12.441658 loss_ctc 12.075949 loss_rnnt 9.097347 hw_loss 0.234012 lr 0.00044979 rank 2
2023-02-22 04:04:37,904 DEBUG TRAIN Batch 14/6800 loss 1.883408 loss_att 4.430501 loss_ctc 2.334974 loss_rnnt 1.149095 hw_loss 0.308785 lr 0.00044977 rank 4
2023-02-22 04:04:37,907 DEBUG TRAIN Batch 14/6800 loss 10.256932 loss_att 13.545906 loss_ctc 13.168440 loss_rnnt 9.068120 hw_loss 0.267779 lr 0.00044976 rank 5
2023-02-22 04:04:37,911 DEBUG TRAIN Batch 14/6800 loss 8.715046 loss_att 10.776779 loss_ctc 12.283571 loss_rnnt 7.671415 hw_loss 0.291526 lr 0.00044980 rank 0
2023-02-22 04:05:51,253 DEBUG TRAIN Batch 14/6900 loss 12.350856 loss_att 12.671346 loss_ctc 16.918827 loss_rnnt 11.460408 hw_loss 0.407413 lr 0.00044960 rank 2
2023-02-22 04:05:51,258 DEBUG TRAIN Batch 14/6900 loss 18.264187 loss_att 22.936934 loss_ctc 24.437813 loss_rnnt 16.367796 hw_loss 0.260047 lr 0.00044959 rank 3
2023-02-22 04:05:51,258 DEBUG TRAIN Batch 14/6900 loss 9.464318 loss_att 11.442781 loss_ctc 10.925592 loss_rnnt 8.705905 hw_loss 0.314782 lr 0.00044967 rank 1
2023-02-22 04:05:51,259 DEBUG TRAIN Batch 14/6900 loss 12.890923 loss_att 13.295424 loss_ctc 14.726440 loss_rnnt 12.395655 hw_loss 0.318060 lr 0.00044958 rank 5
2023-02-22 04:05:51,263 DEBUG TRAIN Batch 14/6900 loss 19.977812 loss_att 20.281708 loss_ctc 28.303802 loss_rnnt 18.664915 hw_loss 0.266222 lr 0.00044961 rank 6
2023-02-22 04:05:51,263 DEBUG TRAIN Batch 14/6900 loss 6.965039 loss_att 8.691036 loss_ctc 10.796468 loss_rnnt 5.818606 hw_loss 0.544454 lr 0.00044954 rank 7
2023-02-22 04:05:51,265 DEBUG TRAIN Batch 14/6900 loss 12.921138 loss_att 12.723573 loss_ctc 14.428912 loss_rnnt 12.551195 hw_loss 0.390784 lr 0.00044959 rank 4
2023-02-22 04:05:51,268 DEBUG TRAIN Batch 14/6900 loss 13.469265 loss_att 15.495204 loss_ctc 21.166338 loss_rnnt 11.849459 hw_loss 0.353138 lr 0.00044962 rank 0
2023-02-22 04:07:03,684 DEBUG TRAIN Batch 14/7000 loss 7.322460 loss_att 10.709984 loss_ctc 11.410743 loss_rnnt 5.854019 hw_loss 0.460934 lr 0.00044941 rank 3
2023-02-22 04:07:03,695 DEBUG TRAIN Batch 14/7000 loss 5.034081 loss_att 8.914278 loss_ctc 7.988784 loss_rnnt 3.627104 hw_loss 0.444333 lr 0.00044943 rank 6
2023-02-22 04:07:03,703 DEBUG TRAIN Batch 14/7000 loss 8.166596 loss_att 15.694016 loss_ctc 13.238503 loss_rnnt 5.779727 hw_loss 0.384622 lr 0.00044940 rank 5
2023-02-22 04:07:03,704 DEBUG TRAIN Batch 14/7000 loss 8.478844 loss_att 11.347157 loss_ctc 9.766574 loss_rnnt 7.562812 hw_loss 0.320011 lr 0.00044935 rank 7
2023-02-22 04:07:03,705 DEBUG TRAIN Batch 14/7000 loss 15.952262 loss_att 16.059618 loss_ctc 21.097385 loss_rnnt 14.967153 hw_loss 0.520541 lr 0.00044944 rank 0
2023-02-22 04:07:03,705 DEBUG TRAIN Batch 14/7000 loss 18.272287 loss_att 21.417253 loss_ctc 31.924055 loss_rnnt 15.737940 hw_loss 0.159596 lr 0.00044942 rank 2
2023-02-22 04:07:03,710 DEBUG TRAIN Batch 14/7000 loss 8.322560 loss_att 9.335154 loss_ctc 7.694078 loss_rnnt 8.062228 hw_loss 0.265523 lr 0.00044948 rank 1
2023-02-22 04:07:03,751 DEBUG TRAIN Batch 14/7000 loss 22.414516 loss_att 21.817760 loss_ctc 31.385374 loss_rnnt 21.219631 hw_loss 0.221475 lr 0.00044941 rank 4
2023-02-22 04:08:18,070 DEBUG TRAIN Batch 14/7100 loss 18.470449 loss_att 21.301861 loss_ctc 25.558792 loss_rnnt 16.841522 hw_loss 0.220372 lr 0.00044930 rank 1
2023-02-22 04:08:18,079 DEBUG TRAIN Batch 14/7100 loss 12.849404 loss_att 12.245876 loss_ctc 15.029517 loss_rnnt 12.354475 hw_loss 0.609288 lr 0.00044923 rank 4
2023-02-22 04:08:18,080 DEBUG TRAIN Batch 14/7100 loss 5.169450 loss_att 8.034384 loss_ctc 6.639876 loss_rnnt 4.362195 hw_loss 0.071647 lr 0.00044925 rank 6
2023-02-22 04:08:18,082 DEBUG TRAIN Batch 14/7100 loss 14.625393 loss_att 18.196014 loss_ctc 21.893780 loss_rnnt 12.766917 hw_loss 0.328563 lr 0.00044924 rank 2
2023-02-22 04:08:18,084 DEBUG TRAIN Batch 14/7100 loss 14.511410 loss_att 17.372568 loss_ctc 15.223819 loss_rnnt 13.621616 hw_loss 0.417326 lr 0.00044923 rank 3
2023-02-22 04:08:18,085 DEBUG TRAIN Batch 14/7100 loss 8.099564 loss_att 9.797894 loss_ctc 10.158080 loss_rnnt 7.383896 hw_loss 0.190372 lr 0.00044926 rank 0
2023-02-22 04:08:18,086 DEBUG TRAIN Batch 14/7100 loss 10.626892 loss_att 14.783956 loss_ctc 15.247650 loss_rnnt 8.985865 hw_loss 0.362836 lr 0.00044922 rank 5
2023-02-22 04:08:18,088 DEBUG TRAIN Batch 14/7100 loss 4.258549 loss_att 5.007762 loss_ctc 5.214811 loss_rnnt 3.758969 hw_loss 0.416691 lr 0.00044917 rank 7
2023-02-22 04:09:30,842 DEBUG TRAIN Batch 14/7200 loss 16.589737 loss_att 15.703794 loss_ctc 18.845371 loss_rnnt 16.331999 hw_loss 0.251578 lr 0.00044906 rank 2
2023-02-22 04:09:30,845 DEBUG TRAIN Batch 14/7200 loss 7.492622 loss_att 10.493971 loss_ctc 11.016250 loss_rnnt 6.316572 hw_loss 0.198683 lr 0.00044906 rank 6
2023-02-22 04:09:30,848 DEBUG TRAIN Batch 14/7200 loss 12.345997 loss_att 16.288441 loss_ctc 17.943003 loss_rnnt 10.659969 hw_loss 0.283634 lr 0.00044904 rank 3
2023-02-22 04:09:30,848 DEBUG TRAIN Batch 14/7200 loss 12.114450 loss_att 16.202995 loss_ctc 15.751890 loss_rnnt 10.703750 hw_loss 0.202501 lr 0.00044905 rank 4
2023-02-22 04:09:30,850 DEBUG TRAIN Batch 14/7200 loss 16.333097 loss_att 19.728046 loss_ctc 24.046898 loss_rnnt 14.542688 hw_loss 0.155457 lr 0.00044908 rank 0
2023-02-22 04:09:30,852 DEBUG TRAIN Batch 14/7200 loss 12.661470 loss_att 16.788849 loss_ctc 15.830168 loss_rnnt 11.339630 hw_loss 0.138509 lr 0.00044904 rank 5
2023-02-22 04:09:30,853 DEBUG TRAIN Batch 14/7200 loss 12.490790 loss_att 14.444330 loss_ctc 20.112148 loss_rnnt 10.932425 hw_loss 0.284020 lr 0.00044912 rank 1
2023-02-22 04:09:30,856 DEBUG TRAIN Batch 14/7200 loss 7.283011 loss_att 12.072880 loss_ctc 9.521484 loss_rnnt 5.946334 hw_loss 0.150451 lr 0.00044899 rank 7
2023-02-22 04:10:42,787 DEBUG TRAIN Batch 14/7300 loss 11.089489 loss_att 14.655570 loss_ctc 14.572454 loss_rnnt 9.808760 hw_loss 0.193346 lr 0.00044888 rank 6
2023-02-22 04:10:42,790 DEBUG TRAIN Batch 14/7300 loss 17.570436 loss_att 19.152321 loss_ctc 22.233837 loss_rnnt 16.535818 hw_loss 0.180855 lr 0.00044886 rank 3
2023-02-22 04:10:42,790 DEBUG TRAIN Batch 14/7300 loss 10.448635 loss_att 14.283619 loss_ctc 15.546206 loss_rnnt 8.861523 hw_loss 0.263325 lr 0.00044894 rank 1
2023-02-22 04:10:42,793 DEBUG TRAIN Batch 14/7300 loss 10.207927 loss_att 15.707235 loss_ctc 11.139395 loss_rnnt 8.857153 hw_loss 0.237592 lr 0.00044886 rank 5
2023-02-22 04:10:42,794 DEBUG TRAIN Batch 14/7300 loss 17.571857 loss_att 19.916864 loss_ctc 22.931797 loss_rnnt 16.190365 hw_loss 0.370936 lr 0.00044888 rank 2
2023-02-22 04:10:42,795 DEBUG TRAIN Batch 14/7300 loss 15.920946 loss_att 19.471571 loss_ctc 23.534496 loss_rnnt 13.948849 hw_loss 0.462810 lr 0.00044886 rank 4
2023-02-22 04:10:42,797 DEBUG TRAIN Batch 14/7300 loss 12.977015 loss_att 17.104721 loss_ctc 18.579269 loss_rnnt 11.251063 hw_loss 0.287705 lr 0.00044881 rank 7
2023-02-22 04:10:42,799 DEBUG TRAIN Batch 14/7300 loss 10.070310 loss_att 14.006306 loss_ctc 14.894534 loss_rnnt 8.516705 hw_loss 0.230955 lr 0.00044890 rank 0
2023-02-22 04:11:55,986 DEBUG TRAIN Batch 14/7400 loss 6.782146 loss_att 9.457609 loss_ctc 9.204859 loss_rnnt 5.787268 hw_loss 0.256419 lr 0.00044863 rank 7
2023-02-22 04:11:55,996 DEBUG TRAIN Batch 14/7400 loss 12.943334 loss_att 16.328274 loss_ctc 18.554390 loss_rnnt 11.450643 hw_loss 0.126678 lr 0.00044870 rank 6
2023-02-22 04:11:55,997 DEBUG TRAIN Batch 14/7400 loss 23.782389 loss_att 25.929882 loss_ctc 26.807955 loss_rnnt 22.890270 hw_loss 0.111024 lr 0.00044870 rank 2
2023-02-22 04:11:55,997 DEBUG TRAIN Batch 14/7400 loss 7.303681 loss_att 8.249835 loss_ctc 8.115891 loss_rnnt 6.745959 hw_loss 0.487867 lr 0.00044876 rank 1
2023-02-22 04:11:55,998 DEBUG TRAIN Batch 14/7400 loss 13.227562 loss_att 15.476580 loss_ctc 16.973330 loss_rnnt 12.143211 hw_loss 0.253334 lr 0.00044868 rank 3
2023-02-22 04:11:56,002 DEBUG TRAIN Batch 14/7400 loss 13.560863 loss_att 17.734991 loss_ctc 17.150780 loss_rnnt 12.166876 hw_loss 0.150949 lr 0.00044872 rank 0
2023-02-22 04:11:56,007 DEBUG TRAIN Batch 14/7400 loss 10.882010 loss_att 14.151943 loss_ctc 17.713501 loss_rnnt 9.211448 hw_loss 0.198209 lr 0.00044868 rank 4
2023-02-22 04:11:56,040 DEBUG TRAIN Batch 14/7400 loss 15.109108 loss_att 17.694304 loss_ctc 17.893402 loss_rnnt 14.095842 hw_loss 0.234351 lr 0.00044868 rank 5
2023-02-22 04:13:11,161 DEBUG TRAIN Batch 14/7500 loss 15.563246 loss_att 17.395226 loss_ctc 20.492849 loss_rnnt 14.390637 hw_loss 0.279245 lr 0.00044858 rank 1
2023-02-22 04:13:11,163 DEBUG TRAIN Batch 14/7500 loss 9.737457 loss_att 14.466795 loss_ctc 13.287546 loss_rnnt 8.198168 hw_loss 0.225143 lr 0.00044850 rank 4
2023-02-22 04:13:11,164 DEBUG TRAIN Batch 14/7500 loss 10.897408 loss_att 11.752381 loss_ctc 14.413219 loss_rnnt 10.085347 hw_loss 0.323046 lr 0.00044850 rank 3
2023-02-22 04:13:11,164 DEBUG TRAIN Batch 14/7500 loss 12.802030 loss_att 13.572489 loss_ctc 18.254379 loss_rnnt 11.773908 hw_loss 0.275718 lr 0.00044845 rank 7
2023-02-22 04:13:11,165 DEBUG TRAIN Batch 14/7500 loss 13.230326 loss_att 15.909320 loss_ctc 16.234318 loss_rnnt 12.068615 hw_loss 0.422585 lr 0.00044854 rank 0
2023-02-22 04:13:11,166 DEBUG TRAIN Batch 14/7500 loss 10.878672 loss_att 14.933455 loss_ctc 19.079906 loss_rnnt 8.821178 hw_loss 0.286946 lr 0.00044852 rank 6
2023-02-22 04:13:11,168 DEBUG TRAIN Batch 14/7500 loss 10.241977 loss_att 12.100722 loss_ctc 14.448357 loss_rnnt 9.182199 hw_loss 0.238458 lr 0.00044852 rank 2
2023-02-22 04:13:11,168 DEBUG TRAIN Batch 14/7500 loss 10.398600 loss_att 10.118314 loss_ctc 14.375216 loss_rnnt 9.677568 hw_loss 0.462888 lr 0.00044849 rank 5
2023-02-22 04:14:23,943 DEBUG TRAIN Batch 14/7600 loss 10.080038 loss_att 14.819901 loss_ctc 17.371288 loss_rnnt 8.058126 hw_loss 0.190824 lr 0.00044834 rank 2
2023-02-22 04:14:23,954 DEBUG TRAIN Batch 14/7600 loss 14.857168 loss_att 14.311978 loss_ctc 20.213373 loss_rnnt 14.049562 hw_loss 0.379656 lr 0.00044834 rank 6
2023-02-22 04:14:23,959 DEBUG TRAIN Batch 14/7600 loss 16.163795 loss_att 17.830584 loss_ctc 20.083284 loss_rnnt 15.213788 hw_loss 0.176342 lr 0.00044836 rank 0
2023-02-22 04:14:23,958 DEBUG TRAIN Batch 14/7600 loss 10.594133 loss_att 10.807585 loss_ctc 13.380709 loss_rnnt 9.874356 hw_loss 0.572894 lr 0.00044840 rank 1
2023-02-22 04:14:23,959 DEBUG TRAIN Batch 14/7600 loss 16.770130 loss_att 19.399118 loss_ctc 22.556623 loss_rnnt 15.352966 hw_loss 0.224687 lr 0.00044831 rank 5
2023-02-22 04:14:23,960 DEBUG TRAIN Batch 14/7600 loss 13.100376 loss_att 13.371484 loss_ctc 16.208416 loss_rnnt 12.427406 hw_loss 0.383141 lr 0.00044832 rank 4
2023-02-22 04:14:23,963 DEBUG TRAIN Batch 14/7600 loss 12.161220 loss_att 18.144402 loss_ctc 18.209000 loss_rnnt 9.993979 hw_loss 0.307940 lr 0.00044832 rank 3
2023-02-22 04:14:24,017 DEBUG TRAIN Batch 14/7600 loss 11.175234 loss_att 13.694614 loss_ctc 16.821146 loss_rnnt 9.818185 hw_loss 0.188219 lr 0.00044827 rank 7
2023-02-22 04:15:36,393 DEBUG TRAIN Batch 14/7700 loss 15.124902 loss_att 18.524097 loss_ctc 21.391785 loss_rnnt 13.515509 hw_loss 0.176194 lr 0.00044816 rank 6
2023-02-22 04:15:36,396 DEBUG TRAIN Batch 14/7700 loss 17.345650 loss_att 22.788208 loss_ctc 25.000191 loss_rnnt 15.038395 hw_loss 0.371510 lr 0.00044816 rank 2
2023-02-22 04:15:36,398 DEBUG TRAIN Batch 14/7700 loss 9.294249 loss_att 9.453173 loss_ctc 10.660949 loss_rnnt 8.733789 hw_loss 0.649591 lr 0.00044818 rank 0
2023-02-22 04:15:36,399 DEBUG TRAIN Batch 14/7700 loss 5.316313 loss_att 8.145449 loss_ctc 7.894491 loss_rnnt 4.263234 hw_loss 0.269053 lr 0.00044822 rank 1
2023-02-22 04:15:36,401 DEBUG TRAIN Batch 14/7700 loss 10.244002 loss_att 13.191330 loss_ctc 16.811413 loss_rnnt 8.565351 hw_loss 0.400371 lr 0.00044814 rank 3
2023-02-22 04:15:36,402 DEBUG TRAIN Batch 14/7700 loss 7.592589 loss_att 12.089375 loss_ctc 6.813262 loss_rnnt 6.676533 hw_loss 0.226142 lr 0.00044809 rank 7
2023-02-22 04:15:36,403 DEBUG TRAIN Batch 14/7700 loss 14.434235 loss_att 15.177388 loss_ctc 16.192097 loss_rnnt 13.935606 hw_loss 0.216781 lr 0.00044814 rank 4
2023-02-22 04:15:36,406 DEBUG TRAIN Batch 14/7700 loss 17.140030 loss_att 18.519451 loss_ctc 21.004759 loss_rnnt 16.219368 hw_loss 0.242776 lr 0.00044813 rank 5
2023-02-22 04:16:49,993 DEBUG TRAIN Batch 14/7800 loss 7.820113 loss_att 11.131868 loss_ctc 8.701562 loss_rnnt 6.856838 hw_loss 0.343871 lr 0.00044796 rank 3
2023-02-22 04:16:50,008 DEBUG TRAIN Batch 14/7800 loss 6.945866 loss_att 11.667010 loss_ctc 8.604200 loss_rnnt 5.699108 hw_loss 0.152658 lr 0.00044796 rank 4
2023-02-22 04:16:50,007 DEBUG TRAIN Batch 14/7800 loss 22.872263 loss_att 33.371025 loss_ctc 34.976902 loss_rnnt 18.913334 hw_loss 0.459802 lr 0.00044798 rank 6
2023-02-22 04:16:50,008 DEBUG TRAIN Batch 14/7800 loss 6.200457 loss_att 10.008889 loss_ctc 7.850780 loss_rnnt 5.121750 hw_loss 0.181832 lr 0.00044798 rank 2
2023-02-22 04:16:50,009 DEBUG TRAIN Batch 14/7800 loss 13.985355 loss_att 20.502083 loss_ctc 13.538106 loss_rnnt 12.667126 hw_loss 0.139721 lr 0.00044795 rank 5
2023-02-22 04:16:50,010 DEBUG TRAIN Batch 14/7800 loss 5.648057 loss_att 10.969180 loss_ctc 8.315760 loss_rnnt 4.083292 hw_loss 0.271586 lr 0.00044791 rank 7
2023-02-22 04:16:50,014 DEBUG TRAIN Batch 14/7800 loss 7.304187 loss_att 11.795165 loss_ctc 8.607866 loss_rnnt 6.080553 hw_loss 0.284279 lr 0.00044804 rank 1
2023-02-22 04:16:50,031 DEBUG TRAIN Batch 14/7800 loss 12.121037 loss_att 13.064402 loss_ctc 15.612007 loss_rnnt 11.332891 hw_loss 0.251266 lr 0.00044800 rank 0
2023-02-22 04:18:03,306 DEBUG TRAIN Batch 14/7900 loss 10.675196 loss_att 12.089675 loss_ctc 11.166541 loss_rnnt 10.098195 hw_loss 0.428609 lr 0.00044782 rank 0
2023-02-22 04:18:03,306 DEBUG TRAIN Batch 14/7900 loss 17.803932 loss_att 17.559666 loss_ctc 16.967144 loss_rnnt 17.807272 hw_loss 0.294538 lr 0.00044780 rank 2
2023-02-22 04:18:03,307 DEBUG TRAIN Batch 14/7900 loss 13.199955 loss_att 16.329706 loss_ctc 16.224541 loss_rnnt 12.000237 hw_loss 0.319670 lr 0.00044780 rank 6
2023-02-22 04:18:03,308 DEBUG TRAIN Batch 14/7900 loss 4.132551 loss_att 5.504909 loss_ctc 5.181414 loss_rnnt 3.567144 hw_loss 0.283288 lr 0.00044778 rank 4
2023-02-22 04:18:03,309 DEBUG TRAIN Batch 14/7900 loss 7.180323 loss_att 10.453213 loss_ctc 12.095289 loss_rnnt 5.703923 hw_loss 0.312173 lr 0.00044778 rank 3
2023-02-22 04:18:03,312 DEBUG TRAIN Batch 14/7900 loss 18.840628 loss_att 19.439222 loss_ctc 19.866024 loss_rnnt 18.511993 hw_loss 0.135364 lr 0.00044786 rank 1
2023-02-22 04:18:03,314 DEBUG TRAIN Batch 14/7900 loss 9.980639 loss_att 12.882013 loss_ctc 16.986353 loss_rnnt 8.254505 hw_loss 0.397054 lr 0.00044777 rank 5
2023-02-22 04:18:03,333 DEBUG TRAIN Batch 14/7900 loss 16.818367 loss_att 21.394451 loss_ctc 24.153229 loss_rnnt 14.820296 hw_loss 0.196634 lr 0.00044773 rank 7
2023-02-22 04:19:15,275 DEBUG TRAIN Batch 14/8000 loss 20.783504 loss_att 23.812443 loss_ctc 28.928822 loss_rnnt 18.927193 hw_loss 0.308405 lr 0.00044764 rank 0
2023-02-22 04:19:15,276 DEBUG TRAIN Batch 14/8000 loss 15.211444 loss_att 16.354202 loss_ctc 18.889345 loss_rnnt 14.337429 hw_loss 0.290768 lr 0.00044762 rank 2
2023-02-22 04:19:15,278 DEBUG TRAIN Batch 14/8000 loss 12.871414 loss_att 14.996269 loss_ctc 18.121752 loss_rnnt 11.617588 hw_loss 0.241521 lr 0.00044755 rank 7
2023-02-22 04:19:15,282 DEBUG TRAIN Batch 14/8000 loss 9.804008 loss_att 13.753019 loss_ctc 15.846754 loss_rnnt 8.029482 hw_loss 0.335672 lr 0.00044760 rank 4
2023-02-22 04:19:15,281 DEBUG TRAIN Batch 14/8000 loss 15.859491 loss_att 15.841956 loss_ctc 17.945499 loss_rnnt 15.429620 hw_loss 0.291083 lr 0.00044762 rank 6
2023-02-22 04:19:15,283 DEBUG TRAIN Batch 14/8000 loss 6.236303 loss_att 8.473640 loss_ctc 8.671391 loss_rnnt 5.353433 hw_loss 0.207609 lr 0.00044760 rank 3
2023-02-22 04:19:15,283 DEBUG TRAIN Batch 14/8000 loss 11.038896 loss_att 13.024704 loss_ctc 15.540168 loss_rnnt 9.777197 hw_loss 0.495689 lr 0.00044768 rank 1
2023-02-22 04:19:15,286 DEBUG TRAIN Batch 14/8000 loss 13.601580 loss_att 15.587976 loss_ctc 15.318748 loss_rnnt 12.807034 hw_loss 0.315582 lr 0.00044760 rank 5
2023-02-22 04:20:27,960 DEBUG TRAIN Batch 14/8100 loss 15.126545 loss_att 15.893664 loss_ctc 15.098366 loss_rnnt 14.883286 hw_loss 0.175486 lr 0.00044744 rank 2
2023-02-22 04:20:27,963 DEBUG TRAIN Batch 14/8100 loss 12.686901 loss_att 16.048855 loss_ctc 15.291682 loss_rnnt 11.468399 hw_loss 0.372762 lr 0.00044737 rank 7
2023-02-22 04:20:27,964 DEBUG TRAIN Batch 14/8100 loss 10.474418 loss_att 17.111717 loss_ctc 11.756022 loss_rnnt 8.872252 hw_loss 0.194671 lr 0.00044742 rank 3
2023-02-22 04:20:27,966 DEBUG TRAIN Batch 14/8100 loss 11.879857 loss_att 12.686016 loss_ctc 18.982105 loss_rnnt 10.664614 hw_loss 0.200708 lr 0.00044750 rank 1
2023-02-22 04:20:27,968 DEBUG TRAIN Batch 14/8100 loss 10.626947 loss_att 14.755556 loss_ctc 10.903567 loss_rnnt 9.618613 hw_loss 0.273243 lr 0.00044744 rank 6
2023-02-22 04:20:27,968 DEBUG TRAIN Batch 14/8100 loss 10.576839 loss_att 11.648062 loss_ctc 15.036948 loss_rnnt 9.637394 hw_loss 0.244725 lr 0.00044742 rank 4
2023-02-22 04:20:27,969 DEBUG TRAIN Batch 14/8100 loss 12.757792 loss_att 20.150070 loss_ctc 19.467848 loss_rnnt 10.172725 hw_loss 0.397384 lr 0.00044742 rank 5
2023-02-22 04:20:28,019 DEBUG TRAIN Batch 14/8100 loss 9.922449 loss_att 13.838612 loss_ctc 12.252080 loss_rnnt 8.608072 hw_loss 0.413490 lr 0.00044746 rank 0
2023-02-22 04:21:41,820 DEBUG TRAIN Batch 14/8200 loss 12.617295 loss_att 14.666544 loss_ctc 13.117869 loss_rnnt 11.933154 hw_loss 0.389154 lr 0.00044726 rank 2
2023-02-22 04:21:41,821 DEBUG TRAIN Batch 14/8200 loss 10.752512 loss_att 14.583907 loss_ctc 15.207279 loss_rnnt 9.203065 hw_loss 0.354747 lr 0.00044724 rank 3
2023-02-22 04:21:41,831 DEBUG TRAIN Batch 14/8200 loss 8.130698 loss_att 8.765882 loss_ctc 9.667540 loss_rnnt 7.682295 hw_loss 0.218352 lr 0.00044726 rank 6
2023-02-22 04:21:41,831 DEBUG TRAIN Batch 14/8200 loss 10.982573 loss_att 15.597656 loss_ctc 19.722622 loss_rnnt 8.678349 hw_loss 0.404751 lr 0.00044728 rank 0
2023-02-22 04:21:41,834 DEBUG TRAIN Batch 14/8200 loss 15.308529 loss_att 15.458488 loss_ctc 17.593819 loss_rnnt 14.866441 hw_loss 0.201357 lr 0.00044719 rank 7
2023-02-22 04:21:41,835 DEBUG TRAIN Batch 14/8200 loss 14.079281 loss_att 16.761709 loss_ctc 19.973534 loss_rnnt 12.590109 hw_loss 0.312723 lr 0.00044724 rank 5
2023-02-22 04:21:41,835 DEBUG TRAIN Batch 14/8200 loss 10.924598 loss_att 11.934143 loss_ctc 13.259097 loss_rnnt 10.265978 hw_loss 0.272706 lr 0.00044732 rank 1
2023-02-22 04:21:41,846 DEBUG TRAIN Batch 14/8200 loss 3.603911 loss_att 7.330093 loss_ctc 5.622325 loss_rnnt 2.446468 hw_loss 0.268283 lr 0.00044725 rank 4
2023-02-22 04:22:53,706 DEBUG TRAIN Batch 14/8300 loss 16.590435 loss_att 20.250217 loss_ctc 20.076496 loss_rnnt 15.280570 hw_loss 0.212064 lr 0.00044707 rank 4
2023-02-22 04:22:53,706 DEBUG TRAIN Batch 14/8300 loss 4.117891 loss_att 7.019660 loss_ctc 6.907415 loss_rnnt 3.056154 hw_loss 0.205213 lr 0.00044706 rank 5
2023-02-22 04:22:53,708 DEBUG TRAIN Batch 14/8300 loss 6.782262 loss_att 10.386837 loss_ctc 9.274660 loss_rnnt 5.478053 hw_loss 0.470578 lr 0.00044707 rank 3
2023-02-22 04:22:53,710 DEBUG TRAIN Batch 14/8300 loss 7.196780 loss_att 13.563498 loss_ctc 10.342196 loss_rnnt 5.385941 hw_loss 0.221450 lr 0.00044708 rank 2
2023-02-22 04:22:53,714 DEBUG TRAIN Batch 14/8300 loss 5.345140 loss_att 7.616045 loss_ctc 5.043197 loss_rnnt 4.793281 hw_loss 0.258631 lr 0.00044714 rank 1
2023-02-22 04:22:53,715 DEBUG TRAIN Batch 14/8300 loss 14.934740 loss_att 14.128934 loss_ctc 18.412739 loss_rnnt 14.326144 hw_loss 0.573796 lr 0.00044708 rank 6
2023-02-22 04:22:53,715 DEBUG TRAIN Batch 14/8300 loss 13.914042 loss_att 17.196384 loss_ctc 20.926498 loss_rnnt 12.190168 hw_loss 0.248271 lr 0.00044701 rank 7
2023-02-22 04:22:53,761 DEBUG TRAIN Batch 14/8300 loss 13.525250 loss_att 14.356028 loss_ctc 16.300957 loss_rnnt 12.774232 hw_loss 0.402691 lr 0.00044710 rank 0
2023-02-22 04:23:44,925 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 3
2023-02-22 04:23:44,926 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 0
2023-02-22 04:23:44,926 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 5
2023-02-22 04:23:44,928 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 2
2023-02-22 04:23:44,934 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 1
2023-02-22 04:23:44,937 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 4
2023-02-22 04:23:44,948 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 7
2023-02-22 04:23:44,952 DEBUG CV Batch 14/0 loss 2.742675 loss_att 2.618933 loss_ctc 3.393742 loss_rnnt 2.283209 hw_loss 0.745135 history loss 2.641094 rank 6
2023-02-22 04:23:56,245 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 2
2023-02-22 04:23:56,357 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 3
2023-02-22 04:23:56,420 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 6
2023-02-22 04:23:56,442 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 7
2023-02-22 04:23:56,515 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 4
2023-02-22 04:23:56,548 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 5
2023-02-22 04:23:56,660 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 0
2023-02-22 04:23:56,669 DEBUG CV Batch 14/100 loss 7.710465 loss_att 8.801136 loss_ctc 10.212162 loss_rnnt 6.953732 hw_loss 0.384450 history loss 4.166280 rank 1
2023-02-22 04:24:09,654 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 2
2023-02-22 04:24:09,662 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 3
2023-02-22 04:24:09,819 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 6
2023-02-22 04:24:10,089 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 7
2023-02-22 04:24:10,173 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 1
2023-02-22 04:24:10,178 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 4
2023-02-22 04:24:10,691 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 5
2023-02-22 04:24:10,823 DEBUG CV Batch 14/200 loss 5.575749 loss_att 15.189247 loss_ctc 6.803446 loss_rnnt 3.432456 hw_loss 0.106690 history loss 4.783777 rank 0
2023-02-22 04:24:21,957 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 2
2023-02-22 04:24:21,961 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 3
2023-02-22 04:24:22,099 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 6
2023-02-22 04:24:22,371 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 7
2023-02-22 04:24:22,434 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 1
2023-02-22 04:24:22,580 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 4
2023-02-22 04:24:23,413 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 0
2023-02-22 04:24:23,519 DEBUG CV Batch 14/300 loss 5.942778 loss_att 6.442443 loss_ctc 8.651439 loss_rnnt 5.272561 hw_loss 0.392117 history loss 5.027442 rank 5
2023-02-22 04:24:34,017 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 2
2023-02-22 04:24:34,088 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 3
2023-02-22 04:24:34,280 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 6
2023-02-22 04:24:34,747 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 1
2023-02-22 04:24:34,769 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 7
2023-02-22 04:24:35,028 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 4
2023-02-22 04:24:36,005 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 0
2023-02-22 04:24:36,340 DEBUG CV Batch 14/400 loss 22.593952 loss_att 89.291893 loss_ctc 12.980117 loss_rnnt 10.408595 hw_loss 0.239277 history loss 6.098029 rank 5
2023-02-22 04:24:44,821 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 2
2023-02-22 04:24:44,847 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 3
2023-02-22 04:24:45,114 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 6
2023-02-22 04:24:45,631 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 7
2023-02-22 04:24:45,909 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 1
2023-02-22 04:24:45,962 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 4
2023-02-22 04:24:47,441 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 0
2023-02-22 04:24:47,766 DEBUG CV Batch 14/500 loss 7.523492 loss_att 7.559148 loss_ctc 8.735698 loss_rnnt 7.205956 hw_loss 0.278958 history loss 7.047744 rank 5
2023-02-22 04:24:57,025 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 3
2023-02-22 04:24:57,028 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 2
2023-02-22 04:24:57,377 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 6
2023-02-22 04:24:58,086 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 7
2023-02-22 04:24:58,213 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 1
2023-02-22 04:24:58,389 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 4
2023-02-22 04:25:00,041 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 0
2023-02-22 04:25:00,467 DEBUG CV Batch 14/600 loss 9.315380 loss_att 8.597879 loss_ctc 11.486691 loss_rnnt 8.834821 hw_loss 0.627283 history loss 8.080027 rank 5
2023-02-22 04:25:08,499 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 2
2023-02-22 04:25:08,578 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 3
2023-02-22 04:25:08,878 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 6
2023-02-22 04:25:09,732 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 1
2023-02-22 04:25:09,771 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 7
2023-02-22 04:25:09,935 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 4
2023-02-22 04:25:12,085 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 0
2023-02-22 04:25:12,460 DEBUG CV Batch 14/700 loss 18.955034 loss_att 56.510849 loss_ctc 16.012705 loss_rnnt 11.794694 hw_loss 0.077786 history loss 8.800003 rank 5
2023-02-22 04:25:19,952 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 2
2023-02-22 04:25:20,095 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 3
2023-02-22 04:25:20,429 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 6
2023-02-22 04:25:21,196 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 1
2023-02-22 04:25:21,498 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 4
2023-02-22 04:25:21,749 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 7
2023-02-22 04:25:24,025 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 0
2023-02-22 04:25:24,840 DEBUG CV Batch 14/800 loss 12.592571 loss_att 11.963388 loss_ctc 15.124785 loss_rnnt 12.230258 hw_loss 0.282229 history loss 8.177932 rank 5
2023-02-22 04:25:33,419 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 2
2023-02-22 04:25:33,581 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 3
2023-02-22 04:25:34,019 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 6
2023-02-22 04:25:34,878 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 4
2023-02-22 04:25:34,994 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 1
2023-02-22 04:25:35,434 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 7
2023-02-22 04:25:37,866 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 0
2023-02-22 04:25:38,607 DEBUG CV Batch 14/900 loss 16.985113 loss_att 26.933573 loss_ctc 25.914618 loss_rnnt 13.709994 hw_loss 0.177800 history loss 7.935492 rank 5
2023-02-22 04:25:45,778 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 2
2023-02-22 04:25:45,939 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 3
2023-02-22 04:25:46,469 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 6
2023-02-22 04:25:47,323 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 4
2023-02-22 04:25:47,562 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 1
2023-02-22 04:25:48,025 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 7
2023-02-22 04:25:50,973 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 0
2023-02-22 04:25:51,900 DEBUG CV Batch 14/1000 loss 4.725349 loss_att 5.693843 loss_ctc 5.293186 loss_rnnt 4.263033 hw_loss 0.361698 history loss 7.688388 rank 5
2023-02-22 04:25:57,875 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 2
2023-02-22 04:25:58,083 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 3
2023-02-22 04:25:58,605 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 6
2023-02-22 04:25:59,339 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 4
2023-02-22 04:25:59,519 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 1
2023-02-22 04:26:00,362 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 7
2023-02-22 04:26:03,461 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 0
2023-02-22 04:26:04,596 DEBUG CV Batch 14/1100 loss 7.624198 loss_att 6.331111 loss_ctc 8.915705 loss_rnnt 7.403694 hw_loss 0.575477 history loss 7.659385 rank 5
2023-02-22 04:26:08,760 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 2
2023-02-22 04:26:08,904 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 3
2023-02-22 04:26:09,438 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 6
2023-02-22 04:26:10,252 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 4
2023-02-22 04:26:10,544 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 1
2023-02-22 04:26:11,431 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 7
2023-02-22 04:26:15,226 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 0
2023-02-22 04:26:15,871 DEBUG CV Batch 14/1200 loss 6.895997 loss_att 8.922712 loss_ctc 6.816093 loss_rnnt 6.281002 hw_loss 0.413072 history loss 8.066930 rank 5
2023-02-22 04:26:20,886 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 2
2023-02-22 04:26:21,073 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 3
2023-02-22 04:26:21,555 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 6
2023-02-22 04:26:22,500 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 4
2023-02-22 04:26:22,765 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 1
2023-02-22 04:26:24,267 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 7
2023-02-22 04:26:28,124 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 0
2023-02-22 04:26:28,462 DEBUG CV Batch 14/1300 loss 7.301296 loss_att 6.707840 loss_ctc 9.482694 loss_rnnt 6.874285 hw_loss 0.477844 history loss 8.406190 rank 5
2023-02-22 04:26:32,330 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 2
2023-02-22 04:26:32,394 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 3
2023-02-22 04:26:32,994 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 6
2023-02-22 04:26:34,093 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 1
2023-02-22 04:26:34,421 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 4
2023-02-22 04:26:35,806 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 7
2023-02-22 04:26:39,824 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 0
2023-02-22 04:26:40,372 DEBUG CV Batch 14/1400 loss 8.533938 loss_att 26.570568 loss_ctc 6.596030 loss_rnnt 5.118678 hw_loss 0.124354 history loss 8.760209 rank 5
2023-02-22 04:26:43,915 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 2
2023-02-22 04:26:44,134 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 3
2023-02-22 04:26:44,742 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 6
2023-02-22 04:26:45,792 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 1
2023-02-22 04:26:47,054 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 4
2023-02-22 04:26:47,708 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 7
2023-02-22 04:26:51,935 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 0
2023-02-22 04:26:52,551 DEBUG CV Batch 14/1500 loss 6.903515 loss_att 9.680634 loss_ctc 7.244936 loss_rnnt 6.123920 hw_loss 0.334966 history loss 8.548125 rank 5
2023-02-22 04:26:57,109 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 2
2023-02-22 04:26:57,379 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 3
2023-02-22 04:26:58,068 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 6
2023-02-22 04:26:58,877 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 1
2023-02-22 04:27:00,511 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 4
2023-02-22 04:27:01,061 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 7
2023-02-22 04:27:05,554 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 0
2023-02-22 04:27:06,224 DEBUG CV Batch 14/1600 loss 8.645954 loss_att 14.957180 loss_ctc 14.478451 loss_rnnt 6.480736 hw_loss 0.234951 history loss 8.457333 rank 5
2023-02-22 04:27:09,740 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356193 history loss 8.352637 rank 2
2023-02-22 04:27:09,879 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356194 history loss 8.352637 rank 3
2023-02-22 04:27:10,623 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356193 history loss 8.352637 rank 6
2023-02-22 04:27:11,396 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356194 history loss 8.352637 rank 1
2023-02-22 04:27:13,046 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356194 history loss 8.352637 rank 4
2023-02-22 04:27:13,620 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356194 history loss 8.352637 rank 7
2023-02-22 04:27:18,084 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356194 history loss 8.352637 rank 0
2023-02-22 04:27:18,697 DEBUG CV Batch 14/1700 loss 11.210460 loss_att 10.453463 loss_ctc 16.543182 loss_rnnt 10.460859 hw_loss 0.356194 history loss 8.352637 rank 5
2023-02-22 04:27:18,931 INFO Epoch 14 CV info cv_loss 8.304316936260808
2023-02-22 04:27:18,931 INFO Epoch 15 TRAIN info lr 0.0004470026600134637
2023-02-22 04:27:18,933 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:27:19,064 INFO Epoch 14 CV info cv_loss 8.30431693633403
2023-02-22 04:27:19,064 INFO Epoch 15 TRAIN info lr 0.0004470258840397933
2023-02-22 04:27:19,066 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:27:19,836 INFO Epoch 14 CV info cv_loss 8.304316935468261
2023-02-22 04:27:19,837 INFO Epoch 15 TRAIN info lr 0.00044701695129360075
2023-02-22 04:27:19,842 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:27:20,390 INFO Epoch 14 CV info cv_loss 8.304316934283749
2023-02-22 04:27:20,391 INFO Epoch 15 TRAIN info lr 0.00044705983335982297
2023-02-22 04:27:20,393 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:27:22,110 INFO Epoch 14 CV info cv_loss 8.304316935080603
2023-02-22 04:27:22,110 INFO Epoch 15 TRAIN info lr 0.0004470383907841668
2023-02-22 04:27:22,115 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:27:23,010 INFO Epoch 14 CV info cv_loss 8.304316937608997
2023-02-22 04:27:23,011 INFO Epoch 15 TRAIN info lr 0.00044692586785954305
2023-02-22 04:27:23,015 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:27:27,460 INFO Epoch 14 CV info cv_loss 8.304316938100031
2023-02-22 04:27:27,461 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/14.pt
2023-02-22 04:27:28,043 INFO Epoch 15 TRAIN info lr 0.0004470455379665612
2023-02-22 04:27:28,047 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:27:28,282 INFO Epoch 14 CV info cv_loss 8.304316936601085
2023-02-22 04:27:28,282 INFO Epoch 15 TRAIN info lr 0.0004469455085967575
2023-02-22 04:27:28,286 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:28:30,587 DEBUG TRAIN Batch 15/0 loss 16.129473 loss_att 13.263041 loss_ctc 17.408892 loss_rnnt 16.229357 hw_loss 0.567773 lr 0.00044702 rank 6
2023-02-22 04:28:30,590 DEBUG TRAIN Batch 15/0 loss 12.443861 loss_att 11.590652 loss_ctc 14.137793 loss_rnnt 12.064028 hw_loss 0.608657 lr 0.00044706 rank 1
2023-02-22 04:28:30,591 DEBUG TRAIN Batch 15/0 loss 10.457379 loss_att 9.405607 loss_ctc 11.774972 loss_rnnt 10.232012 hw_loss 0.487581 lr 0.00044704 rank 4
2023-02-22 04:28:30,593 DEBUG TRAIN Batch 15/0 loss 11.172404 loss_att 10.191875 loss_ctc 12.822640 loss_rnnt 10.802927 hw_loss 0.647909 lr 0.00044702 rank 3
2023-02-22 04:28:30,594 DEBUG TRAIN Batch 15/0 loss 7.099276 loss_att 7.520081 loss_ctc 8.696764 loss_rnnt 6.502919 hw_loss 0.560993 lr 0.00044700 rank 2
2023-02-22 04:28:30,597 DEBUG TRAIN Batch 15/0 loss 10.836438 loss_att 10.769637 loss_ctc 13.682913 loss_rnnt 10.123433 hw_loss 0.650318 lr 0.00044694 rank 5
2023-02-22 04:28:30,631 DEBUG TRAIN Batch 15/0 loss 10.463256 loss_att 10.342067 loss_ctc 12.547023 loss_rnnt 9.848456 hw_loss 0.677253 lr 0.00044704 rank 0
2023-02-22 04:28:30,662 DEBUG TRAIN Batch 15/0 loss 12.212944 loss_att 10.933599 loss_ctc 13.446486 loss_rnnt 11.976096 hw_loss 0.615458 lr 0.00044692 rank 7
2023-02-22 04:29:42,104 DEBUG TRAIN Batch 15/100 loss 8.993107 loss_att 12.669090 loss_ctc 11.532904 loss_rnnt 7.760543 hw_loss 0.297615 lr 0.00044687 rank 0
2023-02-22 04:29:42,113 DEBUG TRAIN Batch 15/100 loss 13.149097 loss_att 17.784056 loss_ctc 18.587061 loss_rnnt 11.392889 hw_loss 0.195290 lr 0.00044682 rank 2
2023-02-22 04:29:42,117 DEBUG TRAIN Batch 15/100 loss 18.977489 loss_att 21.834656 loss_ctc 21.169138 loss_rnnt 17.909477 hw_loss 0.383172 lr 0.00044685 rank 3
2023-02-22 04:29:42,117 DEBUG TRAIN Batch 15/100 loss 10.323306 loss_att 13.900272 loss_ctc 16.091572 loss_rnnt 8.719933 hw_loss 0.222894 lr 0.00044688 rank 1
2023-02-22 04:29:42,118 DEBUG TRAIN Batch 15/100 loss 10.217917 loss_att 11.658599 loss_ctc 8.983066 loss_rnnt 9.879580 hw_loss 0.402839 lr 0.00044684 rank 6
2023-02-22 04:29:42,122 DEBUG TRAIN Batch 15/100 loss 24.313368 loss_att 26.890076 loss_ctc 31.311865 loss_rnnt 22.798376 hw_loss 0.124716 lr 0.00044675 rank 7
2023-02-22 04:29:42,122 DEBUG TRAIN Batch 15/100 loss 14.515696 loss_att 19.225418 loss_ctc 20.933216 loss_rnnt 12.602187 hw_loss 0.217301 lr 0.00044677 rank 5
2023-02-22 04:29:42,176 DEBUG TRAIN Batch 15/100 loss 10.497281 loss_att 12.646490 loss_ctc 17.466286 loss_rnnt 9.012108 hw_loss 0.236495 lr 0.00044686 rank 4
2023-02-22 04:30:54,133 DEBUG TRAIN Batch 15/200 loss 18.107256 loss_att 18.243969 loss_ctc 25.453369 loss_rnnt 17.026501 hw_loss 0.138620 lr 0.00044667 rank 3
2023-02-22 04:30:54,135 DEBUG TRAIN Batch 15/200 loss 14.997481 loss_att 17.284063 loss_ctc 19.950474 loss_rnnt 13.773842 hw_loss 0.198608 lr 0.00044664 rank 2
2023-02-22 04:30:54,137 DEBUG TRAIN Batch 15/200 loss 4.714486 loss_att 7.848144 loss_ctc 4.891112 loss_rnnt 3.996474 hw_loss 0.126994 lr 0.00044666 rank 6
2023-02-22 04:30:54,139 DEBUG TRAIN Batch 15/200 loss 9.781404 loss_att 12.528072 loss_ctc 16.897171 loss_rnnt 8.153675 hw_loss 0.243045 lr 0.00044657 rank 7
2023-02-22 04:30:54,138 DEBUG TRAIN Batch 15/200 loss 11.004641 loss_att 12.593113 loss_ctc 18.228722 loss_rnnt 9.529029 hw_loss 0.365077 lr 0.00044659 rank 5
2023-02-22 04:30:54,139 DEBUG TRAIN Batch 15/200 loss 7.708038 loss_att 13.040313 loss_ctc 11.411002 loss_rnnt 6.055961 hw_loss 0.172300 lr 0.00044668 rank 4
2023-02-22 04:30:54,141 DEBUG TRAIN Batch 15/200 loss 8.929226 loss_att 11.499888 loss_ctc 12.497696 loss_rnnt 7.799236 hw_loss 0.262614 lr 0.00044670 rank 1
2023-02-22 04:30:54,157 DEBUG TRAIN Batch 15/200 loss 14.575378 loss_att 17.762411 loss_ctc 23.641699 loss_rnnt 12.550841 hw_loss 0.334288 lr 0.00044669 rank 0
2023-02-22 04:32:07,132 DEBUG TRAIN Batch 15/300 loss 12.485249 loss_att 17.454727 loss_ctc 19.455151 loss_rnnt 10.477091 hw_loss 0.159267 lr 0.00044641 rank 5
2023-02-22 04:32:07,143 DEBUG TRAIN Batch 15/300 loss 5.491700 loss_att 9.463160 loss_ctc 7.185649 loss_rnnt 4.294975 hw_loss 0.331073 lr 0.00044647 rank 2
2023-02-22 04:32:07,144 DEBUG TRAIN Batch 15/300 loss 10.486581 loss_att 16.395769 loss_ctc 18.013294 loss_rnnt 8.171704 hw_loss 0.242769 lr 0.00044650 rank 4
2023-02-22 04:32:07,147 DEBUG TRAIN Batch 15/300 loss 7.174685 loss_att 10.495470 loss_ctc 8.669088 loss_rnnt 6.122799 hw_loss 0.353388 lr 0.00044639 rank 7
2023-02-22 04:32:07,151 DEBUG TRAIN Batch 15/300 loss 6.591035 loss_att 11.452522 loss_ctc 9.206594 loss_rnnt 5.146645 hw_loss 0.231285 lr 0.00044649 rank 3
2023-02-22 04:32:07,151 DEBUG TRAIN Batch 15/300 loss 22.201710 loss_att 26.984856 loss_ctc 27.873943 loss_rnnt 20.329973 hw_loss 0.297767 lr 0.00044648 rank 6
2023-02-22 04:32:07,155 DEBUG TRAIN Batch 15/300 loss 11.693914 loss_att 10.847456 loss_ctc 12.336446 loss_rnnt 11.644251 hw_loss 0.249907 lr 0.00044652 rank 1
2023-02-22 04:32:07,158 DEBUG TRAIN Batch 15/300 loss 9.626469 loss_att 11.228975 loss_ctc 13.382067 loss_rnnt 8.689038 hw_loss 0.217842 lr 0.00044651 rank 0
2023-02-22 04:33:20,629 DEBUG TRAIN Batch 15/400 loss 16.004034 loss_att 19.195841 loss_ctc 22.270170 loss_rnnt 14.406339 hw_loss 0.232214 lr 0.00044630 rank 6
2023-02-22 04:33:20,631 DEBUG TRAIN Batch 15/400 loss 8.498141 loss_att 11.572845 loss_ctc 11.790325 loss_rnnt 7.297364 hw_loss 0.275397 lr 0.00044629 rank 2
2023-02-22 04:33:20,632 DEBUG TRAIN Batch 15/400 loss 10.248151 loss_att 15.388811 loss_ctc 14.422565 loss_rnnt 8.554694 hw_loss 0.203880 lr 0.00044631 rank 3
2023-02-22 04:33:20,634 DEBUG TRAIN Batch 15/400 loss 11.976339 loss_att 13.456983 loss_ctc 15.202047 loss_rnnt 11.114930 hw_loss 0.253473 lr 0.00044632 rank 4
2023-02-22 04:33:20,638 DEBUG TRAIN Batch 15/400 loss 9.396931 loss_att 12.111696 loss_ctc 11.669574 loss_rnnt 8.339750 hw_loss 0.396016 lr 0.00044623 rank 5
2023-02-22 04:33:20,640 DEBUG TRAIN Batch 15/400 loss 12.719981 loss_att 12.739092 loss_ctc 16.880247 loss_rnnt 11.928543 hw_loss 0.436715 lr 0.00044634 rank 1
2023-02-22 04:33:20,657 DEBUG TRAIN Batch 15/400 loss 9.478444 loss_att 11.237290 loss_ctc 12.231827 loss_rnnt 8.574303 hw_loss 0.347352 lr 0.00044633 rank 0
2023-02-22 04:33:20,664 DEBUG TRAIN Batch 15/400 loss 10.874186 loss_att 11.853344 loss_ctc 13.260063 loss_rnnt 10.193398 hw_loss 0.312824 lr 0.00044621 rank 7
2023-02-22 04:34:32,885 DEBUG TRAIN Batch 15/500 loss 12.953102 loss_att 17.741194 loss_ctc 18.865181 loss_rnnt 11.015267 hw_loss 0.359884 lr 0.00044612 rank 6
2023-02-22 04:34:32,885 DEBUG TRAIN Batch 15/500 loss 21.838234 loss_att 23.519232 loss_ctc 25.884399 loss_rnnt 20.828442 hw_loss 0.251444 lr 0.00044613 rank 3
2023-02-22 04:34:32,887 DEBUG TRAIN Batch 15/500 loss 9.537266 loss_att 12.415113 loss_ctc 15.297118 loss_rnnt 8.023689 hw_loss 0.318800 lr 0.00044615 rank 0
2023-02-22 04:34:32,888 DEBUG TRAIN Batch 15/500 loss 11.622725 loss_att 15.076769 loss_ctc 13.928756 loss_rnnt 10.542896 hw_loss 0.152903 lr 0.00044611 rank 2
2023-02-22 04:34:32,890 DEBUG TRAIN Batch 15/500 loss 16.213669 loss_att 20.390011 loss_ctc 20.799601 loss_rnnt 14.567591 hw_loss 0.373784 lr 0.00044615 rank 4
2023-02-22 04:34:32,893 DEBUG TRAIN Batch 15/500 loss 12.533628 loss_att 16.305103 loss_ctc 17.097792 loss_rnnt 11.049242 hw_loss 0.227880 lr 0.00044603 rank 7
2023-02-22 04:34:32,894 DEBUG TRAIN Batch 15/500 loss 9.419814 loss_att 14.129683 loss_ctc 14.193301 loss_rnnt 7.702384 hw_loss 0.260607 lr 0.00044605 rank 5
2023-02-22 04:34:32,897 DEBUG TRAIN Batch 15/500 loss 6.406185 loss_att 9.957174 loss_ctc 12.082214 loss_rnnt 4.808177 hw_loss 0.245636 lr 0.00044617 rank 1
2023-02-22 04:35:46,415 DEBUG TRAIN Batch 15/600 loss 8.536322 loss_att 9.300934 loss_ctc 9.481092 loss_rnnt 8.050993 hw_loss 0.387067 lr 0.00044595 rank 6
2023-02-22 04:35:46,419 DEBUG TRAIN Batch 15/600 loss 15.303853 loss_att 15.994083 loss_ctc 19.251776 loss_rnnt 14.469961 hw_loss 0.317731 lr 0.00044586 rank 7
2023-02-22 04:35:46,422 DEBUG TRAIN Batch 15/600 loss 17.523054 loss_att 17.737595 loss_ctc 22.289013 loss_rnnt 16.564304 hw_loss 0.525715 lr 0.00044593 rank 2
2023-02-22 04:35:46,422 DEBUG TRAIN Batch 15/600 loss 9.699902 loss_att 10.591065 loss_ctc 13.934168 loss_rnnt 8.774393 hw_loss 0.342574 lr 0.00044598 rank 0
2023-02-22 04:35:46,423 DEBUG TRAIN Batch 15/600 loss 9.718881 loss_att 12.376537 loss_ctc 14.179754 loss_rnnt 8.463195 hw_loss 0.242573 lr 0.00044597 rank 4
2023-02-22 04:35:46,424 DEBUG TRAIN Batch 15/600 loss 12.357523 loss_att 11.813210 loss_ctc 17.031622 loss_rnnt 11.637642 hw_loss 0.385371 lr 0.00044599 rank 1
2023-02-22 04:35:46,425 DEBUG TRAIN Batch 15/600 loss 13.742323 loss_att 13.940701 loss_ctc 16.660528 loss_rnnt 13.129558 hw_loss 0.344993 lr 0.00044596 rank 3
2023-02-22 04:35:46,431 DEBUG TRAIN Batch 15/600 loss 19.775660 loss_att 19.670063 loss_ctc 25.727448 loss_rnnt 18.888481 hw_loss 0.215109 lr 0.00044588 rank 5
2023-02-22 04:37:00,312 DEBUG TRAIN Batch 15/700 loss 6.934781 loss_att 9.000660 loss_ctc 7.436815 loss_rnnt 6.325477 hw_loss 0.242234 lr 0.00044576 rank 2
2023-02-22 04:37:00,318 DEBUG TRAIN Batch 15/700 loss 9.220276 loss_att 15.130316 loss_ctc 13.451942 loss_rnnt 7.388373 hw_loss 0.160637 lr 0.00044579 rank 4
2023-02-22 04:37:00,319 DEBUG TRAIN Batch 15/700 loss 15.141375 loss_att 19.576216 loss_ctc 23.304434 loss_rnnt 13.063263 hw_loss 0.192628 lr 0.00044578 rank 3
2023-02-22 04:37:00,319 DEBUG TRAIN Batch 15/700 loss 13.574341 loss_att 18.050003 loss_ctc 16.535694 loss_rnnt 12.170565 hw_loss 0.213369 lr 0.00044580 rank 0
2023-02-22 04:37:00,323 DEBUG TRAIN Batch 15/700 loss 8.759054 loss_att 10.107015 loss_ctc 11.496840 loss_rnnt 8.020957 hw_loss 0.194002 lr 0.00044577 rank 6
2023-02-22 04:37:00,325 DEBUG TRAIN Batch 15/700 loss 14.817209 loss_att 18.679642 loss_ctc 18.090101 loss_rnnt 13.455015 hw_loss 0.287479 lr 0.00044570 rank 5
2023-02-22 04:37:00,335 DEBUG TRAIN Batch 15/700 loss 11.172829 loss_att 16.230188 loss_ctc 16.140362 loss_rnnt 9.372149 hw_loss 0.237883 lr 0.00044581 rank 1
2023-02-22 04:37:00,342 DEBUG TRAIN Batch 15/700 loss 10.724300 loss_att 13.698331 loss_ctc 12.418348 loss_rnnt 9.731054 hw_loss 0.323562 lr 0.00044568 rank 7
2023-02-22 04:38:13,536 DEBUG TRAIN Batch 15/800 loss 19.201460 loss_att 23.230125 loss_ctc 25.306942 loss_rnnt 17.403690 hw_loss 0.333694 lr 0.00044560 rank 3
2023-02-22 04:38:13,535 DEBUG TRAIN Batch 15/800 loss 9.727686 loss_att 14.819361 loss_ctc 12.247512 loss_rnnt 8.274637 hw_loss 0.185131 lr 0.00044558 rank 2
2023-02-22 04:38:13,545 DEBUG TRAIN Batch 15/800 loss 10.408381 loss_att 14.646111 loss_ctc 12.889586 loss_rnnt 9.118374 hw_loss 0.209316 lr 0.00044564 rank 1
2023-02-22 04:38:13,544 DEBUG TRAIN Batch 15/800 loss 10.467392 loss_att 12.132765 loss_ctc 10.476304 loss_rnnt 10.043923 hw_loss 0.167261 lr 0.00044562 rank 0
2023-02-22 04:38:13,545 DEBUG TRAIN Batch 15/800 loss 9.555881 loss_att 13.727541 loss_ctc 15.273044 loss_rnnt 7.870368 hw_loss 0.166671 lr 0.00044561 rank 4
2023-02-22 04:38:13,548 DEBUG TRAIN Batch 15/800 loss 19.435146 loss_att 22.229450 loss_ctc 34.947655 loss_rnnt 16.708420 hw_loss 0.186621 lr 0.00044550 rank 7
2023-02-22 04:38:13,549 DEBUG TRAIN Batch 15/800 loss 25.106028 loss_att 29.477280 loss_ctc 32.752968 loss_rnnt 23.121328 hw_loss 0.170357 lr 0.00044559 rank 6
2023-02-22 04:38:13,551 DEBUG TRAIN Batch 15/800 loss 18.576189 loss_att 24.791821 loss_ctc 25.121674 loss_rnnt 16.331020 hw_loss 0.242458 lr 0.00044552 rank 5
2023-02-22 04:39:25,511 DEBUG TRAIN Batch 15/900 loss 8.902693 loss_att 12.539885 loss_ctc 14.549187 loss_rnnt 7.297724 hw_loss 0.233744 lr 0.00044533 rank 7
2023-02-22 04:39:25,531 DEBUG TRAIN Batch 15/900 loss 14.443420 loss_att 16.293030 loss_ctc 18.811874 loss_rnnt 13.324914 hw_loss 0.311483 lr 0.00044542 rank 3
2023-02-22 04:39:25,531 DEBUG TRAIN Batch 15/900 loss 9.622532 loss_att 13.596581 loss_ctc 12.423010 loss_rnnt 8.255617 hw_loss 0.372578 lr 0.00044535 rank 5
2023-02-22 04:39:25,531 DEBUG TRAIN Batch 15/900 loss 6.926997 loss_att 8.225444 loss_ctc 9.425762 loss_rnnt 6.147444 hw_loss 0.350053 lr 0.00044540 rank 2
2023-02-22 04:39:25,534 DEBUG TRAIN Batch 15/900 loss 21.281031 loss_att 24.120859 loss_ctc 34.258480 loss_rnnt 18.841461 hw_loss 0.264894 lr 0.00044542 rank 6
2023-02-22 04:39:25,535 DEBUG TRAIN Batch 15/900 loss 9.190121 loss_att 13.177865 loss_ctc 11.183933 loss_rnnt 7.977210 hw_loss 0.280352 lr 0.00044544 rank 4
2023-02-22 04:39:25,539 DEBUG TRAIN Batch 15/900 loss 9.124122 loss_att 11.944020 loss_ctc 12.838240 loss_rnnt 7.920738 hw_loss 0.270355 lr 0.00044544 rank 0
2023-02-22 04:39:25,543 DEBUG TRAIN Batch 15/900 loss 12.153996 loss_att 13.622829 loss_ctc 13.260718 loss_rnnt 11.619005 hw_loss 0.175615 lr 0.00044546 rank 1
2023-02-22 04:40:38,035 DEBUG TRAIN Batch 15/1000 loss 8.273433 loss_att 11.368134 loss_ctc 13.005365 loss_rnnt 6.874145 hw_loss 0.280169 lr 0.00044515 rank 7
2023-02-22 04:40:38,038 DEBUG TRAIN Batch 15/1000 loss 7.895799 loss_att 9.970023 loss_ctc 8.897299 loss_rnnt 7.274806 hw_loss 0.136154 lr 0.00044528 rank 1
2023-02-22 04:40:38,039 DEBUG TRAIN Batch 15/1000 loss 19.906319 loss_att 22.073673 loss_ctc 21.724083 loss_rnnt 19.062328 hw_loss 0.315284 lr 0.00044523 rank 2
2023-02-22 04:40:38,040 DEBUG TRAIN Batch 15/1000 loss 13.919444 loss_att 15.797975 loss_ctc 19.687792 loss_rnnt 12.691236 hw_loss 0.156352 lr 0.00044525 rank 3
2023-02-22 04:40:38,041 DEBUG TRAIN Batch 15/1000 loss 18.467999 loss_att 20.922956 loss_ctc 23.424053 loss_rnnt 17.192085 hw_loss 0.232716 lr 0.00044517 rank 5
2023-02-22 04:40:38,042 DEBUG TRAIN Batch 15/1000 loss 17.611967 loss_att 22.266520 loss_ctc 24.755594 loss_rnnt 15.615294 hw_loss 0.212405 lr 0.00044527 rank 0
2023-02-22 04:40:38,044 DEBUG TRAIN Batch 15/1000 loss 10.452471 loss_att 13.275396 loss_ctc 15.369774 loss_rnnt 9.097211 hw_loss 0.253188 lr 0.00044524 rank 6
2023-02-22 04:40:38,065 DEBUG TRAIN Batch 15/1000 loss 14.023949 loss_att 17.876829 loss_ctc 14.352663 loss_rnnt 13.102339 hw_loss 0.201010 lr 0.00044526 rank 4
2023-02-22 04:41:53,018 DEBUG TRAIN Batch 15/1100 loss 24.951639 loss_att 25.451611 loss_ctc 32.244312 loss_rnnt 23.789312 hw_loss 0.168706 lr 0.00044499 rank 5
2023-02-22 04:41:53,028 DEBUG TRAIN Batch 15/1100 loss 11.247134 loss_att 16.096081 loss_ctc 13.693046 loss_rnnt 9.771170 hw_loss 0.337601 lr 0.00044505 rank 2
2023-02-22 04:41:53,029 DEBUG TRAIN Batch 15/1100 loss 6.569183 loss_att 8.887182 loss_ctc 8.459346 loss_rnnt 5.700073 hw_loss 0.287791 lr 0.00044506 rank 6
2023-02-22 04:41:53,029 DEBUG TRAIN Batch 15/1100 loss 13.617269 loss_att 15.004022 loss_ctc 15.279652 loss_rnnt 12.943336 hw_loss 0.327996 lr 0.00044511 rank 1
2023-02-22 04:41:53,030 DEBUG TRAIN Batch 15/1100 loss 17.941919 loss_att 20.406263 loss_ctc 22.445045 loss_rnnt 16.656712 hw_loss 0.359856 lr 0.00044509 rank 0
2023-02-22 04:41:53,033 DEBUG TRAIN Batch 15/1100 loss 19.858459 loss_att 24.918537 loss_ctc 26.824875 loss_rnnt 17.784033 hw_loss 0.250415 lr 0.00044508 rank 4
2023-02-22 04:41:53,033 DEBUG TRAIN Batch 15/1100 loss 5.444291 loss_att 8.156290 loss_ctc 5.613241 loss_rnnt 4.690495 hw_loss 0.354131 lr 0.00044497 rank 7
2023-02-22 04:41:53,035 DEBUG TRAIN Batch 15/1100 loss 13.221704 loss_att 13.182030 loss_ctc 17.336912 loss_rnnt 12.491951 hw_loss 0.354363 lr 0.00044507 rank 3
2023-02-22 04:43:07,510 DEBUG TRAIN Batch 15/1200 loss 13.083820 loss_att 13.437092 loss_ctc 19.644915 loss_rnnt 11.956972 hw_loss 0.340086 lr 0.00044487 rank 2
2023-02-22 04:43:07,511 DEBUG TRAIN Batch 15/1200 loss 10.994389 loss_att 12.357350 loss_ctc 14.279461 loss_rnnt 10.086763 hw_loss 0.369417 lr 0.00044493 rank 1
2023-02-22 04:43:07,512 DEBUG TRAIN Batch 15/1200 loss 15.248704 loss_att 16.040230 loss_ctc 19.501539 loss_rnnt 14.293330 hw_loss 0.431295 lr 0.00044489 rank 6
2023-02-22 04:43:07,516 DEBUG TRAIN Batch 15/1200 loss 11.472823 loss_att 13.567342 loss_ctc 15.740631 loss_rnnt 10.393732 hw_loss 0.170902 lr 0.00044480 rank 7
2023-02-22 04:43:07,516 DEBUG TRAIN Batch 15/1200 loss 5.874693 loss_att 7.877815 loss_ctc 8.057129 loss_rnnt 5.064565 hw_loss 0.222211 lr 0.00044490 rank 3
2023-02-22 04:43:07,519 DEBUG TRAIN Batch 15/1200 loss 11.992478 loss_att 14.139610 loss_ctc 12.612877 loss_rnnt 11.381514 hw_loss 0.185286 lr 0.00044491 rank 0
2023-02-22 04:43:07,522 DEBUG TRAIN Batch 15/1200 loss 15.689701 loss_att 18.805431 loss_ctc 18.209213 loss_rnnt 14.569518 hw_loss 0.302067 lr 0.00044491 rank 4
2023-02-22 04:43:07,565 DEBUG TRAIN Batch 15/1200 loss 15.904907 loss_att 14.522100 loss_ctc 18.838127 loss_rnnt 15.542001 hw_loss 0.465696 lr 0.00044482 rank 5
2023-02-22 04:44:20,849 DEBUG TRAIN Batch 15/1300 loss 18.875391 loss_att 30.898293 loss_ctc 25.838680 loss_rnnt 15.412837 hw_loss 0.242877 lr 0.00044470 rank 2
2023-02-22 04:44:20,852 DEBUG TRAIN Batch 15/1300 loss 10.967836 loss_att 14.460424 loss_ctc 13.466671 loss_rnnt 9.814688 hw_loss 0.227727 lr 0.00044475 rank 1
2023-02-22 04:44:20,853 DEBUG TRAIN Batch 15/1300 loss 5.833069 loss_att 6.470503 loss_ctc 7.367839 loss_rnnt 5.242201 hw_loss 0.485148 lr 0.00044473 rank 4
2023-02-22 04:44:20,854 DEBUG TRAIN Batch 15/1300 loss 18.819109 loss_att 21.890522 loss_ctc 19.051933 loss_rnnt 17.997713 hw_loss 0.330130 lr 0.00044471 rank 6
2023-02-22 04:44:20,854 DEBUG TRAIN Batch 15/1300 loss 9.324892 loss_att 14.808041 loss_ctc 14.366898 loss_rnnt 7.402738 hw_loss 0.287356 lr 0.00044474 rank 0
2023-02-22 04:44:20,854 DEBUG TRAIN Batch 15/1300 loss 4.785056 loss_att 8.039330 loss_ctc 6.481765 loss_rnnt 3.726527 hw_loss 0.340210 lr 0.00044472 rank 3
2023-02-22 04:44:20,860 DEBUG TRAIN Batch 15/1300 loss 9.351946 loss_att 12.516231 loss_ctc 12.638212 loss_rnnt 8.090125 hw_loss 0.357742 lr 0.00044464 rank 5
2023-02-22 04:44:20,903 DEBUG TRAIN Batch 15/1300 loss 5.737581 loss_att 10.214886 loss_ctc 7.130497 loss_rnnt 4.515570 hw_loss 0.264054 lr 0.00044462 rank 7
2023-02-22 04:45:35,607 DEBUG TRAIN Batch 15/1400 loss 8.267359 loss_att 10.556453 loss_ctc 12.051865 loss_rnnt 7.178905 hw_loss 0.236314 lr 0.00044452 rank 2
2023-02-22 04:45:35,610 DEBUG TRAIN Batch 15/1400 loss 18.574545 loss_att 20.936323 loss_ctc 22.959524 loss_rnnt 17.453945 hw_loss 0.119215 lr 0.00044458 rank 1
2023-02-22 04:45:35,612 DEBUG TRAIN Batch 15/1400 loss 14.536537 loss_att 16.611782 loss_ctc 19.490149 loss_rnnt 13.363513 hw_loss 0.182799 lr 0.00044454 rank 3
2023-02-22 04:45:35,613 DEBUG TRAIN Batch 15/1400 loss 7.127249 loss_att 11.304620 loss_ctc 10.588431 loss_rnnt 5.728982 hw_loss 0.189940 lr 0.00044445 rank 7
2023-02-22 04:45:35,613 DEBUG TRAIN Batch 15/1400 loss 4.434098 loss_att 7.381554 loss_ctc 7.960242 loss_rnnt 3.235805 hw_loss 0.259968 lr 0.00044456 rank 4
2023-02-22 04:45:35,614 DEBUG TRAIN Batch 15/1400 loss 11.731493 loss_att 11.508825 loss_ctc 13.336615 loss_rnnt 11.446357 hw_loss 0.216851 lr 0.00044446 rank 5
2023-02-22 04:45:35,615 DEBUG TRAIN Batch 15/1400 loss 10.181540 loss_att 12.657600 loss_ctc 10.462366 loss_rnnt 9.505440 hw_loss 0.268955 lr 0.00044453 rank 6
2023-02-22 04:45:35,648 DEBUG TRAIN Batch 15/1400 loss 9.163360 loss_att 12.557921 loss_ctc 8.579434 loss_rnnt 8.431486 hw_loss 0.245282 lr 0.00044456 rank 0
2023-02-22 04:46:48,667 DEBUG TRAIN Batch 15/1500 loss 7.286930 loss_att 9.622011 loss_ctc 8.318817 loss_rnnt 6.555536 hw_loss 0.237735 lr 0.00044435 rank 2
2023-02-22 04:46:48,673 DEBUG TRAIN Batch 15/1500 loss 17.236937 loss_att 21.064903 loss_ctc 24.873608 loss_rnnt 15.398978 hw_loss 0.101513 lr 0.00044439 rank 0
2023-02-22 04:46:48,674 DEBUG TRAIN Batch 15/1500 loss 7.984638 loss_att 11.205021 loss_ctc 12.826471 loss_rnnt 6.601803 hw_loss 0.174712 lr 0.00044437 rank 3
2023-02-22 04:46:48,674 DEBUG TRAIN Batch 15/1500 loss 8.915821 loss_att 10.739357 loss_ctc 10.904371 loss_rnnt 8.089945 hw_loss 0.367552 lr 0.00044436 rank 6
2023-02-22 04:46:48,680 DEBUG TRAIN Batch 15/1500 loss 7.714951 loss_att 11.096148 loss_ctc 10.482178 loss_rnnt 6.550987 hw_loss 0.222676 lr 0.00044427 rank 7
2023-02-22 04:46:48,680 DEBUG TRAIN Batch 15/1500 loss 8.174678 loss_att 10.688317 loss_ctc 10.112335 loss_rnnt 7.284554 hw_loss 0.241952 lr 0.00044429 rank 5
2023-02-22 04:46:48,684 DEBUG TRAIN Batch 15/1500 loss 6.947241 loss_att 11.701934 loss_ctc 9.484586 loss_rnnt 5.595080 hw_loss 0.117956 lr 0.00044438 rank 4
2023-02-22 04:46:48,723 DEBUG TRAIN Batch 15/1500 loss 10.448308 loss_att 13.396426 loss_ctc 11.540157 loss_rnnt 9.608061 hw_loss 0.196955 lr 0.00044440 rank 1
2023-02-22 04:48:01,241 DEBUG TRAIN Batch 15/1600 loss 10.947379 loss_att 13.065561 loss_ctc 15.881135 loss_rnnt 9.752554 hw_loss 0.212541 lr 0.00044419 rank 3
2023-02-22 04:48:01,247 DEBUG TRAIN Batch 15/1600 loss 11.727522 loss_att 14.492742 loss_ctc 14.862394 loss_rnnt 10.642341 hw_loss 0.214040 lr 0.00044423 rank 1
2023-02-22 04:48:01,248 DEBUG TRAIN Batch 15/1600 loss 14.679820 loss_att 19.059290 loss_ctc 22.436230 loss_rnnt 12.656240 hw_loss 0.212809 lr 0.00044417 rank 2
2023-02-22 04:48:01,247 DEBUG TRAIN Batch 15/1600 loss 16.084307 loss_att 18.246643 loss_ctc 18.759241 loss_rnnt 15.140452 hw_loss 0.290115 lr 0.00044418 rank 6
2023-02-22 04:48:01,248 DEBUG TRAIN Batch 15/1600 loss 22.082409 loss_att 24.811935 loss_ctc 25.611946 loss_rnnt 20.908520 hw_loss 0.295085 lr 0.00044421 rank 0
2023-02-22 04:48:01,251 DEBUG TRAIN Batch 15/1600 loss 3.431229 loss_att 5.971592 loss_ctc 3.037786 loss_rnnt 2.805471 hw_loss 0.319020 lr 0.00044409 rank 7
2023-02-22 04:48:01,253 DEBUG TRAIN Batch 15/1600 loss 19.286018 loss_att 20.852676 loss_ctc 25.527969 loss_rnnt 18.058849 hw_loss 0.152961 lr 0.00044411 rank 5
2023-02-22 04:48:01,295 DEBUG TRAIN Batch 15/1600 loss 10.762563 loss_att 13.461303 loss_ctc 13.041302 loss_rnnt 9.752117 hw_loss 0.312873 lr 0.00044420 rank 4
2023-02-22 04:49:14,083 DEBUG TRAIN Batch 15/1700 loss 9.283638 loss_att 11.775607 loss_ctc 11.308906 loss_rnnt 8.417167 hw_loss 0.183827 lr 0.00044394 rank 5
2023-02-22 04:49:14,088 DEBUG TRAIN Batch 15/1700 loss 12.119383 loss_att 14.206627 loss_ctc 18.295971 loss_rnnt 10.677311 hw_loss 0.377021 lr 0.00044399 rank 2
2023-02-22 04:49:14,089 DEBUG TRAIN Batch 15/1700 loss 16.764927 loss_att 18.831446 loss_ctc 22.561369 loss_rnnt 15.473841 hw_loss 0.196730 lr 0.00044404 rank 0
2023-02-22 04:49:14,089 DEBUG TRAIN Batch 15/1700 loss 10.018995 loss_att 14.504295 loss_ctc 12.924319 loss_rnnt 8.614788 hw_loss 0.224572 lr 0.00044402 rank 3
2023-02-22 04:49:14,092 DEBUG TRAIN Batch 15/1700 loss 17.592096 loss_att 22.739822 loss_ctc 24.508396 loss_rnnt 15.550459 hw_loss 0.168595 lr 0.00044403 rank 4
2023-02-22 04:49:14,095 DEBUG TRAIN Batch 15/1700 loss 13.583183 loss_att 17.268345 loss_ctc 17.436825 loss_rnnt 12.214533 hw_loss 0.220871 lr 0.00044392 rank 7
2023-02-22 04:49:14,095 DEBUG TRAIN Batch 15/1700 loss 19.025213 loss_att 21.466814 loss_ctc 23.774015 loss_rnnt 17.772514 hw_loss 0.246012 lr 0.00044401 rank 6
2023-02-22 04:49:14,096 DEBUG TRAIN Batch 15/1700 loss 8.106674 loss_att 13.455832 loss_ctc 10.787791 loss_rnnt 6.540471 hw_loss 0.260414 lr 0.00044405 rank 1
2023-02-22 04:50:29,318 DEBUG TRAIN Batch 15/1800 loss 7.907073 loss_att 10.086881 loss_ctc 11.229766 loss_rnnt 6.886611 hw_loss 0.265264 lr 0.00044374 rank 7
2023-02-22 04:50:29,332 DEBUG TRAIN Batch 15/1800 loss 18.022434 loss_att 20.814156 loss_ctc 25.137711 loss_rnnt 16.406185 hw_loss 0.204752 lr 0.00044383 rank 6
2023-02-22 04:50:29,333 DEBUG TRAIN Batch 15/1800 loss 7.662170 loss_att 11.746890 loss_ctc 10.903607 loss_rnnt 6.288467 hw_loss 0.233565 lr 0.00044385 rank 4
2023-02-22 04:50:29,335 DEBUG TRAIN Batch 15/1800 loss 13.660571 loss_att 16.677547 loss_ctc 16.914183 loss_rnnt 12.447501 hw_loss 0.329735 lr 0.00044386 rank 0
2023-02-22 04:50:29,336 DEBUG TRAIN Batch 15/1800 loss 14.768483 loss_att 16.280121 loss_ctc 19.935848 loss_rnnt 13.623248 hw_loss 0.288611 lr 0.00044382 rank 2
2023-02-22 04:50:29,338 DEBUG TRAIN Batch 15/1800 loss 14.134690 loss_att 16.082201 loss_ctc 18.677015 loss_rnnt 13.024286 hw_loss 0.216109 lr 0.00044388 rank 1
2023-02-22 04:50:29,343 DEBUG TRAIN Batch 15/1800 loss 13.935653 loss_att 15.695591 loss_ctc 15.783355 loss_rnnt 13.207535 hw_loss 0.243318 lr 0.00044376 rank 5
2023-02-22 04:50:29,343 DEBUG TRAIN Batch 15/1800 loss 11.185152 loss_att 14.627756 loss_ctc 12.038225 loss_rnnt 10.284897 hw_loss 0.183734 lr 0.00044384 rank 3
2023-02-22 04:51:41,918 DEBUG TRAIN Batch 15/1900 loss 9.265357 loss_att 13.555423 loss_ctc 12.887835 loss_rnnt 7.845618 hw_loss 0.147617 lr 0.00044365 rank 2
2023-02-22 04:51:41,918 DEBUG TRAIN Batch 15/1900 loss 17.832489 loss_att 19.337296 loss_ctc 20.883482 loss_rnnt 16.969807 hw_loss 0.290481 lr 0.00044366 rank 6
2023-02-22 04:51:41,921 DEBUG TRAIN Batch 15/1900 loss 22.193277 loss_att 25.349113 loss_ctc 27.769056 loss_rnnt 20.766567 hw_loss 0.097699 lr 0.00044359 rank 5
2023-02-22 04:51:41,923 DEBUG TRAIN Batch 15/1900 loss 10.814970 loss_att 9.902250 loss_ctc 11.883908 loss_rnnt 10.637941 hw_loss 0.406965 lr 0.00044367 rank 3
2023-02-22 04:51:41,924 DEBUG TRAIN Batch 15/1900 loss 4.309384 loss_att 4.825076 loss_ctc 5.754776 loss_rnnt 3.881847 hw_loss 0.246900 lr 0.00044370 rank 1
2023-02-22 04:51:41,926 DEBUG TRAIN Batch 15/1900 loss 19.744520 loss_att 20.041206 loss_ctc 24.119923 loss_rnnt 18.819412 hw_loss 0.529468 lr 0.00044357 rank 7
2023-02-22 04:51:41,932 DEBUG TRAIN Batch 15/1900 loss 11.835951 loss_att 11.610265 loss_ctc 14.491286 loss_rnnt 11.213352 hw_loss 0.588172 lr 0.00044368 rank 4
2023-02-22 04:51:41,933 DEBUG TRAIN Batch 15/1900 loss 3.973127 loss_att 7.285023 loss_ctc 9.626278 loss_rnnt 2.384194 hw_loss 0.324001 lr 0.00044369 rank 0
2023-02-22 04:52:53,775 DEBUG TRAIN Batch 15/2000 loss 10.541044 loss_att 9.843451 loss_ctc 10.439811 loss_rnnt 10.529089 hw_loss 0.309322 lr 0.00044347 rank 2
2023-02-22 04:52:53,777 DEBUG TRAIN Batch 15/2000 loss 9.699433 loss_att 13.307551 loss_ctc 14.944822 loss_rnnt 8.119633 hw_loss 0.297735 lr 0.00044348 rank 6
2023-02-22 04:52:53,781 DEBUG TRAIN Batch 15/2000 loss 11.664070 loss_att 15.785444 loss_ctc 17.608215 loss_rnnt 9.851990 hw_loss 0.366100 lr 0.00044340 rank 7
2023-02-22 04:52:53,783 DEBUG TRAIN Batch 15/2000 loss 9.024794 loss_att 12.179062 loss_ctc 10.804812 loss_rnnt 7.960754 hw_loss 0.367220 lr 0.00044351 rank 4
2023-02-22 04:52:53,782 DEBUG TRAIN Batch 15/2000 loss 14.468472 loss_att 17.075748 loss_ctc 20.002790 loss_rnnt 13.091578 hw_loss 0.220365 lr 0.00044341 rank 5
2023-02-22 04:52:53,783 DEBUG TRAIN Batch 15/2000 loss 13.525689 loss_att 19.748911 loss_ctc 18.238729 loss_rnnt 11.476397 hw_loss 0.330455 lr 0.00044349 rank 3
2023-02-22 04:52:53,788 DEBUG TRAIN Batch 15/2000 loss 10.565534 loss_att 15.276796 loss_ctc 15.445697 loss_rnnt 8.878176 hw_loss 0.177034 lr 0.00044351 rank 0
2023-02-22 04:52:53,789 DEBUG TRAIN Batch 15/2000 loss 15.160683 loss_att 21.783405 loss_ctc 18.978909 loss_rnnt 13.170336 hw_loss 0.293823 lr 0.00044353 rank 1
2023-02-22 04:54:07,881 DEBUG TRAIN Batch 15/2100 loss 7.782702 loss_att 9.767598 loss_ctc 7.940101 loss_rnnt 7.265016 hw_loss 0.186976 lr 0.00044322 rank 7
2023-02-22 04:54:07,887 DEBUG TRAIN Batch 15/2100 loss 17.507463 loss_att 20.323879 loss_ctc 22.207302 loss_rnnt 16.116470 hw_loss 0.376999 lr 0.00044330 rank 2
2023-02-22 04:54:07,887 DEBUG TRAIN Batch 15/2100 loss 11.173379 loss_att 16.388243 loss_ctc 20.305687 loss_rnnt 8.765643 hw_loss 0.275852 lr 0.00044332 rank 3
2023-02-22 04:54:07,894 DEBUG TRAIN Batch 15/2100 loss 12.241995 loss_att 15.767056 loss_ctc 20.963148 loss_rnnt 10.235050 hw_loss 0.260835 lr 0.00044331 rank 6
2023-02-22 04:54:07,895 DEBUG TRAIN Batch 15/2100 loss 9.244624 loss_att 12.022203 loss_ctc 13.182013 loss_rnnt 8.023874 hw_loss 0.262966 lr 0.00044335 rank 1
2023-02-22 04:54:07,897 DEBUG TRAIN Batch 15/2100 loss 9.274660 loss_att 12.808833 loss_ctc 14.139606 loss_rnnt 7.817878 hw_loss 0.189917 lr 0.00044324 rank 5
2023-02-22 04:54:07,915 DEBUG TRAIN Batch 15/2100 loss 12.080537 loss_att 17.566574 loss_ctc 16.265732 loss_rnnt 10.353616 hw_loss 0.134413 lr 0.00044334 rank 0
2023-02-22 04:54:07,918 DEBUG TRAIN Batch 15/2100 loss 11.868578 loss_att 15.565084 loss_ctc 17.673914 loss_rnnt 10.227918 hw_loss 0.238715 lr 0.00044333 rank 4
2023-02-22 04:55:21,131 DEBUG TRAIN Batch 15/2200 loss 16.912933 loss_att 25.044706 loss_ctc 23.824402 loss_rnnt 14.280563 hw_loss 0.158409 lr 0.00044312 rank 2
2023-02-22 04:55:21,132 DEBUG TRAIN Batch 15/2200 loss 7.262632 loss_att 9.753731 loss_ctc 8.836457 loss_rnnt 6.509438 hw_loss 0.084621 lr 0.00044314 rank 6
2023-02-22 04:55:21,134 DEBUG TRAIN Batch 15/2200 loss 10.842379 loss_att 14.827442 loss_ctc 15.378513 loss_rnnt 9.307371 hw_loss 0.249708 lr 0.00044318 rank 1
2023-02-22 04:55:21,137 DEBUG TRAIN Batch 15/2200 loss 8.321174 loss_att 14.385992 loss_ctc 14.934378 loss_rnnt 6.062757 hw_loss 0.306923 lr 0.00044314 rank 3
2023-02-22 04:55:21,139 DEBUG TRAIN Batch 15/2200 loss 7.804319 loss_att 9.210224 loss_ctc 11.761929 loss_rnnt 6.867014 hw_loss 0.240831 lr 0.00044305 rank 7
2023-02-22 04:55:21,141 DEBUG TRAIN Batch 15/2200 loss 8.194627 loss_att 13.062584 loss_ctc 10.149729 loss_rnnt 6.862895 hw_loss 0.182737 lr 0.00044307 rank 5
2023-02-22 04:55:21,141 DEBUG TRAIN Batch 15/2200 loss 9.426276 loss_att 9.957724 loss_ctc 13.770933 loss_rnnt 8.572250 hw_loss 0.315840 lr 0.00044316 rank 4
2023-02-22 04:55:21,147 DEBUG TRAIN Batch 15/2200 loss 11.877636 loss_att 15.908575 loss_ctc 16.199728 loss_rnnt 10.294849 hw_loss 0.375601 lr 0.00044316 rank 0
2023-02-22 04:56:33,138 DEBUG TRAIN Batch 15/2300 loss 15.040701 loss_att 16.520905 loss_ctc 17.591190 loss_rnnt 14.269695 hw_loss 0.252935 lr 0.00044299 rank 0
2023-02-22 04:56:33,155 DEBUG TRAIN Batch 15/2300 loss 9.273431 loss_att 14.031558 loss_ctc 11.948878 loss_rnnt 7.799784 hw_loss 0.309927 lr 0.00044287 rank 7
2023-02-22 04:56:33,158 DEBUG TRAIN Batch 15/2300 loss 10.255392 loss_att 15.745224 loss_ctc 12.401382 loss_rnnt 8.714220 hw_loss 0.294511 lr 0.00044297 rank 3
2023-02-22 04:56:33,158 DEBUG TRAIN Batch 15/2300 loss 12.082699 loss_att 15.857941 loss_ctc 15.004126 loss_rnnt 10.830338 hw_loss 0.202103 lr 0.00044295 rank 2
2023-02-22 04:56:33,161 DEBUG TRAIN Batch 15/2300 loss 16.052986 loss_att 16.487419 loss_ctc 20.840403 loss_rnnt 15.094404 hw_loss 0.437575 lr 0.00044289 rank 5
2023-02-22 04:56:33,162 DEBUG TRAIN Batch 15/2300 loss 21.366161 loss_att 21.506117 loss_ctc 28.328682 loss_rnnt 20.248863 hw_loss 0.301819 lr 0.00044296 rank 6
2023-02-22 04:56:33,163 DEBUG TRAIN Batch 15/2300 loss 10.156524 loss_att 10.889433 loss_ctc 13.198714 loss_rnnt 9.410743 hw_loss 0.362953 lr 0.00044300 rank 1
2023-02-22 04:56:33,205 DEBUG TRAIN Batch 15/2300 loss 11.312080 loss_att 14.209220 loss_ctc 15.207872 loss_rnnt 10.027772 hw_loss 0.347702 lr 0.00044298 rank 4
2023-02-22 04:57:45,416 DEBUG TRAIN Batch 15/2400 loss 17.748482 loss_att 21.905718 loss_ctc 26.695728 loss_rnnt 15.622427 hw_loss 0.190579 lr 0.00044277 rank 2
2023-02-22 04:57:45,421 DEBUG TRAIN Batch 15/2400 loss 14.320683 loss_att 17.109297 loss_ctc 21.498043 loss_rnnt 12.633533 hw_loss 0.323335 lr 0.00044281 rank 4
2023-02-22 04:57:45,424 DEBUG TRAIN Batch 15/2400 loss 7.423857 loss_att 11.015688 loss_ctc 12.320269 loss_rnnt 5.919160 hw_loss 0.250266 lr 0.00044279 rank 6
2023-02-22 04:57:45,424 DEBUG TRAIN Batch 15/2400 loss 9.050534 loss_att 11.227370 loss_ctc 9.633162 loss_rnnt 8.368484 hw_loss 0.316873 lr 0.00044280 rank 3
2023-02-22 04:57:45,426 DEBUG TRAIN Batch 15/2400 loss 4.518274 loss_att 6.556626 loss_ctc 6.502088 loss_rnnt 3.673939 hw_loss 0.322793 lr 0.00044272 rank 5
2023-02-22 04:57:45,429 DEBUG TRAIN Batch 15/2400 loss 6.014874 loss_att 9.127318 loss_ctc 10.131689 loss_rnnt 4.698735 hw_loss 0.271388 lr 0.00044270 rank 7
2023-02-22 04:57:45,442 DEBUG TRAIN Batch 15/2400 loss 10.595196 loss_att 15.454016 loss_ctc 15.419761 loss_rnnt 8.818688 hw_loss 0.302755 lr 0.00044283 rank 1
2023-02-22 04:57:45,476 DEBUG TRAIN Batch 15/2400 loss 18.939470 loss_att 18.902052 loss_ctc 20.396069 loss_rnnt 18.612665 hw_loss 0.262644 lr 0.00044282 rank 0
2023-02-22 04:59:00,942 DEBUG TRAIN Batch 15/2500 loss 21.878569 loss_att 23.018044 loss_ctc 25.990808 loss_rnnt 20.866657 hw_loss 0.441969 lr 0.00044260 rank 2
2023-02-22 04:59:00,946 DEBUG TRAIN Batch 15/2500 loss 7.070621 loss_att 9.890618 loss_ctc 7.941600 loss_rnnt 6.222938 hw_loss 0.314165 lr 0.00044261 rank 6
2023-02-22 04:59:00,950 DEBUG TRAIN Batch 15/2500 loss 9.359525 loss_att 10.489181 loss_ctc 11.868589 loss_rnnt 8.645810 hw_loss 0.287325 lr 0.00044262 rank 3
2023-02-22 04:59:00,952 DEBUG TRAIN Batch 15/2500 loss 12.890452 loss_att 13.441771 loss_ctc 12.802375 loss_rnnt 12.619925 hw_loss 0.322516 lr 0.00044253 rank 7
2023-02-22 04:59:00,953 DEBUG TRAIN Batch 15/2500 loss 8.576693 loss_att 10.277695 loss_ctc 10.628571 loss_rnnt 7.804985 hw_loss 0.296107 lr 0.00044266 rank 1
2023-02-22 04:59:00,956 DEBUG TRAIN Batch 15/2500 loss 6.190725 loss_att 6.511243 loss_ctc 7.320339 loss_rnnt 5.726241 hw_loss 0.468310 lr 0.00044255 rank 5
2023-02-22 04:59:00,961 DEBUG TRAIN Batch 15/2500 loss 14.449944 loss_att 14.409561 loss_ctc 19.275217 loss_rnnt 13.623821 hw_loss 0.357803 lr 0.00044264 rank 0
2023-02-22 04:59:01,000 DEBUG TRAIN Batch 15/2500 loss 9.783626 loss_att 9.378136 loss_ctc 12.455149 loss_rnnt 9.170140 hw_loss 0.634463 lr 0.00044264 rank 4
2023-02-22 05:00:13,657 DEBUG TRAIN Batch 15/2600 loss 13.505445 loss_att 21.110188 loss_ctc 19.296476 loss_rnnt 11.084617 hw_loss 0.239517 lr 0.00044246 rank 4
2023-02-22 05:00:13,675 DEBUG TRAIN Batch 15/2600 loss 7.376284 loss_att 12.523764 loss_ctc 7.295734 loss_rnnt 6.276125 hw_loss 0.152630 lr 0.00044245 rank 3
2023-02-22 05:00:13,675 DEBUG TRAIN Batch 15/2600 loss 15.291424 loss_att 17.612938 loss_ctc 21.985701 loss_rnnt 13.876644 hw_loss 0.108574 lr 0.00044237 rank 5
2023-02-22 05:00:13,675 DEBUG TRAIN Batch 15/2600 loss 14.924902 loss_att 20.297318 loss_ctc 21.629425 loss_rnnt 12.723116 hw_loss 0.437561 lr 0.00044243 rank 2
2023-02-22 05:00:13,677 DEBUG TRAIN Batch 15/2600 loss 9.774386 loss_att 14.465535 loss_ctc 11.612514 loss_rnnt 8.397023 hw_loss 0.363844 lr 0.00044235 rank 7
2023-02-22 05:00:13,679 DEBUG TRAIN Batch 15/2600 loss 12.603583 loss_att 18.145370 loss_ctc 14.408777 loss_rnnt 11.153034 hw_loss 0.190311 lr 0.00044247 rank 0
2023-02-22 05:00:13,680 DEBUG TRAIN Batch 15/2600 loss 5.125188 loss_att 8.154110 loss_ctc 10.010180 loss_rnnt 3.665163 hw_loss 0.380456 lr 0.00044244 rank 6
2023-02-22 05:00:13,720 DEBUG TRAIN Batch 15/2600 loss 8.951136 loss_att 12.962820 loss_ctc 7.856021 loss_rnnt 8.169802 hw_loss 0.234399 lr 0.00044248 rank 1
2023-02-22 05:01:25,430 DEBUG TRAIN Batch 15/2700 loss 8.702191 loss_att 14.194863 loss_ctc 15.613579 loss_rnnt 6.503160 hw_loss 0.335587 lr 0.00044225 rank 2
2023-02-22 05:01:25,433 DEBUG TRAIN Batch 15/2700 loss 23.508329 loss_att 26.810268 loss_ctc 33.931496 loss_rnnt 21.276566 hw_loss 0.340534 lr 0.00044227 rank 6
2023-02-22 05:01:25,435 DEBUG TRAIN Batch 15/2700 loss 14.172848 loss_att 18.546106 loss_ctc 19.059107 loss_rnnt 12.556739 hw_loss 0.168667 lr 0.00044228 rank 3
2023-02-22 05:01:25,436 DEBUG TRAIN Batch 15/2700 loss 13.146149 loss_att 22.324949 loss_ctc 16.658312 loss_rnnt 10.784071 hw_loss 0.108805 lr 0.00044220 rank 5
2023-02-22 05:01:25,438 DEBUG TRAIN Batch 15/2700 loss 7.679008 loss_att 12.609611 loss_ctc 11.518333 loss_rnnt 5.942636 hw_loss 0.446890 lr 0.00044231 rank 1
2023-02-22 05:01:25,439 DEBUG TRAIN Batch 15/2700 loss 8.033442 loss_att 11.262605 loss_ctc 8.802719 loss_rnnt 7.136110 hw_loss 0.279244 lr 0.00044229 rank 4
2023-02-22 05:01:25,440 DEBUG TRAIN Batch 15/2700 loss 7.302646 loss_att 9.367714 loss_ctc 9.218758 loss_rnnt 6.457424 hw_loss 0.331363 lr 0.00044230 rank 0
2023-02-22 05:01:25,444 DEBUG TRAIN Batch 15/2700 loss 9.774480 loss_att 13.900118 loss_ctc 19.033245 loss_rnnt 7.627624 hw_loss 0.163551 lr 0.00044218 rank 7
2023-02-22 05:02:39,590 DEBUG TRAIN Batch 15/2800 loss 12.939051 loss_att 14.705427 loss_ctc 15.793499 loss_rnnt 12.038811 hw_loss 0.311947 lr 0.00044203 rank 5
2023-02-22 05:02:39,595 DEBUG TRAIN Batch 15/2800 loss 7.994855 loss_att 17.279758 loss_ctc 8.914402 loss_rnnt 5.872566 hw_loss 0.267568 lr 0.00044208 rank 2
2023-02-22 05:02:39,600 DEBUG TRAIN Batch 15/2800 loss 4.755983 loss_att 7.255281 loss_ctc 5.350783 loss_rnnt 4.025582 hw_loss 0.283565 lr 0.00044201 rank 7
2023-02-22 05:02:39,600 DEBUG TRAIN Batch 15/2800 loss 13.587564 loss_att 15.058389 loss_ctc 17.371208 loss_rnnt 12.666258 hw_loss 0.229978 lr 0.00044210 rank 3
2023-02-22 05:02:39,600 DEBUG TRAIN Batch 15/2800 loss 6.000748 loss_att 11.237803 loss_ctc 8.578476 loss_rnnt 4.465002 hw_loss 0.271197 lr 0.00044214 rank 1
2023-02-22 05:02:39,602 DEBUG TRAIN Batch 15/2800 loss 13.376862 loss_att 17.102482 loss_ctc 21.727020 loss_rnnt 11.391632 hw_loss 0.237658 lr 0.00044212 rank 0
2023-02-22 05:02:39,603 DEBUG TRAIN Batch 15/2800 loss 5.501746 loss_att 7.893319 loss_ctc 10.878302 loss_rnnt 4.095903 hw_loss 0.394975 lr 0.00044210 rank 6
2023-02-22 05:02:39,603 DEBUG TRAIN Batch 15/2800 loss 10.708091 loss_att 15.428387 loss_ctc 14.828016 loss_rnnt 9.085501 hw_loss 0.242263 lr 0.00044212 rank 4
2023-02-22 05:03:53,921 DEBUG TRAIN Batch 15/2900 loss 32.780491 loss_att 32.353149 loss_ctc 40.264107 loss_rnnt 31.767136 hw_loss 0.189394 lr 0.00044191 rank 2
2023-02-22 05:03:53,946 DEBUG TRAIN Batch 15/2900 loss 26.771685 loss_att 26.139526 loss_ctc 35.164528 loss_rnnt 25.602039 hw_loss 0.331933 lr 0.00044196 rank 1
2023-02-22 05:03:53,946 DEBUG TRAIN Batch 15/2900 loss 9.223085 loss_att 12.041634 loss_ctc 11.537118 loss_rnnt 8.231826 hw_loss 0.223148 lr 0.00044194 rank 4
2023-02-22 05:03:53,948 DEBUG TRAIN Batch 15/2900 loss 11.915288 loss_att 15.101531 loss_ctc 15.265486 loss_rnnt 10.682008 hw_loss 0.280010 lr 0.00044183 rank 7
2023-02-22 05:03:53,948 DEBUG TRAIN Batch 15/2900 loss 16.982660 loss_att 18.247883 loss_ctc 22.114120 loss_rnnt 15.932922 hw_loss 0.210931 lr 0.00044193 rank 3
2023-02-22 05:03:53,949 DEBUG TRAIN Batch 15/2900 loss 17.142471 loss_att 20.587751 loss_ctc 24.772469 loss_rnnt 15.347996 hw_loss 0.165161 lr 0.00044185 rank 5
2023-02-22 05:03:53,951 DEBUG TRAIN Batch 15/2900 loss 14.383804 loss_att 17.460173 loss_ctc 20.942364 loss_rnnt 12.750660 hw_loss 0.268868 lr 0.00044192 rank 6
2023-02-22 05:03:53,992 DEBUG TRAIN Batch 15/2900 loss 23.847738 loss_att 27.640560 loss_ctc 27.531757 loss_rnnt 22.523369 hw_loss 0.139879 lr 0.00044195 rank 0
2023-02-22 05:05:06,227 DEBUG TRAIN Batch 15/3000 loss 12.858967 loss_att 15.053083 loss_ctc 13.680328 loss_rnnt 12.227564 hw_loss 0.155744 lr 0.00044176 rank 3
2023-02-22 05:05:06,234 DEBUG TRAIN Batch 15/3000 loss 6.755186 loss_att 9.630814 loss_ctc 10.267003 loss_rnnt 5.492442 hw_loss 0.411331 lr 0.00044179 rank 1
2023-02-22 05:05:06,235 DEBUG TRAIN Batch 15/3000 loss 14.778340 loss_att 15.945808 loss_ctc 16.981457 loss_rnnt 14.135563 hw_loss 0.216628 lr 0.00044177 rank 4
2023-02-22 05:05:06,236 DEBUG TRAIN Batch 15/3000 loss 25.003244 loss_att 26.792175 loss_ctc 30.724154 loss_rnnt 23.829588 hw_loss 0.099532 lr 0.00044174 rank 2
2023-02-22 05:05:06,239 DEBUG TRAIN Batch 15/3000 loss 11.860832 loss_att 16.606224 loss_ctc 15.260225 loss_rnnt 10.319163 hw_loss 0.261260 lr 0.00044178 rank 0
2023-02-22 05:05:06,240 DEBUG TRAIN Batch 15/3000 loss 13.011185 loss_att 18.838345 loss_ctc 19.005499 loss_rnnt 10.917970 hw_loss 0.241011 lr 0.00044175 rank 6
2023-02-22 05:05:06,244 DEBUG TRAIN Batch 15/3000 loss 10.729606 loss_att 12.616202 loss_ctc 11.276554 loss_rnnt 10.112123 hw_loss 0.313569 lr 0.00044168 rank 5
2023-02-22 05:05:06,285 DEBUG TRAIN Batch 15/3000 loss 20.939337 loss_att 23.737698 loss_ctc 25.729151 loss_rnnt 19.610920 hw_loss 0.243942 lr 0.00044166 rank 7
2023-02-22 05:06:19,458 DEBUG TRAIN Batch 15/3100 loss 14.689103 loss_att 15.900740 loss_ctc 18.085630 loss_rnnt 13.833403 hw_loss 0.300943 lr 0.00044158 rank 6
2023-02-22 05:06:19,459 DEBUG TRAIN Batch 15/3100 loss 6.290781 loss_att 9.709539 loss_ctc 6.837426 loss_rnnt 5.268826 hw_loss 0.497471 lr 0.00044156 rank 2
2023-02-22 05:06:19,463 DEBUG TRAIN Batch 15/3100 loss 13.145133 loss_att 14.665047 loss_ctc 14.981522 loss_rnnt 12.428377 hw_loss 0.314854 lr 0.00044159 rank 3
2023-02-22 05:06:19,464 DEBUG TRAIN Batch 15/3100 loss 13.144377 loss_att 15.151783 loss_ctc 16.388126 loss_rnnt 12.174544 hw_loss 0.254722 lr 0.00044161 rank 0
2023-02-22 05:06:19,468 DEBUG TRAIN Batch 15/3100 loss 6.299739 loss_att 7.831453 loss_ctc 8.506844 loss_rnnt 5.566672 hw_loss 0.248332 lr 0.00044160 rank 4
2023-02-22 05:06:19,468 DEBUG TRAIN Batch 15/3100 loss 17.051161 loss_att 19.445091 loss_ctc 24.456409 loss_rnnt 15.478651 hw_loss 0.199424 lr 0.00044162 rank 1
2023-02-22 05:06:19,470 DEBUG TRAIN Batch 15/3100 loss 8.315552 loss_att 11.750237 loss_ctc 10.566363 loss_rnnt 7.117682 hw_loss 0.395295 lr 0.00044149 rank 7
2023-02-22 05:06:19,542 DEBUG TRAIN Batch 15/3100 loss 12.427703 loss_att 13.229874 loss_ctc 16.367273 loss_rnnt 11.474658 hw_loss 0.501253 lr 0.00044151 rank 5
2023-02-22 05:07:34,612 DEBUG TRAIN Batch 15/3200 loss 38.424736 loss_att 43.262142 loss_ctc 47.458023 loss_rnnt 36.130081 hw_loss 0.230134 lr 0.00044141 rank 3
2023-02-22 05:07:34,618 DEBUG TRAIN Batch 15/3200 loss 3.924969 loss_att 7.291196 loss_ctc 4.787111 loss_rnnt 2.966891 hw_loss 0.318527 lr 0.00044143 rank 0
2023-02-22 05:07:34,619 DEBUG TRAIN Batch 15/3200 loss 8.628517 loss_att 12.776577 loss_ctc 11.909252 loss_rnnt 7.210171 hw_loss 0.283693 lr 0.00044132 rank 7
2023-02-22 05:07:34,624 DEBUG TRAIN Batch 15/3200 loss 14.420823 loss_att 20.096003 loss_ctc 22.994370 loss_rnnt 12.098736 hw_loss 0.082332 lr 0.00044141 rank 6
2023-02-22 05:07:34,623 DEBUG TRAIN Batch 15/3200 loss 10.071444 loss_att 11.681439 loss_ctc 14.679887 loss_rnnt 8.926312 hw_loss 0.391259 lr 0.00044139 rank 2
2023-02-22 05:07:34,624 DEBUG TRAIN Batch 15/3200 loss 5.650637 loss_att 9.484370 loss_ctc 7.403903 loss_rnnt 4.570415 hw_loss 0.149448 lr 0.00044143 rank 4
2023-02-22 05:07:34,624 DEBUG TRAIN Batch 15/3200 loss 12.220129 loss_att 12.341542 loss_ctc 16.050653 loss_rnnt 11.353011 hw_loss 0.622685 lr 0.00044145 rank 1
2023-02-22 05:07:34,695 DEBUG TRAIN Batch 15/3200 loss 19.122057 loss_att 21.889311 loss_ctc 23.042929 loss_rnnt 17.896879 hw_loss 0.279270 lr 0.00044134 rank 5
2023-02-22 05:08:47,011 DEBUG TRAIN Batch 15/3300 loss 14.214882 loss_att 13.774397 loss_ctc 16.572504 loss_rnnt 13.714293 hw_loss 0.514379 lr 0.00044123 rank 6
2023-02-22 05:08:47,028 DEBUG TRAIN Batch 15/3300 loss 13.935345 loss_att 16.880592 loss_ctc 18.379852 loss_rnnt 12.597445 hw_loss 0.292966 lr 0.00044125 rank 4
2023-02-22 05:08:47,029 DEBUG TRAIN Batch 15/3300 loss 17.674557 loss_att 24.101826 loss_ctc 21.542610 loss_rnnt 15.760578 hw_loss 0.211470 lr 0.00044128 rank 1
2023-02-22 05:08:47,030 DEBUG TRAIN Batch 15/3300 loss 25.444330 loss_att 29.676693 loss_ctc 40.469433 loss_rnnt 22.508556 hw_loss 0.161166 lr 0.00044117 rank 5
2023-02-22 05:08:47,031 DEBUG TRAIN Batch 15/3300 loss 14.900956 loss_att 15.341435 loss_ctc 19.474737 loss_rnnt 14.022150 hw_loss 0.339136 lr 0.00044122 rank 2
2023-02-22 05:08:47,031 DEBUG TRAIN Batch 15/3300 loss 4.911364 loss_att 9.680592 loss_ctc 6.469645 loss_rnnt 3.616962 hw_loss 0.248972 lr 0.00044124 rank 3
2023-02-22 05:08:47,034 DEBUG TRAIN Batch 15/3300 loss 12.985769 loss_att 14.871981 loss_ctc 13.653328 loss_rnnt 12.340321 hw_loss 0.335998 lr 0.00044126 rank 0
2023-02-22 05:08:47,083 DEBUG TRAIN Batch 15/3300 loss 10.058723 loss_att 11.620458 loss_ctc 12.356277 loss_rnnt 9.243999 hw_loss 0.367569 lr 0.00044115 rank 7
2023-02-22 05:09:59,604 DEBUG TRAIN Batch 15/3400 loss 14.708775 loss_att 18.380745 loss_ctc 18.774033 loss_rnnt 13.360764 hw_loss 0.134217 lr 0.00044105 rank 2
2023-02-22 05:09:59,607 DEBUG TRAIN Batch 15/3400 loss 20.367533 loss_att 24.925377 loss_ctc 25.999329 loss_rnnt 18.502115 hw_loss 0.380512 lr 0.00044097 rank 7
2023-02-22 05:09:59,609 DEBUG TRAIN Batch 15/3400 loss 12.213471 loss_att 15.405008 loss_ctc 18.494308 loss_rnnt 10.633017 hw_loss 0.196315 lr 0.00044107 rank 3
2023-02-22 05:09:59,608 DEBUG TRAIN Batch 15/3400 loss 14.611231 loss_att 17.723154 loss_ctc 18.563496 loss_rnnt 13.383377 hw_loss 0.147189 lr 0.00044106 rank 6
2023-02-22 05:09:59,612 DEBUG TRAIN Batch 15/3400 loss 10.338849 loss_att 9.955445 loss_ctc 12.193953 loss_rnnt 9.971816 hw_loss 0.368187 lr 0.00044109 rank 0
2023-02-22 05:09:59,613 DEBUG TRAIN Batch 15/3400 loss 11.739963 loss_att 14.288890 loss_ctc 17.345913 loss_rnnt 10.353376 hw_loss 0.242515 lr 0.00044099 rank 5
2023-02-22 05:09:59,614 DEBUG TRAIN Batch 15/3400 loss 16.116228 loss_att 15.505843 loss_ctc 16.404207 loss_rnnt 16.123350 hw_loss 0.143547 lr 0.00044108 rank 4
2023-02-22 05:09:59,616 DEBUG TRAIN Batch 15/3400 loss 9.115940 loss_att 11.263286 loss_ctc 11.283308 loss_rnnt 8.340910 hw_loss 0.106084 lr 0.00044110 rank 1
2023-02-22 05:11:12,914 DEBUG TRAIN Batch 15/3500 loss 12.388183 loss_att 14.971636 loss_ctc 15.997486 loss_rnnt 11.274763 hw_loss 0.216542 lr 0.00044088 rank 2
2023-02-22 05:11:12,917 DEBUG TRAIN Batch 15/3500 loss 9.955095 loss_att 12.444388 loss_ctc 15.042728 loss_rnnt 8.524099 hw_loss 0.477724 lr 0.00044080 rank 7
2023-02-22 05:11:12,932 DEBUG TRAIN Batch 15/3500 loss 26.516859 loss_att 28.015980 loss_ctc 31.918777 loss_rnnt 25.368053 hw_loss 0.241361 lr 0.00044089 rank 6
2023-02-22 05:11:12,933 DEBUG TRAIN Batch 15/3500 loss 18.229137 loss_att 21.808947 loss_ctc 30.553505 loss_rnnt 15.685961 hw_loss 0.344936 lr 0.00044082 rank 5
2023-02-22 05:11:12,936 DEBUG TRAIN Batch 15/3500 loss 19.172123 loss_att 21.108345 loss_ctc 30.112854 loss_rnnt 17.196417 hw_loss 0.243184 lr 0.00044093 rank 1
2023-02-22 05:11:12,937 DEBUG TRAIN Batch 15/3500 loss 12.784931 loss_att 14.591061 loss_ctc 20.594471 loss_rnnt 11.178164 hw_loss 0.383006 lr 0.00044091 rank 4
2023-02-22 05:11:12,944 DEBUG TRAIN Batch 15/3500 loss 8.987864 loss_att 9.036022 loss_ctc 11.756183 loss_rnnt 8.496747 hw_loss 0.210707 lr 0.00044092 rank 0
2023-02-22 05:11:12,961 DEBUG TRAIN Batch 15/3500 loss 8.797479 loss_att 12.688446 loss_ctc 11.872584 loss_rnnt 7.489916 hw_loss 0.223792 lr 0.00044090 rank 3
2023-02-22 05:12:27,038 DEBUG TRAIN Batch 15/3600 loss 10.703635 loss_att 13.971483 loss_ctc 12.674795 loss_rnnt 9.623819 hw_loss 0.306422 lr 0.00044063 rank 7
2023-02-22 05:12:27,042 DEBUG TRAIN Batch 15/3600 loss 12.146816 loss_att 14.637985 loss_ctc 15.079365 loss_rnnt 11.119419 hw_loss 0.259043 lr 0.00044071 rank 2
2023-02-22 05:12:27,046 DEBUG TRAIN Batch 15/3600 loss 12.708545 loss_att 14.743891 loss_ctc 17.177620 loss_rnnt 11.592674 hw_loss 0.211732 lr 0.00044075 rank 0
2023-02-22 05:12:27,049 DEBUG TRAIN Batch 15/3600 loss 7.210093 loss_att 9.673105 loss_ctc 11.233416 loss_rnnt 6.039227 hw_loss 0.265914 lr 0.00044073 rank 3
2023-02-22 05:12:27,050 DEBUG TRAIN Batch 15/3600 loss 4.037267 loss_att 7.017995 loss_ctc 4.392266 loss_rnnt 3.201289 hw_loss 0.360937 lr 0.00044076 rank 1
2023-02-22 05:12:27,051 DEBUG TRAIN Batch 15/3600 loss 7.892197 loss_att 10.860308 loss_ctc 9.749824 loss_rnnt 6.956366 hw_loss 0.177236 lr 0.00044065 rank 5
2023-02-22 05:12:27,051 DEBUG TRAIN Batch 15/3600 loss 9.649556 loss_att 13.212996 loss_ctc 12.353123 loss_rnnt 8.351712 hw_loss 0.421273 lr 0.00044072 rank 6
2023-02-22 05:12:27,054 DEBUG TRAIN Batch 15/3600 loss 11.781023 loss_att 14.313355 loss_ctc 13.557499 loss_rnnt 10.946772 hw_loss 0.170477 lr 0.00044074 rank 4
2023-02-22 05:13:39,556 DEBUG TRAIN Batch 15/3700 loss 7.676974 loss_att 11.375010 loss_ctc 12.753218 loss_rnnt 6.044878 hw_loss 0.404355 lr 0.00044053 rank 2
2023-02-22 05:13:39,559 DEBUG TRAIN Batch 15/3700 loss 10.914372 loss_att 13.905722 loss_ctc 15.199114 loss_rnnt 9.617208 hw_loss 0.239242 lr 0.00044056 rank 3
2023-02-22 05:13:39,560 DEBUG TRAIN Batch 15/3700 loss 8.183264 loss_att 9.807107 loss_ctc 11.088560 loss_rnnt 7.254366 hw_loss 0.406417 lr 0.00044046 rank 7
2023-02-22 05:13:39,562 DEBUG TRAIN Batch 15/3700 loss 10.036379 loss_att 12.496615 loss_ctc 12.727592 loss_rnnt 9.060473 hw_loss 0.234429 lr 0.00044059 rank 1
2023-02-22 05:13:39,563 DEBUG TRAIN Batch 15/3700 loss 20.656628 loss_att 21.904161 loss_ctc 25.380350 loss_rnnt 19.627918 hw_loss 0.280076 lr 0.00044058 rank 0
2023-02-22 05:13:39,563 DEBUG TRAIN Batch 15/3700 loss 6.188323 loss_att 7.645097 loss_ctc 6.427101 loss_rnnt 5.680062 hw_loss 0.347005 lr 0.00044055 rank 6
2023-02-22 05:13:39,565 DEBUG TRAIN Batch 15/3700 loss 8.441771 loss_att 11.872829 loss_ctc 12.953616 loss_rnnt 6.985115 hw_loss 0.316619 lr 0.00044057 rank 4
2023-02-22 05:13:39,615 DEBUG TRAIN Batch 15/3700 loss 13.186271 loss_att 16.177528 loss_ctc 16.047918 loss_rnnt 12.061610 hw_loss 0.271606 lr 0.00044048 rank 5
2023-02-22 05:14:52,766 DEBUG TRAIN Batch 15/3800 loss 19.521461 loss_att 19.456942 loss_ctc 21.461500 loss_rnnt 19.125830 hw_loss 0.280994 lr 0.00044036 rank 2
2023-02-22 05:14:52,768 DEBUG TRAIN Batch 15/3800 loss 10.266332 loss_att 10.038703 loss_ctc 12.075102 loss_rnnt 9.880020 hw_loss 0.357501 lr 0.00044039 rank 3
2023-02-22 05:14:52,771 DEBUG TRAIN Batch 15/3800 loss 16.008583 loss_att 17.681376 loss_ctc 20.591114 loss_rnnt 14.931849 hw_loss 0.245946 lr 0.00044038 rank 6
2023-02-22 05:14:52,778 DEBUG TRAIN Batch 15/3800 loss 14.670674 loss_att 14.348169 loss_ctc 19.049337 loss_rnnt 13.926811 hw_loss 0.421016 lr 0.00044040 rank 4
2023-02-22 05:14:52,778 DEBUG TRAIN Batch 15/3800 loss 16.640285 loss_att 18.073978 loss_ctc 20.675236 loss_rnnt 15.666738 hw_loss 0.279027 lr 0.00044042 rank 1
2023-02-22 05:14:52,778 DEBUG TRAIN Batch 15/3800 loss 9.276114 loss_att 12.677469 loss_ctc 12.818069 loss_rnnt 8.040520 hw_loss 0.155742 lr 0.00044031 rank 5
2023-02-22 05:14:52,780 DEBUG TRAIN Batch 15/3800 loss 17.117743 loss_att 17.810064 loss_ctc 21.065409 loss_rnnt 16.327583 hw_loss 0.235011 lr 0.00044029 rank 7
2023-02-22 05:14:52,832 DEBUG TRAIN Batch 15/3800 loss 5.316432 loss_att 8.244043 loss_ctc 6.920902 loss_rnnt 4.427452 hw_loss 0.167865 lr 0.00044040 rank 0
2023-02-22 05:16:07,309 DEBUG TRAIN Batch 15/3900 loss 7.159523 loss_att 10.679051 loss_ctc 13.682503 loss_rnnt 5.426794 hw_loss 0.298300 lr 0.00044025 rank 1
2023-02-22 05:16:07,316 DEBUG TRAIN Batch 15/3900 loss 11.776866 loss_att 11.605432 loss_ctc 14.967206 loss_rnnt 11.137766 hw_loss 0.465015 lr 0.00044019 rank 2
2023-02-22 05:16:07,323 DEBUG TRAIN Batch 15/3900 loss 10.277401 loss_att 11.847336 loss_ctc 16.597488 loss_rnnt 8.965303 hw_loss 0.291436 lr 0.00044022 rank 3
2023-02-22 05:16:07,324 DEBUG TRAIN Batch 15/3900 loss 6.559083 loss_att 9.513832 loss_ctc 8.486059 loss_rnnt 5.552101 hw_loss 0.298315 lr 0.00044014 rank 5
2023-02-22 05:16:07,324 DEBUG TRAIN Batch 15/3900 loss 14.812507 loss_att 19.839428 loss_ctc 18.103148 loss_rnnt 13.268013 hw_loss 0.188170 lr 0.00044012 rank 7
2023-02-22 05:16:07,325 DEBUG TRAIN Batch 15/3900 loss 10.674886 loss_att 14.254698 loss_ctc 12.706354 loss_rnnt 9.472389 hw_loss 0.404384 lr 0.00044021 rank 6
2023-02-22 05:16:07,331 DEBUG TRAIN Batch 15/3900 loss 9.469102 loss_att 10.299433 loss_ctc 11.658114 loss_rnnt 8.847910 hw_loss 0.306109 lr 0.00044023 rank 0
2023-02-22 05:16:07,377 DEBUG TRAIN Batch 15/3900 loss 7.539804 loss_att 12.748229 loss_ctc 12.491850 loss_rnnt 5.593619 hw_loss 0.457925 lr 0.00044023 rank 4
2023-02-22 05:17:19,972 DEBUG TRAIN Batch 15/4000 loss 14.384058 loss_att 21.684517 loss_ctc 25.014050 loss_rnnt 11.324417 hw_loss 0.341655 lr 0.00044008 rank 1
2023-02-22 05:17:19,975 DEBUG TRAIN Batch 15/4000 loss 13.130908 loss_att 19.452354 loss_ctc 15.788250 loss_rnnt 11.410448 hw_loss 0.190983 lr 0.00044006 rank 4
2023-02-22 05:17:19,975 DEBUG TRAIN Batch 15/4000 loss 13.149157 loss_att 15.851944 loss_ctc 19.897217 loss_rnnt 11.489276 hw_loss 0.411717 lr 0.00044004 rank 3
2023-02-22 05:17:19,975 DEBUG TRAIN Batch 15/4000 loss 12.379150 loss_att 14.555283 loss_ctc 12.803107 loss_rnnt 11.726692 hw_loss 0.301320 lr 0.00044004 rank 6
2023-02-22 05:17:19,975 DEBUG TRAIN Batch 15/4000 loss 14.920555 loss_att 19.944771 loss_ctc 18.517298 loss_rnnt 13.353514 hw_loss 0.154940 lr 0.00044002 rank 2
2023-02-22 05:17:19,976 DEBUG TRAIN Batch 15/4000 loss 7.640798 loss_att 9.758726 loss_ctc 11.154919 loss_rnnt 6.613197 hw_loss 0.253998 lr 0.00043995 rank 7
2023-02-22 05:17:19,977 DEBUG TRAIN Batch 15/4000 loss 13.561007 loss_att 19.352409 loss_ctc 15.323259 loss_rnnt 12.064188 hw_loss 0.194197 lr 0.00044006 rank 0
2023-02-22 05:17:19,983 DEBUG TRAIN Batch 15/4000 loss 10.532973 loss_att 14.550219 loss_ctc 15.878448 loss_rnnt 8.881010 hw_loss 0.254595 lr 0.00043997 rank 5
2023-02-22 05:18:32,224 DEBUG TRAIN Batch 15/4100 loss 11.696517 loss_att 15.755119 loss_ctc 12.123980 loss_rnnt 10.615258 hw_loss 0.398520 lr 0.00043978 rank 7
2023-02-22 05:18:32,230 DEBUG TRAIN Batch 15/4100 loss 11.608443 loss_att 14.343257 loss_ctc 13.215309 loss_rnnt 10.740370 hw_loss 0.200367 lr 0.00043985 rank 2
2023-02-22 05:18:32,237 DEBUG TRAIN Batch 15/4100 loss 8.752070 loss_att 11.133905 loss_ctc 13.834351 loss_rnnt 7.453351 hw_loss 0.271339 lr 0.00043991 rank 1
2023-02-22 05:18:32,237 DEBUG TRAIN Batch 15/4100 loss 22.883591 loss_att 22.576231 loss_ctc 27.200932 loss_rnnt 22.304741 hw_loss 0.121267 lr 0.00043989 rank 0
2023-02-22 05:18:32,239 DEBUG TRAIN Batch 15/4100 loss 9.305612 loss_att 12.637918 loss_ctc 12.631807 loss_rnnt 8.042390 hw_loss 0.287375 lr 0.00043987 rank 6
2023-02-22 05:18:32,238 DEBUG TRAIN Batch 15/4100 loss 7.392825 loss_att 10.579567 loss_ctc 8.106476 loss_rnnt 6.498706 hw_loss 0.303033 lr 0.00043989 rank 4
2023-02-22 05:18:32,241 DEBUG TRAIN Batch 15/4100 loss 6.154784 loss_att 9.108597 loss_ctc 9.654467 loss_rnnt 4.980565 hw_loss 0.219060 lr 0.00043987 rank 3
2023-02-22 05:18:32,291 DEBUG TRAIN Batch 15/4100 loss 13.752905 loss_att 17.906048 loss_ctc 16.958126 loss_rnnt 12.349293 hw_loss 0.273039 lr 0.00043980 rank 5
2023-02-22 05:19:45,187 DEBUG TRAIN Batch 15/4200 loss 12.167166 loss_att 14.288306 loss_ctc 15.065248 loss_rnnt 11.135533 hw_loss 0.414362 lr 0.00043972 rank 0
2023-02-22 05:19:45,199 DEBUG TRAIN Batch 15/4200 loss 10.961612 loss_att 15.548038 loss_ctc 14.434020 loss_rnnt 9.493194 hw_loss 0.165272 lr 0.00043970 rank 6
2023-02-22 05:19:45,199 DEBUG TRAIN Batch 15/4200 loss 12.706994 loss_att 12.708176 loss_ctc 18.662806 loss_rnnt 11.702030 hw_loss 0.394912 lr 0.00043970 rank 3
2023-02-22 05:19:45,199 DEBUG TRAIN Batch 15/4200 loss 13.281376 loss_att 14.538358 loss_ctc 16.396154 loss_rnnt 12.486167 hw_loss 0.240955 lr 0.00043968 rank 2
2023-02-22 05:19:45,201 DEBUG TRAIN Batch 15/4200 loss 9.257041 loss_att 11.647442 loss_ctc 11.786997 loss_rnnt 8.318122 hw_loss 0.231586 lr 0.00043972 rank 4
2023-02-22 05:19:45,202 DEBUG TRAIN Batch 15/4200 loss 14.814911 loss_att 18.758741 loss_ctc 17.267319 loss_rnnt 13.602194 hw_loss 0.181807 lr 0.00043974 rank 1
2023-02-22 05:19:45,213 DEBUG TRAIN Batch 15/4200 loss 13.214654 loss_att 13.819179 loss_ctc 13.478660 loss_rnnt 12.905176 hw_loss 0.287571 lr 0.00043963 rank 5
2023-02-22 05:19:45,217 DEBUG TRAIN Batch 15/4200 loss 14.314075 loss_att 18.147053 loss_ctc 19.053371 loss_rnnt 12.762264 hw_loss 0.287455 lr 0.00043961 rank 7
2023-02-22 05:20:59,440 DEBUG TRAIN Batch 15/4300 loss 18.870495 loss_att 20.198271 loss_ctc 20.884777 loss_rnnt 18.161860 hw_loss 0.327201 lr 0.00043953 rank 3
2023-02-22 05:20:59,441 DEBUG TRAIN Batch 15/4300 loss 18.874968 loss_att 23.677914 loss_ctc 22.698446 loss_rnnt 17.273888 hw_loss 0.245052 lr 0.00043951 rank 2
2023-02-22 05:20:59,442 DEBUG TRAIN Batch 15/4300 loss 14.853333 loss_att 20.318661 loss_ctc 20.557377 loss_rnnt 12.868258 hw_loss 0.246509 lr 0.00043955 rank 0
2023-02-22 05:20:59,443 DEBUG TRAIN Batch 15/4300 loss 17.631458 loss_att 20.482563 loss_ctc 25.571806 loss_rnnt 15.903856 hw_loss 0.185001 lr 0.00043953 rank 6
2023-02-22 05:20:59,445 DEBUG TRAIN Batch 15/4300 loss 4.553111 loss_att 10.148335 loss_ctc 6.582872 loss_rnnt 3.081426 hw_loss 0.153758 lr 0.00043944 rank 7
2023-02-22 05:20:59,447 DEBUG TRAIN Batch 15/4300 loss 16.813877 loss_att 14.906274 loss_ctc 21.101313 loss_rnnt 16.421244 hw_loss 0.379675 lr 0.00043955 rank 4
2023-02-22 05:20:59,447 DEBUG TRAIN Batch 15/4300 loss 9.612321 loss_att 13.048693 loss_ctc 11.615260 loss_rnnt 8.531752 hw_loss 0.236692 lr 0.00043957 rank 1
2023-02-22 05:20:59,454 DEBUG TRAIN Batch 15/4300 loss 8.686952 loss_att 10.157572 loss_ctc 10.914319 loss_rnnt 7.870239 hw_loss 0.423009 lr 0.00043946 rank 5
2023-02-22 05:22:11,340 DEBUG TRAIN Batch 15/4400 loss 11.589115 loss_att 15.003402 loss_ctc 14.561572 loss_rnnt 10.320731 hw_loss 0.354751 lr 0.00043936 rank 6
2023-02-22 05:22:11,345 DEBUG TRAIN Batch 15/4400 loss 12.431879 loss_att 15.494715 loss_ctc 15.867165 loss_rnnt 11.262705 hw_loss 0.184814 lr 0.00043934 rank 2
2023-02-22 05:22:11,345 DEBUG TRAIN Batch 15/4400 loss 11.527032 loss_att 15.576536 loss_ctc 15.742465 loss_rnnt 9.972180 hw_loss 0.342925 lr 0.00043938 rank 0
2023-02-22 05:22:11,345 DEBUG TRAIN Batch 15/4400 loss 18.264658 loss_att 21.640245 loss_ctc 26.213755 loss_rnnt 16.322086 hw_loss 0.389203 lr 0.00043936 rank 3
2023-02-22 05:22:11,347 DEBUG TRAIN Batch 15/4400 loss 11.227911 loss_att 13.064087 loss_ctc 18.063093 loss_rnnt 9.831848 hw_loss 0.220256 lr 0.00043940 rank 1
2023-02-22 05:22:11,347 DEBUG TRAIN Batch 15/4400 loss 13.954833 loss_att 15.487344 loss_ctc 17.663996 loss_rnnt 13.009733 hw_loss 0.270080 lr 0.00043929 rank 5
2023-02-22 05:22:11,348 DEBUG TRAIN Batch 15/4400 loss 14.579447 loss_att 15.066780 loss_ctc 19.551294 loss_rnnt 13.637644 hw_loss 0.340165 lr 0.00043938 rank 4
2023-02-22 05:22:11,349 DEBUG TRAIN Batch 15/4400 loss 5.705403 loss_att 9.036639 loss_ctc 7.285435 loss_rnnt 4.668290 hw_loss 0.300367 lr 0.00043927 rank 7
2023-02-22 05:23:24,003 DEBUG TRAIN Batch 15/4500 loss 13.861462 loss_att 18.710733 loss_ctc 18.061001 loss_rnnt 12.245391 hw_loss 0.161772 lr 0.00043921 rank 0
2023-02-22 05:23:24,018 DEBUG TRAIN Batch 15/4500 loss 16.346083 loss_att 16.760376 loss_ctc 18.868023 loss_rnnt 15.789465 hw_loss 0.257813 lr 0.00043917 rank 2
2023-02-22 05:23:24,021 DEBUG TRAIN Batch 15/4500 loss 6.690957 loss_att 9.861309 loss_ctc 9.480540 loss_rnnt 5.580095 hw_loss 0.196589 lr 0.00043920 rank 3
2023-02-22 05:23:24,022 DEBUG TRAIN Batch 15/4500 loss 15.502017 loss_att 21.433207 loss_ctc 24.467319 loss_rnnt 13.019809 hw_loss 0.188619 lr 0.00043912 rank 5
2023-02-22 05:23:24,024 DEBUG TRAIN Batch 15/4500 loss 23.097893 loss_att 23.964626 loss_ctc 31.799391 loss_rnnt 21.638777 hw_loss 0.235444 lr 0.00043910 rank 7
2023-02-22 05:23:24,025 DEBUG TRAIN Batch 15/4500 loss 5.521463 loss_att 9.019573 loss_ctc 7.742895 loss_rnnt 4.321214 hw_loss 0.383318 lr 0.00043919 rank 6
2023-02-22 05:23:24,027 DEBUG TRAIN Batch 15/4500 loss 13.489580 loss_att 16.985092 loss_ctc 19.935085 loss_rnnt 11.788771 hw_loss 0.266827 lr 0.00043921 rank 4
2023-02-22 05:23:24,028 DEBUG TRAIN Batch 15/4500 loss 19.493763 loss_att 22.376820 loss_ctc 22.604229 loss_rnnt 18.284435 hw_loss 0.408728 lr 0.00043923 rank 1
2023-02-22 05:24:38,441 DEBUG TRAIN Batch 15/4600 loss 22.435234 loss_att 25.979437 loss_ctc 27.077000 loss_rnnt 20.935436 hw_loss 0.322602 lr 0.00043893 rank 7
2023-02-22 05:24:38,450 DEBUG TRAIN Batch 15/4600 loss 7.131266 loss_att 10.175972 loss_ctc 11.458819 loss_rnnt 5.762052 hw_loss 0.343623 lr 0.00043904 rank 4
2023-02-22 05:24:38,450 DEBUG TRAIN Batch 15/4600 loss 13.770595 loss_att 15.330936 loss_ctc 20.314489 loss_rnnt 12.414137 hw_loss 0.322257 lr 0.00043903 rank 3
2023-02-22 05:24:38,453 DEBUG TRAIN Batch 15/4600 loss 13.458943 loss_att 20.378529 loss_ctc 23.641479 loss_rnnt 10.646815 hw_loss 0.132264 lr 0.00043895 rank 5
2023-02-22 05:24:38,452 DEBUG TRAIN Batch 15/4600 loss 4.050382 loss_att 5.867614 loss_ctc 6.560855 loss_rnnt 3.216047 hw_loss 0.255298 lr 0.00043900 rank 2
2023-02-22 05:24:38,455 DEBUG TRAIN Batch 15/4600 loss 10.989985 loss_att 11.180819 loss_ctc 11.956144 loss_rnnt 10.666285 hw_loss 0.293837 lr 0.00043906 rank 1
2023-02-22 05:24:38,456 DEBUG TRAIN Batch 15/4600 loss 6.024079 loss_att 13.968565 loss_ctc 12.559942 loss_rnnt 3.485044 hw_loss 0.147542 lr 0.00043902 rank 6
2023-02-22 05:24:38,474 DEBUG TRAIN Batch 15/4600 loss 12.228361 loss_att 16.002354 loss_ctc 14.991898 loss_rnnt 10.898497 hw_loss 0.387367 lr 0.00043904 rank 0
2023-02-22 05:25:51,235 DEBUG TRAIN Batch 15/4700 loss 2.356094 loss_att 4.853938 loss_ctc 2.968822 loss_rnnt 1.609293 hw_loss 0.310378 lr 0.00043888 rank 0
2023-02-22 05:25:51,239 DEBUG TRAIN Batch 15/4700 loss 4.461147 loss_att 7.660598 loss_ctc 8.045852 loss_rnnt 3.228090 hw_loss 0.216011 lr 0.00043887 rank 4
2023-02-22 05:25:51,242 DEBUG TRAIN Batch 15/4700 loss 12.732657 loss_att 18.749372 loss_ctc 18.112898 loss_rnnt 10.707766 hw_loss 0.195343 lr 0.00043883 rank 2
2023-02-22 05:25:51,243 DEBUG TRAIN Batch 15/4700 loss 14.598905 loss_att 17.384779 loss_ctc 23.487982 loss_rnnt 12.764679 hw_loss 0.172197 lr 0.00043886 rank 3
2023-02-22 05:25:51,244 DEBUG TRAIN Batch 15/4700 loss 26.201399 loss_att 30.332575 loss_ctc 30.081053 loss_rnnt 24.739861 hw_loss 0.221282 lr 0.00043885 rank 6
2023-02-22 05:25:51,248 DEBUG TRAIN Batch 15/4700 loss 8.494965 loss_att 14.429803 loss_ctc 12.646995 loss_rnnt 6.652382 hw_loss 0.191271 lr 0.00043889 rank 1
2023-02-22 05:25:51,251 DEBUG TRAIN Batch 15/4700 loss 6.904011 loss_att 10.702226 loss_ctc 11.564542 loss_rnnt 5.414223 hw_loss 0.203889 lr 0.00043878 rank 5
2023-02-22 05:25:51,261 DEBUG TRAIN Batch 15/4700 loss 10.113718 loss_att 13.691522 loss_ctc 13.294712 loss_rnnt 8.882281 hw_loss 0.172019 lr 0.00043876 rank 7
2023-02-22 05:27:03,857 DEBUG TRAIN Batch 15/4800 loss 8.706809 loss_att 10.795962 loss_ctc 11.465701 loss_rnnt 7.809946 hw_loss 0.208464 lr 0.00043869 rank 3
2023-02-22 05:27:03,858 DEBUG TRAIN Batch 15/4800 loss 9.361971 loss_att 13.512172 loss_ctc 14.097747 loss_rnnt 7.725471 hw_loss 0.328166 lr 0.00043867 rank 2
2023-02-22 05:27:03,859 DEBUG TRAIN Batch 15/4800 loss 10.103179 loss_att 13.937438 loss_ctc 14.736135 loss_rnnt 8.600202 hw_loss 0.221993 lr 0.00043859 rank 7
2023-02-22 05:27:03,861 DEBUG TRAIN Batch 15/4800 loss 12.049916 loss_att 16.161224 loss_ctc 17.936192 loss_rnnt 10.319437 hw_loss 0.231337 lr 0.00043861 rank 5
2023-02-22 05:27:03,862 DEBUG TRAIN Batch 15/4800 loss 10.606219 loss_att 15.124693 loss_ctc 16.864286 loss_rnnt 8.723476 hw_loss 0.271200 lr 0.00043870 rank 4
2023-02-22 05:27:03,863 DEBUG TRAIN Batch 15/4800 loss 13.950899 loss_att 18.643608 loss_ctc 20.760639 loss_rnnt 11.946003 hw_loss 0.296978 lr 0.00043868 rank 6
2023-02-22 05:27:03,863 DEBUG TRAIN Batch 15/4800 loss 16.152061 loss_att 19.085127 loss_ctc 24.636822 loss_rnnt 14.334804 hw_loss 0.186270 lr 0.00043872 rank 1
2023-02-22 05:27:03,864 DEBUG TRAIN Batch 15/4800 loss 8.912653 loss_att 11.016660 loss_ctc 11.191636 loss_rnnt 8.027590 hw_loss 0.300747 lr 0.00043871 rank 0
2023-02-22 05:28:17,308 DEBUG TRAIN Batch 15/4900 loss 14.352420 loss_att 19.433468 loss_ctc 18.088531 loss_rnnt 12.667439 hw_loss 0.319917 lr 0.00043850 rank 2
2023-02-22 05:28:17,314 DEBUG TRAIN Batch 15/4900 loss 13.725343 loss_att 15.605284 loss_ctc 17.772692 loss_rnnt 12.644831 hw_loss 0.309144 lr 0.00043842 rank 7
2023-02-22 05:28:17,314 DEBUG TRAIN Batch 15/4900 loss 16.588409 loss_att 19.545321 loss_ctc 20.331842 loss_rnnt 15.373243 hw_loss 0.233737 lr 0.00043855 rank 1
2023-02-22 05:28:17,318 DEBUG TRAIN Batch 15/4900 loss 9.196465 loss_att 11.810010 loss_ctc 11.631113 loss_rnnt 8.206359 hw_loss 0.267706 lr 0.00043844 rank 5
2023-02-22 05:28:17,318 DEBUG TRAIN Batch 15/4900 loss 11.045951 loss_att 13.992743 loss_ctc 15.884314 loss_rnnt 9.627127 hw_loss 0.345656 lr 0.00043852 rank 3
2023-02-22 05:28:17,319 DEBUG TRAIN Batch 15/4900 loss 3.984909 loss_att 7.147017 loss_ctc 4.647954 loss_rnnt 3.065851 hw_loss 0.371681 lr 0.00043851 rank 6
2023-02-22 05:28:17,321 DEBUG TRAIN Batch 15/4900 loss 16.273764 loss_att 20.585426 loss_ctc 24.124994 loss_rnnt 14.231241 hw_loss 0.250051 lr 0.00043853 rank 4
2023-02-22 05:28:17,342 DEBUG TRAIN Batch 15/4900 loss 10.840200 loss_att 14.385950 loss_ctc 14.559642 loss_rnnt 9.512756 hw_loss 0.229440 lr 0.00043854 rank 0
2023-02-22 05:29:32,752 DEBUG TRAIN Batch 15/5000 loss 12.995847 loss_att 16.811604 loss_ctc 16.722973 loss_rnnt 11.565197 hw_loss 0.319777 lr 0.00043833 rank 2
2023-02-22 05:29:32,753 DEBUG TRAIN Batch 15/5000 loss 21.944729 loss_att 20.901339 loss_ctc 28.530228 loss_rnnt 21.110428 hw_loss 0.309211 lr 0.00043835 rank 3
2023-02-22 05:29:32,753 DEBUG TRAIN Batch 15/5000 loss 14.582232 loss_att 16.060509 loss_ctc 20.498375 loss_rnnt 13.366091 hw_loss 0.246876 lr 0.00043834 rank 6
2023-02-22 05:29:32,754 DEBUG TRAIN Batch 15/5000 loss 15.128928 loss_att 14.710295 loss_ctc 18.437614 loss_rnnt 14.614394 hw_loss 0.294569 lr 0.00043838 rank 1
2023-02-22 05:29:32,759 DEBUG TRAIN Batch 15/5000 loss 11.179739 loss_att 12.987520 loss_ctc 14.224193 loss_rnnt 10.237585 hw_loss 0.327509 lr 0.00043826 rank 7
2023-02-22 05:29:32,760 DEBUG TRAIN Batch 15/5000 loss 17.198826 loss_att 18.387854 loss_ctc 21.278912 loss_rnnt 16.236378 hw_loss 0.338682 lr 0.00043837 rank 0
2023-02-22 05:29:32,769 DEBUG TRAIN Batch 15/5000 loss 12.200824 loss_att 13.510766 loss_ctc 14.873443 loss_rnnt 11.421130 hw_loss 0.302541 lr 0.00043827 rank 5
2023-02-22 05:29:32,806 DEBUG TRAIN Batch 15/5000 loss 4.273280 loss_att 6.106094 loss_ctc 8.300665 loss_rnnt 3.254764 hw_loss 0.215565 lr 0.00043836 rank 4
2023-02-22 05:30:46,145 DEBUG TRAIN Batch 15/5100 loss 14.429310 loss_att 14.592710 loss_ctc 16.489527 loss_rnnt 13.864429 hw_loss 0.482820 lr 0.00043821 rank 1
2023-02-22 05:30:46,144 DEBUG TRAIN Batch 15/5100 loss 11.963329 loss_att 12.178858 loss_ctc 12.187298 loss_rnnt 11.777119 hw_loss 0.212328 lr 0.00043816 rank 2
2023-02-22 05:30:46,144 DEBUG TRAIN Batch 15/5100 loss 8.195354 loss_att 13.017555 loss_ctc 9.941889 loss_rnnt 6.867059 hw_loss 0.245595 lr 0.00043819 rank 4
2023-02-22 05:30:46,145 DEBUG TRAIN Batch 15/5100 loss 11.639580 loss_att 12.196663 loss_ctc 14.183281 loss_rnnt 10.952424 hw_loss 0.443585 lr 0.00043820 rank 0
2023-02-22 05:30:46,147 DEBUG TRAIN Batch 15/5100 loss 4.562370 loss_att 6.523663 loss_ctc 4.950412 loss_rnnt 3.998897 hw_loss 0.224018 lr 0.00043817 rank 6
2023-02-22 05:30:46,148 DEBUG TRAIN Batch 15/5100 loss 9.363074 loss_att 9.602847 loss_ctc 12.524026 loss_rnnt 8.458252 hw_loss 0.816388 lr 0.00043818 rank 3
2023-02-22 05:30:46,150 DEBUG TRAIN Batch 15/5100 loss 14.265362 loss_att 15.153593 loss_ctc 16.638660 loss_rnnt 13.641989 hw_loss 0.242413 lr 0.00043809 rank 7
2023-02-22 05:30:46,154 DEBUG TRAIN Batch 15/5100 loss 14.475994 loss_att 13.345407 loss_ctc 18.167006 loss_rnnt 13.937890 hw_loss 0.510162 lr 0.00043811 rank 5
2023-02-22 05:31:59,202 DEBUG TRAIN Batch 15/5200 loss 11.174121 loss_att 10.619053 loss_ctc 14.454242 loss_rnnt 10.488542 hw_loss 0.673579 lr 0.00043799 rank 2
2023-02-22 05:31:59,208 DEBUG TRAIN Batch 15/5200 loss 9.804015 loss_att 12.826672 loss_ctc 11.680079 loss_rnnt 8.776458 hw_loss 0.324159 lr 0.00043794 rank 5
2023-02-22 05:31:59,209 DEBUG TRAIN Batch 15/5200 loss 11.813496 loss_att 15.964266 loss_ctc 17.061275 loss_rnnt 10.151392 hw_loss 0.247961 lr 0.00043801 rank 6
2023-02-22 05:31:59,208 DEBUG TRAIN Batch 15/5200 loss 3.397730 loss_att 6.194819 loss_ctc 2.862918 loss_rnnt 2.791644 hw_loss 0.221206 lr 0.00043801 rank 3
2023-02-22 05:31:59,209 DEBUG TRAIN Batch 15/5200 loss 13.675505 loss_att 13.273987 loss_ctc 15.227656 loss_rnnt 13.401325 hw_loss 0.276619 lr 0.00043805 rank 1
2023-02-22 05:31:59,210 DEBUG TRAIN Batch 15/5200 loss 12.198067 loss_att 18.682066 loss_ctc 21.016766 loss_rnnt 9.508778 hw_loss 0.406240 lr 0.00043803 rank 4
2023-02-22 05:31:59,213 DEBUG TRAIN Batch 15/5200 loss 5.868101 loss_att 10.138917 loss_ctc 7.446527 loss_rnnt 4.730362 hw_loss 0.137097 lr 0.00043803 rank 0
2023-02-22 05:31:59,257 DEBUG TRAIN Batch 15/5200 loss 9.508037 loss_att 11.234550 loss_ctc 16.038776 loss_rnnt 8.120377 hw_loss 0.321733 lr 0.00043792 rank 7
2023-02-22 05:33:13,582 DEBUG TRAIN Batch 15/5300 loss 11.367054 loss_att 14.455309 loss_ctc 13.057406 loss_rnnt 10.458488 hw_loss 0.122875 lr 0.00043786 rank 0
2023-02-22 05:33:13,590 DEBUG TRAIN Batch 15/5300 loss 8.274735 loss_att 11.284431 loss_ctc 14.726901 loss_rnnt 6.646430 hw_loss 0.311395 lr 0.00043777 rank 5
2023-02-22 05:33:13,604 DEBUG TRAIN Batch 15/5300 loss 3.581222 loss_att 7.214556 loss_ctc 4.961900 loss_rnnt 2.555194 hw_loss 0.216133 lr 0.00043786 rank 4
2023-02-22 05:33:13,605 DEBUG TRAIN Batch 15/5300 loss 8.688016 loss_att 15.008120 loss_ctc 11.039846 loss_rnnt 6.996549 hw_loss 0.213504 lr 0.00043782 rank 2
2023-02-22 05:33:13,610 DEBUG TRAIN Batch 15/5300 loss 12.319371 loss_att 19.811586 loss_ctc 14.596629 loss_rnnt 10.377933 hw_loss 0.261301 lr 0.00043785 rank 3
2023-02-22 05:33:13,611 DEBUG TRAIN Batch 15/5300 loss 21.756182 loss_att 26.934912 loss_ctc 34.331448 loss_rnnt 18.982275 hw_loss 0.115233 lr 0.00043784 rank 6
2023-02-22 05:33:13,622 DEBUG TRAIN Batch 15/5300 loss 7.830875 loss_att 9.613654 loss_ctc 10.311119 loss_rnnt 7.054609 hw_loss 0.166898 lr 0.00043775 rank 7
2023-02-22 05:33:13,629 DEBUG TRAIN Batch 15/5300 loss 14.885006 loss_att 19.521061 loss_ctc 17.166142 loss_rnnt 13.456606 hw_loss 0.369444 lr 0.00043788 rank 1
2023-02-22 05:34:27,127 DEBUG TRAIN Batch 15/5400 loss 9.641578 loss_att 13.563852 loss_ctc 13.301060 loss_rnnt 8.265147 hw_loss 0.195085 lr 0.00043760 rank 5
2023-02-22 05:34:27,131 DEBUG TRAIN Batch 15/5400 loss 11.385048 loss_att 15.770824 loss_ctc 17.490776 loss_rnnt 9.573467 hw_loss 0.225616 lr 0.00043766 rank 2
2023-02-22 05:34:27,133 DEBUG TRAIN Batch 15/5400 loss 21.826870 loss_att 24.290264 loss_ctc 33.631359 loss_rnnt 19.569832 hw_loss 0.357050 lr 0.00043771 rank 1
2023-02-22 05:34:27,136 DEBUG TRAIN Batch 15/5400 loss 16.956436 loss_att 16.805033 loss_ctc 25.531792 loss_rnnt 15.638126 hw_loss 0.384765 lr 0.00043767 rank 6
2023-02-22 05:34:27,139 DEBUG TRAIN Batch 15/5400 loss 10.127095 loss_att 11.552609 loss_ctc 11.497324 loss_rnnt 9.460770 hw_loss 0.372236 lr 0.00043769 rank 4
2023-02-22 05:34:27,138 DEBUG TRAIN Batch 15/5400 loss 13.107823 loss_att 16.629099 loss_ctc 18.591904 loss_rnnt 11.556705 hw_loss 0.216851 lr 0.00043770 rank 0
2023-02-22 05:34:27,139 DEBUG TRAIN Batch 15/5400 loss 17.472496 loss_att 18.876343 loss_ctc 21.564264 loss_rnnt 16.485037 hw_loss 0.302104 lr 0.00043758 rank 7
2023-02-22 05:34:27,140 DEBUG TRAIN Batch 15/5400 loss 6.359921 loss_att 9.191763 loss_ctc 7.101048 loss_rnnt 5.601146 hw_loss 0.175480 lr 0.00043768 rank 3
2023-02-22 05:35:38,126 DEBUG TRAIN Batch 15/5500 loss 13.470604 loss_att 16.436008 loss_ctc 16.282782 loss_rnnt 12.302415 hw_loss 0.375283 lr 0.00043742 rank 7
2023-02-22 05:35:38,127 DEBUG TRAIN Batch 15/5500 loss 8.833098 loss_att 11.710301 loss_ctc 11.146908 loss_rnnt 7.860715 hw_loss 0.165815 lr 0.00043752 rank 4
2023-02-22 05:35:38,128 DEBUG TRAIN Batch 15/5500 loss 14.112410 loss_att 17.001865 loss_ctc 19.046860 loss_rnnt 12.795244 hw_loss 0.152525 lr 0.00043750 rank 6
2023-02-22 05:35:38,131 DEBUG TRAIN Batch 15/5500 loss 16.293264 loss_att 17.464691 loss_ctc 20.517366 loss_rnnt 15.333616 hw_loss 0.304034 lr 0.00043749 rank 2
2023-02-22 05:35:38,131 DEBUG TRAIN Batch 15/5500 loss 15.118125 loss_att 15.631528 loss_ctc 15.054424 loss_rnnt 14.919159 hw_loss 0.196458 lr 0.00043754 rank 1
2023-02-22 05:35:38,132 DEBUG TRAIN Batch 15/5500 loss 9.871685 loss_att 12.443571 loss_ctc 10.669806 loss_rnnt 9.151649 hw_loss 0.186078 lr 0.00043753 rank 0
2023-02-22 05:35:38,133 DEBUG TRAIN Batch 15/5500 loss 8.466605 loss_att 11.133869 loss_ctc 10.360956 loss_rnnt 7.455651 hw_loss 0.421726 lr 0.00043744 rank 5
2023-02-22 05:35:38,134 DEBUG TRAIN Batch 15/5500 loss 18.361712 loss_att 21.178778 loss_ctc 27.276035 loss_rnnt 16.455086 hw_loss 0.289942 lr 0.00043751 rank 3
2023-02-22 05:36:50,317 DEBUG TRAIN Batch 15/5600 loss 8.749659 loss_att 11.498356 loss_ctc 9.631639 loss_rnnt 7.940893 hw_loss 0.265179 lr 0.00043737 rank 1
2023-02-22 05:36:50,329 DEBUG TRAIN Batch 15/5600 loss 8.359523 loss_att 12.156125 loss_ctc 11.241787 loss_rnnt 7.070417 hw_loss 0.272781 lr 0.00043732 rank 2
2023-02-22 05:36:50,332 DEBUG TRAIN Batch 15/5600 loss 13.019462 loss_att 15.059269 loss_ctc 18.798666 loss_rnnt 11.757822 hw_loss 0.155844 lr 0.00043735 rank 4
2023-02-22 05:36:50,334 DEBUG TRAIN Batch 15/5600 loss 15.842562 loss_att 20.065083 loss_ctc 21.882801 loss_rnnt 14.063797 hw_loss 0.241677 lr 0.00043734 rank 3
2023-02-22 05:36:50,334 DEBUG TRAIN Batch 15/5600 loss 11.034946 loss_att 14.401433 loss_ctc 14.731204 loss_rnnt 9.669379 hw_loss 0.373940 lr 0.00043727 rank 5
2023-02-22 05:36:50,335 DEBUG TRAIN Batch 15/5600 loss 13.115451 loss_att 14.403009 loss_ctc 19.262964 loss_rnnt 11.923132 hw_loss 0.215885 lr 0.00043736 rank 0
2023-02-22 05:36:50,338 DEBUG TRAIN Batch 15/5600 loss 10.718616 loss_att 11.609618 loss_ctc 13.719827 loss_rnnt 10.067904 hw_loss 0.135657 lr 0.00043725 rank 7
2023-02-22 05:36:50,355 DEBUG TRAIN Batch 15/5600 loss 15.346451 loss_att 20.325054 loss_ctc 20.922935 loss_rnnt 13.442911 hw_loss 0.308037 lr 0.00043733 rank 6
2023-02-22 05:38:05,367 DEBUG TRAIN Batch 15/5700 loss 8.766179 loss_att 9.088350 loss_ctc 11.603873 loss_rnnt 8.128886 hw_loss 0.364687 lr 0.00043717 rank 6
2023-02-22 05:38:05,370 DEBUG TRAIN Batch 15/5700 loss 8.771679 loss_att 11.550539 loss_ctc 12.066935 loss_rnnt 7.610864 hw_loss 0.310641 lr 0.00043715 rank 2
2023-02-22 05:38:05,372 DEBUG TRAIN Batch 15/5700 loss 6.857836 loss_att 8.372755 loss_ctc 9.357276 loss_rnnt 6.106045 hw_loss 0.216654 lr 0.00043708 rank 7
2023-02-22 05:38:05,374 DEBUG TRAIN Batch 15/5700 loss 10.601719 loss_att 12.317099 loss_ctc 14.387733 loss_rnnt 9.547462 hw_loss 0.386960 lr 0.00043719 rank 0
2023-02-22 05:38:05,374 DEBUG TRAIN Batch 15/5700 loss 8.510513 loss_att 9.072989 loss_ctc 12.456841 loss_rnnt 7.600295 hw_loss 0.509150 lr 0.00043719 rank 4
2023-02-22 05:38:05,375 DEBUG TRAIN Batch 15/5700 loss 17.457285 loss_att 17.202961 loss_ctc 23.503500 loss_rnnt 16.516876 hw_loss 0.347085 lr 0.00043718 rank 3
2023-02-22 05:38:05,376 DEBUG TRAIN Batch 15/5700 loss 14.530517 loss_att 14.462225 loss_ctc 19.070576 loss_rnnt 13.767390 hw_loss 0.321458 lr 0.00043710 rank 5
2023-02-22 05:38:05,377 DEBUG TRAIN Batch 15/5700 loss 12.331811 loss_att 11.404087 loss_ctc 13.348224 loss_rnnt 12.137931 hw_loss 0.457319 lr 0.00043721 rank 1
2023-02-22 05:39:16,890 DEBUG TRAIN Batch 15/5800 loss 8.357830 loss_att 10.840031 loss_ctc 12.649199 loss_rnnt 7.117489 hw_loss 0.321972 lr 0.00043699 rank 2
2023-02-22 05:39:16,900 DEBUG TRAIN Batch 15/5800 loss 14.410993 loss_att 21.497496 loss_ctc 21.866333 loss_rnnt 11.916054 hw_loss 0.156737 lr 0.00043701 rank 3
2023-02-22 05:39:16,902 DEBUG TRAIN Batch 15/5800 loss 10.053669 loss_att 10.020345 loss_ctc 13.083794 loss_rnnt 9.358571 hw_loss 0.558273 lr 0.00043692 rank 7
2023-02-22 05:39:16,905 DEBUG TRAIN Batch 15/5800 loss 9.544027 loss_att 12.004253 loss_ctc 12.633533 loss_rnnt 8.432321 hw_loss 0.389487 lr 0.00043702 rank 4
2023-02-22 05:39:16,908 DEBUG TRAIN Batch 15/5800 loss 6.320072 loss_att 11.615681 loss_ctc 11.643527 loss_rnnt 4.447770 hw_loss 0.193849 lr 0.00043703 rank 0
2023-02-22 05:39:16,909 DEBUG TRAIN Batch 15/5800 loss 12.253873 loss_att 18.399830 loss_ctc 16.231136 loss_rnnt 10.386894 hw_loss 0.201535 lr 0.00043704 rank 1
2023-02-22 05:39:16,910 DEBUG TRAIN Batch 15/5800 loss 8.631665 loss_att 12.695082 loss_ctc 15.321083 loss_rnnt 6.818426 hw_loss 0.203689 lr 0.00043693 rank 5
2023-02-22 05:39:16,910 DEBUG TRAIN Batch 15/5800 loss 10.288398 loss_att 14.021551 loss_ctc 13.513064 loss_rnnt 9.039923 hw_loss 0.134790 lr 0.00043700 rank 6
2023-02-22 05:40:29,011 DEBUG TRAIN Batch 15/5900 loss 10.888704 loss_att 14.717331 loss_ctc 14.075951 loss_rnnt 9.607848 hw_loss 0.169059 lr 0.00043675 rank 7
2023-02-22 05:40:29,011 DEBUG TRAIN Batch 15/5900 loss 10.864836 loss_att 11.684932 loss_ctc 13.067717 loss_rnnt 10.310545 hw_loss 0.181039 lr 0.00043686 rank 0
2023-02-22 05:40:29,013 DEBUG TRAIN Batch 15/5900 loss 7.543474 loss_att 10.165578 loss_ctc 12.592592 loss_rnnt 6.222048 hw_loss 0.232104 lr 0.00043684 rank 3
2023-02-22 05:40:29,017 DEBUG TRAIN Batch 15/5900 loss 18.576826 loss_att 21.854361 loss_ctc 24.738379 loss_rnnt 16.958027 hw_loss 0.265787 lr 0.00043677 rank 5
2023-02-22 05:40:29,019 DEBUG TRAIN Batch 15/5900 loss 8.912411 loss_att 12.403071 loss_ctc 18.200291 loss_rnnt 6.808566 hw_loss 0.313739 lr 0.00043687 rank 1
2023-02-22 05:40:29,023 DEBUG TRAIN Batch 15/5900 loss 7.544858 loss_att 11.284120 loss_ctc 10.275565 loss_rnnt 6.346601 hw_loss 0.161832 lr 0.00043685 rank 4
2023-02-22 05:40:29,042 DEBUG TRAIN Batch 15/5900 loss 12.790613 loss_att 19.065529 loss_ctc 16.197281 loss_rnnt 10.911357 hw_loss 0.318847 lr 0.00043682 rank 2
2023-02-22 05:40:29,055 DEBUG TRAIN Batch 15/5900 loss 10.779619 loss_att 13.003675 loss_ctc 13.780597 loss_rnnt 9.751532 hw_loss 0.343399 lr 0.00043683 rank 6
2023-02-22 05:41:43,353 DEBUG TRAIN Batch 15/6000 loss 11.213086 loss_att 11.023147 loss_ctc 12.052307 loss_rnnt 11.037556 hw_loss 0.190542 lr 0.00043671 rank 1
2023-02-22 05:41:43,353 DEBUG TRAIN Batch 15/6000 loss 5.628449 loss_att 7.634598 loss_ctc 7.611959 loss_rnnt 4.798150 hw_loss 0.308628 lr 0.00043669 rank 0
2023-02-22 05:41:43,353 DEBUG TRAIN Batch 15/6000 loss 9.530919 loss_att 11.980647 loss_ctc 9.643077 loss_rnnt 8.795509 hw_loss 0.432206 lr 0.00043669 rank 4
2023-02-22 05:41:43,363 DEBUG TRAIN Batch 15/6000 loss 4.109779 loss_att 7.892059 loss_ctc 7.519941 loss_rnnt 2.797693 hw_loss 0.189267 lr 0.00043665 rank 2
2023-02-22 05:41:43,366 DEBUG TRAIN Batch 15/6000 loss 5.579410 loss_att 7.566045 loss_ctc 8.957355 loss_rnnt 4.614956 hw_loss 0.218878 lr 0.00043658 rank 7
2023-02-22 05:41:43,366 DEBUG TRAIN Batch 15/6000 loss 21.438473 loss_att 22.084684 loss_ctc 28.459259 loss_rnnt 20.265972 hw_loss 0.200916 lr 0.00043667 rank 6
2023-02-22 05:41:43,367 DEBUG TRAIN Batch 15/6000 loss 7.271759 loss_att 12.876022 loss_ctc 10.121797 loss_rnnt 5.683763 hw_loss 0.163384 lr 0.00043668 rank 3
2023-02-22 05:41:43,415 DEBUG TRAIN Batch 15/6000 loss 12.171844 loss_att 16.913570 loss_ctc 15.519864 loss_rnnt 10.642890 hw_loss 0.251635 lr 0.00043660 rank 5
2023-02-22 05:42:57,118 DEBUG TRAIN Batch 15/6100 loss 2.744078 loss_att 5.930520 loss_ctc 3.283872 loss_rnnt 1.881802 hw_loss 0.286903 lr 0.00043649 rank 2
2023-02-22 05:42:57,118 DEBUG TRAIN Batch 15/6100 loss 31.807875 loss_att 37.641521 loss_ctc 32.997646 loss_rnnt 30.394230 hw_loss 0.165522 lr 0.00043653 rank 0
2023-02-22 05:42:57,119 DEBUG TRAIN Batch 15/6100 loss 18.187557 loss_att 23.214621 loss_ctc 23.059357 loss_rnnt 16.449524 hw_loss 0.155711 lr 0.00043650 rank 6
2023-02-22 05:42:57,122 DEBUG TRAIN Batch 15/6100 loss 6.449585 loss_att 8.881073 loss_ctc 11.117624 loss_rnnt 5.215932 hw_loss 0.234283 lr 0.00043651 rank 3
2023-02-22 05:42:57,124 DEBUG TRAIN Batch 15/6100 loss 14.472101 loss_att 16.004902 loss_ctc 16.441582 loss_rnnt 13.805803 hw_loss 0.182138 lr 0.00043642 rank 7
2023-02-22 05:42:57,124 DEBUG TRAIN Batch 15/6100 loss 12.127635 loss_att 14.756405 loss_ctc 17.073278 loss_rnnt 10.753429 hw_loss 0.354437 lr 0.00043643 rank 5
2023-02-22 05:42:57,125 DEBUG TRAIN Batch 15/6100 loss 17.016272 loss_att 21.077684 loss_ctc 23.439960 loss_rnnt 15.164572 hw_loss 0.342984 lr 0.00043652 rank 4
2023-02-22 05:42:57,176 DEBUG TRAIN Batch 15/6100 loss 8.253058 loss_att 10.969509 loss_ctc 11.240874 loss_rnnt 7.262684 hw_loss 0.091330 lr 0.00043654 rank 1
2023-02-22 05:44:09,575 DEBUG TRAIN Batch 15/6200 loss 12.611157 loss_att 14.969907 loss_ctc 15.215517 loss_rnnt 11.741482 hw_loss 0.095019 lr 0.00043634 rank 3
2023-02-22 05:44:09,591 DEBUG TRAIN Batch 15/6200 loss 14.588511 loss_att 18.853828 loss_ctc 17.621571 loss_rnnt 13.167635 hw_loss 0.306380 lr 0.00043632 rank 2
2023-02-22 05:44:09,594 DEBUG TRAIN Batch 15/6200 loss 7.697729 loss_att 11.157925 loss_ctc 9.206316 loss_rnnt 6.494166 hw_loss 0.581959 lr 0.00043633 rank 6
2023-02-22 05:44:09,595 DEBUG TRAIN Batch 15/6200 loss 11.193859 loss_att 13.269094 loss_ctc 15.164573 loss_rnnt 10.096140 hw_loss 0.287332 lr 0.00043635 rank 4
2023-02-22 05:44:09,600 DEBUG TRAIN Batch 15/6200 loss 6.037386 loss_att 9.305969 loss_ctc 8.893098 loss_rnnt 4.863244 hw_loss 0.261870 lr 0.00043637 rank 1
2023-02-22 05:44:09,601 DEBUG TRAIN Batch 15/6200 loss 8.463123 loss_att 12.656527 loss_ctc 15.010107 loss_rnnt 6.603459 hw_loss 0.277595 lr 0.00043636 rank 0
2023-02-22 05:44:09,604 DEBUG TRAIN Batch 15/6200 loss 11.095530 loss_att 13.429514 loss_ctc 13.626455 loss_rnnt 10.166124 hw_loss 0.234660 lr 0.00043627 rank 5
2023-02-22 05:44:09,648 DEBUG TRAIN Batch 15/6200 loss 9.431535 loss_att 11.252996 loss_ctc 11.379251 loss_rnnt 8.636034 hw_loss 0.321587 lr 0.00043625 rank 7
2023-02-22 05:45:22,073 DEBUG TRAIN Batch 15/6300 loss 10.248594 loss_att 11.422740 loss_ctc 11.137717 loss_rnnt 9.734650 hw_loss 0.301060 lr 0.00043608 rank 7
2023-02-22 05:45:22,086 DEBUG TRAIN Batch 15/6300 loss 13.579309 loss_att 15.991026 loss_ctc 18.938690 loss_rnnt 12.236297 hw_loss 0.273910 lr 0.00043617 rank 6
2023-02-22 05:45:22,086 DEBUG TRAIN Batch 15/6300 loss 18.410906 loss_att 20.422960 loss_ctc 24.317093 loss_rnnt 17.093889 hw_loss 0.238338 lr 0.00043616 rank 2
2023-02-22 05:45:22,089 DEBUG TRAIN Batch 15/6300 loss 7.417732 loss_att 9.198853 loss_ctc 11.026138 loss_rnnt 6.432878 hw_loss 0.276580 lr 0.00043618 rank 3
2023-02-22 05:45:22,091 DEBUG TRAIN Batch 15/6300 loss 13.382227 loss_att 16.023018 loss_ctc 18.993488 loss_rnnt 11.948321 hw_loss 0.295461 lr 0.00043610 rank 5
2023-02-22 05:45:22,093 DEBUG TRAIN Batch 15/6300 loss 8.268247 loss_att 12.004464 loss_ctc 11.791344 loss_rnnt 6.843752 hw_loss 0.389073 lr 0.00043621 rank 1
2023-02-22 05:45:22,097 DEBUG TRAIN Batch 15/6300 loss 12.739275 loss_att 12.632845 loss_ctc 16.261244 loss_rnnt 12.121595 hw_loss 0.317568 lr 0.00043619 rank 4
2023-02-22 05:45:22,096 DEBUG TRAIN Batch 15/6300 loss 13.690532 loss_att 16.365322 loss_ctc 20.984983 loss_rnnt 12.080200 hw_loss 0.192712 lr 0.00043619 rank 0
2023-02-22 05:46:37,864 DEBUG TRAIN Batch 15/6400 loss 13.275596 loss_att 14.869598 loss_ctc 16.140379 loss_rnnt 12.371214 hw_loss 0.381770 lr 0.00043599 rank 2
2023-02-22 05:46:37,869 DEBUG TRAIN Batch 15/6400 loss 11.827498 loss_att 14.178841 loss_ctc 16.770550 loss_rnnt 10.574462 hw_loss 0.231928 lr 0.00043601 rank 3
2023-02-22 05:46:37,871 DEBUG TRAIN Batch 15/6400 loss 10.700394 loss_att 11.737756 loss_ctc 12.880548 loss_rnnt 9.897797 hw_loss 0.570821 lr 0.00043603 rank 0
2023-02-22 05:46:37,873 DEBUG TRAIN Batch 15/6400 loss 19.861782 loss_att 22.065660 loss_ctc 20.858601 loss_rnnt 19.143787 hw_loss 0.270583 lr 0.00043594 rank 5
2023-02-22 05:46:37,880 DEBUG TRAIN Batch 15/6400 loss 16.258545 loss_att 17.944191 loss_ctc 24.874931 loss_rnnt 14.663493 hw_loss 0.204506 lr 0.00043600 rank 6
2023-02-22 05:46:37,901 DEBUG TRAIN Batch 15/6400 loss 13.794182 loss_att 19.635601 loss_ctc 16.011299 loss_rnnt 12.208082 hw_loss 0.229129 lr 0.00043602 rank 4
2023-02-22 05:46:37,909 DEBUG TRAIN Batch 15/6400 loss 9.141389 loss_att 9.805310 loss_ctc 11.758478 loss_rnnt 8.408485 hw_loss 0.470951 lr 0.00043592 rank 7
2023-02-22 05:46:37,946 DEBUG TRAIN Batch 15/6400 loss 3.176302 loss_att 6.626245 loss_ctc 5.329369 loss_rnnt 2.049449 hw_loss 0.280853 lr 0.00043604 rank 1
2023-02-22 05:47:49,828 DEBUG TRAIN Batch 15/6500 loss 9.875525 loss_att 13.223851 loss_ctc 14.541720 loss_rnnt 8.416854 hw_loss 0.312839 lr 0.00043588 rank 1
2023-02-22 05:47:49,836 DEBUG TRAIN Batch 15/6500 loss 8.478381 loss_att 13.447519 loss_ctc 8.773572 loss_rnnt 7.343442 hw_loss 0.190785 lr 0.00043584 rank 6
2023-02-22 05:47:49,837 DEBUG TRAIN Batch 15/6500 loss 12.553861 loss_att 20.318235 loss_ctc 16.260809 loss_rnnt 10.408591 hw_loss 0.184005 lr 0.00043582 rank 2
2023-02-22 05:47:49,838 DEBUG TRAIN Batch 15/6500 loss 17.810452 loss_att 17.592981 loss_ctc 21.067747 loss_rnnt 17.331356 hw_loss 0.165532 lr 0.00043577 rank 5
2023-02-22 05:47:49,840 DEBUG TRAIN Batch 15/6500 loss 6.745268 loss_att 8.796500 loss_ctc 10.052403 loss_rnnt 5.758049 hw_loss 0.255040 lr 0.00043586 rank 4
2023-02-22 05:47:49,843 DEBUG TRAIN Batch 15/6500 loss 7.112813 loss_att 9.760487 loss_ctc 10.273094 loss_rnnt 6.083360 hw_loss 0.147276 lr 0.00043585 rank 3
2023-02-22 05:47:49,844 DEBUG TRAIN Batch 15/6500 loss 12.642360 loss_att 16.724018 loss_ctc 20.692722 loss_rnnt 10.629572 hw_loss 0.230762 lr 0.00043586 rank 0
2023-02-22 05:47:49,887 DEBUG TRAIN Batch 15/6500 loss 4.302199 loss_att 7.913242 loss_ctc 5.001363 loss_rnnt 3.352258 hw_loss 0.252207 lr 0.00043575 rank 7
2023-02-22 05:49:01,419 DEBUG TRAIN Batch 15/6600 loss 9.729451 loss_att 11.594370 loss_ctc 11.241267 loss_rnnt 9.078238 hw_loss 0.143726 lr 0.00043569 rank 4
2023-02-22 05:49:01,419 DEBUG TRAIN Batch 15/6600 loss 7.942134 loss_att 12.601064 loss_ctc 12.909161 loss_rnnt 6.232224 hw_loss 0.217228 lr 0.00043568 rank 3
2023-02-22 05:49:01,421 DEBUG TRAIN Batch 15/6600 loss 9.599427 loss_att 12.098652 loss_ctc 13.912262 loss_rnnt 8.371032 hw_loss 0.287823 lr 0.00043571 rank 1
2023-02-22 05:49:01,423 DEBUG TRAIN Batch 15/6600 loss 13.807020 loss_att 19.503096 loss_ctc 15.852716 loss_rnnt 12.355003 hw_loss 0.075079 lr 0.00043559 rank 7
2023-02-22 05:49:01,425 DEBUG TRAIN Batch 15/6600 loss 22.170994 loss_att 24.834244 loss_ctc 27.153999 loss_rnnt 20.818493 hw_loss 0.291473 lr 0.00043561 rank 5
2023-02-22 05:49:01,425 DEBUG TRAIN Batch 15/6600 loss 16.718908 loss_att 17.663738 loss_ctc 20.167137 loss_rnnt 15.914983 hw_loss 0.290991 lr 0.00043567 rank 6
2023-02-22 05:49:01,425 DEBUG TRAIN Batch 15/6600 loss 5.779538 loss_att 8.429200 loss_ctc 7.246498 loss_rnnt 4.953803 hw_loss 0.187890 lr 0.00043566 rank 2
2023-02-22 05:49:01,471 DEBUG TRAIN Batch 15/6600 loss 14.506719 loss_att 17.166723 loss_ctc 16.533493 loss_rnnt 13.537180 hw_loss 0.313689 lr 0.00043570 rank 0
2023-02-22 05:50:14,117 DEBUG TRAIN Batch 15/6700 loss 8.349237 loss_att 13.031982 loss_ctc 9.937368 loss_rnnt 6.998782 hw_loss 0.379043 lr 0.00043542 rank 7
2023-02-22 05:50:14,120 DEBUG TRAIN Batch 15/6700 loss 13.041431 loss_att 17.232939 loss_ctc 16.505379 loss_rnnt 11.588152 hw_loss 0.287096 lr 0.00043553 rank 4
2023-02-22 05:50:14,122 DEBUG TRAIN Batch 15/6700 loss 9.227868 loss_att 11.840584 loss_ctc 12.388648 loss_rnnt 8.122904 hw_loss 0.301846 lr 0.00043549 rank 2
2023-02-22 05:50:14,124 DEBUG TRAIN Batch 15/6700 loss 15.916118 loss_att 18.067642 loss_ctc 17.289597 loss_rnnt 15.162245 hw_loss 0.263321 lr 0.00043551 rank 3
2023-02-22 05:50:14,124 DEBUG TRAIN Batch 15/6700 loss 15.550346 loss_att 21.684134 loss_ctc 24.602190 loss_rnnt 12.933285 hw_loss 0.343856 lr 0.00043551 rank 6
2023-02-22 05:50:14,126 DEBUG TRAIN Batch 15/6700 loss 11.925198 loss_att 15.179974 loss_ctc 19.818073 loss_rnnt 10.051411 hw_loss 0.319592 lr 0.00043544 rank 5
2023-02-22 05:50:14,127 DEBUG TRAIN Batch 15/6700 loss 12.034100 loss_att 14.227324 loss_ctc 15.231094 loss_rnnt 11.083965 hw_loss 0.159792 lr 0.00043553 rank 0
2023-02-22 05:50:14,127 DEBUG TRAIN Batch 15/6700 loss 19.075657 loss_att 20.180315 loss_ctc 22.005980 loss_rnnt 18.318504 hw_loss 0.272834 lr 0.00043555 rank 1
2023-02-22 05:51:27,922 DEBUG TRAIN Batch 15/6800 loss 9.736028 loss_att 13.164187 loss_ctc 15.454970 loss_rnnt 8.133036 hw_loss 0.290314 lr 0.00043533 rank 2
2023-02-22 05:51:27,922 DEBUG TRAIN Batch 15/6800 loss 19.413685 loss_att 21.572924 loss_ctc 24.133142 loss_rnnt 18.175152 hw_loss 0.332671 lr 0.00043536 rank 4
2023-02-22 05:51:27,922 DEBUG TRAIN Batch 15/6800 loss 7.604445 loss_att 10.696470 loss_ctc 12.284475 loss_rnnt 6.185977 hw_loss 0.330112 lr 0.00043534 rank 6
2023-02-22 05:51:27,923 DEBUG TRAIN Batch 15/6800 loss 11.865910 loss_att 14.688955 loss_ctc 17.242563 loss_rnnt 10.445287 hw_loss 0.260860 lr 0.00043535 rank 3
2023-02-22 05:51:27,924 DEBUG TRAIN Batch 15/6800 loss 12.766002 loss_att 14.751146 loss_ctc 16.306053 loss_rnnt 11.777971 hw_loss 0.223112 lr 0.00043537 rank 0
2023-02-22 05:51:27,929 DEBUG TRAIN Batch 15/6800 loss 14.058048 loss_att 15.854597 loss_ctc 17.111341 loss_rnnt 13.162847 hw_loss 0.241475 lr 0.00043526 rank 7
2023-02-22 05:51:27,930 DEBUG TRAIN Batch 15/6800 loss 8.564481 loss_att 11.606631 loss_ctc 12.229698 loss_rnnt 7.334236 hw_loss 0.249598 lr 0.00043538 rank 1
2023-02-22 05:51:27,933 DEBUG TRAIN Batch 15/6800 loss 6.759916 loss_att 10.435835 loss_ctc 7.949911 loss_rnnt 5.738736 hw_loss 0.238744 lr 0.00043527 rank 5
2023-02-22 05:52:40,088 DEBUG TRAIN Batch 15/6900 loss 7.980416 loss_att 11.729782 loss_ctc 10.739583 loss_rnnt 6.672750 hw_loss 0.356070 lr 0.00043516 rank 2
2023-02-22 05:52:40,094 DEBUG TRAIN Batch 15/6900 loss 17.158451 loss_att 19.434151 loss_ctc 22.714270 loss_rnnt 15.832361 hw_loss 0.244075 lr 0.00043509 rank 7
2023-02-22 05:52:40,095 DEBUG TRAIN Batch 15/6900 loss 24.045979 loss_att 23.278374 loss_ctc 32.200424 loss_rnnt 22.936729 hw_loss 0.329079 lr 0.00043518 rank 3
2023-02-22 05:52:40,098 DEBUG TRAIN Batch 15/6900 loss 6.747584 loss_att 7.993449 loss_ctc 7.225309 loss_rnnt 6.304332 hw_loss 0.244468 lr 0.00043520 rank 0
2023-02-22 05:52:40,099 DEBUG TRAIN Batch 15/6900 loss 7.545734 loss_att 10.351898 loss_ctc 9.895423 loss_rnnt 6.524728 hw_loss 0.274652 lr 0.00043518 rank 6
2023-02-22 05:52:40,100 DEBUG TRAIN Batch 15/6900 loss 7.109007 loss_att 10.158334 loss_ctc 12.851992 loss_rnnt 5.622890 hw_loss 0.207228 lr 0.00043511 rank 5
2023-02-22 05:52:40,101 DEBUG TRAIN Batch 15/6900 loss 4.421418 loss_att 8.726332 loss_ctc 7.392930 loss_rnnt 3.000806 hw_loss 0.306425 lr 0.00043520 rank 4
2023-02-22 05:52:40,105 DEBUG TRAIN Batch 15/6900 loss 8.030572 loss_att 9.511171 loss_ctc 11.437604 loss_rnnt 7.074550 hw_loss 0.385558 lr 0.00043522 rank 1
2023-02-22 05:53:52,924 DEBUG TRAIN Batch 15/7000 loss 5.652324 loss_att 8.408030 loss_ctc 10.402328 loss_rnnt 4.367998 hw_loss 0.187218 lr 0.00043501 rank 6
2023-02-22 05:53:52,927 DEBUG TRAIN Batch 15/7000 loss 9.985322 loss_att 10.832500 loss_ctc 13.746835 loss_rnnt 9.065722 hw_loss 0.466180 lr 0.00043495 rank 5
2023-02-22 05:53:52,928 DEBUG TRAIN Batch 15/7000 loss 9.690991 loss_att 11.476832 loss_ctc 11.305980 loss_rnnt 8.950947 hw_loss 0.314145 lr 0.00043502 rank 3
2023-02-22 05:53:52,929 DEBUG TRAIN Batch 15/7000 loss 7.651907 loss_att 9.204801 loss_ctc 10.172922 loss_rnnt 6.861450 hw_loss 0.269519 lr 0.00043503 rank 4
2023-02-22 05:53:52,928 DEBUG TRAIN Batch 15/7000 loss 12.590988 loss_att 14.390667 loss_ctc 17.563574 loss_rnnt 11.388832 hw_loss 0.336017 lr 0.00043500 rank 2
2023-02-22 05:53:52,931 DEBUG TRAIN Batch 15/7000 loss 9.352815 loss_att 14.062720 loss_ctc 13.922592 loss_rnnt 7.618572 hw_loss 0.343046 lr 0.00043504 rank 0
2023-02-22 05:53:52,932 DEBUG TRAIN Batch 15/7000 loss 9.037573 loss_att 9.484203 loss_ctc 11.111111 loss_rnnt 8.403543 hw_loss 0.502934 lr 0.00043505 rank 1
2023-02-22 05:53:52,981 DEBUG TRAIN Batch 15/7000 loss 12.728464 loss_att 12.017491 loss_ctc 14.065865 loss_rnnt 12.455822 hw_loss 0.443468 lr 0.00043493 rank 7
2023-02-22 05:55:07,981 DEBUG TRAIN Batch 15/7100 loss 16.682775 loss_att 19.164766 loss_ctc 21.669022 loss_rnnt 15.351333 hw_loss 0.319147 lr 0.00043476 rank 7
2023-02-22 05:55:07,982 DEBUG TRAIN Batch 15/7100 loss 7.871749 loss_att 13.259544 loss_ctc 10.277201 loss_rnnt 6.385292 hw_loss 0.165322 lr 0.00043485 rank 3
2023-02-22 05:55:07,983 DEBUG TRAIN Batch 15/7100 loss 10.184212 loss_att 10.795486 loss_ctc 12.411355 loss_rnnt 9.569347 hw_loss 0.366857 lr 0.00043483 rank 2
2023-02-22 05:55:07,985 DEBUG TRAIN Batch 15/7100 loss 8.589387 loss_att 11.051702 loss_ctc 14.447688 loss_rnnt 7.192162 hw_loss 0.231854 lr 0.00043485 rank 6
2023-02-22 05:55:07,986 DEBUG TRAIN Batch 15/7100 loss 13.148228 loss_att 16.851866 loss_ctc 11.759415 loss_rnnt 12.346698 hw_loss 0.461208 lr 0.00043487 rank 0
2023-02-22 05:55:07,993 DEBUG TRAIN Batch 15/7100 loss 7.138633 loss_att 8.077750 loss_ctc 9.283265 loss_rnnt 6.540002 hw_loss 0.234107 lr 0.00043489 rank 1
2023-02-22 05:55:08,031 DEBUG TRAIN Batch 15/7100 loss 12.381537 loss_att 14.008829 loss_ctc 14.319574 loss_rnnt 11.639148 hw_loss 0.297238 lr 0.00043487 rank 4
2023-02-22 05:55:08,032 DEBUG TRAIN Batch 15/7100 loss 9.648245 loss_att 14.021621 loss_ctc 13.130033 loss_rnnt 8.208982 hw_loss 0.188153 lr 0.00043478 rank 5
2023-02-22 05:56:19,694 DEBUG TRAIN Batch 15/7200 loss 12.145426 loss_att 12.250456 loss_ctc 23.933872 loss_rnnt 10.374681 hw_loss 0.333647 lr 0.00043467 rank 2
2023-02-22 05:56:19,700 DEBUG TRAIN Batch 15/7200 loss 11.544697 loss_att 15.352892 loss_ctc 18.582703 loss_rnnt 9.621344 hw_loss 0.418712 lr 0.00043471 rank 0
2023-02-22 05:56:19,700 DEBUG TRAIN Batch 15/7200 loss 7.333558 loss_att 10.583391 loss_ctc 10.742191 loss_rnnt 6.151250 hw_loss 0.145980 lr 0.00043468 rank 6
2023-02-22 05:56:19,701 DEBUG TRAIN Batch 15/7200 loss 3.799544 loss_att 6.985797 loss_ctc 6.132194 loss_rnnt 2.703630 hw_loss 0.276832 lr 0.00043470 rank 4
2023-02-22 05:56:19,702 DEBUG TRAIN Batch 15/7200 loss 11.754864 loss_att 16.848402 loss_ctc 17.016644 loss_rnnt 9.967638 hw_loss 0.125526 lr 0.00043469 rank 3
2023-02-22 05:56:19,704 DEBUG TRAIN Batch 15/7200 loss 6.051562 loss_att 8.397354 loss_ctc 11.041599 loss_rnnt 4.723545 hw_loss 0.362851 lr 0.00043460 rank 7
2023-02-22 05:56:19,707 DEBUG TRAIN Batch 15/7200 loss 7.397977 loss_att 9.410544 loss_ctc 5.598357 loss_rnnt 7.128225 hw_loss 0.200979 lr 0.00043472 rank 1
2023-02-22 05:56:19,708 DEBUG TRAIN Batch 15/7200 loss 9.940743 loss_att 13.472530 loss_ctc 13.529840 loss_rnnt 8.602485 hw_loss 0.287541 lr 0.00043462 rank 5
2023-02-22 05:57:31,702 DEBUG TRAIN Batch 15/7300 loss 18.248627 loss_att 23.188946 loss_ctc 27.890347 loss_rnnt 15.817005 hw_loss 0.296241 lr 0.00043445 rank 5
2023-02-22 05:57:31,713 DEBUG TRAIN Batch 15/7300 loss 8.934004 loss_att 11.627634 loss_ctc 8.265043 loss_rnnt 8.344492 hw_loss 0.262464 lr 0.00043451 rank 2
2023-02-22 05:57:31,713 DEBUG TRAIN Batch 15/7300 loss 9.909812 loss_att 13.594995 loss_ctc 16.793486 loss_rnnt 8.067574 hw_loss 0.351335 lr 0.00043454 rank 4
2023-02-22 05:57:31,717 DEBUG TRAIN Batch 15/7300 loss 11.561705 loss_att 14.403622 loss_ctc 13.613552 loss_rnnt 10.559601 hw_loss 0.300263 lr 0.00043453 rank 3
2023-02-22 05:57:31,718 DEBUG TRAIN Batch 15/7300 loss 12.306546 loss_att 15.741572 loss_ctc 14.207024 loss_rnnt 11.266541 hw_loss 0.186758 lr 0.00043456 rank 1
2023-02-22 05:57:31,720 DEBUG TRAIN Batch 15/7300 loss 8.435997 loss_att 12.315142 loss_ctc 15.584940 loss_rnnt 6.551480 hw_loss 0.291555 lr 0.00043443 rank 7
2023-02-22 05:57:31,721 DEBUG TRAIN Batch 15/7300 loss 4.130157 loss_att 8.651446 loss_ctc 7.849179 loss_rnnt 2.651896 hw_loss 0.146502 lr 0.00043454 rank 0
2023-02-22 05:57:31,721 DEBUG TRAIN Batch 15/7300 loss 12.421655 loss_att 16.978127 loss_ctc 15.520330 loss_rnnt 10.932714 hw_loss 0.308417 lr 0.00043452 rank 6
2023-02-22 05:58:44,506 DEBUG TRAIN Batch 15/7400 loss 23.350271 loss_att 27.148321 loss_ctc 31.474325 loss_rnnt 21.291641 hw_loss 0.404649 lr 0.00043437 rank 4
2023-02-22 05:58:44,511 DEBUG TRAIN Batch 15/7400 loss 7.400204 loss_att 10.006399 loss_ctc 8.545422 loss_rnnt 6.577138 hw_loss 0.279621 lr 0.00043427 rank 7
2023-02-22 05:58:44,516 DEBUG TRAIN Batch 15/7400 loss 6.189770 loss_att 9.520432 loss_ctc 7.279282 loss_rnnt 5.285157 hw_loss 0.174773 lr 0.00043434 rank 2
2023-02-22 05:58:44,519 DEBUG TRAIN Batch 15/7400 loss 10.991132 loss_att 15.867414 loss_ctc 16.351624 loss_rnnt 9.157425 hw_loss 0.269472 lr 0.00043439 rank 1
2023-02-22 05:58:44,519 DEBUG TRAIN Batch 15/7400 loss 8.862899 loss_att 13.189997 loss_ctc 9.141407 loss_rnnt 7.849580 hw_loss 0.207683 lr 0.00043436 rank 3
2023-02-22 05:58:44,526 DEBUG TRAIN Batch 15/7400 loss 5.120441 loss_att 9.682175 loss_ctc 8.299489 loss_rnnt 3.642173 hw_loss 0.266341 lr 0.00043429 rank 5
2023-02-22 05:58:44,527 DEBUG TRAIN Batch 15/7400 loss 11.083795 loss_att 14.202049 loss_ctc 14.448388 loss_rnnt 9.809473 hw_loss 0.378858 lr 0.00043435 rank 6
2023-02-22 05:58:44,540 DEBUG TRAIN Batch 15/7400 loss 13.891191 loss_att 19.807781 loss_ctc 22.430325 loss_rnnt 11.452591 hw_loss 0.218869 lr 0.00043438 rank 0
2023-02-22 05:59:58,343 DEBUG TRAIN Batch 15/7500 loss 11.350140 loss_att 15.036434 loss_ctc 16.605995 loss_rnnt 9.755256 hw_loss 0.294081 lr 0.00043420 rank 3
2023-02-22 05:59:58,348 DEBUG TRAIN Batch 15/7500 loss 11.532649 loss_att 15.821775 loss_ctc 17.241091 loss_rnnt 9.812059 hw_loss 0.190573 lr 0.00043418 rank 2
2023-02-22 05:59:58,348 DEBUG TRAIN Batch 15/7500 loss 7.308049 loss_att 9.726015 loss_ctc 10.544211 loss_rnnt 6.232325 hw_loss 0.301202 lr 0.00043421 rank 4
2023-02-22 05:59:58,351 DEBUG TRAIN Batch 15/7500 loss 24.359989 loss_att 27.736481 loss_ctc 30.610355 loss_rnnt 22.677914 hw_loss 0.325116 lr 0.00043419 rank 6
2023-02-22 05:59:58,352 DEBUG TRAIN Batch 15/7500 loss 6.631310 loss_att 11.783175 loss_ctc 10.567385 loss_rnnt 4.927904 hw_loss 0.277919 lr 0.00043411 rank 7
2023-02-22 05:59:58,354 DEBUG TRAIN Batch 15/7500 loss 9.222326 loss_att 13.803860 loss_ctc 12.849960 loss_rnnt 7.722104 hw_loss 0.187930 lr 0.00043422 rank 0
2023-02-22 05:59:58,354 DEBUG TRAIN Batch 15/7500 loss 6.127294 loss_att 9.347744 loss_ctc 6.375170 loss_rnnt 5.284951 hw_loss 0.309754 lr 0.00043412 rank 5
2023-02-22 05:59:58,358 DEBUG TRAIN Batch 15/7500 loss 7.325350 loss_att 11.752013 loss_ctc 9.416533 loss_rnnt 6.089199 hw_loss 0.134989 lr 0.00043423 rank 1
2023-02-22 06:01:11,148 DEBUG TRAIN Batch 15/7600 loss 16.110834 loss_att 21.295605 loss_ctc 29.668686 loss_rnnt 13.092474 hw_loss 0.325674 lr 0.00043403 rank 6
2023-02-22 06:01:11,162 DEBUG TRAIN Batch 15/7600 loss 4.555006 loss_att 6.839023 loss_ctc 8.036284 loss_rnnt 3.458164 hw_loss 0.329753 lr 0.00043401 rank 2
2023-02-22 06:01:11,162 DEBUG TRAIN Batch 15/7600 loss 9.115629 loss_att 10.495618 loss_ctc 11.515364 loss_rnnt 8.336918 hw_loss 0.342656 lr 0.00043405 rank 0
2023-02-22 06:01:11,166 DEBUG TRAIN Batch 15/7600 loss 13.792812 loss_att 12.796826 loss_ctc 16.658344 loss_rnnt 13.345559 hw_loss 0.495711 lr 0.00043405 rank 4
2023-02-22 06:01:11,166 DEBUG TRAIN Batch 15/7600 loss 13.339533 loss_att 14.237814 loss_ctc 15.483079 loss_rnnt 12.622041 hw_loss 0.472555 lr 0.00043407 rank 1
2023-02-22 06:01:11,166 DEBUG TRAIN Batch 15/7600 loss 18.232075 loss_att 19.901234 loss_ctc 22.341377 loss_rnnt 17.268959 hw_loss 0.152583 lr 0.00043403 rank 3
2023-02-22 06:01:11,167 DEBUG TRAIN Batch 15/7600 loss 16.096703 loss_att 19.319481 loss_ctc 26.665558 loss_rnnt 13.861381 hw_loss 0.340470 lr 0.00043394 rank 7
2023-02-22 06:01:11,217 DEBUG TRAIN Batch 15/7600 loss 18.876926 loss_att 18.773512 loss_ctc 22.701256 loss_rnnt 18.258209 hw_loss 0.242793 lr 0.00043396 rank 5
2023-02-22 06:02:23,661 DEBUG TRAIN Batch 15/7700 loss 14.906468 loss_att 15.638037 loss_ctc 17.987064 loss_rnnt 14.209427 hw_loss 0.262467 lr 0.00043378 rank 7
2023-02-22 06:02:23,663 DEBUG TRAIN Batch 15/7700 loss 13.420178 loss_att 13.591506 loss_ctc 15.474318 loss_rnnt 12.910548 hw_loss 0.377774 lr 0.00043385 rank 2
2023-02-22 06:02:23,663 DEBUG TRAIN Batch 15/7700 loss 15.994878 loss_att 19.602509 loss_ctc 23.321875 loss_rnnt 14.205005 hw_loss 0.171402 lr 0.00043388 rank 4
2023-02-22 06:02:23,667 DEBUG TRAIN Batch 15/7700 loss 9.727448 loss_att 14.025290 loss_ctc 13.437739 loss_rnnt 8.269601 hw_loss 0.194197 lr 0.00043386 rank 6
2023-02-22 06:02:23,668 DEBUG TRAIN Batch 15/7700 loss 11.958628 loss_att 12.955585 loss_ctc 17.484909 loss_rnnt 10.854758 hw_loss 0.314326 lr 0.00043389 rank 0
2023-02-22 06:02:23,668 DEBUG TRAIN Batch 15/7700 loss 10.205312 loss_att 10.429260 loss_ctc 11.956758 loss_rnnt 9.800144 hw_loss 0.237845 lr 0.00043387 rank 3
2023-02-22 06:02:23,673 DEBUG TRAIN Batch 15/7700 loss 25.550299 loss_att 29.429487 loss_ctc 32.670357 loss_rnnt 23.659256 hw_loss 0.310992 lr 0.00043390 rank 1
2023-02-22 06:02:23,674 DEBUG TRAIN Batch 15/7700 loss 9.248514 loss_att 12.529550 loss_ctc 11.893124 loss_rnnt 8.132253 hw_loss 0.201450 lr 0.00043380 rank 5
2023-02-22 06:03:38,173 DEBUG TRAIN Batch 15/7800 loss 8.481422 loss_att 12.660371 loss_ctc 11.627971 loss_rnnt 7.069380 hw_loss 0.293836 lr 0.00043373 rank 0
2023-02-22 06:03:38,177 DEBUG TRAIN Batch 15/7800 loss 19.240393 loss_att 19.648598 loss_ctc 23.941132 loss_rnnt 18.435162 hw_loss 0.181545 lr 0.00043372 rank 4
2023-02-22 06:03:38,184 DEBUG TRAIN Batch 15/7800 loss 24.716604 loss_att 29.687706 loss_ctc 36.200653 loss_rnnt 22.081556 hw_loss 0.205540 lr 0.00043370 rank 6
2023-02-22 06:03:38,185 DEBUG TRAIN Batch 15/7800 loss 7.485020 loss_att 8.749738 loss_ctc 9.063427 loss_rnnt 6.816276 hw_loss 0.385024 lr 0.00043369 rank 2
2023-02-22 06:03:38,188 DEBUG TRAIN Batch 15/7800 loss 16.222237 loss_att 19.270275 loss_ctc 21.683815 loss_rnnt 14.754538 hw_loss 0.243527 lr 0.00043362 rank 7
2023-02-22 06:03:38,189 DEBUG TRAIN Batch 15/7800 loss 2.441043 loss_att 5.671101 loss_ctc 3.115026 loss_rnnt 1.499341 hw_loss 0.385922 lr 0.00043371 rank 3
2023-02-22 06:03:38,191 DEBUG TRAIN Batch 15/7800 loss 8.746184 loss_att 13.380943 loss_ctc 11.182144 loss_rnnt 7.427360 hw_loss 0.125771 lr 0.00043363 rank 5
2023-02-22 06:03:38,193 DEBUG TRAIN Batch 15/7800 loss 8.347878 loss_att 13.648775 loss_ctc 11.440784 loss_rnnt 6.780900 hw_loss 0.177020 lr 0.00043374 rank 1
2023-02-22 06:04:51,174 DEBUG TRAIN Batch 15/7900 loss 4.209035 loss_att 7.401924 loss_ctc 6.160060 loss_rnnt 3.146935 hw_loss 0.306347 lr 0.00043352 rank 2
2023-02-22 06:04:51,178 DEBUG TRAIN Batch 15/7900 loss 10.061596 loss_att 13.244230 loss_ctc 14.614487 loss_rnnt 8.682727 hw_loss 0.253669 lr 0.00043345 rank 7
2023-02-22 06:04:51,181 DEBUG TRAIN Batch 15/7900 loss 10.798445 loss_att 11.700064 loss_ctc 12.536576 loss_rnnt 10.228901 hw_loss 0.295255 lr 0.00043358 rank 1
2023-02-22 06:04:51,182 DEBUG TRAIN Batch 15/7900 loss 13.374119 loss_att 18.211626 loss_ctc 18.239342 loss_rnnt 11.644033 hw_loss 0.213538 lr 0.00043354 rank 6
2023-02-22 06:04:51,182 DEBUG TRAIN Batch 15/7900 loss 13.367322 loss_att 16.977911 loss_ctc 20.166103 loss_rnnt 11.561677 hw_loss 0.331920 lr 0.00043355 rank 3
2023-02-22 06:04:51,184 DEBUG TRAIN Batch 15/7900 loss 14.407343 loss_att 16.208546 loss_ctc 16.430779 loss_rnnt 13.514733 hw_loss 0.492331 lr 0.00043356 rank 4
2023-02-22 06:04:51,184 DEBUG TRAIN Batch 15/7900 loss 9.209583 loss_att 11.722799 loss_ctc 12.168114 loss_rnnt 8.141215 hw_loss 0.321102 lr 0.00043356 rank 0
2023-02-22 06:04:51,186 DEBUG TRAIN Batch 15/7900 loss 7.157959 loss_att 10.915527 loss_ctc 9.195827 loss_rnnt 6.070908 hw_loss 0.119666 lr 0.00043347 rank 5
2023-02-22 06:06:03,474 DEBUG TRAIN Batch 15/8000 loss 12.457319 loss_att 15.555630 loss_ctc 15.959533 loss_rnnt 11.187154 hw_loss 0.344140 lr 0.00043336 rank 2
2023-02-22 06:06:03,482 DEBUG TRAIN Batch 15/8000 loss 12.154290 loss_att 13.141655 loss_ctc 15.763102 loss_rnnt 11.287548 hw_loss 0.352676 lr 0.00043339 rank 4
2023-02-22 06:06:03,483 DEBUG TRAIN Batch 15/8000 loss 9.170486 loss_att 10.570925 loss_ctc 11.717061 loss_rnnt 8.415836 hw_loss 0.253161 lr 0.00043337 rank 6
2023-02-22 06:06:03,484 DEBUG TRAIN Batch 15/8000 loss 10.154263 loss_att 13.184937 loss_ctc 16.522633 loss_rnnt 8.655075 hw_loss 0.082382 lr 0.00043341 rank 1
2023-02-22 06:06:03,485 DEBUG TRAIN Batch 15/8000 loss 14.808743 loss_att 16.653175 loss_ctc 15.386564 loss_rnnt 14.238622 hw_loss 0.232858 lr 0.00043338 rank 3
2023-02-22 06:06:03,486 DEBUG TRAIN Batch 15/8000 loss 10.373484 loss_att 13.949434 loss_ctc 14.963381 loss_rnnt 8.899324 hw_loss 0.275593 lr 0.00043331 rank 5
2023-02-22 06:06:03,495 DEBUG TRAIN Batch 15/8000 loss 11.820726 loss_att 13.615802 loss_ctc 17.437628 loss_rnnt 10.578217 hw_loss 0.252329 lr 0.00043340 rank 0
2023-02-22 06:06:03,498 DEBUG TRAIN Batch 15/8000 loss 19.464306 loss_att 24.886808 loss_ctc 20.822281 loss_rnnt 18.047340 hw_loss 0.283881 lr 0.00043329 rank 7
2023-02-22 06:07:16,224 DEBUG TRAIN Batch 15/8100 loss 9.819942 loss_att 12.608298 loss_ctc 14.158890 loss_rnnt 8.516380 hw_loss 0.313806 lr 0.00043323 rank 4
2023-02-22 06:07:16,229 DEBUG TRAIN Batch 15/8100 loss 6.899655 loss_att 10.168400 loss_ctc 10.937235 loss_rnnt 5.602438 hw_loss 0.197108 lr 0.00043324 rank 0
2023-02-22 06:07:16,229 DEBUG TRAIN Batch 15/8100 loss 8.524397 loss_att 11.573547 loss_ctc 10.859968 loss_rnnt 7.428533 hw_loss 0.327420 lr 0.00043325 rank 1
2023-02-22 06:07:16,237 DEBUG TRAIN Batch 15/8100 loss 9.922825 loss_att 11.508835 loss_ctc 12.769771 loss_rnnt 9.113981 hw_loss 0.210093 lr 0.00043313 rank 7
2023-02-22 06:07:16,238 DEBUG TRAIN Batch 15/8100 loss 8.954242 loss_att 13.061773 loss_ctc 14.571235 loss_rnnt 7.231268 hw_loss 0.286005 lr 0.00043320 rank 2
2023-02-22 06:07:16,243 DEBUG TRAIN Batch 15/8100 loss 13.657372 loss_att 15.470528 loss_ctc 15.015935 loss_rnnt 12.914110 hw_loss 0.374040 lr 0.00043322 rank 3
2023-02-22 06:07:16,247 DEBUG TRAIN Batch 15/8100 loss 14.472829 loss_att 16.580090 loss_ctc 20.551731 loss_rnnt 13.088574 hw_loss 0.285528 lr 0.00043321 rank 6
2023-02-22 06:07:16,247 DEBUG TRAIN Batch 15/8100 loss 10.761819 loss_att 13.091180 loss_ctc 14.935314 loss_rnnt 9.502534 hw_loss 0.444274 lr 0.00043315 rank 5
2023-02-22 06:08:29,073 DEBUG TRAIN Batch 15/8200 loss 10.259464 loss_att 12.384419 loss_ctc 14.271885 loss_rnnt 9.117508 hw_loss 0.341203 lr 0.00043304 rank 2
2023-02-22 06:08:29,077 DEBUG TRAIN Batch 15/8200 loss 13.638854 loss_att 15.504616 loss_ctc 18.454145 loss_rnnt 12.479391 hw_loss 0.270512 lr 0.00043297 rank 7
2023-02-22 06:08:29,076 DEBUG TRAIN Batch 15/8200 loss 5.892497 loss_att 8.581079 loss_ctc 8.747334 loss_rnnt 4.793111 hw_loss 0.339421 lr 0.00043298 rank 5
2023-02-22 06:08:29,079 DEBUG TRAIN Batch 15/8200 loss 7.967690 loss_att 9.564007 loss_ctc 8.949815 loss_rnnt 7.360448 hw_loss 0.294428 lr 0.00043306 rank 3
2023-02-22 06:08:29,079 DEBUG TRAIN Batch 15/8200 loss 8.515211 loss_att 9.511440 loss_ctc 12.433726 loss_rnnt 7.602016 hw_loss 0.359025 lr 0.00043305 rank 6
2023-02-22 06:08:29,080 DEBUG TRAIN Batch 15/8200 loss 17.290089 loss_att 19.491123 loss_ctc 24.915930 loss_rnnt 15.658844 hw_loss 0.326733 lr 0.00043307 rank 4
2023-02-22 06:08:29,084 DEBUG TRAIN Batch 15/8200 loss 6.441271 loss_att 9.556546 loss_ctc 7.941977 loss_rnnt 5.456080 hw_loss 0.303829 lr 0.00043307 rank 0
2023-02-22 06:08:29,085 DEBUG TRAIN Batch 15/8200 loss 16.657028 loss_att 17.731194 loss_ctc 21.819077 loss_rnnt 15.596766 hw_loss 0.294666 lr 0.00043309 rank 1
2023-02-22 06:09:41,817 DEBUG TRAIN Batch 15/8300 loss 6.964543 loss_att 9.819770 loss_ctc 7.845614 loss_rnnt 6.198862 hw_loss 0.144673 lr 0.00043289 rank 3
2023-02-22 06:09:41,817 DEBUG TRAIN Batch 15/8300 loss 11.543389 loss_att 13.767769 loss_ctc 14.903900 loss_rnnt 10.456177 hw_loss 0.364255 lr 0.00043291 rank 4
2023-02-22 06:09:41,820 DEBUG TRAIN Batch 15/8300 loss 7.792360 loss_att 10.821364 loss_ctc 12.526819 loss_rnnt 6.458986 hw_loss 0.180587 lr 0.00043280 rank 7
2023-02-22 06:09:41,819 DEBUG TRAIN Batch 15/8300 loss 9.686222 loss_att 12.613817 loss_ctc 13.151583 loss_rnnt 8.449284 hw_loss 0.355073 lr 0.00043291 rank 0
2023-02-22 06:09:41,820 DEBUG TRAIN Batch 15/8300 loss 18.980082 loss_att 23.738308 loss_ctc 25.324928 loss_rnnt 17.029377 hw_loss 0.287023 lr 0.00043287 rank 2
2023-02-22 06:09:41,823 DEBUG TRAIN Batch 15/8300 loss 7.823031 loss_att 15.360975 loss_ctc 11.815520 loss_rnnt 5.667722 hw_loss 0.216354 lr 0.00043293 rank 1
2023-02-22 06:09:41,823 DEBUG TRAIN Batch 15/8300 loss 6.721679 loss_att 7.530109 loss_ctc 6.152421 loss_rnnt 6.452229 hw_loss 0.344373 lr 0.00043289 rank 6
2023-02-22 06:09:41,829 DEBUG TRAIN Batch 15/8300 loss 21.222555 loss_att 24.453794 loss_ctc 29.016401 loss_rnnt 19.448221 hw_loss 0.166699 lr 0.00043282 rank 5
2023-02-22 06:10:25,612 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 0
2023-02-22 06:10:25,618 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 2
2023-02-22 06:10:25,624 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 5
2023-02-22 06:10:25,626 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 1
2023-02-22 06:10:25,628 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 6
2023-02-22 06:10:25,632 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 7
2023-02-22 06:10:25,634 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 3
2023-02-22 06:10:25,635 DEBUG CV Batch 15/0 loss 1.951237 loss_att 2.029458 loss_ctc 2.765298 loss_rnnt 1.413205 hw_loss 0.775962 history loss 1.878969 rank 4
2023-02-22 06:10:36,776 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 0
2023-02-22 06:10:36,780 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 1
2023-02-22 06:10:36,959 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 7
2023-02-22 06:10:36,961 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 5
2023-02-22 06:10:37,237 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 2
2023-02-22 06:10:37,303 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 4
2023-02-22 06:10:37,305 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 6
2023-02-22 06:10:37,325 DEBUG CV Batch 15/100 loss 9.350470 loss_att 8.956255 loss_ctc 10.099551 loss_rnnt 9.118697 hw_loss 0.395133 history loss 3.858683 rank 3
2023-02-22 06:10:50,037 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 1
2023-02-22 06:10:50,304 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 5
2023-02-22 06:10:50,311 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 7
2023-02-22 06:10:50,359 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 0
2023-02-22 06:10:50,604 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 4
2023-02-22 06:10:50,967 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 2
2023-02-22 06:10:51,140 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 6
2023-02-22 06:10:51,171 DEBUG CV Batch 15/200 loss 9.575727 loss_att 17.323729 loss_ctc 10.242808 loss_rnnt 7.841906 hw_loss 0.178643 history loss 4.483247 rank 3
2023-02-22 06:11:02,015 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 1
2023-02-22 06:11:02,311 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 7
2023-02-22 06:11:02,509 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 5
2023-02-22 06:11:02,744 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 0
2023-02-22 06:11:02,868 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 4
2023-02-22 06:11:03,566 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 2
2023-02-22 06:11:03,788 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 3
2023-02-22 06:11:03,788 DEBUG CV Batch 15/300 loss 6.493485 loss_att 6.695200 loss_ctc 9.188890 loss_rnnt 5.936960 hw_loss 0.293991 history loss 4.691784 rank 6
2023-02-22 06:11:13,949 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 1
2023-02-22 06:11:14,495 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 7
2023-02-22 06:11:14,739 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 5
2023-02-22 06:11:14,948 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 0
2023-02-22 06:11:14,983 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 4
2023-02-22 06:11:16,118 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 2
2023-02-22 06:11:16,359 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 6
2023-02-22 06:11:16,398 DEBUG CV Batch 15/400 loss 16.793814 loss_att 87.610962 loss_ctc 5.190662 loss_rnnt 4.136340 hw_loss 0.077119 history loss 5.729682 rank 3
2023-02-22 06:11:24,384 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 1
2023-02-22 06:11:25,158 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 7
2023-02-22 06:11:25,602 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 5
2023-02-22 06:11:25,684 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 4
2023-02-22 06:11:26,024 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 0
2023-02-22 06:11:27,225 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 2
2023-02-22 06:11:27,567 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 3
2023-02-22 06:11:27,650 DEBUG CV Batch 15/500 loss 6.327001 loss_att 6.743609 loss_ctc 8.031413 loss_rnnt 5.903512 hw_loss 0.211711 history loss 6.530153 rank 6
2023-02-22 06:11:36,371 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 1
2023-02-22 06:11:37,298 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 7
2023-02-22 06:11:37,764 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 5
2023-02-22 06:11:38,007 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 4
2023-02-22 06:11:38,607 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 0
2023-02-22 06:11:39,907 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 2
2023-02-22 06:11:40,180 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 3
2023-02-22 06:11:40,324 DEBUG CV Batch 15/600 loss 8.501399 loss_att 8.779287 loss_ctc 10.673514 loss_rnnt 7.845891 hw_loss 0.581839 history loss 7.534030 rank 6
2023-02-22 06:11:47,621 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 1
2023-02-22 06:11:48,518 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 7
2023-02-22 06:11:49,166 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 5
2023-02-22 06:11:49,275 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 4
2023-02-22 06:11:50,285 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 0
2023-02-22 06:11:51,884 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 2
2023-02-22 06:11:51,971 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 3
2023-02-22 06:11:52,315 DEBUG CV Batch 15/700 loss 15.641908 loss_att 51.653179 loss_ctc 14.497544 loss_rnnt 8.407921 hw_loss 0.345587 history loss 8.195139 rank 6
2023-02-22 06:11:58,785 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 1
2023-02-22 06:12:00,089 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 7
2023-02-22 06:12:00,587 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 4
2023-02-22 06:12:00,650 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 5
2023-02-22 06:12:02,073 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 0
2023-02-22 06:12:03,841 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 3
2023-02-22 06:12:03,909 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 2
2023-02-22 06:12:04,299 DEBUG CV Batch 15/800 loss 12.773737 loss_att 11.702727 loss_ctc 15.164344 loss_rnnt 12.502223 hw_loss 0.313065 history loss 7.611902 rank 6
2023-02-22 06:12:11,953 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 1
2023-02-22 06:12:13,457 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 7
2023-02-22 06:12:13,821 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 4
2023-02-22 06:12:13,979 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 5
2023-02-22 06:12:15,657 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 0
2023-02-22 06:12:17,723 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 2
2023-02-22 06:12:17,724 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 3
2023-02-22 06:12:18,134 DEBUG CV Batch 15/900 loss 14.147290 loss_att 20.844105 loss_ctc 24.094646 loss_rnnt 11.409895 hw_loss 0.134474 history loss 7.396750 rank 6
2023-02-22 06:12:24,161 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 1
2023-02-22 06:12:26,080 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 7
2023-02-22 06:12:26,225 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 4
2023-02-22 06:12:26,558 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 5
2023-02-22 06:12:28,310 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 0
2023-02-22 06:12:30,414 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 3
2023-02-22 06:12:30,507 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 2
2023-02-22 06:12:31,031 DEBUG CV Batch 15/1000 loss 4.015256 loss_att 4.507483 loss_ctc 4.256023 loss_rnnt 3.615640 hw_loss 0.504503 history loss 7.161590 rank 6
2023-02-22 06:12:35,879 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 1
2023-02-22 06:12:37,996 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 4
2023-02-22 06:12:38,526 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 5
2023-02-22 06:12:38,542 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 7
2023-02-22 06:12:40,490 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 0
2023-02-22 06:12:42,894 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 2
2023-02-22 06:12:42,946 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 3
2023-02-22 06:12:43,546 DEBUG CV Batch 15/1100 loss 7.466806 loss_att 6.780309 loss_ctc 8.688530 loss_rnnt 7.091639 hw_loss 0.655444 history loss 7.151628 rank 6
2023-02-22 06:12:46,448 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 1
2023-02-22 06:12:48,745 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 4
2023-02-22 06:12:49,322 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 5
2023-02-22 06:12:49,737 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 7
2023-02-22 06:12:51,456 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 0
2023-02-22 06:12:54,112 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 3
2023-02-22 06:12:54,174 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 2
2023-02-22 06:12:54,789 DEBUG CV Batch 15/1200 loss 8.410914 loss_att 9.800079 loss_ctc 8.999305 loss_rnnt 7.905826 hw_loss 0.279007 history loss 7.502294 rank 6
2023-02-22 06:12:58,360 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 1
2023-02-22 06:13:00,780 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 4
2023-02-22 06:13:01,425 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 5
2023-02-22 06:13:01,981 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 7
2023-02-22 06:13:04,138 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 0
2023-02-22 06:13:06,680 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 2
2023-02-22 06:13:06,724 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 3
2023-02-22 06:13:07,385 DEBUG CV Batch 15/1300 loss 6.569984 loss_att 6.369684 loss_ctc 7.998462 loss_rnnt 6.149033 hw_loss 0.507278 history loss 7.836329 rank 6
2023-02-22 06:13:09,528 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 1
2023-02-22 06:13:12,339 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 4
2023-02-22 06:13:12,853 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 5
2023-02-22 06:13:13,242 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 7
2023-02-22 06:13:15,580 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 0
2023-02-22 06:13:18,391 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 2
2023-02-22 06:13:18,431 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 3
2023-02-22 06:13:19,376 DEBUG CV Batch 15/1400 loss 7.241999 loss_att 18.944027 loss_ctc 5.881180 loss_rnnt 4.975441 hw_loss 0.201741 history loss 8.163784 rank 6
2023-02-22 06:13:20,996 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 1
2023-02-22 06:13:23,965 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 4
2023-02-22 06:13:24,688 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 5
2023-02-22 06:13:25,060 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 7
2023-02-22 06:13:27,504 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 0
2023-02-22 06:13:30,537 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 3
2023-02-22 06:13:30,604 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 2
2023-02-22 06:13:31,536 DEBUG CV Batch 15/1500 loss 8.667685 loss_att 9.251248 loss_ctc 7.821895 loss_rnnt 8.439079 hw_loss 0.421246 history loss 7.977007 rank 6
2023-02-22 06:13:33,773 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 1
2023-02-22 06:13:36,943 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 4
2023-02-22 06:13:37,795 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 5
2023-02-22 06:13:38,286 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 7
2023-02-22 06:13:40,808 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 0
2023-02-22 06:13:44,027 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 3
2023-02-22 06:13:44,143 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 2
2023-02-22 06:13:45,132 DEBUG CV Batch 15/1600 loss 8.913963 loss_att 16.511221 loss_ctc 11.506708 loss_rnnt 6.915151 hw_loss 0.250616 history loss 7.899912 rank 6
2023-02-22 06:13:46,403 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 1
2023-02-22 06:13:49,435 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 4
2023-02-22 06:13:50,263 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 5
2023-02-22 06:13:50,826 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 7
2023-02-22 06:13:53,299 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 0
2023-02-22 06:13:55,471 INFO Epoch 15 CV info cv_loss 7.773724376935631
2023-02-22 06:13:55,472 INFO Epoch 16 TRAIN info lr 0.0004328541980628791
2023-02-22 06:13:55,473 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:13:56,326 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 3
2023-02-22 06:13:56,620 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 2
2023-02-22 06:13:57,683 DEBUG CV Batch 15/1700 loss 10.278352 loss_att 9.528770 loss_ctc 14.958312 loss_rnnt 9.604517 hw_loss 0.374543 history loss 7.805677 rank 6
2023-02-22 06:13:58,508 INFO Epoch 15 CV info cv_loss 7.773724373291641
2023-02-22 06:13:58,509 INFO Epoch 16 TRAIN info lr 0.0004328347351942514
2023-02-22 06:13:58,514 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:13:59,473 INFO Epoch 15 CV info cv_loss 7.7737243741100315
2023-02-22 06:13:59,474 INFO Epoch 16 TRAIN info lr 0.0004327569099653492
2023-02-22 06:13:59,478 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:13:59,985 INFO Epoch 15 CV info cv_loss 7.7737243729987435
2023-02-22 06:13:59,985 INFO Epoch 16 TRAIN info lr 0.0004327520472822924
2023-02-22 06:13:59,987 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:14:02,830 INFO Epoch 15 CV info cv_loss 7.773724376901172
2023-02-22 06:14:02,830 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/15.pt
2023-02-22 06:14:05,080 INFO Epoch 16 TRAIN info lr 0.0004328687969374603
2023-02-22 06:14:05,084 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:14:05,573 INFO Epoch 15 CV info cv_loss 7.7737243754582215
2023-02-22 06:14:05,573 INFO Epoch 16 TRAIN info lr 0.0004328233830665656
2023-02-22 06:14:05,575 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:14:05,990 INFO Epoch 15 CV info cv_loss 7.773724371323198
2023-02-22 06:14:05,991 INFO Epoch 16 TRAIN info lr 0.0004328347351942514
2023-02-22 06:14:05,993 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:14:07,135 INFO Epoch 15 CV info cv_loss 7.773724371977909
2023-02-22 06:14:07,136 INFO Epoch 16 TRAIN info lr 0.00043280230291324894
2023-02-22 06:14:07,141 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:15:06,849 DEBUG TRAIN Batch 16/0 loss 8.894338 loss_att 8.555973 loss_ctc 11.283669 loss_rnnt 8.271431 hw_loss 0.697504 lr 0.00043276 rank 5
2023-02-22 06:15:06,850 DEBUG TRAIN Batch 16/0 loss 7.879177 loss_att 8.182177 loss_ctc 10.480098 loss_rnnt 7.214495 hw_loss 0.482424 lr 0.00043275 rank 7
2023-02-22 06:15:06,852 DEBUG TRAIN Batch 16/0 loss 9.901096 loss_att 8.789310 loss_ctc 10.957617 loss_rnnt 9.546786 hw_loss 0.817122 lr 0.00043283 rank 4
2023-02-22 06:15:06,864 DEBUG TRAIN Batch 16/0 loss 8.000946 loss_att 7.634190 loss_ctc 9.554022 loss_rnnt 7.461781 hw_loss 0.760198 lr 0.00043285 rank 1
2023-02-22 06:15:06,869 DEBUG TRAIN Batch 16/0 loss 8.955251 loss_att 8.515728 loss_ctc 12.461390 loss_rnnt 8.252490 hw_loss 0.605961 lr 0.00043280 rank 6
2023-02-22 06:15:06,876 DEBUG TRAIN Batch 16/0 loss 4.507802 loss_att 5.390604 loss_ctc 5.979291 loss_rnnt 3.869593 hw_loss 0.497719 lr 0.00043282 rank 3
2023-02-22 06:15:06,915 DEBUG TRAIN Batch 16/0 loss 13.048886 loss_att 12.192516 loss_ctc 17.693933 loss_rnnt 12.215734 hw_loss 0.722039 lr 0.00043283 rank 2
2023-02-22 06:15:06,920 DEBUG TRAIN Batch 16/0 loss 10.142323 loss_att 9.114511 loss_ctc 13.133309 loss_rnnt 9.585992 hw_loss 0.680803 lr 0.00043287 rank 0
2023-02-22 06:16:19,549 DEBUG TRAIN Batch 16/100 loss 8.705724 loss_att 13.636963 loss_ctc 10.194007 loss_rnnt 7.391874 hw_loss 0.242182 lr 0.00043259 rank 7
2023-02-22 06:16:19,554 DEBUG TRAIN Batch 16/100 loss 10.860171 loss_att 12.624769 loss_ctc 12.575314 loss_rnnt 10.072915 hw_loss 0.385595 lr 0.00043269 rank 1
2023-02-22 06:16:19,567 DEBUG TRAIN Batch 16/100 loss 1.999040 loss_att 5.067898 loss_ctc 2.937443 loss_rnnt 1.108529 hw_loss 0.284285 lr 0.00043267 rank 2
2023-02-22 06:16:19,569 DEBUG TRAIN Batch 16/100 loss 8.832290 loss_att 12.764627 loss_ctc 12.879950 loss_rnnt 7.298452 hw_loss 0.389403 lr 0.00043264 rank 6
2023-02-22 06:16:19,570 DEBUG TRAIN Batch 16/100 loss 9.022660 loss_att 12.443180 loss_ctc 10.986912 loss_rnnt 7.958292 hw_loss 0.221931 lr 0.00043266 rank 3
2023-02-22 06:16:19,572 DEBUG TRAIN Batch 16/100 loss 20.764416 loss_att 25.931931 loss_ctc 27.807892 loss_rnnt 18.738607 hw_loss 0.099709 lr 0.00043267 rank 4
2023-02-22 06:16:19,574 DEBUG TRAIN Batch 16/100 loss 22.858356 loss_att 28.990993 loss_ctc 24.758251 loss_rnnt 21.212551 hw_loss 0.311176 lr 0.00043271 rank 0
2023-02-22 06:16:19,574 DEBUG TRAIN Batch 16/100 loss 6.374115 loss_att 12.605148 loss_ctc 9.917110 loss_rnnt 4.499976 hw_loss 0.291623 lr 0.00043259 rank 5
2023-02-22 06:17:31,451 DEBUG TRAIN Batch 16/200 loss 12.491762 loss_att 15.245921 loss_ctc 13.475180 loss_rnnt 11.654198 hw_loss 0.291769 lr 0.00043250 rank 3
2023-02-22 06:17:31,453 DEBUG TRAIN Batch 16/200 loss 4.237235 loss_att 10.923382 loss_ctc 7.182071 loss_rnnt 2.409191 hw_loss 0.184067 lr 0.00043248 rank 6
2023-02-22 06:17:31,454 DEBUG TRAIN Batch 16/200 loss 6.840562 loss_att 11.949688 loss_ctc 10.667357 loss_rnnt 5.140971 hw_loss 0.314112 lr 0.00043251 rank 2
2023-02-22 06:17:31,455 DEBUG TRAIN Batch 16/200 loss 6.803085 loss_att 10.872602 loss_ctc 10.101015 loss_rnnt 5.381772 hw_loss 0.314410 lr 0.00043254 rank 0
2023-02-22 06:17:31,456 DEBUG TRAIN Batch 16/200 loss 11.672489 loss_att 13.728781 loss_ctc 15.847785 loss_rnnt 10.587680 hw_loss 0.219082 lr 0.00043243 rank 7
2023-02-22 06:17:31,458 DEBUG TRAIN Batch 16/200 loss 5.410397 loss_att 7.123834 loss_ctc 7.496030 loss_rnnt 4.663959 hw_loss 0.235624 lr 0.00043253 rank 1
2023-02-22 06:17:31,460 DEBUG TRAIN Batch 16/200 loss 8.923103 loss_att 11.097485 loss_ctc 10.601793 loss_rnnt 8.117658 hw_loss 0.275145 lr 0.00043251 rank 4
2023-02-22 06:17:31,464 DEBUG TRAIN Batch 16/200 loss 13.912601 loss_att 15.509966 loss_ctc 18.551388 loss_rnnt 12.857428 hw_loss 0.219742 lr 0.00043243 rank 5
2023-02-22 06:18:44,781 DEBUG TRAIN Batch 16/300 loss 15.543695 loss_att 16.859547 loss_ctc 20.409637 loss_rnnt 14.541382 hw_loss 0.169407 lr 0.00043234 rank 3
2023-02-22 06:18:44,784 DEBUG TRAIN Batch 16/300 loss 10.929060 loss_att 11.386484 loss_ctc 14.103668 loss_rnnt 10.202994 hw_loss 0.396188 lr 0.00043235 rank 4
2023-02-22 06:18:44,785 DEBUG TRAIN Batch 16/300 loss 10.319391 loss_att 12.738138 loss_ctc 12.984062 loss_rnnt 9.363811 hw_loss 0.218516 lr 0.00043235 rank 2
2023-02-22 06:18:44,786 DEBUG TRAIN Batch 16/300 loss 9.342057 loss_att 10.187196 loss_ctc 12.327440 loss_rnnt 8.642729 hw_loss 0.247968 lr 0.00043232 rank 6
2023-02-22 06:18:44,786 DEBUG TRAIN Batch 16/300 loss 5.166728 loss_att 11.771823 loss_ctc 8.208464 loss_rnnt 3.309831 hw_loss 0.244336 lr 0.00043238 rank 0
2023-02-22 06:18:44,787 DEBUG TRAIN Batch 16/300 loss 13.284148 loss_att 15.382452 loss_ctc 19.293861 loss_rnnt 11.901423 hw_loss 0.303319 lr 0.00043226 rank 7
2023-02-22 06:18:44,788 DEBUG TRAIN Batch 16/300 loss 15.266682 loss_att 21.067984 loss_ctc 24.495163 loss_rnnt 12.772939 hw_loss 0.193158 lr 0.00043227 rank 5
2023-02-22 06:18:44,802 DEBUG TRAIN Batch 16/300 loss 9.153814 loss_att 13.418091 loss_ctc 8.980802 loss_rnnt 8.190355 hw_loss 0.250635 lr 0.00043237 rank 1
2023-02-22 06:19:58,811 DEBUG TRAIN Batch 16/400 loss 20.384172 loss_att 19.205967 loss_ctc 24.346291 loss_rnnt 19.890930 hw_loss 0.376124 lr 0.00043222 rank 0
2023-02-22 06:19:58,815 DEBUG TRAIN Batch 16/400 loss 7.416896 loss_att 10.003721 loss_ctc 8.455887 loss_rnnt 6.591186 hw_loss 0.318400 lr 0.00043219 rank 2
2023-02-22 06:19:58,815 DEBUG TRAIN Batch 16/400 loss 13.495435 loss_att 13.187000 loss_ctc 15.663573 loss_rnnt 13.199049 hw_loss 0.129353 lr 0.00043217 rank 3
2023-02-22 06:19:58,817 DEBUG TRAIN Batch 16/400 loss 17.040724 loss_att 18.282265 loss_ctc 20.931513 loss_rnnt 16.125538 hw_loss 0.277700 lr 0.00043215 rank 6
2023-02-22 06:19:58,818 DEBUG TRAIN Batch 16/400 loss 11.613104 loss_att 11.924391 loss_ctc 16.490147 loss_rnnt 10.760158 hw_loss 0.263280 lr 0.00043219 rank 4
2023-02-22 06:19:58,823 DEBUG TRAIN Batch 16/400 loss 5.657039 loss_att 10.913941 loss_ctc 10.490590 loss_rnnt 3.804467 hw_loss 0.293848 lr 0.00043210 rank 7
2023-02-22 06:19:58,824 DEBUG TRAIN Batch 16/400 loss 7.374188 loss_att 8.996209 loss_ctc 9.103629 loss_rnnt 6.648322 hw_loss 0.320381 lr 0.00043211 rank 5
2023-02-22 06:19:58,871 DEBUG TRAIN Batch 16/400 loss 10.226581 loss_att 11.534187 loss_ctc 12.490376 loss_rnnt 9.544876 hw_loss 0.221895 lr 0.00043221 rank 1
2023-02-22 06:21:11,570 DEBUG TRAIN Batch 16/500 loss 15.230002 loss_att 15.043016 loss_ctc 21.559465 loss_rnnt 14.312553 hw_loss 0.207971 lr 0.00043202 rank 4
2023-02-22 06:21:11,577 DEBUG TRAIN Batch 16/500 loss 10.257561 loss_att 14.500376 loss_ctc 11.812059 loss_rnnt 9.056240 hw_loss 0.272796 lr 0.00043202 rank 2
2023-02-22 06:21:11,577 DEBUG TRAIN Batch 16/500 loss 5.202977 loss_att 8.569735 loss_ctc 7.854409 loss_rnnt 3.956866 hw_loss 0.411066 lr 0.00043199 rank 6
2023-02-22 06:21:11,580 DEBUG TRAIN Batch 16/500 loss 11.913747 loss_att 12.299946 loss_ctc 15.220802 loss_rnnt 11.232309 hw_loss 0.306107 lr 0.00043201 rank 3
2023-02-22 06:21:11,583 DEBUG TRAIN Batch 16/500 loss 6.311415 loss_att 9.709324 loss_ctc 9.758545 loss_rnnt 5.027960 hw_loss 0.270479 lr 0.00043204 rank 1
2023-02-22 06:21:11,584 DEBUG TRAIN Batch 16/500 loss 14.439445 loss_att 15.564585 loss_ctc 15.206357 loss_rnnt 14.006094 hw_loss 0.198879 lr 0.00043206 rank 0
2023-02-22 06:21:11,584 DEBUG TRAIN Batch 16/500 loss 11.377357 loss_att 13.201601 loss_ctc 14.184038 loss_rnnt 10.475658 hw_loss 0.304923 lr 0.00043195 rank 5
2023-02-22 06:21:11,623 DEBUG TRAIN Batch 16/500 loss 11.033072 loss_att 15.405487 loss_ctc 16.479815 loss_rnnt 9.179946 hw_loss 0.473271 lr 0.00043194 rank 7
2023-02-22 06:22:25,271 DEBUG TRAIN Batch 16/600 loss 6.454120 loss_att 9.142723 loss_ctc 8.462324 loss_rnnt 5.400723 hw_loss 0.464841 lr 0.00043186 rank 2
2023-02-22 06:22:25,272 DEBUG TRAIN Batch 16/600 loss 10.451285 loss_att 12.596739 loss_ctc 16.648947 loss_rnnt 8.986597 hw_loss 0.392329 lr 0.00043190 rank 0
2023-02-22 06:22:25,273 DEBUG TRAIN Batch 16/600 loss 10.359958 loss_att 11.081368 loss_ctc 14.518700 loss_rnnt 9.392868 hw_loss 0.503076 lr 0.00043183 rank 6
2023-02-22 06:22:25,276 DEBUG TRAIN Batch 16/600 loss 13.566669 loss_att 16.624119 loss_ctc 22.541510 loss_rnnt 11.612754 hw_loss 0.273338 lr 0.00043178 rank 7
2023-02-22 06:22:25,275 DEBUG TRAIN Batch 16/600 loss 8.259915 loss_att 9.098824 loss_ctc 9.411451 loss_rnnt 7.747851 hw_loss 0.357646 lr 0.00043185 rank 3
2023-02-22 06:22:25,278 DEBUG TRAIN Batch 16/600 loss 10.991969 loss_att 11.921755 loss_ctc 14.314352 loss_rnnt 10.150601 hw_loss 0.398298 lr 0.00043188 rank 1
2023-02-22 06:22:25,283 DEBUG TRAIN Batch 16/600 loss 11.598353 loss_att 12.774890 loss_ctc 15.566382 loss_rnnt 10.612737 hw_loss 0.414822 lr 0.00043179 rank 5
2023-02-22 06:22:25,330 DEBUG TRAIN Batch 16/600 loss 10.897396 loss_att 11.345015 loss_ctc 13.364107 loss_rnnt 10.272647 hw_loss 0.386869 lr 0.00043186 rank 4
2023-02-22 06:23:40,452 DEBUG TRAIN Batch 16/700 loss 23.796444 loss_att 23.764179 loss_ctc 34.458443 loss_rnnt 22.230003 hw_loss 0.283673 lr 0.00043170 rank 2
2023-02-22 06:23:40,462 DEBUG TRAIN Batch 16/700 loss 17.684122 loss_att 22.891708 loss_ctc 25.553701 loss_rnnt 15.518977 hw_loss 0.139406 lr 0.00043172 rank 1
2023-02-22 06:23:40,469 DEBUG TRAIN Batch 16/700 loss 14.737362 loss_att 19.547009 loss_ctc 22.027077 loss_rnnt 12.729121 hw_loss 0.139406 lr 0.00043169 rank 3
2023-02-22 06:23:40,476 DEBUG TRAIN Batch 16/700 loss 6.328491 loss_att 10.596789 loss_ctc 7.409074 loss_rnnt 5.189048 hw_loss 0.265697 lr 0.00043170 rank 4
2023-02-22 06:23:40,477 DEBUG TRAIN Batch 16/700 loss 5.830711 loss_att 10.093178 loss_ctc 8.343394 loss_rnnt 4.456784 hw_loss 0.349517 lr 0.00043167 rank 6
2023-02-22 06:23:40,480 DEBUG TRAIN Batch 16/700 loss 4.506949 loss_att 8.192754 loss_ctc 5.887577 loss_rnnt 3.449721 hw_loss 0.254969 lr 0.00043162 rank 7
2023-02-22 06:23:40,502 DEBUG TRAIN Batch 16/700 loss 7.889332 loss_att 9.570578 loss_ctc 11.738039 loss_rnnt 6.954288 hw_loss 0.160567 lr 0.00043163 rank 5
2023-02-22 06:23:40,530 DEBUG TRAIN Batch 16/700 loss 16.208763 loss_att 18.346699 loss_ctc 23.548332 loss_rnnt 14.714370 hw_loss 0.165365 lr 0.00043174 rank 0
2023-02-22 06:24:53,120 DEBUG TRAIN Batch 16/800 loss 6.782872 loss_att 10.577445 loss_ctc 9.822177 loss_rnnt 5.545210 hw_loss 0.137824 lr 0.00043151 rank 6
2023-02-22 06:24:53,130 DEBUG TRAIN Batch 16/800 loss 5.633003 loss_att 9.484748 loss_ctc 8.098530 loss_rnnt 4.449862 hw_loss 0.157603 lr 0.00043158 rank 0
2023-02-22 06:24:53,133 DEBUG TRAIN Batch 16/800 loss 6.296578 loss_att 10.803206 loss_ctc 9.951593 loss_rnnt 4.812183 hw_loss 0.179502 lr 0.00043154 rank 2
2023-02-22 06:24:53,132 DEBUG TRAIN Batch 16/800 loss 6.121214 loss_att 8.871037 loss_ctc 7.042544 loss_rnnt 5.355997 hw_loss 0.173264 lr 0.00043146 rank 5
2023-02-22 06:24:53,133 DEBUG TRAIN Batch 16/800 loss 8.630226 loss_att 11.337162 loss_ctc 13.960373 loss_rnnt 7.224674 hw_loss 0.287772 lr 0.00043154 rank 4
2023-02-22 06:24:53,133 DEBUG TRAIN Batch 16/800 loss 7.493916 loss_att 11.112179 loss_ctc 9.512300 loss_rnnt 6.384132 hw_loss 0.219400 lr 0.00043153 rank 3
2023-02-22 06:24:53,137 DEBUG TRAIN Batch 16/800 loss 14.204609 loss_att 16.447281 loss_ctc 20.747513 loss_rnnt 12.681769 hw_loss 0.378594 lr 0.00043146 rank 7
2023-02-22 06:24:53,151 DEBUG TRAIN Batch 16/800 loss 12.227718 loss_att 13.890551 loss_ctc 19.228928 loss_rnnt 10.841616 hw_loss 0.225078 lr 0.00043156 rank 1
2023-02-22 06:26:05,224 DEBUG TRAIN Batch 16/900 loss 4.839395 loss_att 8.071288 loss_ctc 6.308842 loss_rnnt 3.873265 hw_loss 0.232172 lr 0.00043140 rank 1
2023-02-22 06:26:05,233 DEBUG TRAIN Batch 16/900 loss 8.806330 loss_att 12.768514 loss_ctc 11.091085 loss_rnnt 7.613204 hw_loss 0.180105 lr 0.00043138 rank 2
2023-02-22 06:26:05,235 DEBUG TRAIN Batch 16/900 loss 12.860822 loss_att 16.396486 loss_ctc 15.356391 loss_rnnt 11.751992 hw_loss 0.129287 lr 0.00043130 rank 7
2023-02-22 06:26:05,236 DEBUG TRAIN Batch 16/900 loss 9.926198 loss_att 14.146921 loss_ctc 14.374535 loss_rnnt 8.383770 hw_loss 0.197198 lr 0.00043141 rank 0
2023-02-22 06:26:05,240 DEBUG TRAIN Batch 16/900 loss 14.013084 loss_att 16.311949 loss_ctc 16.496298 loss_rnnt 13.098364 hw_loss 0.232225 lr 0.00043135 rank 6
2023-02-22 06:26:05,243 DEBUG TRAIN Batch 16/900 loss 16.739958 loss_att 21.261017 loss_ctc 25.036665 loss_rnnt 14.632426 hw_loss 0.182046 lr 0.00043138 rank 4
2023-02-22 06:26:05,244 DEBUG TRAIN Batch 16/900 loss 13.426285 loss_att 18.785236 loss_ctc 16.675127 loss_rnnt 11.816796 hw_loss 0.195972 lr 0.00043137 rank 3
2023-02-22 06:26:05,288 DEBUG TRAIN Batch 16/900 loss 10.819013 loss_att 13.407473 loss_ctc 14.140938 loss_rnnt 9.710713 hw_loss 0.276906 lr 0.00043130 rank 5
2023-02-22 06:27:17,965 DEBUG TRAIN Batch 16/1000 loss 6.767754 loss_att 11.220093 loss_ctc 8.166272 loss_rnnt 5.534033 hw_loss 0.293971 lr 0.00043114 rank 5
2023-02-22 06:27:17,972 DEBUG TRAIN Batch 16/1000 loss 10.500559 loss_att 14.170097 loss_ctc 11.362888 loss_rnnt 9.500158 hw_loss 0.284091 lr 0.00043121 rank 3
2023-02-22 06:27:17,975 DEBUG TRAIN Batch 16/1000 loss 6.850986 loss_att 10.908946 loss_ctc 10.841173 loss_rnnt 5.340802 hw_loss 0.312311 lr 0.00043122 rank 2
2023-02-22 06:27:17,977 DEBUG TRAIN Batch 16/1000 loss 24.509686 loss_att 27.028299 loss_ctc 28.004055 loss_rnnt 23.356171 hw_loss 0.344769 lr 0.00043122 rank 4
2023-02-22 06:27:17,978 DEBUG TRAIN Batch 16/1000 loss 11.120387 loss_att 14.454346 loss_ctc 16.696344 loss_rnnt 9.595440 hw_loss 0.215050 lr 0.00043125 rank 0
2023-02-22 06:27:17,978 DEBUG TRAIN Batch 16/1000 loss 13.804604 loss_att 16.863268 loss_ctc 18.569260 loss_rnnt 12.345350 hw_loss 0.397937 lr 0.00043119 rank 6
2023-02-22 06:27:17,982 DEBUG TRAIN Batch 16/1000 loss 13.601189 loss_att 15.525953 loss_ctc 19.057261 loss_rnnt 12.396338 hw_loss 0.173288 lr 0.00043124 rank 1
2023-02-22 06:27:17,992 DEBUG TRAIN Batch 16/1000 loss 12.739382 loss_att 17.280285 loss_ctc 17.531708 loss_rnnt 11.078884 hw_loss 0.212513 lr 0.00043114 rank 7
2023-02-22 06:28:32,201 DEBUG TRAIN Batch 16/1100 loss 9.029996 loss_att 10.496948 loss_ctc 12.371234 loss_rnnt 8.113646 hw_loss 0.332740 lr 0.00043103 rank 6
2023-02-22 06:28:32,201 DEBUG TRAIN Batch 16/1100 loss 9.102352 loss_att 10.920864 loss_ctc 13.683737 loss_rnnt 8.008531 hw_loss 0.223627 lr 0.00043106 rank 2
2023-02-22 06:28:32,204 DEBUG TRAIN Batch 16/1100 loss 9.811068 loss_att 13.220851 loss_ctc 14.086618 loss_rnnt 8.447590 hw_loss 0.208964 lr 0.00043105 rank 3
2023-02-22 06:28:32,208 DEBUG TRAIN Batch 16/1100 loss 6.073235 loss_att 8.658062 loss_ctc 8.325209 loss_rnnt 5.131842 hw_loss 0.232807 lr 0.00043108 rank 1
2023-02-22 06:28:32,208 DEBUG TRAIN Batch 16/1100 loss 16.746313 loss_att 19.605139 loss_ctc 19.874226 loss_rnnt 15.638039 hw_loss 0.223977 lr 0.00043098 rank 5
2023-02-22 06:28:32,208 DEBUG TRAIN Batch 16/1100 loss 8.669994 loss_att 10.925464 loss_ctc 11.826447 loss_rnnt 7.663530 hw_loss 0.252206 lr 0.00043098 rank 7
2023-02-22 06:28:32,210 DEBUG TRAIN Batch 16/1100 loss 8.289547 loss_att 10.064032 loss_ctc 9.821173 loss_rnnt 7.639973 hw_loss 0.169613 lr 0.00043106 rank 4
2023-02-22 06:28:32,211 DEBUG TRAIN Batch 16/1100 loss 9.462464 loss_att 14.259894 loss_ctc 9.729725 loss_rnnt 8.295048 hw_loss 0.323055 lr 0.00043109 rank 0
2023-02-22 06:29:44,950 DEBUG TRAIN Batch 16/1200 loss 4.300296 loss_att 6.047489 loss_ctc 6.559761 loss_rnnt 3.423104 hw_loss 0.424671 lr 0.00043089 rank 3
2023-02-22 06:29:44,952 DEBUG TRAIN Batch 16/1200 loss 8.388899 loss_att 11.947855 loss_ctc 12.397594 loss_rnnt 7.012260 hw_loss 0.244415 lr 0.00043090 rank 2
2023-02-22 06:29:44,953 DEBUG TRAIN Batch 16/1200 loss 12.207652 loss_att 13.459230 loss_ctc 14.776869 loss_rnnt 11.414877 hw_loss 0.374809 lr 0.00043082 rank 7
2023-02-22 06:29:44,956 DEBUG TRAIN Batch 16/1200 loss 6.583741 loss_att 9.138687 loss_ctc 10.546065 loss_rnnt 5.325143 hw_loss 0.411186 lr 0.00043093 rank 0
2023-02-22 06:29:44,959 DEBUG TRAIN Batch 16/1200 loss 11.801149 loss_att 15.716074 loss_ctc 17.625553 loss_rnnt 10.047011 hw_loss 0.364810 lr 0.00043090 rank 4
2023-02-22 06:29:44,962 DEBUG TRAIN Batch 16/1200 loss 9.193341 loss_att 9.608456 loss_ctc 12.288546 loss_rnnt 8.342571 hw_loss 0.665725 lr 0.00043087 rank 6
2023-02-22 06:29:44,963 DEBUG TRAIN Batch 16/1200 loss 12.294154 loss_att 12.194611 loss_ctc 10.183047 loss_rnnt 12.173447 hw_loss 0.791432 lr 0.00043082 rank 5
2023-02-22 06:29:45,009 DEBUG TRAIN Batch 16/1200 loss 11.787848 loss_att 12.310593 loss_ctc 16.052633 loss_rnnt 10.915783 hw_loss 0.372895 lr 0.00043092 rank 1
2023-02-22 06:30:57,066 DEBUG TRAIN Batch 16/1300 loss 8.357153 loss_att 10.798748 loss_ctc 11.201153 loss_rnnt 7.385234 hw_loss 0.195752 lr 0.00043071 rank 6
2023-02-22 06:30:57,067 DEBUG TRAIN Batch 16/1300 loss 6.966397 loss_att 10.732505 loss_ctc 7.516470 loss_rnnt 6.026034 hw_loss 0.213373 lr 0.00043074 rank 2
2023-02-22 06:30:57,068 DEBUG TRAIN Batch 16/1300 loss 7.060729 loss_att 11.732582 loss_ctc 9.461595 loss_rnnt 5.680382 hw_loss 0.235990 lr 0.00043073 rank 3
2023-02-22 06:30:57,069 DEBUG TRAIN Batch 16/1300 loss 11.462524 loss_att 16.412746 loss_ctc 13.191165 loss_rnnt 10.052032 hw_loss 0.356179 lr 0.00043076 rank 1
2023-02-22 06:30:57,071 DEBUG TRAIN Batch 16/1300 loss 19.235846 loss_att 26.313519 loss_ctc 25.806355 loss_rnnt 16.751453 hw_loss 0.361481 lr 0.00043066 rank 7
2023-02-22 06:30:57,073 DEBUG TRAIN Batch 16/1300 loss 6.571680 loss_att 10.521641 loss_ctc 11.495083 loss_rnnt 5.018520 hw_loss 0.200087 lr 0.00043066 rank 5
2023-02-22 06:30:57,073 DEBUG TRAIN Batch 16/1300 loss 11.998732 loss_att 12.049075 loss_ctc 15.002613 loss_rnnt 11.414810 hw_loss 0.325002 lr 0.00043077 rank 0
2023-02-22 06:30:57,074 DEBUG TRAIN Batch 16/1300 loss 3.259559 loss_att 6.300823 loss_ctc 1.838274 loss_rnnt 2.774970 hw_loss 0.123451 lr 0.00043074 rank 4
2023-02-22 06:32:11,032 DEBUG TRAIN Batch 16/1400 loss 14.889263 loss_att 17.115242 loss_ctc 19.493744 loss_rnnt 13.680729 hw_loss 0.280140 lr 0.00043050 rank 7
2023-02-22 06:32:11,034 DEBUG TRAIN Batch 16/1400 loss 9.740726 loss_att 10.802855 loss_ctc 8.317393 loss_rnnt 9.563029 hw_loss 0.290718 lr 0.00043050 rank 5
2023-02-22 06:32:11,037 DEBUG TRAIN Batch 16/1400 loss 6.391123 loss_att 7.794438 loss_ctc 6.616624 loss_rnnt 6.021715 hw_loss 0.110020 lr 0.00043058 rank 2
2023-02-22 06:32:11,041 DEBUG TRAIN Batch 16/1400 loss 8.103122 loss_att 11.280262 loss_ctc 9.661077 loss_rnnt 7.210797 hw_loss 0.092192 lr 0.00043061 rank 0
2023-02-22 06:32:11,042 DEBUG TRAIN Batch 16/1400 loss 13.104424 loss_att 13.545172 loss_ctc 17.381279 loss_rnnt 12.342982 hw_loss 0.193209 lr 0.00043060 rank 1
2023-02-22 06:32:11,045 DEBUG TRAIN Batch 16/1400 loss 13.443247 loss_att 19.987499 loss_ctc 22.217407 loss_rnnt 10.716002 hw_loss 0.465951 lr 0.00043057 rank 3
2023-02-22 06:32:11,049 DEBUG TRAIN Batch 16/1400 loss 15.062479 loss_att 18.285713 loss_ctc 19.810234 loss_rnnt 13.574771 hw_loss 0.393800 lr 0.00043055 rank 6
2023-02-22 06:32:11,091 DEBUG TRAIN Batch 16/1400 loss 3.697762 loss_att 7.498031 loss_ctc 5.659601 loss_rnnt 2.569438 hw_loss 0.200048 lr 0.00043058 rank 4
2023-02-22 06:33:24,056 DEBUG TRAIN Batch 16/1500 loss 5.859388 loss_att 9.029908 loss_ctc 9.113203 loss_rnnt 4.615227 hw_loss 0.330402 lr 0.00043042 rank 2
2023-02-22 06:33:24,057 DEBUG TRAIN Batch 16/1500 loss 14.736573 loss_att 18.569889 loss_ctc 18.736671 loss_rnnt 13.211880 hw_loss 0.421284 lr 0.00043039 rank 6
2023-02-22 06:33:24,060 DEBUG TRAIN Batch 16/1500 loss 12.875363 loss_att 15.489922 loss_ctc 19.416918 loss_rnnt 11.303436 hw_loss 0.331517 lr 0.00043034 rank 7
2023-02-22 06:33:24,060 DEBUG TRAIN Batch 16/1500 loss 9.024187 loss_att 10.556236 loss_ctc 8.847368 loss_rnnt 8.639551 hw_loss 0.190878 lr 0.00043041 rank 3
2023-02-22 06:33:24,067 DEBUG TRAIN Batch 16/1500 loss 23.451336 loss_att 23.966234 loss_ctc 22.831551 loss_rnnt 23.268377 hw_loss 0.304910 lr 0.00043045 rank 0
2023-02-22 06:33:24,068 DEBUG TRAIN Batch 16/1500 loss 10.975926 loss_att 12.251849 loss_ctc 13.352934 loss_rnnt 10.285690 hw_loss 0.221470 lr 0.00043034 rank 5
2023-02-22 06:33:24,099 DEBUG TRAIN Batch 16/1500 loss 13.697450 loss_att 17.966564 loss_ctc 17.304352 loss_rnnt 12.282474 hw_loss 0.150438 lr 0.00043042 rank 4
2023-02-22 06:33:24,108 DEBUG TRAIN Batch 16/1500 loss 16.681009 loss_att 22.151379 loss_ctc 25.552319 loss_rnnt 14.214848 hw_loss 0.354840 lr 0.00043044 rank 1
2023-02-22 06:34:36,337 DEBUG TRAIN Batch 16/1600 loss 12.617185 loss_att 13.566563 loss_ctc 16.613705 loss_rnnt 11.762540 hw_loss 0.247311 lr 0.00043026 rank 2
2023-02-22 06:34:36,340 DEBUG TRAIN Batch 16/1600 loss 7.223566 loss_att 11.792158 loss_ctc 9.776175 loss_rnnt 5.823978 hw_loss 0.272855 lr 0.00043018 rank 7
2023-02-22 06:34:36,340 DEBUG TRAIN Batch 16/1600 loss 10.036043 loss_att 12.882146 loss_ctc 15.419467 loss_rnnt 8.649160 hw_loss 0.187260 lr 0.00043028 rank 1
2023-02-22 06:34:36,340 DEBUG TRAIN Batch 16/1600 loss 10.179470 loss_att 15.143227 loss_ctc 12.501851 loss_rnnt 8.769153 hw_loss 0.202341 lr 0.00043025 rank 3
2023-02-22 06:34:36,343 DEBUG TRAIN Batch 16/1600 loss 7.774345 loss_att 9.722260 loss_ctc 11.496992 loss_rnnt 6.764274 hw_loss 0.232755 lr 0.00043023 rank 6
2023-02-22 06:34:36,344 DEBUG TRAIN Batch 16/1600 loss 8.086093 loss_att 11.922078 loss_ctc 14.581367 loss_rnnt 6.283728 hw_loss 0.317121 lr 0.00043029 rank 0
2023-02-22 06:34:36,346 DEBUG TRAIN Batch 16/1600 loss 6.351038 loss_att 10.334330 loss_ctc 9.062996 loss_rnnt 5.098060 hw_loss 0.177612 lr 0.00043026 rank 4
2023-02-22 06:34:36,398 DEBUG TRAIN Batch 16/1600 loss 23.755447 loss_att 26.577953 loss_ctc 30.911442 loss_rnnt 22.116062 hw_loss 0.226406 lr 0.00043018 rank 5
2023-02-22 06:35:48,735 DEBUG TRAIN Batch 16/1700 loss 9.077218 loss_att 11.460222 loss_ctc 13.725682 loss_rnnt 7.792154 hw_loss 0.353752 lr 0.00043009 rank 3
2023-02-22 06:35:48,739 DEBUG TRAIN Batch 16/1700 loss 9.677303 loss_att 11.168635 loss_ctc 15.545134 loss_rnnt 8.480537 hw_loss 0.217729 lr 0.00043010 rank 4
2023-02-22 06:35:48,739 DEBUG TRAIN Batch 16/1700 loss 9.346489 loss_att 11.571235 loss_ctc 11.587854 loss_rnnt 8.488968 hw_loss 0.213232 lr 0.00043014 rank 0
2023-02-22 06:35:48,741 DEBUG TRAIN Batch 16/1700 loss 10.306307 loss_att 12.183040 loss_ctc 15.025534 loss_rnnt 9.139181 hw_loss 0.304781 lr 0.00043010 rank 2
2023-02-22 06:35:48,743 DEBUG TRAIN Batch 16/1700 loss 8.685577 loss_att 12.711905 loss_ctc 14.406208 loss_rnnt 7.028778 hw_loss 0.166470 lr 0.00043007 rank 6
2023-02-22 06:35:48,747 DEBUG TRAIN Batch 16/1700 loss 12.263096 loss_att 17.655209 loss_ctc 18.142979 loss_rnnt 10.229609 hw_loss 0.320777 lr 0.00043012 rank 1
2023-02-22 06:35:48,747 DEBUG TRAIN Batch 16/1700 loss 23.893806 loss_att 24.872046 loss_ctc 38.676041 loss_rnnt 21.533102 hw_loss 0.363927 lr 0.00043003 rank 5
2023-02-22 06:35:48,748 DEBUG TRAIN Batch 16/1700 loss 9.617038 loss_att 10.721184 loss_ctc 13.864840 loss_rnnt 8.698275 hw_loss 0.246675 lr 0.00043002 rank 7
2023-02-22 06:37:03,863 DEBUG TRAIN Batch 16/1800 loss 12.248578 loss_att 14.781960 loss_ctc 17.394501 loss_rnnt 10.855581 hw_loss 0.375371 lr 0.00042991 rank 6
2023-02-22 06:37:03,865 DEBUG TRAIN Batch 16/1800 loss 15.263188 loss_att 17.833494 loss_ctc 20.208063 loss_rnnt 13.854100 hw_loss 0.441957 lr 0.00042986 rank 7
2023-02-22 06:37:03,866 DEBUG TRAIN Batch 16/1800 loss 10.940475 loss_att 13.858639 loss_ctc 11.710404 loss_rnnt 10.037907 hw_loss 0.405522 lr 0.00042994 rank 2
2023-02-22 06:37:03,867 DEBUG TRAIN Batch 16/1800 loss 8.818353 loss_att 9.732872 loss_ctc 10.567503 loss_rnnt 8.260998 hw_loss 0.264810 lr 0.00042996 rank 1
2023-02-22 06:37:03,869 DEBUG TRAIN Batch 16/1800 loss 11.611944 loss_att 14.145424 loss_ctc 20.805622 loss_rnnt 9.766072 hw_loss 0.212534 lr 0.00042994 rank 4
2023-02-22 06:37:03,870 DEBUG TRAIN Batch 16/1800 loss 8.743942 loss_att 11.600119 loss_ctc 8.721586 loss_rnnt 8.042251 hw_loss 0.250196 lr 0.00042993 rank 3
2023-02-22 06:37:03,871 DEBUG TRAIN Batch 16/1800 loss 6.304610 loss_att 8.138081 loss_ctc 8.314373 loss_rnnt 5.545225 hw_loss 0.233855 lr 0.00042998 rank 0
2023-02-22 06:37:03,875 DEBUG TRAIN Batch 16/1800 loss 10.251280 loss_att 11.081050 loss_ctc 12.968557 loss_rnnt 9.569842 hw_loss 0.287213 lr 0.00042987 rank 5
2023-02-22 06:38:15,843 DEBUG TRAIN Batch 16/1900 loss 5.885276 loss_att 6.074321 loss_ctc 6.986052 loss_rnnt 5.433515 hw_loss 0.500967 lr 0.00042978 rank 2
2023-02-22 06:38:15,849 DEBUG TRAIN Batch 16/1900 loss 8.967234 loss_att 10.392263 loss_ctc 10.956156 loss_rnnt 8.253235 hw_loss 0.307132 lr 0.00042977 rank 3
2023-02-22 06:38:15,852 DEBUG TRAIN Batch 16/1900 loss 30.009546 loss_att 40.374485 loss_ctc 43.721588 loss_rnnt 25.922867 hw_loss 0.347661 lr 0.00042975 rank 6
2023-02-22 06:38:15,853 DEBUG TRAIN Batch 16/1900 loss 7.916553 loss_att 10.765461 loss_ctc 12.435692 loss_rnnt 6.621010 hw_loss 0.231019 lr 0.00042971 rank 5
2023-02-22 06:38:15,853 DEBUG TRAIN Batch 16/1900 loss 12.410726 loss_att 16.639072 loss_ctc 14.245716 loss_rnnt 11.197222 hw_loss 0.230939 lr 0.00042980 rank 1
2023-02-22 06:38:15,854 DEBUG TRAIN Batch 16/1900 loss 5.727812 loss_att 7.150661 loss_ctc 7.030340 loss_rnnt 4.996107 hw_loss 0.512745 lr 0.00042982 rank 0
2023-02-22 06:38:15,856 DEBUG TRAIN Batch 16/1900 loss 9.925082 loss_att 16.636700 loss_ctc 11.828818 loss_rnnt 8.134620 hw_loss 0.364328 lr 0.00042970 rank 7
2023-02-22 06:38:15,906 DEBUG TRAIN Batch 16/1900 loss 7.948962 loss_att 8.381744 loss_ctc 9.146107 loss_rnnt 7.433605 hw_loss 0.504715 lr 0.00042978 rank 4
2023-02-22 06:39:27,867 DEBUG TRAIN Batch 16/2000 loss 12.207211 loss_att 13.538253 loss_ctc 12.733366 loss_rnnt 11.738487 hw_loss 0.248180 lr 0.00042963 rank 2
2023-02-22 06:39:27,870 DEBUG TRAIN Batch 16/2000 loss 11.573659 loss_att 12.799507 loss_ctc 11.498474 loss_rnnt 11.225653 hw_loss 0.211618 lr 0.00042959 rank 6
2023-02-22 06:39:27,872 DEBUG TRAIN Batch 16/2000 loss 15.473188 loss_att 22.058382 loss_ctc 20.930992 loss_rnnt 13.283541 hw_loss 0.271689 lr 0.00042963 rank 4
2023-02-22 06:39:27,873 DEBUG TRAIN Batch 16/2000 loss 12.490546 loss_att 13.776638 loss_ctc 16.681576 loss_rnnt 11.529018 hw_loss 0.272822 lr 0.00042955 rank 5
2023-02-22 06:39:27,874 DEBUG TRAIN Batch 16/2000 loss 8.473197 loss_att 10.733858 loss_ctc 10.021973 loss_rnnt 7.694811 hw_loss 0.224530 lr 0.00042964 rank 1
2023-02-22 06:39:27,877 DEBUG TRAIN Batch 16/2000 loss 9.717027 loss_att 15.442554 loss_ctc 12.787376 loss_rnnt 7.943964 hw_loss 0.409833 lr 0.00042961 rank 3
2023-02-22 06:39:27,884 DEBUG TRAIN Batch 16/2000 loss 8.929011 loss_att 11.650574 loss_ctc 13.210230 loss_rnnt 7.653547 hw_loss 0.300605 lr 0.00042966 rank 0
2023-02-22 06:39:27,921 DEBUG TRAIN Batch 16/2000 loss 10.918382 loss_att 14.109675 loss_ctc 16.185163 loss_rnnt 9.355434 hw_loss 0.417096 lr 0.00042954 rank 7
2023-02-22 06:40:41,935 DEBUG TRAIN Batch 16/2100 loss 16.324863 loss_att 20.084717 loss_ctc 24.893894 loss_rnnt 14.258594 hw_loss 0.322055 lr 0.00042947 rank 4
2023-02-22 06:40:41,948 DEBUG TRAIN Batch 16/2100 loss 7.927167 loss_att 10.003698 loss_ctc 11.968463 loss_rnnt 6.864303 hw_loss 0.203849 lr 0.00042939 rank 7
2023-02-22 06:40:41,947 DEBUG TRAIN Batch 16/2100 loss 14.019835 loss_att 16.366137 loss_ctc 19.043314 loss_rnnt 12.718557 hw_loss 0.304164 lr 0.00042947 rank 2
2023-02-22 06:40:41,950 DEBUG TRAIN Batch 16/2100 loss 11.634796 loss_att 12.280993 loss_ctc 14.877548 loss_rnnt 10.905826 hw_loss 0.313808 lr 0.00042950 rank 0
2023-02-22 06:40:41,953 DEBUG TRAIN Batch 16/2100 loss 4.814545 loss_att 7.259916 loss_ctc 6.791666 loss_rnnt 3.933666 hw_loss 0.240352 lr 0.00042944 rank 6
2023-02-22 06:40:41,963 DEBUG TRAIN Batch 16/2100 loss 5.157656 loss_att 8.686316 loss_ctc 10.566533 loss_rnnt 3.582839 hw_loss 0.277313 lr 0.00042949 rank 1
2023-02-22 06:40:41,967 DEBUG TRAIN Batch 16/2100 loss 6.091416 loss_att 7.587436 loss_ctc 6.787536 loss_rnnt 5.608701 hw_loss 0.170053 lr 0.00042946 rank 3
2023-02-22 06:40:42,002 DEBUG TRAIN Batch 16/2100 loss 6.983208 loss_att 10.725898 loss_ctc 10.084233 loss_rnnt 5.616757 hw_loss 0.383328 lr 0.00042939 rank 5
2023-02-22 06:41:55,245 DEBUG TRAIN Batch 16/2200 loss 8.656456 loss_att 11.757347 loss_ctc 10.220648 loss_rnnt 7.696548 hw_loss 0.245946 lr 0.00042923 rank 7
2023-02-22 06:41:55,245 DEBUG TRAIN Batch 16/2200 loss 11.821489 loss_att 15.255820 loss_ctc 15.463976 loss_rnnt 10.440038 hw_loss 0.391726 lr 0.00042930 rank 3
2023-02-22 06:41:55,247 DEBUG TRAIN Batch 16/2200 loss 7.702088 loss_att 10.191797 loss_ctc 10.886967 loss_rnnt 6.538781 hw_loss 0.451340 lr 0.00042931 rank 2
2023-02-22 06:41:55,249 DEBUG TRAIN Batch 16/2200 loss 12.120408 loss_att 15.108220 loss_ctc 17.735121 loss_rnnt 10.663622 hw_loss 0.207364 lr 0.00042934 rank 0
2023-02-22 06:41:55,252 DEBUG TRAIN Batch 16/2200 loss 20.458975 loss_att 26.026918 loss_ctc 28.139719 loss_rnnt 18.152874 hw_loss 0.315774 lr 0.00042931 rank 4
2023-02-22 06:41:55,253 DEBUG TRAIN Batch 16/2200 loss 11.219378 loss_att 12.109731 loss_ctc 12.085436 loss_rnnt 10.764864 hw_loss 0.301813 lr 0.00042923 rank 5
2023-02-22 06:41:55,255 DEBUG TRAIN Batch 16/2200 loss 17.486292 loss_att 18.690136 loss_ctc 21.790068 loss_rnnt 16.551750 hw_loss 0.224882 lr 0.00042933 rank 1
2023-02-22 06:41:55,254 DEBUG TRAIN Batch 16/2200 loss 5.624921 loss_att 8.571624 loss_ctc 6.820577 loss_rnnt 4.729748 hw_loss 0.274521 lr 0.00042928 rank 6
2023-02-22 06:43:07,781 DEBUG TRAIN Batch 16/2300 loss 9.643022 loss_att 14.128834 loss_ctc 11.181114 loss_rnnt 8.441270 hw_loss 0.186580 lr 0.00042907 rank 5
2023-02-22 06:43:07,788 DEBUG TRAIN Batch 16/2300 loss 15.048158 loss_att 17.388371 loss_ctc 19.758835 loss_rnnt 13.836147 hw_loss 0.217270 lr 0.00042914 rank 3
2023-02-22 06:43:07,789 DEBUG TRAIN Batch 16/2300 loss 10.837827 loss_att 13.416752 loss_ctc 13.792322 loss_rnnt 9.738136 hw_loss 0.356198 lr 0.00042915 rank 4
2023-02-22 06:43:07,789 DEBUG TRAIN Batch 16/2300 loss 5.363099 loss_att 6.016407 loss_ctc 15.342023 loss_rnnt 3.757377 hw_loss 0.271006 lr 0.00042915 rank 2
2023-02-22 06:43:07,791 DEBUG TRAIN Batch 16/2300 loss 6.058291 loss_att 8.478557 loss_ctc 7.242492 loss_rnnt 5.264897 hw_loss 0.283963 lr 0.00042907 rank 7
2023-02-22 06:43:07,795 DEBUG TRAIN Batch 16/2300 loss 7.996947 loss_att 10.567062 loss_ctc 10.642492 loss_rnnt 7.006024 hw_loss 0.232802 lr 0.00042912 rank 6
2023-02-22 06:43:07,795 DEBUG TRAIN Batch 16/2300 loss 7.259411 loss_att 10.161621 loss_ctc 8.060219 loss_rnnt 6.462904 hw_loss 0.204920 lr 0.00042918 rank 0
2023-02-22 06:43:07,842 DEBUG TRAIN Batch 16/2300 loss 19.674290 loss_att 21.166164 loss_ctc 26.320545 loss_rnnt 18.371979 hw_loss 0.220814 lr 0.00042917 rank 1
2023-02-22 06:44:20,620 DEBUG TRAIN Batch 16/2400 loss 10.017044 loss_att 13.493067 loss_ctc 12.954390 loss_rnnt 8.761786 hw_loss 0.315764 lr 0.00042901 rank 1
2023-02-22 06:44:20,628 DEBUG TRAIN Batch 16/2400 loss 16.436716 loss_att 18.185349 loss_ctc 21.068098 loss_rnnt 15.332137 hw_loss 0.257508 lr 0.00042899 rank 4
2023-02-22 06:44:20,629 DEBUG TRAIN Batch 16/2400 loss 7.771465 loss_att 11.891903 loss_ctc 12.144370 loss_rnnt 6.172100 hw_loss 0.360421 lr 0.00042891 rank 7
2023-02-22 06:44:20,628 DEBUG TRAIN Batch 16/2400 loss 15.801461 loss_att 17.174923 loss_ctc 20.484787 loss_rnnt 14.819779 hw_loss 0.154773 lr 0.00042899 rank 2
2023-02-22 06:44:20,631 DEBUG TRAIN Batch 16/2400 loss 8.072574 loss_att 10.575085 loss_ctc 10.972206 loss_rnnt 7.029581 hw_loss 0.292263 lr 0.00042892 rank 5
2023-02-22 06:44:20,633 DEBUG TRAIN Batch 16/2400 loss 9.549892 loss_att 11.550093 loss_ctc 13.943664 loss_rnnt 8.337943 hw_loss 0.423888 lr 0.00042896 rank 6
2023-02-22 06:44:20,635 DEBUG TRAIN Batch 16/2400 loss 13.792045 loss_att 16.626408 loss_ctc 17.525053 loss_rnnt 12.638432 hw_loss 0.166886 lr 0.00042898 rank 3
2023-02-22 06:44:20,635 DEBUG TRAIN Batch 16/2400 loss 7.650194 loss_att 11.747366 loss_ctc 12.077152 loss_rnnt 6.106748 hw_loss 0.250782 lr 0.00042903 rank 0
2023-02-22 06:45:36,174 DEBUG TRAIN Batch 16/2500 loss 11.195481 loss_att 15.280729 loss_ctc 14.371440 loss_rnnt 9.801843 hw_loss 0.287113 lr 0.00042880 rank 6
2023-02-22 06:45:36,177 DEBUG TRAIN Batch 16/2500 loss 5.243906 loss_att 6.556943 loss_ctc 9.126902 loss_rnnt 4.275230 hw_loss 0.353131 lr 0.00042883 rank 2
2023-02-22 06:45:36,178 DEBUG TRAIN Batch 16/2500 loss 8.021344 loss_att 8.770319 loss_ctc 11.086834 loss_rnnt 7.254045 hw_loss 0.391446 lr 0.00042883 rank 4
2023-02-22 06:45:36,177 DEBUG TRAIN Batch 16/2500 loss 22.837973 loss_att 18.844206 loss_ctc 31.830536 loss_rnnt 22.278677 hw_loss 0.298202 lr 0.00042882 rank 3
2023-02-22 06:45:36,180 DEBUG TRAIN Batch 16/2500 loss 12.878125 loss_att 14.042738 loss_ctc 14.838633 loss_rnnt 12.291377 hw_loss 0.173297 lr 0.00042887 rank 0
2023-02-22 06:45:36,183 DEBUG TRAIN Batch 16/2500 loss 7.615533 loss_att 14.503097 loss_ctc 14.049227 loss_rnnt 5.318549 hw_loss 0.115585 lr 0.00042885 rank 1
2023-02-22 06:45:36,184 DEBUG TRAIN Batch 16/2500 loss 14.643789 loss_att 14.496125 loss_ctc 20.967451 loss_rnnt 13.548932 hw_loss 0.527315 lr 0.00042875 rank 7
2023-02-22 06:45:36,184 DEBUG TRAIN Batch 16/2500 loss 4.743559 loss_att 9.699352 loss_ctc 6.547694 loss_rnnt 3.333105 hw_loss 0.335145 lr 0.00042876 rank 5
2023-02-22 06:46:48,429 DEBUG TRAIN Batch 16/2600 loss 4.223362 loss_att 5.980605 loss_ctc 3.987577 loss_rnnt 3.769105 hw_loss 0.251712 lr 0.00042868 rank 2
2023-02-22 06:46:48,432 DEBUG TRAIN Batch 16/2600 loss 14.724564 loss_att 23.006330 loss_ctc 20.973522 loss_rnnt 12.110924 hw_loss 0.232674 lr 0.00042865 rank 6
2023-02-22 06:46:48,433 DEBUG TRAIN Batch 16/2600 loss 5.892768 loss_att 7.451814 loss_ctc 7.307138 loss_rnnt 5.276450 hw_loss 0.217361 lr 0.00042867 rank 3
2023-02-22 06:46:48,435 DEBUG TRAIN Batch 16/2600 loss 12.429354 loss_att 16.207039 loss_ctc 13.874044 loss_rnnt 11.309024 hw_loss 0.322815 lr 0.00042860 rank 5
2023-02-22 06:46:48,435 DEBUG TRAIN Batch 16/2600 loss 5.303820 loss_att 10.564746 loss_ctc 6.154584 loss_rnnt 4.060238 hw_loss 0.146176 lr 0.00042870 rank 1
2023-02-22 06:46:48,437 DEBUG TRAIN Batch 16/2600 loss 8.408941 loss_att 12.645431 loss_ctc 10.903700 loss_rnnt 7.118446 hw_loss 0.207305 lr 0.00042860 rank 7
2023-02-22 06:46:48,449 DEBUG TRAIN Batch 16/2600 loss 8.779178 loss_att 13.916303 loss_ctc 13.019455 loss_rnnt 7.055503 hw_loss 0.245400 lr 0.00042871 rank 0
2023-02-22 06:46:48,470 DEBUG TRAIN Batch 16/2600 loss 11.754628 loss_att 13.841303 loss_ctc 13.764224 loss_rnnt 10.896747 hw_loss 0.323625 lr 0.00042868 rank 4
2023-02-22 06:48:00,199 DEBUG TRAIN Batch 16/2700 loss 8.285064 loss_att 11.662950 loss_ctc 10.445804 loss_rnnt 7.244804 hw_loss 0.143595 lr 0.00042855 rank 0
2023-02-22 06:48:00,219 DEBUG TRAIN Batch 16/2700 loss 17.681013 loss_att 21.503342 loss_ctc 23.983028 loss_rnnt 15.953495 hw_loss 0.230217 lr 0.00042852 rank 2
2023-02-22 06:48:00,224 DEBUG TRAIN Batch 16/2700 loss 9.630968 loss_att 15.908300 loss_ctc 12.813219 loss_rnnt 7.767856 hw_loss 0.343772 lr 0.00042851 rank 3
2023-02-22 06:48:00,224 DEBUG TRAIN Batch 16/2700 loss 9.104660 loss_att 10.692250 loss_ctc 11.154208 loss_rnnt 8.313738 hw_loss 0.375243 lr 0.00042844 rank 7
2023-02-22 06:48:00,224 DEBUG TRAIN Batch 16/2700 loss 11.278790 loss_att 12.837864 loss_ctc 13.212540 loss_rnnt 10.457980 hw_loss 0.470932 lr 0.00042854 rank 1
2023-02-22 06:48:00,227 DEBUG TRAIN Batch 16/2700 loss 14.558466 loss_att 14.836799 loss_ctc 18.429981 loss_rnnt 13.807208 hw_loss 0.336354 lr 0.00042844 rank 5
2023-02-22 06:48:00,226 DEBUG TRAIN Batch 16/2700 loss 16.104254 loss_att 18.159405 loss_ctc 20.571028 loss_rnnt 14.986753 hw_loss 0.207941 lr 0.00042852 rank 4
2023-02-22 06:48:00,226 DEBUG TRAIN Batch 16/2700 loss 8.339664 loss_att 11.714797 loss_ctc 11.298011 loss_rnnt 7.055471 hw_loss 0.402597 lr 0.00042849 rank 6
2023-02-22 06:49:13,520 DEBUG TRAIN Batch 16/2800 loss 15.377741 loss_att 18.420498 loss_ctc 20.879477 loss_rnnt 13.862722 hw_loss 0.324193 lr 0.00042829 rank 5
2023-02-22 06:49:13,521 DEBUG TRAIN Batch 16/2800 loss 8.783947 loss_att 11.419271 loss_ctc 14.932676 loss_rnnt 7.308831 hw_loss 0.240412 lr 0.00042836 rank 2
2023-02-22 06:49:13,522 DEBUG TRAIN Batch 16/2800 loss 9.051641 loss_att 13.830843 loss_ctc 16.044975 loss_rnnt 7.005178 hw_loss 0.296581 lr 0.00042840 rank 0
2023-02-22 06:49:13,522 DEBUG TRAIN Batch 16/2800 loss 10.823245 loss_att 13.063234 loss_ctc 12.981026 loss_rnnt 9.954830 hw_loss 0.248838 lr 0.00042835 rank 3
2023-02-22 06:49:13,525 DEBUG TRAIN Batch 16/2800 loss 14.220739 loss_att 17.813005 loss_ctc 22.815372 loss_rnnt 12.248198 hw_loss 0.202760 lr 0.00042833 rank 6
2023-02-22 06:49:13,540 DEBUG TRAIN Batch 16/2800 loss 9.449694 loss_att 13.994793 loss_ctc 15.403525 loss_rnnt 7.612496 hw_loss 0.251872 lr 0.00042828 rank 7
2023-02-22 06:49:13,545 DEBUG TRAIN Batch 16/2800 loss 12.142481 loss_att 14.729584 loss_ctc 19.521042 loss_rnnt 10.495366 hw_loss 0.273535 lr 0.00042838 rank 1
2023-02-22 06:49:13,548 DEBUG TRAIN Batch 16/2800 loss 10.991515 loss_att 14.898769 loss_ctc 15.669037 loss_rnnt 9.463321 hw_loss 0.230763 lr 0.00042836 rank 4
2023-02-22 06:50:27,324 DEBUG TRAIN Batch 16/2900 loss 15.143457 loss_att 16.889381 loss_ctc 18.577366 loss_rnnt 14.203246 hw_loss 0.249698 lr 0.00042817 rank 6
2023-02-22 06:50:27,328 DEBUG TRAIN Batch 16/2900 loss 7.088726 loss_att 8.727625 loss_ctc 10.847253 loss_rnnt 6.152076 hw_loss 0.202001 lr 0.00042822 rank 1
2023-02-22 06:50:27,329 DEBUG TRAIN Batch 16/2900 loss 11.971930 loss_att 13.928444 loss_ctc 13.714330 loss_rnnt 11.230183 hw_loss 0.221482 lr 0.00042813 rank 5
2023-02-22 06:50:27,329 DEBUG TRAIN Batch 16/2900 loss 6.090808 loss_att 8.716983 loss_ctc 9.180603 loss_rnnt 4.928391 hw_loss 0.422269 lr 0.00042819 rank 3
2023-02-22 06:50:27,330 DEBUG TRAIN Batch 16/2900 loss 9.062519 loss_att 12.999806 loss_ctc 11.907848 loss_rnnt 7.797216 hw_loss 0.184627 lr 0.00042824 rank 0
2023-02-22 06:50:27,331 DEBUG TRAIN Batch 16/2900 loss 7.716272 loss_att 9.372447 loss_ctc 6.853658 loss_rnnt 7.373330 hw_loss 0.237604 lr 0.00042821 rank 2
2023-02-22 06:50:27,332 DEBUG TRAIN Batch 16/2900 loss 9.376922 loss_att 12.690733 loss_ctc 12.842558 loss_rnnt 8.176018 hw_loss 0.142606 lr 0.00042813 rank 7
2023-02-22 06:50:27,338 DEBUG TRAIN Batch 16/2900 loss 7.615537 loss_att 9.895103 loss_ctc 12.408487 loss_rnnt 6.372029 hw_loss 0.278503 lr 0.00042821 rank 4
2023-02-22 06:51:40,172 DEBUG TRAIN Batch 16/3000 loss 16.434278 loss_att 19.630066 loss_ctc 25.038998 loss_rnnt 14.510741 hw_loss 0.257034 lr 0.00042805 rank 2
2023-02-22 06:51:40,176 DEBUG TRAIN Batch 16/3000 loss 9.883533 loss_att 12.593317 loss_ctc 16.204815 loss_rnnt 8.387789 hw_loss 0.208031 lr 0.00042808 rank 0
2023-02-22 06:51:40,176 DEBUG TRAIN Batch 16/3000 loss 15.420878 loss_att 20.610395 loss_ctc 25.968815 loss_rnnt 12.863361 hw_loss 0.212290 lr 0.00042802 rank 6
2023-02-22 06:51:40,177 DEBUG TRAIN Batch 16/3000 loss 24.664062 loss_att 22.357664 loss_ctc 28.210800 loss_rnnt 24.509264 hw_loss 0.268464 lr 0.00042804 rank 3
2023-02-22 06:51:40,185 DEBUG TRAIN Batch 16/3000 loss 6.625126 loss_att 9.865767 loss_ctc 8.071355 loss_rnnt 5.647655 hw_loss 0.255963 lr 0.00042797 rank 7
2023-02-22 06:51:40,188 DEBUG TRAIN Batch 16/3000 loss 10.353958 loss_att 14.209809 loss_ctc 12.509722 loss_rnnt 9.168587 hw_loss 0.237688 lr 0.00042805 rank 4
2023-02-22 06:51:40,189 DEBUG TRAIN Batch 16/3000 loss 11.524534 loss_att 14.228232 loss_ctc 16.725750 loss_rnnt 10.128219 hw_loss 0.303902 lr 0.00042797 rank 5
2023-02-22 06:51:40,190 DEBUG TRAIN Batch 16/3000 loss 9.261213 loss_att 11.049209 loss_ctc 12.815132 loss_rnnt 8.293174 hw_loss 0.256097 lr 0.00042807 rank 1
2023-02-22 06:52:52,849 DEBUG TRAIN Batch 16/3100 loss 7.331032 loss_att 12.180490 loss_ctc 9.256518 loss_rnnt 5.922474 hw_loss 0.341128 lr 0.00042789 rank 2
2023-02-22 06:52:52,852 DEBUG TRAIN Batch 16/3100 loss 11.728388 loss_att 13.711952 loss_ctc 16.021456 loss_rnnt 10.518003 hw_loss 0.452369 lr 0.00042781 rank 7
2023-02-22 06:52:52,852 DEBUG TRAIN Batch 16/3100 loss 6.894707 loss_att 9.611479 loss_ctc 9.749476 loss_rnnt 5.836200 hw_loss 0.252219 lr 0.00042789 rank 4
2023-02-22 06:52:52,854 DEBUG TRAIN Batch 16/3100 loss 11.055574 loss_att 12.624590 loss_ctc 16.132093 loss_rnnt 9.857571 hw_loss 0.388746 lr 0.00042788 rank 3
2023-02-22 06:52:52,855 DEBUG TRAIN Batch 16/3100 loss 17.830574 loss_att 18.394260 loss_ctc 21.064749 loss_rnnt 17.005796 hw_loss 0.526535 lr 0.00042786 rank 6
2023-02-22 06:52:52,858 DEBUG TRAIN Batch 16/3100 loss 5.566959 loss_att 5.880566 loss_ctc 7.112577 loss_rnnt 4.991531 hw_loss 0.574920 lr 0.00042782 rank 5
2023-02-22 06:52:52,863 DEBUG TRAIN Batch 16/3100 loss 7.254027 loss_att 8.465865 loss_ctc 9.329050 loss_rnnt 6.476139 hw_loss 0.485345 lr 0.00042791 rank 1
2023-02-22 06:52:52,903 DEBUG TRAIN Batch 16/3100 loss 16.127075 loss_att 18.376799 loss_ctc 20.435753 loss_rnnt 14.918006 hw_loss 0.346188 lr 0.00042792 rank 0
2023-02-22 06:54:08,256 DEBUG TRAIN Batch 16/3200 loss 5.325057 loss_att 8.435493 loss_ctc 5.847416 loss_rnnt 4.479892 hw_loss 0.287680 lr 0.00042777 rank 0
2023-02-22 06:54:08,269 DEBUG TRAIN Batch 16/3200 loss 9.974386 loss_att 10.350964 loss_ctc 10.612881 loss_rnnt 9.642176 hw_loss 0.322054 lr 0.00042772 rank 3
2023-02-22 06:54:08,271 DEBUG TRAIN Batch 16/3200 loss 7.031263 loss_att 11.099324 loss_ctc 9.454884 loss_rnnt 5.761078 hw_loss 0.250169 lr 0.00042773 rank 4
2023-02-22 06:54:08,274 DEBUG TRAIN Batch 16/3200 loss 9.780286 loss_att 14.473130 loss_ctc 14.968753 loss_rnnt 7.969358 hw_loss 0.338557 lr 0.00042770 rank 6
2023-02-22 06:54:08,275 DEBUG TRAIN Batch 16/3200 loss 7.431448 loss_att 8.702632 loss_ctc 8.138569 loss_rnnt 6.888736 hw_loss 0.364109 lr 0.00042773 rank 2
2023-02-22 06:54:08,279 DEBUG TRAIN Batch 16/3200 loss 14.662527 loss_att 16.877308 loss_ctc 20.157158 loss_rnnt 13.371486 hw_loss 0.216502 lr 0.00042766 rank 7
2023-02-22 06:54:08,284 DEBUG TRAIN Batch 16/3200 loss 2.975800 loss_att 5.994542 loss_ctc 5.317631 loss_rnnt 1.880159 hw_loss 0.336841 lr 0.00042775 rank 1
2023-02-22 06:54:08,318 DEBUG TRAIN Batch 16/3200 loss 9.884631 loss_att 13.925703 loss_ctc 15.866206 loss_rnnt 8.068896 hw_loss 0.393707 lr 0.00042766 rank 5
2023-02-22 06:55:20,194 DEBUG TRAIN Batch 16/3300 loss 15.902706 loss_att 19.811090 loss_ctc 19.455505 loss_rnnt 14.533888 hw_loss 0.212690 lr 0.00042758 rank 4
2023-02-22 06:55:20,196 DEBUG TRAIN Batch 16/3300 loss 5.487887 loss_att 9.863641 loss_ctc 6.541722 loss_rnnt 4.355111 hw_loss 0.219588 lr 0.00042761 rank 0
2023-02-22 06:55:20,196 DEBUG TRAIN Batch 16/3300 loss 8.325803 loss_att 11.858974 loss_ctc 11.638872 loss_rnnt 7.100356 hw_loss 0.144508 lr 0.00042758 rank 2
2023-02-22 06:55:20,199 DEBUG TRAIN Batch 16/3300 loss 7.994610 loss_att 12.747124 loss_ctc 11.142299 loss_rnnt 6.433213 hw_loss 0.358503 lr 0.00042757 rank 3
2023-02-22 06:55:20,204 DEBUG TRAIN Batch 16/3300 loss 4.869267 loss_att 8.621527 loss_ctc 7.795801 loss_rnnt 3.594035 hw_loss 0.252328 lr 0.00042755 rank 6
2023-02-22 06:55:20,207 DEBUG TRAIN Batch 16/3300 loss 6.013108 loss_att 8.615038 loss_ctc 11.376479 loss_rnnt 4.660342 hw_loss 0.219870 lr 0.00042760 rank 1
2023-02-22 06:55:20,209 DEBUG TRAIN Batch 16/3300 loss 6.183497 loss_att 11.144992 loss_ctc 12.231620 loss_rnnt 4.245509 hw_loss 0.261138 lr 0.00042750 rank 7
2023-02-22 06:55:20,210 DEBUG TRAIN Batch 16/3300 loss 17.051949 loss_att 18.887686 loss_ctc 29.407536 loss_rnnt 14.884003 hw_loss 0.287601 lr 0.00042750 rank 5
2023-02-22 06:56:33,136 DEBUG TRAIN Batch 16/3400 loss 13.717109 loss_att 16.557772 loss_ctc 20.395805 loss_rnnt 12.071237 hw_loss 0.351088 lr 0.00042735 rank 5
2023-02-22 06:56:33,138 DEBUG TRAIN Batch 16/3400 loss 9.902164 loss_att 14.313710 loss_ctc 14.780258 loss_rnnt 8.309267 hw_loss 0.112826 lr 0.00042741 rank 3
2023-02-22 06:56:33,140 DEBUG TRAIN Batch 16/3400 loss 12.404426 loss_att 14.922911 loss_ctc 18.327278 loss_rnnt 10.985747 hw_loss 0.234878 lr 0.00042742 rank 4
2023-02-22 06:56:33,140 DEBUG TRAIN Batch 16/3400 loss 6.152595 loss_att 9.027394 loss_ctc 7.074162 loss_rnnt 5.360817 hw_loss 0.176141 lr 0.00042742 rank 2
2023-02-22 06:56:33,142 DEBUG TRAIN Batch 16/3400 loss 7.662314 loss_att 9.286987 loss_ctc 11.712196 loss_rnnt 6.689338 hw_loss 0.202606 lr 0.00042739 rank 6
2023-02-22 06:56:33,143 DEBUG TRAIN Batch 16/3400 loss 23.260622 loss_att 21.386223 loss_ctc 35.727776 loss_rnnt 21.897949 hw_loss 0.141126 lr 0.00042746 rank 0
2023-02-22 06:56:33,143 DEBUG TRAIN Batch 16/3400 loss 8.680098 loss_att 14.571070 loss_ctc 17.410446 loss_rnnt 6.228002 hw_loss 0.205977 lr 0.00042744 rank 1
2023-02-22 06:56:33,146 DEBUG TRAIN Batch 16/3400 loss 13.957848 loss_att 16.040688 loss_ctc 21.676733 loss_rnnt 12.459059 hw_loss 0.099445 lr 0.00042734 rank 7
2023-02-22 06:57:46,615 DEBUG TRAIN Batch 16/3500 loss 9.476650 loss_att 12.112103 loss_ctc 12.464911 loss_rnnt 8.375194 hw_loss 0.329872 lr 0.00042727 rank 4
2023-02-22 06:57:46,618 DEBUG TRAIN Batch 16/3500 loss 4.113559 loss_att 6.944175 loss_ctc 4.887607 loss_rnnt 3.297600 hw_loss 0.274931 lr 0.00042719 rank 7
2023-02-22 06:57:46,619 DEBUG TRAIN Batch 16/3500 loss 4.248270 loss_att 6.132270 loss_ctc 6.558376 loss_rnnt 3.480633 hw_loss 0.155291 lr 0.00042728 rank 1
2023-02-22 06:57:46,625 DEBUG TRAIN Batch 16/3500 loss 8.649776 loss_att 12.870350 loss_ctc 13.662501 loss_rnnt 6.911169 hw_loss 0.423989 lr 0.00042727 rank 2
2023-02-22 06:57:46,631 DEBUG TRAIN Batch 16/3500 loss 4.090297 loss_att 5.905071 loss_ctc 5.884690 loss_rnnt 3.283473 hw_loss 0.383656 lr 0.00042723 rank 6
2023-02-22 06:57:46,633 DEBUG TRAIN Batch 16/3500 loss 19.796202 loss_att 20.727535 loss_ctc 23.087841 loss_rnnt 18.916801 hw_loss 0.476715 lr 0.00042726 rank 3
2023-02-22 06:57:46,638 DEBUG TRAIN Batch 16/3500 loss 10.526096 loss_att 12.599924 loss_ctc 15.017352 loss_rnnt 9.375928 hw_loss 0.256065 lr 0.00042719 rank 5
2023-02-22 06:57:46,649 DEBUG TRAIN Batch 16/3500 loss 21.037987 loss_att 24.018116 loss_ctc 32.503242 loss_rnnt 18.682119 hw_loss 0.433386 lr 0.00042730 rank 0
2023-02-22 06:59:00,974 DEBUG TRAIN Batch 16/3600 loss 11.407949 loss_att 15.798882 loss_ctc 17.718508 loss_rnnt 9.551464 hw_loss 0.256672 lr 0.00042714 rank 0
2023-02-22 06:59:00,978 DEBUG TRAIN Batch 16/3600 loss 14.382970 loss_att 17.440590 loss_ctc 20.520536 loss_rnnt 12.754024 hw_loss 0.373276 lr 0.00042711 rank 4
2023-02-22 06:59:00,990 DEBUG TRAIN Batch 16/3600 loss 13.243791 loss_att 15.940026 loss_ctc 15.272795 loss_rnnt 12.291660 hw_loss 0.266904 lr 0.00042711 rank 2
2023-02-22 06:59:00,991 DEBUG TRAIN Batch 16/3600 loss 5.330411 loss_att 9.550461 loss_ctc 5.908114 loss_rnnt 4.286258 hw_loss 0.230843 lr 0.00042708 rank 6
2023-02-22 06:59:00,994 DEBUG TRAIN Batch 16/3600 loss 7.398299 loss_att 11.095539 loss_ctc 13.251253 loss_rnnt 5.689837 hw_loss 0.353662 lr 0.00042710 rank 3
2023-02-22 06:59:00,996 DEBUG TRAIN Batch 16/3600 loss 9.449469 loss_att 11.273664 loss_ctc 15.255614 loss_rnnt 8.159296 hw_loss 0.283463 lr 0.00042703 rank 7
2023-02-22 06:59:01,001 DEBUG TRAIN Batch 16/3600 loss 6.675462 loss_att 9.559380 loss_ctc 10.267492 loss_rnnt 5.482102 hw_loss 0.258071 lr 0.00042704 rank 5
2023-02-22 06:59:01,052 DEBUG TRAIN Batch 16/3600 loss 16.172850 loss_att 18.612988 loss_ctc 20.086536 loss_rnnt 14.944363 hw_loss 0.409942 lr 0.00042713 rank 1
2023-02-22 07:00:14,020 DEBUG TRAIN Batch 16/3700 loss 7.020883 loss_att 10.543475 loss_ctc 13.891083 loss_rnnt 5.295661 hw_loss 0.196267 lr 0.00042695 rank 2
2023-02-22 07:00:14,021 DEBUG TRAIN Batch 16/3700 loss 14.639642 loss_att 16.000980 loss_ctc 20.456594 loss_rnnt 13.425684 hw_loss 0.311428 lr 0.00042694 rank 3
2023-02-22 07:00:14,022 DEBUG TRAIN Batch 16/3700 loss 13.306463 loss_att 15.963644 loss_ctc 20.200632 loss_rnnt 11.731493 hw_loss 0.233083 lr 0.00042699 rank 0
2023-02-22 07:00:14,022 DEBUG TRAIN Batch 16/3700 loss 14.386836 loss_att 18.320698 loss_ctc 18.225897 loss_rnnt 12.970014 hw_loss 0.221576 lr 0.00042692 rank 6
2023-02-22 07:00:14,026 DEBUG TRAIN Batch 16/3700 loss 20.571493 loss_att 21.948936 loss_ctc 33.212265 loss_rnnt 18.382948 hw_loss 0.426790 lr 0.00042688 rank 7
2023-02-22 07:00:14,026 DEBUG TRAIN Batch 16/3700 loss 11.803774 loss_att 14.865093 loss_ctc 14.193338 loss_rnnt 10.717387 hw_loss 0.291590 lr 0.00042697 rank 1
2023-02-22 07:00:14,029 DEBUG TRAIN Batch 16/3700 loss 8.621810 loss_att 11.330235 loss_ctc 13.888687 loss_rnnt 7.264060 hw_loss 0.213404 lr 0.00042695 rank 4
2023-02-22 07:00:14,041 DEBUG TRAIN Batch 16/3700 loss 8.346779 loss_att 8.582531 loss_ctc 10.740201 loss_rnnt 7.772846 hw_loss 0.389362 lr 0.00042688 rank 5
2023-02-22 07:01:26,505 DEBUG TRAIN Batch 16/3800 loss 7.438787 loss_att 7.518951 loss_ctc 11.128000 loss_rnnt 6.688419 hw_loss 0.454574 lr 0.00042679 rank 3
2023-02-22 07:01:26,505 DEBUG TRAIN Batch 16/3800 loss 11.580061 loss_att 14.463255 loss_ctc 15.043114 loss_rnnt 10.380247 hw_loss 0.302691 lr 0.00042680 rank 2
2023-02-22 07:01:26,510 DEBUG TRAIN Batch 16/3800 loss 11.043844 loss_att 11.998978 loss_ctc 14.403553 loss_rnnt 10.223363 hw_loss 0.340299 lr 0.00042680 rank 4
2023-02-22 07:01:26,511 DEBUG TRAIN Batch 16/3800 loss 6.182918 loss_att 7.323886 loss_ctc 9.503246 loss_rnnt 5.284895 hw_loss 0.425848 lr 0.00042677 rank 6
2023-02-22 07:01:26,512 DEBUG TRAIN Batch 16/3800 loss 8.235058 loss_att 9.155503 loss_ctc 8.143682 loss_rnnt 7.847466 hw_loss 0.404410 lr 0.00042683 rank 0
2023-02-22 07:01:26,512 DEBUG TRAIN Batch 16/3800 loss 7.633862 loss_att 8.944311 loss_ctc 8.089758 loss_rnnt 7.237313 hw_loss 0.138136 lr 0.00042672 rank 5
2023-02-22 07:01:26,516 DEBUG TRAIN Batch 16/3800 loss 11.797956 loss_att 12.176970 loss_ctc 14.148034 loss_rnnt 11.152642 hw_loss 0.480310 lr 0.00042672 rank 7
2023-02-22 07:01:26,517 DEBUG TRAIN Batch 16/3800 loss 12.214102 loss_att 11.834122 loss_ctc 19.080153 loss_rnnt 11.158172 hw_loss 0.405851 lr 0.00042682 rank 1
2023-02-22 07:02:41,598 DEBUG TRAIN Batch 16/3900 loss 5.607852 loss_att 8.330567 loss_ctc 6.688370 loss_rnnt 4.677701 hw_loss 0.452884 lr 0.00042663 rank 3
2023-02-22 07:02:41,599 DEBUG TRAIN Batch 16/3900 loss 11.663739 loss_att 13.952096 loss_ctc 14.192144 loss_rnnt 10.719008 hw_loss 0.281137 lr 0.00042657 rank 5
2023-02-22 07:02:41,599 DEBUG TRAIN Batch 16/3900 loss 5.595578 loss_att 6.513757 loss_ctc 6.456872 loss_rnnt 5.111124 hw_loss 0.348710 lr 0.00042664 rank 2
2023-02-22 07:02:41,599 DEBUG TRAIN Batch 16/3900 loss 16.113958 loss_att 21.280130 loss_ctc 21.212273 loss_rnnt 14.310202 hw_loss 0.170147 lr 0.00042661 rank 6
2023-02-22 07:02:41,618 DEBUG TRAIN Batch 16/3900 loss 7.421194 loss_att 8.538696 loss_ctc 10.769001 loss_rnnt 6.544785 hw_loss 0.387251 lr 0.00042656 rank 7
2023-02-22 07:02:41,626 DEBUG TRAIN Batch 16/3900 loss 5.771332 loss_att 9.186910 loss_ctc 8.400055 loss_rnnt 4.602203 hw_loss 0.254094 lr 0.00042666 rank 1
2023-02-22 07:02:41,644 DEBUG TRAIN Batch 16/3900 loss 8.937194 loss_att 12.718399 loss_ctc 14.785421 loss_rnnt 7.274908 hw_loss 0.236776 lr 0.00042664 rank 4
2023-02-22 07:02:41,653 DEBUG TRAIN Batch 16/3900 loss 8.460701 loss_att 10.021970 loss_ctc 11.745284 loss_rnnt 7.524635 hw_loss 0.348502 lr 0.00042668 rank 0
2023-02-22 07:03:54,652 DEBUG TRAIN Batch 16/4000 loss 7.854961 loss_att 11.627241 loss_ctc 9.926321 loss_rnnt 6.667058 hw_loss 0.294873 lr 0.00042649 rank 2
2023-02-22 07:03:54,653 DEBUG TRAIN Batch 16/4000 loss 6.105593 loss_att 9.101619 loss_ctc 9.141606 loss_rnnt 4.991502 hw_loss 0.206409 lr 0.00042646 rank 6
2023-02-22 07:03:54,656 DEBUG TRAIN Batch 16/4000 loss 11.796021 loss_att 14.503683 loss_ctc 16.863722 loss_rnnt 10.393541 hw_loss 0.347350 lr 0.00042651 rank 1
2023-02-22 07:03:54,658 DEBUG TRAIN Batch 16/4000 loss 14.934547 loss_att 20.364733 loss_ctc 21.850088 loss_rnnt 12.776557 hw_loss 0.281025 lr 0.00042648 rank 3
2023-02-22 07:03:54,660 DEBUG TRAIN Batch 16/4000 loss 7.069518 loss_att 10.575226 loss_ctc 8.842593 loss_rnnt 5.987129 hw_loss 0.271570 lr 0.00042652 rank 0
2023-02-22 07:03:54,662 DEBUG TRAIN Batch 16/4000 loss 8.612663 loss_att 13.811234 loss_ctc 10.310883 loss_rnnt 7.289865 hw_loss 0.106227 lr 0.00042641 rank 5
2023-02-22 07:03:54,664 DEBUG TRAIN Batch 16/4000 loss 2.979823 loss_att 6.828765 loss_ctc 3.535118 loss_rnnt 2.007021 hw_loss 0.241827 lr 0.00042649 rank 4
2023-02-22 07:03:54,705 DEBUG TRAIN Batch 16/4000 loss 5.354816 loss_att 10.437299 loss_ctc 5.493007 loss_rnnt 4.225387 hw_loss 0.177201 lr 0.00042641 rank 7
2023-02-22 07:05:07,449 DEBUG TRAIN Batch 16/4100 loss 10.888459 loss_att 13.738230 loss_ctc 17.507978 loss_rnnt 9.304124 hw_loss 0.247083 lr 0.00042625 rank 7
2023-02-22 07:05:07,457 DEBUG TRAIN Batch 16/4100 loss 8.179047 loss_att 11.169707 loss_ctc 8.024147 loss_rnnt 7.526082 hw_loss 0.141534 lr 0.00042633 rank 2
2023-02-22 07:05:07,459 DEBUG TRAIN Batch 16/4100 loss 16.106600 loss_att 19.027130 loss_ctc 21.644905 loss_rnnt 14.684803 hw_loss 0.186095 lr 0.00042632 rank 3
2023-02-22 07:05:07,461 DEBUG TRAIN Batch 16/4100 loss 10.965156 loss_att 14.176843 loss_ctc 16.490456 loss_rnnt 9.448868 hw_loss 0.257329 lr 0.00042630 rank 6
2023-02-22 07:05:07,465 DEBUG TRAIN Batch 16/4100 loss 15.729254 loss_att 19.183647 loss_ctc 22.975212 loss_rnnt 13.942192 hw_loss 0.243852 lr 0.00042635 rank 1
2023-02-22 07:05:07,466 DEBUG TRAIN Batch 16/4100 loss 15.697047 loss_att 20.757008 loss_ctc 20.776577 loss_rnnt 13.863764 hw_loss 0.270037 lr 0.00042633 rank 4
2023-02-22 07:05:07,466 DEBUG TRAIN Batch 16/4100 loss 9.891953 loss_att 12.369767 loss_ctc 15.041484 loss_rnnt 8.554562 hw_loss 0.291044 lr 0.00042626 rank 5
2023-02-22 07:05:07,512 DEBUG TRAIN Batch 16/4100 loss 6.176842 loss_att 6.657856 loss_ctc 6.245909 loss_rnnt 5.943637 hw_loss 0.239614 lr 0.00042637 rank 0
2023-02-22 07:06:20,956 DEBUG TRAIN Batch 16/4200 loss 5.810297 loss_att 8.942284 loss_ctc 7.597222 loss_rnnt 4.758541 hw_loss 0.350816 lr 0.00042621 rank 0
2023-02-22 07:06:20,956 DEBUG TRAIN Batch 16/4200 loss 3.170488 loss_att 5.338206 loss_ctc 4.404547 loss_rnnt 2.426536 hw_loss 0.273502 lr 0.00042618 rank 2
2023-02-22 07:06:20,957 DEBUG TRAIN Batch 16/4200 loss 7.998394 loss_att 11.601814 loss_ctc 10.503691 loss_rnnt 6.781168 hw_loss 0.304690 lr 0.00042617 rank 3
2023-02-22 07:06:20,957 DEBUG TRAIN Batch 16/4200 loss 8.039536 loss_att 10.539349 loss_ctc 12.782858 loss_rnnt 6.717390 hw_loss 0.355763 lr 0.00042620 rank 1
2023-02-22 07:06:20,958 DEBUG TRAIN Batch 16/4200 loss 4.418661 loss_att 5.680367 loss_ctc 4.046027 loss_rnnt 4.062989 hw_loss 0.286903 lr 0.00042610 rank 7
2023-02-22 07:06:20,958 DEBUG TRAIN Batch 16/4200 loss 6.679246 loss_att 10.462048 loss_ctc 9.127386 loss_rnnt 5.473200 hw_loss 0.230749 lr 0.00042615 rank 6
2023-02-22 07:06:20,970 DEBUG TRAIN Batch 16/4200 loss 25.454893 loss_att 26.243027 loss_ctc 28.999887 loss_rnnt 24.676813 hw_loss 0.277102 lr 0.00042618 rank 4
2023-02-22 07:06:21,013 DEBUG TRAIN Batch 16/4200 loss 7.018126 loss_att 11.506029 loss_ctc 11.327761 loss_rnnt 5.392860 hw_loss 0.286998 lr 0.00042610 rank 5
2023-02-22 07:07:36,858 DEBUG TRAIN Batch 16/4300 loss 11.432620 loss_att 12.946042 loss_ctc 13.326263 loss_rnnt 10.756617 hw_loss 0.226563 lr 0.00042595 rank 5
2023-02-22 07:07:36,868 DEBUG TRAIN Batch 16/4300 loss 6.041167 loss_att 8.224307 loss_ctc 7.083293 loss_rnnt 5.330704 hw_loss 0.252910 lr 0.00042602 rank 2
2023-02-22 07:07:36,869 DEBUG TRAIN Batch 16/4300 loss 9.997581 loss_att 14.531590 loss_ctc 13.843254 loss_rnnt 8.487652 hw_loss 0.169445 lr 0.00042602 rank 4
2023-02-22 07:07:36,871 DEBUG TRAIN Batch 16/4300 loss 9.116291 loss_att 12.551164 loss_ctc 10.400012 loss_rnnt 8.141685 hw_loss 0.218376 lr 0.00042606 rank 0
2023-02-22 07:07:36,871 DEBUG TRAIN Batch 16/4300 loss 4.581489 loss_att 7.219769 loss_ctc 6.772591 loss_rnnt 3.651279 hw_loss 0.207012 lr 0.00042599 rank 6
2023-02-22 07:07:36,874 DEBUG TRAIN Batch 16/4300 loss 9.808041 loss_att 12.538121 loss_ctc 12.175037 loss_rnnt 8.796351 hw_loss 0.281388 lr 0.00042601 rank 3
2023-02-22 07:07:36,881 DEBUG TRAIN Batch 16/4300 loss 11.402148 loss_att 15.604944 loss_ctc 13.642752 loss_rnnt 10.109490 hw_loss 0.287536 lr 0.00042594 rank 7
2023-02-22 07:07:36,921 DEBUG TRAIN Batch 16/4300 loss 12.508145 loss_att 15.887184 loss_ctc 18.311453 loss_rnnt 10.865149 hw_loss 0.362654 lr 0.00042604 rank 1
2023-02-22 07:08:50,531 DEBUG TRAIN Batch 16/4400 loss 11.341219 loss_att 9.739757 loss_ctc 13.014379 loss_rnnt 11.061577 hw_loss 0.706590 lr 0.00042587 rank 2
2023-02-22 07:08:50,531 DEBUG TRAIN Batch 16/4400 loss 13.350732 loss_att 13.143208 loss_ctc 16.542154 loss_rnnt 12.673227 hw_loss 0.550284 lr 0.00042584 rank 6
2023-02-22 07:08:50,534 DEBUG TRAIN Batch 16/4400 loss 10.533688 loss_att 12.161629 loss_ctc 14.166483 loss_rnnt 9.528331 hw_loss 0.366369 lr 0.00042589 rank 1
2023-02-22 07:08:50,535 DEBUG TRAIN Batch 16/4400 loss 13.621678 loss_att 15.967667 loss_ctc 18.032345 loss_rnnt 12.405697 hw_loss 0.297555 lr 0.00042579 rank 7
2023-02-22 07:08:50,539 DEBUG TRAIN Batch 16/4400 loss 6.094244 loss_att 8.677194 loss_ctc 6.498613 loss_rnnt 5.248976 hw_loss 0.515179 lr 0.00042579 rank 5
2023-02-22 07:08:50,541 DEBUG TRAIN Batch 16/4400 loss 7.350428 loss_att 10.081561 loss_ctc 13.774238 loss_rnnt 5.773867 hw_loss 0.325924 lr 0.00042590 rank 0
2023-02-22 07:08:50,544 DEBUG TRAIN Batch 16/4400 loss 13.422460 loss_att 12.835756 loss_ctc 15.205910 loss_rnnt 13.114039 hw_loss 0.352441 lr 0.00042586 rank 3
2023-02-22 07:08:50,589 DEBUG TRAIN Batch 16/4400 loss 11.111162 loss_att 13.063020 loss_ctc 15.779779 loss_rnnt 9.957644 hw_loss 0.263745 lr 0.00042587 rank 4
2023-02-22 07:10:03,877 DEBUG TRAIN Batch 16/4500 loss 16.644260 loss_att 14.391758 loss_ctc 21.199413 loss_rnnt 16.395731 hw_loss 0.171892 lr 0.00042571 rank 2
2023-02-22 07:10:03,882 DEBUG TRAIN Batch 16/4500 loss 11.141245 loss_att 9.632767 loss_ctc 15.373862 loss_rnnt 10.603201 hw_loss 0.516358 lr 0.00042571 rank 4
2023-02-22 07:10:03,881 DEBUG TRAIN Batch 16/4500 loss 11.743293 loss_att 18.514938 loss_ctc 17.514660 loss_rnnt 9.474787 hw_loss 0.271238 lr 0.00042570 rank 3
2023-02-22 07:10:03,882 DEBUG TRAIN Batch 16/4500 loss 14.197355 loss_att 16.454273 loss_ctc 17.316288 loss_rnnt 13.212942 hw_loss 0.219699 lr 0.00042564 rank 7
2023-02-22 07:10:03,886 DEBUG TRAIN Batch 16/4500 loss 11.529750 loss_att 15.913330 loss_ctc 14.998795 loss_rnnt 10.046415 hw_loss 0.270151 lr 0.00042568 rank 6
2023-02-22 07:10:03,886 DEBUG TRAIN Batch 16/4500 loss 12.653831 loss_att 16.826757 loss_ctc 16.540665 loss_rnnt 11.085245 hw_loss 0.404543 lr 0.00042564 rank 5
2023-02-22 07:10:03,889 DEBUG TRAIN Batch 16/4500 loss 4.332412 loss_att 6.292073 loss_ctc 7.427971 loss_rnnt 3.417674 hw_loss 0.206370 lr 0.00042575 rank 0
2023-02-22 07:10:03,893 DEBUG TRAIN Batch 16/4500 loss 8.395714 loss_att 11.468941 loss_ctc 7.933554 loss_rnnt 7.659907 hw_loss 0.342718 lr 0.00042573 rank 1
2023-02-22 07:11:18,667 DEBUG TRAIN Batch 16/4600 loss 18.114574 loss_att 20.701099 loss_ctc 26.575893 loss_rnnt 16.343971 hw_loss 0.234604 lr 0.00042559 rank 0
2023-02-22 07:11:18,674 DEBUG TRAIN Batch 16/4600 loss 11.349440 loss_att 13.154305 loss_ctc 17.614185 loss_rnnt 10.054762 hw_loss 0.184510 lr 0.00042555 rank 3
2023-02-22 07:11:18,676 DEBUG TRAIN Batch 16/4600 loss 10.296425 loss_att 16.510983 loss_ctc 13.605665 loss_rnnt 8.536754 hw_loss 0.141617 lr 0.00042556 rank 2
2023-02-22 07:11:18,677 DEBUG TRAIN Batch 16/4600 loss 4.922386 loss_att 8.433165 loss_ctc 7.735106 loss_rnnt 3.761202 hw_loss 0.157498 lr 0.00042558 rank 1
2023-02-22 07:11:18,677 DEBUG TRAIN Batch 16/4600 loss 6.163228 loss_att 7.899413 loss_ctc 6.140537 loss_rnnt 5.690145 hw_loss 0.241633 lr 0.00042553 rank 6
2023-02-22 07:11:18,678 DEBUG TRAIN Batch 16/4600 loss 15.285600 loss_att 19.361881 loss_ctc 18.938606 loss_rnnt 13.866470 hw_loss 0.219008 lr 0.00042548 rank 7
2023-02-22 07:11:18,677 DEBUG TRAIN Batch 16/4600 loss 6.531377 loss_att 9.316748 loss_ctc 8.051390 loss_rnnt 5.645518 hw_loss 0.236470 lr 0.00042549 rank 5
2023-02-22 07:11:18,727 DEBUG TRAIN Batch 16/4600 loss 10.556949 loss_att 15.648510 loss_ctc 14.479635 loss_rnnt 8.860268 hw_loss 0.291268 lr 0.00042556 rank 4
2023-02-22 07:12:32,190 DEBUG TRAIN Batch 16/4700 loss 5.941398 loss_att 10.094896 loss_ctc 9.883498 loss_rnnt 4.519721 hw_loss 0.122557 lr 0.00042541 rank 4
2023-02-22 07:12:32,191 DEBUG TRAIN Batch 16/4700 loss 8.338818 loss_att 11.425910 loss_ctc 10.511105 loss_rnnt 7.299644 hw_loss 0.247723 lr 0.00042541 rank 2
2023-02-22 07:12:32,193 DEBUG TRAIN Batch 16/4700 loss 11.537227 loss_att 10.699616 loss_ctc 12.752073 loss_rnnt 11.346826 hw_loss 0.367393 lr 0.00042542 rank 1
2023-02-22 07:12:32,195 DEBUG TRAIN Batch 16/4700 loss 7.650633 loss_att 9.331338 loss_ctc 12.007652 loss_rnnt 6.606483 hw_loss 0.238265 lr 0.00042533 rank 7
2023-02-22 07:12:32,194 DEBUG TRAIN Batch 16/4700 loss 9.063613 loss_att 12.287348 loss_ctc 12.151428 loss_rnnt 7.859847 hw_loss 0.276208 lr 0.00042540 rank 3
2023-02-22 07:12:32,197 DEBUG TRAIN Batch 16/4700 loss 12.414788 loss_att 15.974067 loss_ctc 18.436287 loss_rnnt 10.741534 hw_loss 0.297249 lr 0.00042538 rank 6
2023-02-22 07:12:32,199 DEBUG TRAIN Batch 16/4700 loss 19.885490 loss_att 23.664639 loss_ctc 25.018105 loss_rnnt 18.275852 hw_loss 0.317734 lr 0.00042533 rank 5
2023-02-22 07:12:32,200 DEBUG TRAIN Batch 16/4700 loss 7.106489 loss_att 11.951571 loss_ctc 12.136505 loss_rnnt 5.274259 hw_loss 0.361021 lr 0.00042544 rank 0
2023-02-22 07:13:44,437 DEBUG TRAIN Batch 16/4800 loss 11.886268 loss_att 16.813803 loss_ctc 17.795866 loss_rnnt 9.966575 hw_loss 0.274198 lr 0.00042525 rank 4
2023-02-22 07:13:44,443 DEBUG TRAIN Batch 16/4800 loss 8.646225 loss_att 15.084040 loss_ctc 11.168372 loss_rnnt 6.884188 hw_loss 0.259103 lr 0.00042525 rank 2
2023-02-22 07:13:44,452 DEBUG TRAIN Batch 16/4800 loss 14.826096 loss_att 18.578863 loss_ctc 21.113283 loss_rnnt 13.127803 hw_loss 0.205217 lr 0.00042518 rank 5
2023-02-22 07:13:44,453 DEBUG TRAIN Batch 16/4800 loss 15.939107 loss_att 20.758650 loss_ctc 24.355495 loss_rnnt 13.676200 hw_loss 0.331523 lr 0.00042517 rank 7
2023-02-22 07:13:44,453 DEBUG TRAIN Batch 16/4800 loss 6.047453 loss_att 8.148071 loss_ctc 4.554647 loss_rnnt 5.645759 hw_loss 0.338647 lr 0.00042522 rank 6
2023-02-22 07:13:44,455 DEBUG TRAIN Batch 16/4800 loss 9.750907 loss_att 13.910354 loss_ctc 16.308151 loss_rnnt 7.902056 hw_loss 0.267491 lr 0.00042524 rank 3
2023-02-22 07:13:44,455 DEBUG TRAIN Batch 16/4800 loss 3.912136 loss_att 6.884436 loss_ctc 6.361506 loss_rnnt 2.900782 hw_loss 0.169334 lr 0.00042527 rank 1
2023-02-22 07:13:44,456 DEBUG TRAIN Batch 16/4800 loss 12.471649 loss_att 14.651255 loss_ctc 13.552495 loss_rnnt 11.789648 hw_loss 0.191191 lr 0.00042528 rank 0
2023-02-22 07:14:56,557 DEBUG TRAIN Batch 16/4900 loss 14.820647 loss_att 15.127752 loss_ctc 17.580864 loss_rnnt 14.155868 hw_loss 0.441243 lr 0.00042503 rank 5
2023-02-22 07:14:56,558 DEBUG TRAIN Batch 16/4900 loss 14.508224 loss_att 18.170540 loss_ctc 20.873199 loss_rnnt 12.708200 hw_loss 0.410432 lr 0.00042510 rank 2
2023-02-22 07:14:56,561 DEBUG TRAIN Batch 16/4900 loss 16.824928 loss_att 20.270102 loss_ctc 23.493561 loss_rnnt 15.157594 hw_loss 0.167152 lr 0.00042512 rank 1
2023-02-22 07:14:56,564 DEBUG TRAIN Batch 16/4900 loss 14.245406 loss_att 19.817987 loss_ctc 23.313499 loss_rnnt 11.760233 hw_loss 0.302957 lr 0.00042510 rank 4
2023-02-22 07:14:56,563 DEBUG TRAIN Batch 16/4900 loss 6.475481 loss_att 11.262327 loss_ctc 7.748034 loss_rnnt 5.277518 hw_loss 0.132974 lr 0.00042509 rank 3
2023-02-22 07:14:56,564 DEBUG TRAIN Batch 16/4900 loss 5.480440 loss_att 8.296043 loss_ctc 7.365629 loss_rnnt 4.462276 hw_loss 0.381908 lr 0.00042507 rank 6
2023-02-22 07:14:56,567 DEBUG TRAIN Batch 16/4900 loss 6.799736 loss_att 9.658620 loss_ctc 7.290425 loss_rnnt 5.964181 hw_loss 0.371911 lr 0.00042502 rank 7
2023-02-22 07:14:56,611 DEBUG TRAIN Batch 16/4900 loss 10.925714 loss_att 12.663615 loss_ctc 12.680022 loss_rnnt 10.214967 hw_loss 0.242361 lr 0.00042513 rank 0
2023-02-22 07:16:12,201 DEBUG TRAIN Batch 16/5000 loss 8.739088 loss_att 10.171329 loss_ctc 9.725805 loss_rnnt 8.110403 hw_loss 0.395013 lr 0.00042493 rank 3
2023-02-22 07:16:12,205 DEBUG TRAIN Batch 16/5000 loss 12.228003 loss_att 13.503233 loss_ctc 16.407888 loss_rnnt 11.282595 hw_loss 0.249454 lr 0.00042495 rank 2
2023-02-22 07:16:12,206 DEBUG TRAIN Batch 16/5000 loss 11.362646 loss_att 10.333968 loss_ctc 15.190166 loss_rnnt 10.927470 hw_loss 0.244830 lr 0.00042487 rank 5
2023-02-22 07:16:12,207 DEBUG TRAIN Batch 16/5000 loss 10.879486 loss_att 14.834530 loss_ctc 16.732550 loss_rnnt 9.175220 hw_loss 0.249092 lr 0.00042487 rank 7
2023-02-22 07:16:12,207 DEBUG TRAIN Batch 16/5000 loss 7.183105 loss_att 7.849154 loss_ctc 8.838022 loss_rnnt 6.589647 hw_loss 0.449238 lr 0.00042496 rank 1
2023-02-22 07:16:12,208 DEBUG TRAIN Batch 16/5000 loss 16.178455 loss_att 18.872051 loss_ctc 18.532530 loss_rnnt 15.132845 hw_loss 0.361899 lr 0.00042495 rank 4
2023-02-22 07:16:12,209 DEBUG TRAIN Batch 16/5000 loss 12.225513 loss_att 13.800859 loss_ctc 15.348105 loss_rnnt 11.415648 hw_loss 0.147094 lr 0.00042498 rank 0
2023-02-22 07:16:12,209 DEBUG TRAIN Batch 16/5000 loss 15.831970 loss_att 16.285103 loss_ctc 19.745962 loss_rnnt 15.094768 hw_loss 0.233833 lr 0.00042491 rank 6
2023-02-22 07:17:24,772 DEBUG TRAIN Batch 16/5100 loss 8.709830 loss_att 15.611240 loss_ctc 9.336412 loss_rnnt 7.161899 hw_loss 0.157697 lr 0.00042479 rank 2
2023-02-22 07:17:24,773 DEBUG TRAIN Batch 16/5100 loss 7.198278 loss_att 12.329719 loss_ctc 9.477287 loss_rnnt 5.690690 hw_loss 0.332686 lr 0.00042478 rank 3
2023-02-22 07:17:24,775 DEBUG TRAIN Batch 16/5100 loss 7.558122 loss_att 9.351025 loss_ctc 9.855274 loss_rnnt 6.658670 hw_loss 0.439845 lr 0.00042472 rank 5
2023-02-22 07:17:24,777 DEBUG TRAIN Batch 16/5100 loss 9.536605 loss_att 13.422208 loss_ctc 11.925924 loss_rnnt 8.281461 hw_loss 0.298962 lr 0.00042471 rank 7
2023-02-22 07:17:24,777 DEBUG TRAIN Batch 16/5100 loss 5.948253 loss_att 10.015402 loss_ctc 5.004413 loss_rnnt 5.139926 hw_loss 0.226392 lr 0.00042481 rank 1
2023-02-22 07:17:24,777 DEBUG TRAIN Batch 16/5100 loss 2.779341 loss_att 4.964622 loss_ctc 4.262995 loss_rnnt 2.039634 hw_loss 0.196557 lr 0.00042476 rank 6
2023-02-22 07:17:24,779 DEBUG TRAIN Batch 16/5100 loss 13.245984 loss_att 14.971714 loss_ctc 16.624916 loss_rnnt 12.280183 hw_loss 0.318993 lr 0.00042479 rank 4
2023-02-22 07:17:24,779 DEBUG TRAIN Batch 16/5100 loss 12.986072 loss_att 15.012657 loss_ctc 18.012045 loss_rnnt 11.712203 hw_loss 0.372039 lr 0.00042482 rank 0
2023-02-22 07:18:36,688 DEBUG TRAIN Batch 16/5200 loss 7.189908 loss_att 10.792177 loss_ctc 9.102309 loss_rnnt 6.122339 hw_loss 0.172741 lr 0.00042466 rank 1
2023-02-22 07:18:36,689 DEBUG TRAIN Batch 16/5200 loss 8.333520 loss_att 13.739403 loss_ctc 13.781413 loss_rnnt 6.348767 hw_loss 0.332233 lr 0.00042463 rank 3
2023-02-22 07:18:36,689 DEBUG TRAIN Batch 16/5200 loss 13.927125 loss_att 16.856384 loss_ctc 17.903290 loss_rnnt 12.589179 hw_loss 0.416136 lr 0.00042464 rank 4
2023-02-22 07:18:36,690 DEBUG TRAIN Batch 16/5200 loss 6.519063 loss_att 8.891038 loss_ctc 6.095379 loss_rnnt 5.963922 hw_loss 0.257319 lr 0.00042464 rank 2
2023-02-22 07:18:36,693 DEBUG TRAIN Batch 16/5200 loss 2.868475 loss_att 5.404787 loss_ctc 3.147329 loss_rnnt 2.089627 hw_loss 0.439511 lr 0.00042461 rank 6
2023-02-22 07:18:36,693 DEBUG TRAIN Batch 16/5200 loss 17.376883 loss_att 26.143393 loss_ctc 23.645819 loss_rnnt 14.714633 hw_loss 0.137044 lr 0.00042467 rank 0
2023-02-22 07:18:36,696 DEBUG TRAIN Batch 16/5200 loss 17.264734 loss_att 19.397156 loss_ctc 19.487722 loss_rnnt 16.503014 hw_loss 0.072816 lr 0.00042456 rank 7
2023-02-22 07:18:36,702 DEBUG TRAIN Batch 16/5200 loss 10.760880 loss_att 12.193723 loss_ctc 18.800898 loss_rnnt 9.362613 hw_loss 0.074433 lr 0.00042457 rank 5
2023-02-22 07:19:50,937 DEBUG TRAIN Batch 16/5300 loss 9.549181 loss_att 14.124249 loss_ctc 13.099205 loss_rnnt 8.024867 hw_loss 0.254934 lr 0.00042449 rank 2
2023-02-22 07:19:50,943 DEBUG TRAIN Batch 16/5300 loss 4.912074 loss_att 8.223445 loss_ctc 7.528480 loss_rnnt 3.789926 hw_loss 0.208162 lr 0.00042447 rank 3
2023-02-22 07:19:50,954 DEBUG TRAIN Batch 16/5300 loss 20.507532 loss_att 22.189484 loss_ctc 24.095411 loss_rnnt 19.577972 hw_loss 0.215219 lr 0.00042449 rank 4
2023-02-22 07:19:50,956 DEBUG TRAIN Batch 16/5300 loss 8.926303 loss_att 8.290926 loss_ctc 10.455452 loss_rnnt 8.694578 hw_loss 0.290464 lr 0.00042441 rank 7
2023-02-22 07:19:50,956 DEBUG TRAIN Batch 16/5300 loss 9.091453 loss_att 12.100563 loss_ctc 10.905102 loss_rnnt 8.134069 hw_loss 0.213263 lr 0.00042450 rank 1
2023-02-22 07:19:50,959 DEBUG TRAIN Batch 16/5300 loss 7.259240 loss_att 10.020090 loss_ctc 9.056334 loss_rnnt 6.379263 hw_loss 0.165364 lr 0.00042441 rank 5
2023-02-22 07:19:50,962 DEBUG TRAIN Batch 16/5300 loss 5.918943 loss_att 8.961419 loss_ctc 8.525234 loss_rnnt 4.820499 hw_loss 0.267082 lr 0.00042445 rank 6
2023-02-22 07:19:51,003 DEBUG TRAIN Batch 16/5300 loss 7.807282 loss_att 11.268812 loss_ctc 10.867455 loss_rnnt 6.611188 hw_loss 0.179559 lr 0.00042452 rank 0
2023-02-22 07:21:04,678 DEBUG TRAIN Batch 16/5400 loss 13.357066 loss_att 16.985058 loss_ctc 18.546997 loss_rnnt 11.806665 hw_loss 0.249019 lr 0.00042425 rank 7
2023-02-22 07:21:04,691 DEBUG TRAIN Batch 16/5400 loss 13.070824 loss_att 14.772327 loss_ctc 16.539724 loss_rnnt 12.131836 hw_loss 0.255312 lr 0.00042433 rank 2
2023-02-22 07:21:04,691 DEBUG TRAIN Batch 16/5400 loss 12.898995 loss_att 15.015030 loss_ctc 17.094906 loss_rnnt 11.849741 hw_loss 0.124861 lr 0.00042435 rank 1
2023-02-22 07:21:04,695 DEBUG TRAIN Batch 16/5400 loss 9.415566 loss_att 10.763668 loss_ctc 12.455385 loss_rnnt 8.615952 hw_loss 0.233785 lr 0.00042432 rank 3
2023-02-22 07:21:04,698 DEBUG TRAIN Batch 16/5400 loss 5.835127 loss_att 9.521792 loss_ctc 8.009451 loss_rnnt 4.628014 hw_loss 0.337256 lr 0.00042436 rank 0
2023-02-22 07:21:04,699 DEBUG TRAIN Batch 16/5400 loss 9.514179 loss_att 13.323304 loss_ctc 16.507946 loss_rnnt 7.718471 hw_loss 0.190091 lr 0.00042430 rank 6
2023-02-22 07:21:04,699 DEBUG TRAIN Batch 16/5400 loss 15.852117 loss_att 19.210424 loss_ctc 20.064808 loss_rnnt 14.527838 hw_loss 0.170486 lr 0.00042426 rank 5
2023-02-22 07:21:04,747 DEBUG TRAIN Batch 16/5400 loss 7.723518 loss_att 8.740149 loss_ctc 7.538718 loss_rnnt 7.384673 hw_loss 0.300299 lr 0.00042433 rank 4
2023-02-22 07:22:16,640 DEBUG TRAIN Batch 16/5500 loss 13.911049 loss_att 16.560097 loss_ctc 16.265827 loss_rnnt 12.917434 hw_loss 0.280940 lr 0.00042418 rank 2
2023-02-22 07:22:16,648 DEBUG TRAIN Batch 16/5500 loss 11.438467 loss_att 13.601188 loss_ctc 15.887881 loss_rnnt 10.221615 hw_loss 0.358223 lr 0.00042418 rank 4
2023-02-22 07:22:16,651 DEBUG TRAIN Batch 16/5500 loss 11.846155 loss_att 12.541456 loss_ctc 12.235879 loss_rnnt 11.487129 hw_loss 0.315004 lr 0.00042411 rank 5
2023-02-22 07:22:16,655 DEBUG TRAIN Batch 16/5500 loss 8.400599 loss_att 12.945978 loss_ctc 13.300030 loss_rnnt 6.732181 hw_loss 0.198911 lr 0.00042417 rank 3
2023-02-22 07:22:16,657 DEBUG TRAIN Batch 16/5500 loss 13.524486 loss_att 13.510390 loss_ctc 16.656693 loss_rnnt 12.981731 hw_loss 0.239897 lr 0.00042420 rank 1
2023-02-22 07:22:16,658 DEBUG TRAIN Batch 16/5500 loss 12.486942 loss_att 14.864379 loss_ctc 19.561867 loss_rnnt 10.872916 hw_loss 0.366030 lr 0.00042410 rank 7
2023-02-22 07:22:16,658 DEBUG TRAIN Batch 16/5500 loss 10.249552 loss_att 10.728762 loss_ctc 11.842815 loss_rnnt 9.809763 hw_loss 0.246584 lr 0.00042415 rank 6
2023-02-22 07:22:16,661 DEBUG TRAIN Batch 16/5500 loss 8.156506 loss_att 12.490630 loss_ctc 11.542366 loss_rnnt 6.703795 hw_loss 0.252070 lr 0.00042421 rank 0
2023-02-22 07:23:28,744 DEBUG TRAIN Batch 16/5600 loss 13.194742 loss_att 14.268868 loss_ctc 17.569397 loss_rnnt 12.277675 hw_loss 0.223041 lr 0.00042395 rank 5
2023-02-22 07:23:28,744 DEBUG TRAIN Batch 16/5600 loss 11.202676 loss_att 12.079093 loss_ctc 14.239405 loss_rnnt 10.403984 hw_loss 0.409707 lr 0.00042403 rank 2
2023-02-22 07:23:28,745 DEBUG TRAIN Batch 16/5600 loss 15.241667 loss_att 18.550543 loss_ctc 21.119873 loss_rnnt 13.613150 hw_loss 0.343092 lr 0.00042403 rank 4
2023-02-22 07:23:28,746 DEBUG TRAIN Batch 16/5600 loss 23.585941 loss_att 24.916866 loss_ctc 28.288919 loss_rnnt 22.530638 hw_loss 0.303856 lr 0.00042402 rank 3
2023-02-22 07:23:28,749 DEBUG TRAIN Batch 16/5600 loss 12.842905 loss_att 15.560198 loss_ctc 21.508978 loss_rnnt 10.975119 hw_loss 0.316596 lr 0.00042400 rank 6
2023-02-22 07:23:28,750 DEBUG TRAIN Batch 16/5600 loss 12.446872 loss_att 13.395533 loss_ctc 15.359815 loss_rnnt 11.727201 hw_loss 0.265401 lr 0.00042395 rank 7
2023-02-22 07:23:28,756 DEBUG TRAIN Batch 16/5600 loss 10.702550 loss_att 16.606609 loss_ctc 14.222654 loss_rnnt 8.861236 hw_loss 0.358417 lr 0.00042406 rank 0
2023-02-22 07:23:28,759 DEBUG TRAIN Batch 16/5600 loss 11.526827 loss_att 12.518488 loss_ctc 17.295507 loss_rnnt 10.370202 hw_loss 0.354627 lr 0.00042405 rank 1
2023-02-22 07:24:44,024 DEBUG TRAIN Batch 16/5700 loss 13.036166 loss_att 16.025274 loss_ctc 18.313078 loss_rnnt 11.564082 hw_loss 0.320014 lr 0.00042387 rank 4
2023-02-22 07:24:44,037 DEBUG TRAIN Batch 16/5700 loss 11.764336 loss_att 16.007282 loss_ctc 20.753029 loss_rnnt 9.603552 hw_loss 0.213192 lr 0.00042387 rank 2
2023-02-22 07:24:44,039 DEBUG TRAIN Batch 16/5700 loss 4.998182 loss_att 7.472854 loss_ctc 5.508745 loss_rnnt 4.291733 hw_loss 0.268949 lr 0.00042386 rank 3
2023-02-22 07:24:44,039 DEBUG TRAIN Batch 16/5700 loss 12.227576 loss_att 11.264372 loss_ctc 16.235168 loss_rnnt 11.522172 hw_loss 0.681934 lr 0.00042384 rank 6
2023-02-22 07:24:44,040 DEBUG TRAIN Batch 16/5700 loss 9.286435 loss_att 10.488193 loss_ctc 11.992179 loss_rnnt 8.516569 hw_loss 0.316402 lr 0.00042391 rank 0
2023-02-22 07:24:44,044 DEBUG TRAIN Batch 16/5700 loss 11.847428 loss_att 10.545354 loss_ctc 14.126259 loss_rnnt 11.535083 hw_loss 0.504217 lr 0.00042380 rank 5
2023-02-22 07:24:44,044 DEBUG TRAIN Batch 16/5700 loss 18.880451 loss_att 23.038822 loss_ctc 31.050369 loss_rnnt 16.280342 hw_loss 0.273339 lr 0.00042389 rank 1
2023-02-22 07:24:44,105 DEBUG TRAIN Batch 16/5700 loss 6.931873 loss_att 9.403551 loss_ctc 5.758692 loss_rnnt 6.516531 hw_loss 0.145184 lr 0.00042380 rank 7
2023-02-22 07:25:56,556 DEBUG TRAIN Batch 16/5800 loss 14.830721 loss_att 14.902636 loss_ctc 20.151289 loss_rnnt 13.929057 hw_loss 0.333510 lr 0.00042372 rank 2
2023-02-22 07:25:56,561 DEBUG TRAIN Batch 16/5800 loss 17.455158 loss_att 23.230810 loss_ctc 25.159737 loss_rnnt 15.084037 hw_loss 0.353838 lr 0.00042369 rank 6
2023-02-22 07:25:56,562 DEBUG TRAIN Batch 16/5800 loss 9.079622 loss_att 11.463674 loss_ctc 8.468244 loss_rnnt 8.477231 hw_loss 0.388308 lr 0.00042371 rank 3
2023-02-22 07:25:56,564 DEBUG TRAIN Batch 16/5800 loss 7.365001 loss_att 10.093129 loss_ctc 11.525490 loss_rnnt 6.129445 hw_loss 0.253498 lr 0.00042374 rank 1
2023-02-22 07:25:56,567 DEBUG TRAIN Batch 16/5800 loss 11.644949 loss_att 13.776518 loss_ctc 14.933182 loss_rnnt 10.659007 hw_loss 0.227244 lr 0.00042372 rank 4
2023-02-22 07:25:56,569 DEBUG TRAIN Batch 16/5800 loss 8.875783 loss_att 11.863008 loss_ctc 11.784014 loss_rnnt 7.814017 hw_loss 0.143545 lr 0.00042365 rank 5
2023-02-22 07:25:56,574 DEBUG TRAIN Batch 16/5800 loss 11.722873 loss_att 11.311625 loss_ctc 14.019535 loss_rnnt 11.296517 hw_loss 0.379468 lr 0.00042375 rank 0
2023-02-22 07:25:56,611 DEBUG TRAIN Batch 16/5800 loss 7.507617 loss_att 11.516318 loss_ctc 13.192546 loss_rnnt 5.727467 hw_loss 0.413286 lr 0.00042365 rank 7
2023-02-22 07:27:09,240 DEBUG TRAIN Batch 16/5900 loss 8.282622 loss_att 11.140627 loss_ctc 8.715151 loss_rnnt 7.502104 hw_loss 0.283587 lr 0.00042357 rank 4
2023-02-22 07:27:09,242 DEBUG TRAIN Batch 16/5900 loss 16.892952 loss_att 19.773088 loss_ctc 26.204155 loss_rnnt 14.904834 hw_loss 0.319873 lr 0.00042356 rank 3
2023-02-22 07:27:09,246 DEBUG TRAIN Batch 16/5900 loss 6.533628 loss_att 8.880981 loss_ctc 10.886368 loss_rnnt 5.328383 hw_loss 0.291392 lr 0.00042360 rank 0
2023-02-22 07:27:09,247 DEBUG TRAIN Batch 16/5900 loss 8.748066 loss_att 11.757235 loss_ctc 9.531295 loss_rnnt 7.921157 hw_loss 0.226210 lr 0.00042350 rank 5
2023-02-22 07:27:09,250 DEBUG TRAIN Batch 16/5900 loss 28.085972 loss_att 29.729382 loss_ctc 30.523182 loss_rnnt 27.320871 hw_loss 0.208980 lr 0.00042357 rank 2
2023-02-22 07:27:09,252 DEBUG TRAIN Batch 16/5900 loss 5.776962 loss_att 8.639763 loss_ctc 9.782765 loss_rnnt 4.555757 hw_loss 0.214759 lr 0.00042354 rank 6
2023-02-22 07:27:09,252 DEBUG TRAIN Batch 16/5900 loss 8.489676 loss_att 11.091070 loss_ctc 11.107304 loss_rnnt 7.513275 hw_loss 0.200821 lr 0.00042359 rank 1
2023-02-22 07:27:09,298 DEBUG TRAIN Batch 16/5900 loss 9.282499 loss_att 13.477829 loss_ctc 14.145248 loss_rnnt 7.652314 hw_loss 0.267659 lr 0.00042349 rank 7
2023-02-22 07:28:22,896 DEBUG TRAIN Batch 16/6000 loss 12.975199 loss_att 18.262537 loss_ctc 19.200335 loss_rnnt 11.002348 hw_loss 0.160061 lr 0.00042342 rank 2
2023-02-22 07:28:22,896 DEBUG TRAIN Batch 16/6000 loss 4.335447 loss_att 9.905207 loss_ctc 6.379138 loss_rnnt 2.786036 hw_loss 0.305564 lr 0.00042342 rank 4
2023-02-22 07:28:22,898 DEBUG TRAIN Batch 16/6000 loss 9.119810 loss_att 12.447979 loss_ctc 11.613953 loss_rnnt 8.058432 hw_loss 0.118485 lr 0.00042334 rank 7
2023-02-22 07:28:22,899 DEBUG TRAIN Batch 16/6000 loss 10.244827 loss_att 10.995249 loss_ctc 11.222166 loss_rnnt 9.834036 hw_loss 0.244491 lr 0.00042341 rank 3
2023-02-22 07:28:22,900 DEBUG TRAIN Batch 16/6000 loss 3.200882 loss_att 5.777349 loss_ctc 6.011355 loss_rnnt 2.193355 hw_loss 0.220320 lr 0.00042339 rank 6
2023-02-22 07:28:22,899 DEBUG TRAIN Batch 16/6000 loss 14.826311 loss_att 18.501911 loss_ctc 20.539785 loss_rnnt 13.183504 hw_loss 0.273543 lr 0.00042344 rank 1
2023-02-22 07:28:22,900 DEBUG TRAIN Batch 16/6000 loss 7.869215 loss_att 14.490093 loss_ctc 14.613283 loss_rnnt 5.470164 hw_loss 0.329374 lr 0.00042345 rank 0
2023-02-22 07:28:22,927 DEBUG TRAIN Batch 16/6000 loss 4.636500 loss_att 8.603504 loss_ctc 6.086953 loss_rnnt 3.492925 hw_loss 0.293964 lr 0.00042335 rank 5
2023-02-22 07:29:36,084 DEBUG TRAIN Batch 16/6100 loss 10.920930 loss_att 13.562744 loss_ctc 12.646097 loss_rnnt 10.049948 hw_loss 0.211119 lr 0.00042326 rank 3
2023-02-22 07:29:36,088 DEBUG TRAIN Batch 16/6100 loss 7.823982 loss_att 9.839935 loss_ctc 12.820845 loss_rnnt 6.628795 hw_loss 0.235779 lr 0.00042324 rank 6
2023-02-22 07:29:36,087 DEBUG TRAIN Batch 16/6100 loss 9.478192 loss_att 12.048530 loss_ctc 12.624475 loss_rnnt 8.419025 hw_loss 0.235491 lr 0.00042327 rank 2
2023-02-22 07:29:36,088 DEBUG TRAIN Batch 16/6100 loss 12.935394 loss_att 15.163700 loss_ctc 16.849676 loss_rnnt 11.912438 hw_loss 0.103856 lr 0.00042329 rank 1
2023-02-22 07:29:36,092 DEBUG TRAIN Batch 16/6100 loss 3.332735 loss_att 8.047691 loss_ctc 5.004102 loss_rnnt 2.042704 hw_loss 0.232858 lr 0.00042330 rank 0
2023-02-22 07:29:36,092 DEBUG TRAIN Batch 16/6100 loss 6.287799 loss_att 9.339274 loss_ctc 8.006898 loss_rnnt 5.249062 hw_loss 0.373555 lr 0.00042319 rank 5
2023-02-22 07:29:36,103 DEBUG TRAIN Batch 16/6100 loss 21.026249 loss_att 22.973782 loss_ctc 27.510344 loss_rnnt 19.586975 hw_loss 0.347290 lr 0.00042327 rank 4
2023-02-22 07:29:36,136 DEBUG TRAIN Batch 16/6100 loss 5.709466 loss_att 8.622220 loss_ctc 9.046926 loss_rnnt 4.587911 hw_loss 0.176268 lr 0.00042319 rank 7
2023-02-22 07:30:49,075 DEBUG TRAIN Batch 16/6200 loss 8.518429 loss_att 8.769636 loss_ctc 10.107959 loss_rnnt 8.123605 hw_loss 0.248710 lr 0.00042312 rank 2
2023-02-22 07:30:49,077 DEBUG TRAIN Batch 16/6200 loss 13.525144 loss_att 17.429455 loss_ctc 18.055624 loss_rnnt 11.894986 hw_loss 0.459809 lr 0.00042309 rank 6
2023-02-22 07:30:49,082 DEBUG TRAIN Batch 16/6200 loss 6.954041 loss_att 9.183459 loss_ctc 7.940948 loss_rnnt 6.226234 hw_loss 0.281882 lr 0.00042310 rank 3
2023-02-22 07:30:49,086 DEBUG TRAIN Batch 16/6200 loss 7.727566 loss_att 11.120235 loss_ctc 10.542346 loss_rnnt 6.452365 hw_loss 0.415056 lr 0.00042313 rank 1
2023-02-22 07:30:49,087 DEBUG TRAIN Batch 16/6200 loss 8.552746 loss_att 10.388471 loss_ctc 10.529613 loss_rnnt 7.682117 hw_loss 0.449815 lr 0.00042304 rank 5
2023-02-22 07:30:49,087 DEBUG TRAIN Batch 16/6200 loss 13.818520 loss_att 15.686548 loss_ctc 17.744757 loss_rnnt 12.841175 hw_loss 0.150449 lr 0.00042315 rank 0
2023-02-22 07:30:49,087 DEBUG TRAIN Batch 16/6200 loss 26.676239 loss_att 27.581726 loss_ctc 32.680313 loss_rnnt 25.453083 hw_loss 0.452839 lr 0.00042312 rank 4
2023-02-22 07:30:49,090 DEBUG TRAIN Batch 16/6200 loss 5.072402 loss_att 9.623908 loss_ctc 7.534960 loss_rnnt 3.650342 hw_loss 0.343908 lr 0.00042304 rank 7
2023-02-22 07:32:01,972 DEBUG TRAIN Batch 16/6300 loss 13.358961 loss_att 19.091841 loss_ctc 17.305279 loss_rnnt 11.603886 hw_loss 0.154356 lr 0.00042296 rank 4
2023-02-22 07:32:01,986 DEBUG TRAIN Batch 16/6300 loss 10.437634 loss_att 10.599473 loss_ctc 13.780050 loss_rnnt 9.800147 hw_loss 0.298996 lr 0.00042293 rank 6
2023-02-22 07:32:01,988 DEBUG TRAIN Batch 16/6300 loss 6.861074 loss_att 10.846910 loss_ctc 9.305094 loss_rnnt 5.661596 hw_loss 0.143329 lr 0.00042296 rank 2
2023-02-22 07:32:01,989 DEBUG TRAIN Batch 16/6300 loss 13.656102 loss_att 13.884062 loss_ctc 19.286743 loss_rnnt 12.735091 hw_loss 0.233749 lr 0.00042295 rank 3
2023-02-22 07:32:01,990 DEBUG TRAIN Batch 16/6300 loss 8.254837 loss_att 10.261852 loss_ctc 10.797685 loss_rnnt 7.368433 hw_loss 0.273665 lr 0.00042298 rank 1
2023-02-22 07:32:01,990 DEBUG TRAIN Batch 16/6300 loss 13.458157 loss_att 13.448479 loss_ctc 18.537937 loss_rnnt 12.588558 hw_loss 0.364181 lr 0.00042289 rank 7
2023-02-22 07:32:01,992 DEBUG TRAIN Batch 16/6300 loss 11.987720 loss_att 15.709313 loss_ctc 18.455082 loss_rnnt 10.220560 hw_loss 0.300988 lr 0.00042300 rank 0
2023-02-22 07:32:02,043 DEBUG TRAIN Batch 16/6300 loss 6.769093 loss_att 7.506557 loss_ctc 9.407094 loss_rnnt 6.095937 hw_loss 0.326118 lr 0.00042289 rank 5
2023-02-22 07:33:16,893 DEBUG TRAIN Batch 16/6400 loss 3.925920 loss_att 6.475798 loss_ctc 4.061066 loss_rnnt 3.142539 hw_loss 0.478849 lr 0.00042281 rank 2
2023-02-22 07:33:16,896 DEBUG TRAIN Batch 16/6400 loss 25.696634 loss_att 26.589643 loss_ctc 32.560905 loss_rnnt 24.417517 hw_loss 0.347400 lr 0.00042280 rank 3
2023-02-22 07:33:16,896 DEBUG TRAIN Batch 16/6400 loss 9.312950 loss_att 12.019778 loss_ctc 12.952059 loss_rnnt 8.128424 hw_loss 0.296150 lr 0.00042284 rank 0
2023-02-22 07:33:16,899 DEBUG TRAIN Batch 16/6400 loss 10.353545 loss_att 10.665560 loss_ctc 13.263798 loss_rnnt 9.719693 hw_loss 0.343903 lr 0.00042281 rank 4
2023-02-22 07:33:16,900 DEBUG TRAIN Batch 16/6400 loss 9.280042 loss_att 12.031311 loss_ctc 10.770609 loss_rnnt 8.438341 hw_loss 0.173818 lr 0.00042274 rank 5
2023-02-22 07:33:16,901 DEBUG TRAIN Batch 16/6400 loss 4.226978 loss_att 8.992250 loss_ctc 9.441755 loss_rnnt 2.508013 hw_loss 0.132388 lr 0.00042278 rank 6
2023-02-22 07:33:16,901 DEBUG TRAIN Batch 16/6400 loss 7.498703 loss_att 11.966209 loss_ctc 12.043335 loss_rnnt 5.768085 hw_loss 0.433437 lr 0.00042283 rank 1
2023-02-22 07:33:16,907 DEBUG TRAIN Batch 16/6400 loss 7.920117 loss_att 12.073434 loss_ctc 13.390441 loss_rnnt 6.230605 hw_loss 0.242761 lr 0.00042274 rank 7
2023-02-22 07:34:29,139 DEBUG TRAIN Batch 16/6500 loss 6.505919 loss_att 11.687025 loss_ctc 10.613370 loss_rnnt 4.804390 hw_loss 0.220590 lr 0.00042266 rank 2
2023-02-22 07:34:29,141 DEBUG TRAIN Batch 16/6500 loss 6.271251 loss_att 8.829254 loss_ctc 11.623976 loss_rnnt 4.894517 hw_loss 0.283943 lr 0.00042268 rank 1
2023-02-22 07:34:29,143 DEBUG TRAIN Batch 16/6500 loss 10.768132 loss_att 11.945312 loss_ctc 11.180687 loss_rnnt 10.334962 hw_loss 0.267612 lr 0.00042259 rank 5
2023-02-22 07:34:29,144 DEBUG TRAIN Batch 16/6500 loss 18.159880 loss_att 18.396860 loss_ctc 22.966742 loss_rnnt 17.328796 hw_loss 0.267695 lr 0.00042258 rank 7
2023-02-22 07:34:29,148 DEBUG TRAIN Batch 16/6500 loss 9.105943 loss_att 11.267448 loss_ctc 8.346665 loss_rnnt 8.631391 hw_loss 0.269038 lr 0.00042266 rank 4
2023-02-22 07:34:29,148 DEBUG TRAIN Batch 16/6500 loss 14.618959 loss_att 16.704777 loss_ctc 23.943848 loss_rnnt 12.784628 hw_loss 0.325971 lr 0.00042265 rank 3
2023-02-22 07:34:29,149 DEBUG TRAIN Batch 16/6500 loss 7.804143 loss_att 11.398853 loss_ctc 9.991999 loss_rnnt 6.664421 hw_loss 0.242000 lr 0.00042263 rank 6
2023-02-22 07:34:29,191 DEBUG TRAIN Batch 16/6500 loss 7.808826 loss_att 13.654959 loss_ctc 13.872557 loss_rnnt 5.691838 hw_loss 0.261119 lr 0.00042269 rank 0
2023-02-22 07:35:41,606 DEBUG TRAIN Batch 16/6600 loss 11.929605 loss_att 18.619534 loss_ctc 17.961920 loss_rnnt 9.648039 hw_loss 0.261135 lr 0.00042254 rank 0
2023-02-22 07:35:41,610 DEBUG TRAIN Batch 16/6600 loss 7.218138 loss_att 10.086395 loss_ctc 11.466863 loss_rnnt 5.917108 hw_loss 0.301653 lr 0.00042253 rank 1
2023-02-22 07:35:41,609 DEBUG TRAIN Batch 16/6600 loss 8.644186 loss_att 13.306510 loss_ctc 9.688609 loss_rnnt 7.370143 hw_loss 0.379352 lr 0.00042251 rank 4
2023-02-22 07:35:41,611 DEBUG TRAIN Batch 16/6600 loss 11.756818 loss_att 13.408428 loss_ctc 16.590326 loss_rnnt 10.668953 hw_loss 0.212015 lr 0.00042243 rank 7
2023-02-22 07:35:41,611 DEBUG TRAIN Batch 16/6600 loss 5.958292 loss_att 7.378687 loss_ctc 8.703145 loss_rnnt 5.207040 hw_loss 0.189736 lr 0.00042248 rank 6
2023-02-22 07:35:41,613 DEBUG TRAIN Batch 16/6600 loss 14.790982 loss_att 20.400690 loss_ctc 20.714325 loss_rnnt 12.678692 hw_loss 0.376068 lr 0.00042251 rank 2
2023-02-22 07:35:41,614 DEBUG TRAIN Batch 16/6600 loss 10.148323 loss_att 13.967805 loss_ctc 15.883043 loss_rnnt 8.549107 hw_loss 0.132545 lr 0.00042250 rank 3
2023-02-22 07:35:41,617 DEBUG TRAIN Batch 16/6600 loss 11.120210 loss_att 14.352428 loss_ctc 19.519693 loss_rnnt 9.255579 hw_loss 0.184228 lr 0.00042244 rank 5
2023-02-22 07:36:54,720 DEBUG TRAIN Batch 16/6700 loss 3.440514 loss_att 5.934999 loss_ctc 3.912921 loss_rnnt 2.690647 hw_loss 0.352465 lr 0.00042236 rank 4
2023-02-22 07:36:54,721 DEBUG TRAIN Batch 16/6700 loss 12.718904 loss_att 15.211945 loss_ctc 13.832824 loss_rnnt 11.918762 hw_loss 0.286893 lr 0.00042229 rank 5
2023-02-22 07:36:54,731 DEBUG TRAIN Batch 16/6700 loss 10.197866 loss_att 12.733791 loss_ctc 10.861615 loss_rnnt 9.504772 hw_loss 0.182643 lr 0.00042228 rank 7
2023-02-22 07:36:54,731 DEBUG TRAIN Batch 16/6700 loss 5.851195 loss_att 9.940848 loss_ctc 8.751685 loss_rnnt 4.528123 hw_loss 0.222018 lr 0.00042233 rank 6
2023-02-22 07:36:54,733 DEBUG TRAIN Batch 16/6700 loss 3.042150 loss_att 6.303947 loss_ctc 3.965610 loss_rnnt 2.103792 hw_loss 0.305384 lr 0.00042239 rank 0
2023-02-22 07:36:54,732 DEBUG TRAIN Batch 16/6700 loss 11.356233 loss_att 13.752842 loss_ctc 17.546646 loss_rnnt 9.948362 hw_loss 0.193425 lr 0.00042236 rank 2
2023-02-22 07:36:54,734 DEBUG TRAIN Batch 16/6700 loss 6.239643 loss_att 10.049220 loss_ctc 9.959044 loss_rnnt 4.774506 hw_loss 0.388691 lr 0.00042238 rank 1
2023-02-22 07:36:54,750 DEBUG TRAIN Batch 16/6700 loss 4.037497 loss_att 8.037294 loss_ctc 7.439247 loss_rnnt 2.576669 hw_loss 0.388692 lr 0.00042235 rank 3
2023-02-22 07:38:08,362 DEBUG TRAIN Batch 16/6800 loss 10.500677 loss_att 12.097069 loss_ctc 14.539172 loss_rnnt 9.518840 hw_loss 0.232673 lr 0.00042221 rank 2
2023-02-22 07:38:08,367 DEBUG TRAIN Batch 16/6800 loss 14.626433 loss_att 16.665756 loss_ctc 16.951170 loss_rnnt 13.769403 hw_loss 0.261000 lr 0.00042213 rank 7
2023-02-22 07:38:08,368 DEBUG TRAIN Batch 16/6800 loss 5.932225 loss_att 8.986924 loss_ctc 11.679651 loss_rnnt 4.356930 hw_loss 0.371309 lr 0.00042224 rank 0
2023-02-22 07:38:08,371 DEBUG TRAIN Batch 16/6800 loss 20.916595 loss_att 21.261776 loss_ctc 23.682064 loss_rnnt 20.358936 hw_loss 0.224802 lr 0.00042220 rank 3
2023-02-22 07:38:08,373 DEBUG TRAIN Batch 16/6800 loss 6.519451 loss_att 7.353196 loss_ctc 7.058971 loss_rnnt 6.117756 hw_loss 0.305642 lr 0.00042223 rank 1
2023-02-22 07:38:08,374 DEBUG TRAIN Batch 16/6800 loss 7.666014 loss_att 9.809325 loss_ctc 13.546270 loss_rnnt 6.344666 hw_loss 0.203720 lr 0.00042218 rank 6
2023-02-22 07:38:08,375 DEBUG TRAIN Batch 16/6800 loss 11.171119 loss_att 11.635823 loss_ctc 11.270132 loss_rnnt 10.971585 hw_loss 0.175108 lr 0.00042214 rank 5
2023-02-22 07:38:08,425 DEBUG TRAIN Batch 16/6800 loss 12.510407 loss_att 14.832607 loss_ctc 15.699548 loss_rnnt 11.469219 hw_loss 0.284117 lr 0.00042221 rank 4
2023-02-22 07:39:21,147 DEBUG TRAIN Batch 16/6900 loss 18.578371 loss_att 20.794256 loss_ctc 22.230240 loss_rnnt 17.559172 hw_loss 0.167073 lr 0.00042205 rank 3
2023-02-22 07:39:21,152 DEBUG TRAIN Batch 16/6900 loss 23.998114 loss_att 26.758335 loss_ctc 29.903702 loss_rnnt 22.462616 hw_loss 0.367580 lr 0.00042206 rank 4
2023-02-22 07:39:21,151 DEBUG TRAIN Batch 16/6900 loss 8.444448 loss_att 9.240854 loss_ctc 10.841275 loss_rnnt 7.721309 hw_loss 0.458029 lr 0.00042206 rank 2
2023-02-22 07:39:21,153 DEBUG TRAIN Batch 16/6900 loss 13.113733 loss_att 13.613970 loss_ctc 16.826977 loss_rnnt 12.383868 hw_loss 0.252600 lr 0.00042199 rank 5
2023-02-22 07:39:21,154 DEBUG TRAIN Batch 16/6900 loss 12.726333 loss_att 15.825652 loss_ctc 19.649343 loss_rnnt 11.084635 hw_loss 0.185185 lr 0.00042203 rank 6
2023-02-22 07:39:21,154 DEBUG TRAIN Batch 16/6900 loss 15.475102 loss_att 17.045437 loss_ctc 18.149748 loss_rnnt 14.672849 hw_loss 0.246690 lr 0.00042208 rank 1
2023-02-22 07:39:21,156 DEBUG TRAIN Batch 16/6900 loss 12.074571 loss_att 15.499729 loss_ctc 17.682364 loss_rnnt 10.490335 hw_loss 0.284057 lr 0.00042209 rank 0
2023-02-22 07:39:21,157 DEBUG TRAIN Batch 16/6900 loss 7.704982 loss_att 12.310738 loss_ctc 13.457242 loss_rnnt 5.919293 hw_loss 0.182944 lr 0.00042198 rank 7
2023-02-22 07:40:33,597 DEBUG TRAIN Batch 16/7000 loss 8.073205 loss_att 7.678873 loss_ctc 12.240597 loss_rnnt 7.403898 hw_loss 0.360976 lr 0.00042193 rank 1
2023-02-22 07:40:33,598 DEBUG TRAIN Batch 16/7000 loss 12.448855 loss_att 15.530285 loss_ctc 18.466846 loss_rnnt 10.900887 hw_loss 0.242404 lr 0.00042194 rank 0
2023-02-22 07:40:33,598 DEBUG TRAIN Batch 16/7000 loss 6.082652 loss_att 8.070407 loss_ctc 6.857728 loss_rnnt 5.492506 hw_loss 0.167346 lr 0.00042191 rank 2
2023-02-22 07:40:33,603 DEBUG TRAIN Batch 16/7000 loss 7.166453 loss_att 9.397119 loss_ctc 13.408088 loss_rnnt 5.814827 hw_loss 0.137390 lr 0.00042188 rank 6
2023-02-22 07:40:33,605 DEBUG TRAIN Batch 16/7000 loss 9.133681 loss_att 11.171492 loss_ctc 11.342169 loss_rnnt 8.213472 hw_loss 0.409090 lr 0.00042191 rank 4
2023-02-22 07:40:33,606 DEBUG TRAIN Batch 16/7000 loss 10.346233 loss_att 11.402288 loss_ctc 16.746059 loss_rnnt 9.239639 hw_loss 0.078885 lr 0.00042183 rank 7
2023-02-22 07:40:33,609 DEBUG TRAIN Batch 16/7000 loss 6.412523 loss_att 8.912130 loss_ctc 7.872488 loss_rnnt 5.586837 hw_loss 0.245818 lr 0.00042184 rank 5
2023-02-22 07:40:33,610 DEBUG TRAIN Batch 16/7000 loss 13.468018 loss_att 16.126444 loss_ctc 15.755084 loss_rnnt 12.537426 hw_loss 0.176181 lr 0.00042190 rank 3
2023-02-22 07:41:48,048 DEBUG TRAIN Batch 16/7100 loss 11.422677 loss_att 21.318720 loss_ctc 17.711294 loss_rnnt 8.423995 hw_loss 0.339358 lr 0.00042175 rank 3
2023-02-22 07:41:48,053 DEBUG TRAIN Batch 16/7100 loss 6.031702 loss_att 8.453410 loss_ctc 7.029035 loss_rnnt 5.340106 hw_loss 0.139268 lr 0.00042178 rank 1
2023-02-22 07:41:48,052 DEBUG TRAIN Batch 16/7100 loss 14.800525 loss_att 19.641069 loss_ctc 21.255997 loss_rnnt 12.844263 hw_loss 0.238917 lr 0.00042169 rank 5
2023-02-22 07:41:48,054 DEBUG TRAIN Batch 16/7100 loss 15.861104 loss_att 19.207027 loss_ctc 15.835814 loss_rnnt 15.127357 hw_loss 0.127380 lr 0.00042176 rank 2
2023-02-22 07:41:48,057 DEBUG TRAIN Batch 16/7100 loss 13.731614 loss_att 20.983509 loss_ctc 20.798676 loss_rnnt 11.118036 hw_loss 0.414231 lr 0.00042168 rank 7
2023-02-22 07:41:48,056 DEBUG TRAIN Batch 16/7100 loss 16.231430 loss_att 16.648891 loss_ctc 20.945583 loss_rnnt 15.388708 hw_loss 0.245016 lr 0.00042173 rank 6
2023-02-22 07:41:48,057 DEBUG TRAIN Batch 16/7100 loss 8.458090 loss_att 13.217430 loss_ctc 15.722725 loss_rnnt 6.477083 hw_loss 0.113476 lr 0.00042176 rank 4
2023-02-22 07:41:48,061 DEBUG TRAIN Batch 16/7100 loss 6.834936 loss_att 7.561166 loss_ctc 8.499004 loss_rnnt 6.264429 hw_loss 0.381350 lr 0.00042179 rank 0
2023-02-22 07:43:01,044 DEBUG TRAIN Batch 16/7200 loss 18.449352 loss_att 19.092865 loss_ctc 26.736580 loss_rnnt 17.155296 hw_loss 0.113229 lr 0.00042161 rank 2
2023-02-22 07:43:01,051 DEBUG TRAIN Batch 16/7200 loss 2.541212 loss_att 5.634877 loss_ctc 2.429821 loss_rnnt 1.729158 hw_loss 0.390323 lr 0.00042161 rank 4
2023-02-22 07:43:01,052 DEBUG TRAIN Batch 16/7200 loss 6.339255 loss_att 8.645174 loss_ctc 7.099945 loss_rnnt 5.604707 hw_loss 0.322385 lr 0.00042160 rank 3
2023-02-22 07:43:01,054 DEBUG TRAIN Batch 16/7200 loss 5.604711 loss_att 9.658703 loss_ctc 5.967400 loss_rnnt 4.597244 hw_loss 0.278081 lr 0.00042153 rank 7
2023-02-22 07:43:01,057 DEBUG TRAIN Batch 16/7200 loss 4.499031 loss_att 7.481347 loss_ctc 7.373900 loss_rnnt 3.363967 hw_loss 0.291161 lr 0.00042164 rank 0
2023-02-22 07:43:01,059 DEBUG TRAIN Batch 16/7200 loss 13.164967 loss_att 14.468217 loss_ctc 20.754271 loss_rnnt 11.662211 hw_loss 0.431620 lr 0.00042158 rank 6
2023-02-22 07:43:01,059 DEBUG TRAIN Batch 16/7200 loss 6.001534 loss_att 11.215469 loss_ctc 7.402883 loss_rnnt 4.722623 hw_loss 0.092393 lr 0.00042163 rank 1
2023-02-22 07:43:01,060 DEBUG TRAIN Batch 16/7200 loss 9.282342 loss_att 14.269332 loss_ctc 13.326405 loss_rnnt 7.704175 hw_loss 0.077925 lr 0.00042154 rank 5
2023-02-22 07:44:13,623 DEBUG TRAIN Batch 16/7300 loss 19.694876 loss_att 22.674467 loss_ctc 27.445862 loss_rnnt 17.898657 hw_loss 0.312816 lr 0.00042146 rank 2
2023-02-22 07:44:13,641 DEBUG TRAIN Batch 16/7300 loss 8.549131 loss_att 9.399394 loss_ctc 11.937086 loss_rnnt 7.779757 hw_loss 0.276741 lr 0.00042146 rank 4
2023-02-22 07:44:13,643 DEBUG TRAIN Batch 16/7300 loss 14.287740 loss_att 16.900520 loss_ctc 22.047899 loss_rnnt 12.537350 hw_loss 0.362147 lr 0.00042143 rank 6
2023-02-22 07:44:13,644 DEBUG TRAIN Batch 16/7300 loss 9.939178 loss_att 11.400942 loss_ctc 12.267855 loss_rnnt 9.183249 hw_loss 0.287038 lr 0.00042145 rank 3
2023-02-22 07:44:13,648 DEBUG TRAIN Batch 16/7300 loss 8.015097 loss_att 10.939026 loss_ctc 9.547623 loss_rnnt 7.116722 hw_loss 0.204849 lr 0.00042139 rank 5
2023-02-22 07:44:13,650 DEBUG TRAIN Batch 16/7300 loss 13.838997 loss_att 16.920334 loss_ctc 18.665817 loss_rnnt 12.487974 hw_loss 0.170960 lr 0.00042148 rank 1
2023-02-22 07:44:13,652 DEBUG TRAIN Batch 16/7300 loss 13.092696 loss_att 17.278065 loss_ctc 25.455750 loss_rnnt 10.457676 hw_loss 0.280385 lr 0.00042149 rank 0
2023-02-22 07:44:13,696 DEBUG TRAIN Batch 16/7300 loss 19.250544 loss_att 26.555540 loss_ctc 35.086239 loss_rnnt 15.556567 hw_loss 0.227907 lr 0.00042138 rank 7
2023-02-22 07:45:26,578 DEBUG TRAIN Batch 16/7400 loss 10.610008 loss_att 12.958437 loss_ctc 12.255700 loss_rnnt 9.808771 hw_loss 0.210234 lr 0.00042123 rank 7
2023-02-22 07:45:26,577 DEBUG TRAIN Batch 16/7400 loss 8.218926 loss_att 8.595503 loss_ctc 8.542524 loss_rnnt 7.967942 hw_loss 0.248479 lr 0.00042131 rank 4
2023-02-22 07:45:26,580 DEBUG TRAIN Batch 16/7400 loss 14.645174 loss_att 23.060390 loss_ctc 26.564877 loss_rnnt 11.307644 hw_loss 0.122238 lr 0.00042124 rank 5
2023-02-22 07:45:26,580 DEBUG TRAIN Batch 16/7400 loss 12.563355 loss_att 14.831655 loss_ctc 13.393665 loss_rnnt 11.894725 hw_loss 0.195491 lr 0.00042131 rank 2
2023-02-22 07:45:26,581 DEBUG TRAIN Batch 16/7400 loss 6.459447 loss_att 7.551089 loss_ctc 9.610745 loss_rnnt 5.693979 hw_loss 0.238061 lr 0.00042134 rank 0
2023-02-22 07:45:26,585 DEBUG TRAIN Batch 16/7400 loss 5.467004 loss_att 8.913456 loss_ctc 6.842726 loss_rnnt 4.403512 hw_loss 0.357698 lr 0.00042128 rank 6
2023-02-22 07:45:26,594 DEBUG TRAIN Batch 16/7400 loss 10.775584 loss_att 13.538662 loss_ctc 16.776752 loss_rnnt 9.337641 hw_loss 0.159695 lr 0.00042130 rank 3
2023-02-22 07:45:26,629 DEBUG TRAIN Batch 16/7400 loss 10.938320 loss_att 13.863817 loss_ctc 16.040405 loss_rnnt 9.525408 hw_loss 0.276626 lr 0.00042133 rank 1
2023-02-22 07:46:41,701 DEBUG TRAIN Batch 16/7500 loss 9.277265 loss_att 10.906811 loss_ctc 12.845112 loss_rnnt 8.376905 hw_loss 0.185133 lr 0.00042109 rank 5
2023-02-22 07:46:41,710 DEBUG TRAIN Batch 16/7500 loss 9.186289 loss_att 11.284554 loss_ctc 12.552984 loss_rnnt 8.096581 hw_loss 0.414679 lr 0.00042116 rank 2
2023-02-22 07:46:41,710 DEBUG TRAIN Batch 16/7500 loss 8.069164 loss_att 8.925192 loss_ctc 11.158136 loss_rnnt 7.274677 hw_loss 0.396411 lr 0.00042115 rank 3
2023-02-22 07:46:41,713 DEBUG TRAIN Batch 16/7500 loss 7.003628 loss_att 10.340572 loss_ctc 11.628221 loss_rnnt 5.576747 hw_loss 0.267900 lr 0.00042119 rank 0
2023-02-22 07:46:41,713 DEBUG TRAIN Batch 16/7500 loss 15.671042 loss_att 18.544924 loss_ctc 19.547092 loss_rnnt 14.460813 hw_loss 0.222462 lr 0.00042113 rank 6
2023-02-22 07:46:41,716 DEBUG TRAIN Batch 16/7500 loss 24.666712 loss_att 28.364326 loss_ctc 31.796562 loss_rnnt 22.785255 hw_loss 0.358661 lr 0.00042108 rank 7
2023-02-22 07:46:41,716 DEBUG TRAIN Batch 16/7500 loss 22.167049 loss_att 31.949816 loss_ctc 30.578949 loss_rnnt 18.893139 hw_loss 0.367068 lr 0.00042116 rank 4
2023-02-22 07:46:41,722 DEBUG TRAIN Batch 16/7500 loss 7.294781 loss_att 8.998023 loss_ctc 10.730096 loss_rnnt 6.302691 hw_loss 0.362626 lr 0.00042118 rank 1
2023-02-22 07:47:54,706 DEBUG TRAIN Batch 16/7600 loss 11.147923 loss_att 11.035511 loss_ctc 11.829894 loss_rnnt 10.799276 hw_loss 0.525376 lr 0.00042093 rank 7
2023-02-22 07:47:54,707 DEBUG TRAIN Batch 16/7600 loss 5.611120 loss_att 7.053649 loss_ctc 7.675632 loss_rnnt 4.910060 hw_loss 0.257411 lr 0.00042101 rank 2
2023-02-22 07:47:54,711 DEBUG TRAIN Batch 16/7600 loss 12.477201 loss_att 14.617056 loss_ctc 15.705325 loss_rnnt 11.497388 hw_loss 0.227671 lr 0.00042101 rank 4
2023-02-22 07:47:54,712 DEBUG TRAIN Batch 16/7600 loss 10.423071 loss_att 13.271992 loss_ctc 12.634428 loss_rnnt 9.455634 hw_loss 0.192759 lr 0.00042098 rank 6
2023-02-22 07:47:54,714 DEBUG TRAIN Batch 16/7600 loss 11.460035 loss_att 14.215561 loss_ctc 16.066252 loss_rnnt 10.131434 hw_loss 0.306250 lr 0.00042104 rank 0
2023-02-22 07:47:54,715 DEBUG TRAIN Batch 16/7600 loss 20.340664 loss_att 20.562126 loss_ctc 27.860691 loss_rnnt 19.161270 hw_loss 0.248306 lr 0.00042100 rank 3
2023-02-22 07:47:54,715 DEBUG TRAIN Batch 16/7600 loss 12.929014 loss_att 15.030808 loss_ctc 21.210814 loss_rnnt 11.244118 hw_loss 0.300558 lr 0.00042094 rank 5
2023-02-22 07:47:54,718 DEBUG TRAIN Batch 16/7600 loss 5.044502 loss_att 5.427613 loss_ctc 7.064394 loss_rnnt 4.447156 hw_loss 0.471383 lr 0.00042103 rank 1
2023-02-22 07:49:06,981 DEBUG TRAIN Batch 16/7700 loss 7.190235 loss_att 10.617826 loss_ctc 9.317962 loss_rnnt 6.101328 hw_loss 0.224423 lr 0.00042086 rank 4
2023-02-22 07:49:06,989 DEBUG TRAIN Batch 16/7700 loss 3.459499 loss_att 7.287271 loss_ctc 5.998670 loss_rnnt 2.207371 hw_loss 0.277533 lr 0.00042086 rank 2
2023-02-22 07:49:06,991 DEBUG TRAIN Batch 16/7700 loss 6.194180 loss_att 9.077915 loss_ctc 5.193296 loss_rnnt 5.623863 hw_loss 0.238168 lr 0.00042083 rank 6
2023-02-22 07:49:06,996 DEBUG TRAIN Batch 16/7700 loss 3.524313 loss_att 6.748458 loss_ctc 6.385682 loss_rnnt 2.358962 hw_loss 0.260638 lr 0.00042085 rank 3
2023-02-22 07:49:06,997 DEBUG TRAIN Batch 16/7700 loss 14.415196 loss_att 17.110760 loss_ctc 20.006277 loss_rnnt 12.969540 hw_loss 0.302001 lr 0.00042079 rank 7
2023-02-22 07:49:06,997 DEBUG TRAIN Batch 16/7700 loss 19.505020 loss_att 21.501566 loss_ctc 20.936174 loss_rnnt 18.774586 hw_loss 0.263069 lr 0.00042089 rank 0
2023-02-22 07:49:07,002 DEBUG TRAIN Batch 16/7700 loss 5.033909 loss_att 7.511083 loss_ctc 5.736269 loss_rnnt 4.340926 hw_loss 0.194812 lr 0.00042079 rank 5
2023-02-22 07:49:07,049 DEBUG TRAIN Batch 16/7700 loss 12.055414 loss_att 13.469951 loss_ctc 19.200674 loss_rnnt 10.713804 hw_loss 0.198752 lr 0.00042088 rank 1
2023-02-22 07:50:21,306 DEBUG TRAIN Batch 16/7800 loss 20.088486 loss_att 28.597477 loss_ctc 31.712042 loss_rnnt 16.671112 hw_loss 0.310810 lr 0.00042064 rank 5
2023-02-22 07:50:21,309 DEBUG TRAIN Batch 16/7800 loss 12.549471 loss_att 12.851107 loss_ctc 19.480633 loss_rnnt 11.474677 hw_loss 0.169338 lr 0.00042064 rank 7
2023-02-22 07:50:21,316 DEBUG TRAIN Batch 16/7800 loss 8.879274 loss_att 13.685433 loss_ctc 9.599354 loss_rnnt 7.703200 hw_loss 0.222810 lr 0.00042073 rank 1
2023-02-22 07:50:21,316 DEBUG TRAIN Batch 16/7800 loss 4.867853 loss_att 7.244913 loss_ctc 6.823058 loss_rnnt 4.033879 hw_loss 0.183502 lr 0.00042070 rank 3
2023-02-22 07:50:21,321 DEBUG TRAIN Batch 16/7800 loss 9.790043 loss_att 11.141615 loss_ctc 11.899120 loss_rnnt 9.059872 hw_loss 0.334962 lr 0.00042071 rank 4
2023-02-22 07:50:21,322 DEBUG TRAIN Batch 16/7800 loss 22.753119 loss_att 23.750896 loss_ctc 27.568348 loss_rnnt 21.840813 hw_loss 0.132599 lr 0.00042068 rank 6
2023-02-22 07:50:21,322 DEBUG TRAIN Batch 16/7800 loss 9.272909 loss_att 15.156410 loss_ctc 15.503855 loss_rnnt 7.126351 hw_loss 0.260746 lr 0.00042071 rank 2
2023-02-22 07:50:21,323 DEBUG TRAIN Batch 16/7800 loss 12.958445 loss_att 14.150954 loss_ctc 15.043194 loss_rnnt 12.318960 hw_loss 0.230655 lr 0.00042074 rank 0
2023-02-22 07:51:34,833 DEBUG TRAIN Batch 16/7900 loss 7.521349 loss_att 13.706004 loss_ctc 9.000402 loss_rnnt 5.978417 hw_loss 0.203986 lr 0.00042056 rank 4
2023-02-22 07:51:34,834 DEBUG TRAIN Batch 16/7900 loss 14.817231 loss_att 16.573730 loss_ctc 20.575075 loss_rnnt 13.458279 hw_loss 0.449888 lr 0.00042056 rank 2
2023-02-22 07:51:34,837 DEBUG TRAIN Batch 16/7900 loss 9.073835 loss_att 11.124075 loss_ctc 11.783508 loss_rnnt 8.098546 hw_loss 0.382408 lr 0.00042053 rank 6
2023-02-22 07:51:34,839 DEBUG TRAIN Batch 16/7900 loss 8.886022 loss_att 12.802784 loss_ctc 10.724393 loss_rnnt 7.677395 hw_loss 0.337797 lr 0.00042055 rank 3
2023-02-22 07:51:34,842 DEBUG TRAIN Batch 16/7900 loss 16.391191 loss_att 17.080967 loss_ctc 22.760300 loss_rnnt 15.215241 hw_loss 0.353963 lr 0.00042049 rank 7
2023-02-22 07:51:34,843 DEBUG TRAIN Batch 16/7900 loss 24.495422 loss_att 27.499008 loss_ctc 30.498405 loss_rnnt 22.905212 hw_loss 0.354550 lr 0.00042049 rank 5
2023-02-22 07:51:34,868 DEBUG TRAIN Batch 16/7900 loss 8.703411 loss_att 11.761866 loss_ctc 11.564139 loss_rnnt 7.488189 hw_loss 0.416439 lr 0.00042058 rank 1
2023-02-22 07:51:34,903 DEBUG TRAIN Batch 16/7900 loss 10.417213 loss_att 17.288864 loss_ctc 14.295008 loss_rnnt 8.415362 hw_loss 0.207154 lr 0.00042059 rank 0
2023-02-22 07:52:47,204 DEBUG TRAIN Batch 16/8000 loss 21.176983 loss_att 23.301363 loss_ctc 30.959015 loss_rnnt 19.289568 hw_loss 0.296750 lr 0.00042038 rank 6
2023-02-22 07:52:47,212 DEBUG TRAIN Batch 16/8000 loss 8.448133 loss_att 11.250251 loss_ctc 12.584089 loss_rnnt 7.204968 hw_loss 0.246151 lr 0.00042041 rank 2
2023-02-22 07:52:47,212 DEBUG TRAIN Batch 16/8000 loss 21.699919 loss_att 25.580132 loss_ctc 27.855366 loss_rnnt 20.005594 hw_loss 0.182918 lr 0.00042045 rank 0
2023-02-22 07:52:47,215 DEBUG TRAIN Batch 16/8000 loss 13.966785 loss_att 20.246580 loss_ctc 22.691750 loss_rnnt 11.428780 hw_loss 0.222597 lr 0.00042040 rank 3
2023-02-22 07:52:47,218 DEBUG TRAIN Batch 16/8000 loss 6.148252 loss_att 7.883039 loss_ctc 12.165377 loss_rnnt 4.769628 hw_loss 0.430094 lr 0.00042034 rank 7
2023-02-22 07:52:47,219 DEBUG TRAIN Batch 16/8000 loss 18.330812 loss_att 23.083128 loss_ctc 20.838421 loss_rnnt 16.861315 hw_loss 0.346286 lr 0.00042041 rank 4
2023-02-22 07:52:47,223 DEBUG TRAIN Batch 16/8000 loss 10.571232 loss_att 11.196402 loss_ctc 14.216503 loss_rnnt 9.709204 hw_loss 0.470546 lr 0.00042034 rank 5
2023-02-22 07:52:47,266 DEBUG TRAIN Batch 16/8000 loss 7.952177 loss_att 8.850914 loss_ctc 9.061878 loss_rnnt 7.552412 hw_loss 0.135107 lr 0.00042043 rank 1
2023-02-22 07:53:59,846 DEBUG TRAIN Batch 16/8100 loss 6.507300 loss_att 8.978947 loss_ctc 7.712335 loss_rnnt 5.654272 hw_loss 0.371299 lr 0.00042019 rank 5
2023-02-22 07:53:59,850 DEBUG TRAIN Batch 16/8100 loss 13.644311 loss_att 15.324835 loss_ctc 19.319838 loss_rnnt 12.413777 hw_loss 0.258171 lr 0.00042019 rank 7
2023-02-22 07:53:59,853 DEBUG TRAIN Batch 16/8100 loss 16.917135 loss_att 19.065548 loss_ctc 23.916351 loss_rnnt 15.399036 hw_loss 0.290975 lr 0.00042027 rank 2
2023-02-22 07:53:59,854 DEBUG TRAIN Batch 16/8100 loss 10.102015 loss_att 12.787101 loss_ctc 13.626808 loss_rnnt 8.978763 hw_loss 0.217996 lr 0.00042028 rank 1
2023-02-22 07:53:59,856 DEBUG TRAIN Batch 16/8100 loss 19.746519 loss_att 20.797314 loss_ctc 26.175034 loss_rnnt 18.535666 hw_loss 0.269176 lr 0.00042026 rank 3
2023-02-22 07:53:59,860 DEBUG TRAIN Batch 16/8100 loss 6.991198 loss_att 9.421784 loss_ctc 10.408313 loss_rnnt 5.872663 hw_loss 0.331503 lr 0.00042024 rank 6
2023-02-22 07:53:59,874 DEBUG TRAIN Batch 16/8100 loss 12.613523 loss_att 13.785720 loss_ctc 15.009007 loss_rnnt 11.880508 hw_loss 0.335961 lr 0.00042027 rank 4
2023-02-22 07:53:59,876 DEBUG TRAIN Batch 16/8100 loss 8.694674 loss_att 12.333279 loss_ctc 17.346365 loss_rnnt 6.638619 hw_loss 0.327702 lr 0.00042030 rank 0
2023-02-22 07:55:13,604 DEBUG TRAIN Batch 16/8200 loss 11.423704 loss_att 11.934082 loss_ctc 14.719757 loss_rnnt 10.696186 hw_loss 0.348691 lr 0.00042009 rank 6
2023-02-22 07:55:13,606 DEBUG TRAIN Batch 16/8200 loss 11.303887 loss_att 11.992571 loss_ctc 15.195894 loss_rnnt 10.420246 hw_loss 0.425569 lr 0.00042011 rank 3
2023-02-22 07:55:13,606 DEBUG TRAIN Batch 16/8200 loss 18.093637 loss_att 17.658833 loss_ctc 27.571140 loss_rnnt 16.691229 hw_loss 0.423195 lr 0.00042004 rank 7
2023-02-22 07:55:13,608 DEBUG TRAIN Batch 16/8200 loss 8.977754 loss_att 10.460333 loss_ctc 8.449326 loss_rnnt 8.563877 hw_loss 0.352159 lr 0.00042015 rank 0
2023-02-22 07:55:13,609 DEBUG TRAIN Batch 16/8200 loss 8.782071 loss_att 10.454641 loss_ctc 15.866652 loss_rnnt 7.231956 hw_loss 0.508107 lr 0.00042012 rank 2
2023-02-22 07:55:13,611 DEBUG TRAIN Batch 16/8200 loss 11.914815 loss_att 14.833036 loss_ctc 17.344645 loss_rnnt 10.461838 hw_loss 0.272542 lr 0.00042005 rank 5
2023-02-22 07:55:13,611 DEBUG TRAIN Batch 16/8200 loss 14.946079 loss_att 16.472595 loss_ctc 19.188982 loss_rnnt 13.984015 hw_loss 0.170700 lr 0.00042012 rank 4
2023-02-22 07:55:13,612 DEBUG TRAIN Batch 16/8200 loss 13.247890 loss_att 13.888334 loss_ctc 19.316826 loss_rnnt 12.154599 hw_loss 0.292519 lr 0.00042014 rank 1
2023-02-22 07:56:25,987 DEBUG TRAIN Batch 16/8300 loss 14.851137 loss_att 17.488504 loss_ctc 14.913703 loss_rnnt 14.172939 hw_loss 0.266968 lr 0.00041997 rank 2
2023-02-22 07:56:25,996 DEBUG TRAIN Batch 16/8300 loss 11.594128 loss_att 13.151445 loss_ctc 16.080488 loss_rnnt 10.626154 hw_loss 0.109366 lr 0.00041996 rank 3
2023-02-22 07:56:25,998 DEBUG TRAIN Batch 16/8300 loss 3.751789 loss_att 5.850127 loss_ctc 4.483020 loss_rnnt 3.155834 hw_loss 0.147730 lr 0.00041999 rank 1
2023-02-22 07:56:25,998 DEBUG TRAIN Batch 16/8300 loss 3.180161 loss_att 6.708705 loss_ctc 5.307571 loss_rnnt 1.962273 hw_loss 0.428483 lr 0.00041994 rank 6
2023-02-22 07:56:25,999 DEBUG TRAIN Batch 16/8300 loss 16.437737 loss_att 17.953629 loss_ctc 20.708750 loss_rnnt 15.311040 hw_loss 0.476339 lr 0.00041990 rank 5
2023-02-22 07:56:26,000 DEBUG TRAIN Batch 16/8300 loss 5.744491 loss_att 10.251541 loss_ctc 8.603293 loss_rnnt 4.368923 hw_loss 0.174345 lr 0.00042000 rank 0
2023-02-22 07:56:26,000 DEBUG TRAIN Batch 16/8300 loss 7.223928 loss_att 9.573987 loss_ctc 10.004967 loss_rnnt 6.178030 hw_loss 0.384528 lr 0.00041997 rank 4
2023-02-22 07:56:26,002 DEBUG TRAIN Batch 16/8300 loss 9.888265 loss_att 10.349652 loss_ctc 10.819517 loss_rnnt 9.491079 hw_loss 0.338889 lr 0.00041989 rank 7
2023-02-22 07:57:17,495 DEBUG CV Batch 16/0 loss 1.737017 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672683 rank 6
2023-02-22 07:57:17,498 DEBUG CV Batch 16/0 loss 1.737017 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672683 rank 3
2023-02-22 07:57:17,498 DEBUG CV Batch 16/0 loss 1.737017 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672683 rank 5
2023-02-22 07:57:17,502 DEBUG CV Batch 16/0 loss 1.737017 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672683 rank 1
2023-02-22 07:57:17,508 DEBUG CV Batch 16/0 loss 1.737016 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672682 rank 4
2023-02-22 07:57:17,514 DEBUG CV Batch 16/0 loss 1.737017 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672683 rank 0
2023-02-22 07:57:17,516 DEBUG CV Batch 16/0 loss 1.737017 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672683 rank 2
2023-02-22 07:57:17,520 DEBUG CV Batch 16/0 loss 1.737016 loss_att 1.554774 loss_ctc 2.027455 loss_rnnt 1.365327 hw_loss 0.692649 history loss 1.672682 rank 7
2023-02-22 07:57:28,762 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 4
2023-02-22 07:57:28,816 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 7
2023-02-22 07:57:28,853 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 0
2023-02-22 07:57:28,902 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 1
2023-02-22 07:57:29,025 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 3
2023-02-22 07:57:29,213 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 2
2023-02-22 07:57:29,239 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 6
2023-02-22 07:57:29,246 DEBUG CV Batch 16/100 loss 7.677160 loss_att 8.771250 loss_ctc 10.597704 loss_rnnt 6.885142 hw_loss 0.344614 history loss 3.966647 rank 5
2023-02-22 07:57:42,107 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 4
2023-02-22 07:57:42,201 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 7
2023-02-22 07:57:42,411 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 1
2023-02-22 07:57:42,506 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 0
2023-02-22 07:57:42,619 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 3
2023-02-22 07:57:42,661 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 5
2023-02-22 07:57:42,918 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 2
2023-02-22 07:57:43,035 DEBUG CV Batch 16/200 loss 12.029644 loss_att 19.427561 loss_ctc 17.043011 loss_rnnt 9.786759 hw_loss 0.177849 history loss 4.510632 rank 6
2023-02-22 07:57:54,389 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 7
2023-02-22 07:57:54,562 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 4
2023-02-22 07:57:54,962 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 1
2023-02-22 07:57:55,057 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 5
2023-02-22 07:57:55,077 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 0
2023-02-22 07:57:55,078 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 3
2023-02-22 07:57:55,227 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 2
2023-02-22 07:57:55,596 DEBUG CV Batch 16/300 loss 5.541398 loss_att 6.368737 loss_ctc 7.975202 loss_rnnt 4.777706 hw_loss 0.513219 history loss 4.721125 rank 6
2023-02-22 07:58:06,577 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 7
2023-02-22 07:58:06,903 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 4
2023-02-22 07:58:06,962 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 1
2023-02-22 07:58:07,145 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 5
2023-02-22 07:58:07,409 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 0
2023-02-22 07:58:07,466 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 3
2023-02-22 07:58:07,703 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 2
2023-02-22 07:58:08,202 DEBUG CV Batch 16/400 loss 17.315413 loss_att 97.041161 loss_ctc 6.788828 loss_rnnt 2.658824 hw_loss 0.215593 history loss 5.789764 rank 6
2023-02-22 07:58:17,340 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 7
2023-02-22 07:58:17,709 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 4
2023-02-22 07:58:17,735 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 1
2023-02-22 07:58:18,067 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 5
2023-02-22 07:58:18,409 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 3
2023-02-22 07:58:18,638 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 2
2023-02-22 07:58:19,021 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 0
2023-02-22 07:58:19,258 DEBUG CV Batch 16/500 loss 6.071723 loss_att 6.146682 loss_ctc 7.857800 loss_rnnt 5.730087 hw_loss 0.165941 history loss 6.713668 rank 6
2023-02-22 07:58:29,486 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 7
2023-02-22 07:58:29,822 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 1
2023-02-22 07:58:29,845 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 4
2023-02-22 07:58:30,670 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 5
2023-02-22 07:58:30,820 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 3
2023-02-22 07:58:31,180 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 2
2023-02-22 07:58:31,517 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 0
2023-02-22 07:58:31,948 DEBUG CV Batch 16/600 loss 8.370614 loss_att 8.701910 loss_ctc 11.285131 loss_rnnt 7.664209 hw_loss 0.471645 history loss 7.691411 rank 6
2023-02-22 07:58:40,917 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 7
2023-02-22 07:58:41,130 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 1
2023-02-22 07:58:41,598 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 4
2023-02-22 07:58:42,508 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 3
2023-02-22 07:58:42,622 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 5
2023-02-22 07:58:43,077 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 2
2023-02-22 07:58:43,338 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 0
2023-02-22 07:58:43,836 DEBUG CV Batch 16/700 loss 15.622645 loss_att 44.379566 loss_ctc 18.503531 loss_rnnt 9.446951 hw_loss 0.075362 history loss 8.440053 rank 6
2023-02-22 07:58:52,460 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 7
2023-02-22 07:58:52,720 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 1
2023-02-22 07:58:53,240 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 4
2023-02-22 07:58:53,978 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 3
2023-02-22 07:58:54,229 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 5
2023-02-22 07:58:54,706 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 2
2023-02-22 07:58:55,256 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 0
2023-02-22 07:58:55,587 DEBUG CV Batch 16/800 loss 12.167346 loss_att 12.305719 loss_ctc 18.727505 loss_rnnt 11.025959 hw_loss 0.448172 history loss 7.835305 rank 6
2023-02-22 07:59:06,059 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 7
2023-02-22 07:59:06,065 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 1
2023-02-22 07:59:06,598 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 4
2023-02-22 07:59:07,518 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 3
2023-02-22 07:59:07,767 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 5
2023-02-22 07:59:08,426 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 2
2023-02-22 07:59:08,921 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 0
2023-02-22 07:59:09,330 DEBUG CV Batch 16/900 loss 16.535059 loss_att 18.851891 loss_ctc 25.056618 loss_rnnt 14.787215 hw_loss 0.278007 history loss 7.592350 rank 6
2023-02-22 07:59:18,461 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 1
2023-02-22 07:59:18,499 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 7
2023-02-22 07:59:19,286 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 4
2023-02-22 07:59:20,001 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 3
2023-02-22 07:59:20,293 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 5
2023-02-22 07:59:21,222 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 2
2023-02-22 07:59:21,695 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 0
2023-02-22 07:59:22,133 DEBUG CV Batch 16/1000 loss 4.760029 loss_att 4.922671 loss_ctc 5.197982 loss_rnnt 4.393335 hw_loss 0.517072 history loss 7.343696 rank 6
2023-02-22 07:59:30,481 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 1
2023-02-22 07:59:30,580 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 7
2023-02-22 07:59:31,407 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 4
2023-02-22 07:59:32,341 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 3
2023-02-22 07:59:32,409 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 5
2023-02-22 07:59:33,654 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 2
2023-02-22 07:59:33,990 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 0
2023-02-22 07:59:34,588 DEBUG CV Batch 16/1100 loss 7.490419 loss_att 6.608744 loss_ctc 9.125204 loss_rnnt 7.012306 hw_loss 0.818393 history loss 7.316185 rank 6
2023-02-22 07:59:41,260 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 1
2023-02-22 07:59:41,465 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 7
2023-02-22 07:59:42,280 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 4
2023-02-22 07:59:43,367 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 3
2023-02-22 07:59:43,465 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 5
2023-02-22 07:59:44,869 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 2
2023-02-22 07:59:45,429 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 0
2023-02-22 07:59:45,945 DEBUG CV Batch 16/1200 loss 7.694961 loss_att 9.037456 loss_ctc 9.768790 loss_rnnt 6.976909 hw_loss 0.324454 history loss 7.715184 rank 6
2023-02-22 07:59:53,364 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 1
2023-02-22 07:59:53,620 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 7
2023-02-22 07:59:54,497 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 4
2023-02-22 07:59:55,714 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 3
2023-02-22 07:59:56,166 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 5
2023-02-22 07:59:57,485 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 2
2023-02-22 07:59:58,149 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 0
2023-02-22 07:59:58,648 DEBUG CV Batch 16/1300 loss 6.845675 loss_att 7.047660 loss_ctc 10.096039 loss_rnnt 6.123269 hw_loss 0.466177 history loss 8.034861 rank 6
2023-02-22 08:00:04,595 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 1
2023-02-22 08:00:05,250 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 7
2023-02-22 08:00:05,874 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 4
2023-02-22 08:00:07,385 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 3
2023-02-22 08:00:07,480 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 5
2023-02-22 08:00:09,231 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 2
2023-02-22 08:00:09,787 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 0
2023-02-22 08:00:10,535 DEBUG CV Batch 16/1400 loss 8.886303 loss_att 20.415102 loss_ctc 5.973908 loss_rnnt 6.895123 hw_loss 0.138264 history loss 8.397142 rank 6
2023-02-22 08:00:16,231 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 1
2023-02-22 08:00:16,989 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 7
2023-02-22 08:00:17,619 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 4
2023-02-22 08:00:19,212 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 5
2023-02-22 08:00:19,305 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 3
2023-02-22 08:00:21,231 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 2
2023-02-22 08:00:21,867 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 0
2023-02-22 08:00:22,703 DEBUG CV Batch 16/1500 loss 7.665577 loss_att 9.711853 loss_ctc 8.621340 loss_rnnt 7.006349 hw_loss 0.229758 history loss 8.200845 rank 6
2023-02-22 08:00:29,195 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 1
2023-02-22 08:00:30,142 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 7
2023-02-22 08:00:31,290 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 4
2023-02-22 08:00:32,695 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 3
2023-02-22 08:00:32,722 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 5
2023-02-22 08:00:35,136 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 2
2023-02-22 08:00:35,425 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 0
2023-02-22 08:00:36,258 DEBUG CV Batch 16/1600 loss 11.280078 loss_att 14.978602 loss_ctc 13.539024 loss_rnnt 10.198988 hw_loss 0.075362 history loss 8.109923 rank 6
2023-02-22 08:00:41,712 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 1
2023-02-22 08:00:42,717 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 7
2023-02-22 08:00:43,908 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 4
2023-02-22 08:00:45,181 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 3
2023-02-22 08:00:45,373 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 5
2023-02-22 08:00:47,726 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 2
2023-02-22 08:00:48,099 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 0
2023-02-22 08:00:48,843 DEBUG CV Batch 16/1700 loss 10.890724 loss_att 9.763743 loss_ctc 16.086771 loss_rnnt 10.145351 hw_loss 0.521181 history loss 8.002799 rank 6
2023-02-22 08:00:50,929 INFO Epoch 16 CV info cv_loss 7.959429262759179
2023-02-22 08:00:50,929 INFO Epoch 17 TRAIN info lr 0.00041992793982948686
2023-02-22 08:00:50,935 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:00:52,107 INFO Epoch 16 CV info cv_loss 7.9594292615057505
2023-02-22 08:00:52,108 INFO Epoch 17 TRAIN info lr 0.000419834668074998
2023-02-22 08:00:52,113 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:00:52,955 INFO Epoch 16 CV info cv_loss 7.9594292630908425
2023-02-22 08:00:52,956 INFO Epoch 17 TRAIN info lr 0.00041992793982948686
2023-02-22 08:00:52,961 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:00:54,285 INFO Epoch 16 CV info cv_loss 7.959429262858247
2023-02-22 08:00:54,286 INFO Epoch 17 TRAIN info lr 0.0004198746340731177
2023-02-22 08:00:54,291 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:00:54,594 INFO Epoch 16 CV info cv_loss 7.9594292627807155
2023-02-22 08:00:54,594 INFO Epoch 17 TRAIN info lr 0.0004198465086624141
2023-02-22 08:00:54,600 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:00:56,887 INFO Epoch 16 CV info cv_loss 7.9594292639049256
2023-02-22 08:00:56,888 INFO Epoch 17 TRAIN info lr 0.0004198761145144706
2023-02-22 08:00:56,890 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:00:57,502 INFO Epoch 16 CV info cv_loss 7.959429263504345
2023-02-22 08:00:57,502 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/16.pt
2023-02-22 08:01:01,498 INFO Epoch 16 CV info cv_loss 7.959429264128906
2023-02-22 08:01:01,498 INFO Epoch 17 TRAIN info lr 0.00041986871246429904
2023-02-22 08:01:01,507 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:01:01,644 INFO Epoch 17 TRAIN info lr 0.000419964969663075
2023-02-22 08:01:01,649 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:02:02,615 DEBUG TRAIN Batch 17/0 loss 9.323730 loss_att 9.126358 loss_ctc 11.956697 loss_rnnt 8.754347 hw_loss 0.483366 lr 0.00041993 rank 4
2023-02-22 08:02:02,628 DEBUG TRAIN Batch 17/0 loss 7.358064 loss_att 6.719269 loss_ctc 8.327294 loss_rnnt 7.024494 hw_loss 0.622684 lr 0.00041983 rank 7
2023-02-22 08:02:02,629 DEBUG TRAIN Batch 17/0 loss 11.395667 loss_att 10.332432 loss_ctc 13.349781 loss_rnnt 11.033948 hw_loss 0.588407 lr 0.00041987 rank 3
2023-02-22 08:02:02,630 DEBUG TRAIN Batch 17/0 loss 11.512733 loss_att 10.762650 loss_ctc 12.257380 loss_rnnt 11.203582 hw_loss 0.674782 lr 0.00041993 rank 1
2023-02-22 08:02:02,632 DEBUG TRAIN Batch 17/0 loss 9.639178 loss_att 9.053193 loss_ctc 12.065120 loss_rnnt 9.166276 hw_loss 0.499951 lr 0.00041985 rank 5
2023-02-22 08:02:02,633 DEBUG TRAIN Batch 17/0 loss 11.600783 loss_att 11.017567 loss_ctc 14.051297 loss_rnnt 11.069537 hw_loss 0.602167 lr 0.00041987 rank 6
2023-02-22 08:02:02,634 DEBUG TRAIN Batch 17/0 loss 11.968295 loss_att 10.518353 loss_ctc 13.765368 loss_rnnt 11.753698 hw_loss 0.496829 lr 0.00041987 rank 2
2023-02-22 08:02:02,684 DEBUG TRAIN Batch 17/0 loss 8.108597 loss_att 8.200411 loss_ctc 9.662997 loss_rnnt 7.557706 hw_loss 0.609889 lr 0.00041996 rank 0
2023-02-22 08:03:15,101 DEBUG TRAIN Batch 17/100 loss 10.483006 loss_att 12.679281 loss_ctc 12.361041 loss_rnnt 9.657829 hw_loss 0.254093 lr 0.00041982 rank 0
2023-02-22 08:03:15,101 DEBUG TRAIN Batch 17/100 loss 15.283655 loss_att 20.022383 loss_ctc 20.008265 loss_rnnt 13.667250 hw_loss 0.072583 lr 0.00041973 rank 3
2023-02-22 08:03:15,101 DEBUG TRAIN Batch 17/100 loss 8.589787 loss_att 10.977665 loss_ctc 13.687017 loss_rnnt 7.234449 hw_loss 0.371494 lr 0.00041973 rank 2
2023-02-22 08:03:15,101 DEBUG TRAIN Batch 17/100 loss 9.228013 loss_att 11.802187 loss_ctc 13.631186 loss_rnnt 8.002031 hw_loss 0.232606 lr 0.00041978 rank 1
2023-02-22 08:03:15,103 DEBUG TRAIN Batch 17/100 loss 13.512104 loss_att 17.118298 loss_ctc 18.177095 loss_rnnt 12.045852 hw_loss 0.230651 lr 0.00041970 rank 5
2023-02-22 08:03:15,104 DEBUG TRAIN Batch 17/100 loss 7.748485 loss_att 11.784197 loss_ctc 11.146625 loss_rnnt 6.398376 hw_loss 0.168527 lr 0.00041978 rank 4
2023-02-22 08:03:15,107 DEBUG TRAIN Batch 17/100 loss 10.309993 loss_att 14.596209 loss_ctc 16.434692 loss_rnnt 8.511248 hw_loss 0.234141 lr 0.00041972 rank 6
2023-02-22 08:03:15,148 DEBUG TRAIN Batch 17/100 loss 16.859806 loss_att 19.413790 loss_ctc 22.509771 loss_rnnt 15.479237 hw_loss 0.218328 lr 0.00041969 rank 7
2023-02-22 08:04:27,488 DEBUG TRAIN Batch 17/200 loss 7.100822 loss_att 9.603200 loss_ctc 14.296225 loss_rnnt 5.413994 hw_loss 0.425560 lr 0.00041958 rank 2
2023-02-22 08:04:27,490 DEBUG TRAIN Batch 17/200 loss 8.973007 loss_att 12.360099 loss_ctc 12.073048 loss_rnnt 7.717925 hw_loss 0.308109 lr 0.00041957 rank 6
2023-02-22 08:04:27,493 DEBUG TRAIN Batch 17/200 loss 5.453510 loss_att 8.984839 loss_ctc 8.853621 loss_rnnt 4.135911 hw_loss 0.296221 lr 0.00041967 rank 0
2023-02-22 08:04:27,493 DEBUG TRAIN Batch 17/200 loss 11.425674 loss_att 14.741287 loss_ctc 16.491100 loss_rnnt 10.019427 hw_loss 0.127004 lr 0.00041963 rank 1
2023-02-22 08:04:27,494 DEBUG TRAIN Batch 17/200 loss 8.893926 loss_att 13.144488 loss_ctc 9.761389 loss_rnnt 7.761071 hw_loss 0.313275 lr 0.00041958 rank 3
2023-02-22 08:04:27,496 DEBUG TRAIN Batch 17/200 loss 9.657625 loss_att 13.463441 loss_ctc 13.121890 loss_rnnt 8.290165 hw_loss 0.270741 lr 0.00041963 rank 4
2023-02-22 08:04:27,508 DEBUG TRAIN Batch 17/200 loss 19.671926 loss_att 20.647690 loss_ctc 21.875225 loss_rnnt 19.037954 hw_loss 0.271965 lr 0.00041955 rank 5
2023-02-22 08:04:27,541 DEBUG TRAIN Batch 17/200 loss 10.022357 loss_att 10.322670 loss_ctc 13.700622 loss_rnnt 9.281356 hw_loss 0.357195 lr 0.00041954 rank 7
2023-02-22 08:05:40,175 DEBUG TRAIN Batch 17/300 loss 10.641871 loss_att 11.072062 loss_ctc 11.012297 loss_rnnt 10.344955 hw_loss 0.302789 lr 0.00041939 rank 7
2023-02-22 08:05:40,184 DEBUG TRAIN Batch 17/300 loss 12.575132 loss_att 15.554631 loss_ctc 18.692612 loss_rnnt 11.039846 hw_loss 0.231982 lr 0.00041943 rank 2
2023-02-22 08:05:40,185 DEBUG TRAIN Batch 17/300 loss 9.086949 loss_att 11.505107 loss_ctc 12.361210 loss_rnnt 8.011572 hw_loss 0.290960 lr 0.00041948 rank 4
2023-02-22 08:05:40,185 DEBUG TRAIN Batch 17/300 loss 7.612082 loss_att 9.859079 loss_ctc 9.733749 loss_rnnt 6.711917 hw_loss 0.314768 lr 0.00041952 rank 0
2023-02-22 08:05:40,187 DEBUG TRAIN Batch 17/300 loss 5.998734 loss_att 8.555209 loss_ctc 10.271665 loss_rnnt 4.734255 hw_loss 0.343986 lr 0.00041948 rank 1
2023-02-22 08:05:40,190 DEBUG TRAIN Batch 17/300 loss 13.114202 loss_att 19.650234 loss_ctc 21.919722 loss_rnnt 10.502090 hw_loss 0.245320 lr 0.00041943 rank 3
2023-02-22 08:05:40,193 DEBUG TRAIN Batch 17/300 loss 17.978523 loss_att 21.243645 loss_ctc 26.301439 loss_rnnt 15.988601 hw_loss 0.425952 lr 0.00041942 rank 6
2023-02-22 08:05:40,219 DEBUG TRAIN Batch 17/300 loss 12.325268 loss_att 16.170580 loss_ctc 19.952316 loss_rnnt 10.373834 hw_loss 0.310183 lr 0.00041940 rank 5
2023-02-22 08:06:53,634 DEBUG TRAIN Batch 17/400 loss 8.799114 loss_att 13.195216 loss_ctc 13.091419 loss_rnnt 7.203459 hw_loss 0.270239 lr 0.00041928 rank 2
2023-02-22 08:06:53,640 DEBUG TRAIN Batch 17/400 loss 14.378867 loss_att 16.490757 loss_ctc 21.646749 loss_rnnt 12.864964 hw_loss 0.229639 lr 0.00041928 rank 3
2023-02-22 08:06:53,641 DEBUG TRAIN Batch 17/400 loss 13.110089 loss_att 16.029818 loss_ctc 19.011421 loss_rnnt 11.504435 hw_loss 0.440370 lr 0.00041937 rank 0
2023-02-22 08:06:53,641 DEBUG TRAIN Batch 17/400 loss 10.793003 loss_att 13.189404 loss_ctc 18.224926 loss_rnnt 9.171925 hw_loss 0.282891 lr 0.00041924 rank 7
2023-02-22 08:06:53,643 DEBUG TRAIN Batch 17/400 loss 7.996106 loss_att 10.369475 loss_ctc 9.652744 loss_rnnt 7.138603 hw_loss 0.303645 lr 0.00041928 rank 6
2023-02-22 08:06:53,645 DEBUG TRAIN Batch 17/400 loss 4.194663 loss_att 6.454093 loss_ctc 6.853972 loss_rnnt 3.256735 hw_loss 0.246501 lr 0.00041925 rank 5
2023-02-22 08:06:53,650 DEBUG TRAIN Batch 17/400 loss 14.734777 loss_att 15.878404 loss_ctc 18.310287 loss_rnnt 13.842566 hw_loss 0.350160 lr 0.00041934 rank 1
2023-02-22 08:06:53,651 DEBUG TRAIN Batch 17/400 loss 14.011512 loss_att 19.568642 loss_ctc 17.279436 loss_rnnt 12.355906 hw_loss 0.203357 lr 0.00041934 rank 4
2023-02-22 08:08:05,648 DEBUG TRAIN Batch 17/500 loss 6.179740 loss_att 8.691677 loss_ctc 8.665971 loss_rnnt 5.215702 hw_loss 0.244038 lr 0.00041914 rank 2
2023-02-22 08:08:05,651 DEBUG TRAIN Batch 17/500 loss 14.944926 loss_att 15.377944 loss_ctc 18.615019 loss_rnnt 14.237848 hw_loss 0.245865 lr 0.00041913 rank 6
2023-02-22 08:08:05,651 DEBUG TRAIN Batch 17/500 loss 12.920725 loss_att 14.330731 loss_ctc 16.254482 loss_rnnt 12.066519 hw_loss 0.239447 lr 0.00041913 rank 3
2023-02-22 08:08:05,652 DEBUG TRAIN Batch 17/500 loss 8.218492 loss_att 8.118616 loss_ctc 9.133475 loss_rnnt 8.031596 hw_loss 0.159136 lr 0.00041919 rank 4
2023-02-22 08:08:05,652 DEBUG TRAIN Batch 17/500 loss 8.374858 loss_att 11.343727 loss_ctc 12.706402 loss_rnnt 7.103386 hw_loss 0.187797 lr 0.00041922 rank 0
2023-02-22 08:08:05,653 DEBUG TRAIN Batch 17/500 loss 9.197796 loss_att 9.812801 loss_ctc 10.164510 loss_rnnt 8.804362 hw_loss 0.265383 lr 0.00041911 rank 5
2023-02-22 08:08:05,654 DEBUG TRAIN Batch 17/500 loss 9.580694 loss_att 12.401819 loss_ctc 18.154869 loss_rnnt 7.729713 hw_loss 0.269125 lr 0.00041919 rank 1
2023-02-22 08:08:05,656 DEBUG TRAIN Batch 17/500 loss 8.693985 loss_att 11.044169 loss_ctc 12.208299 loss_rnnt 7.612475 hw_loss 0.267933 lr 0.00041910 rank 7
2023-02-22 08:09:18,112 DEBUG TRAIN Batch 17/600 loss 9.654576 loss_att 12.591625 loss_ctc 13.271994 loss_rnnt 8.434431 hw_loss 0.282024 lr 0.00041899 rank 2
2023-02-22 08:09:18,117 DEBUG TRAIN Batch 17/600 loss 5.777479 loss_att 7.676141 loss_ctc 7.602599 loss_rnnt 4.957692 hw_loss 0.368822 lr 0.00041896 rank 5
2023-02-22 08:09:18,117 DEBUG TRAIN Batch 17/600 loss 14.306516 loss_att 15.832716 loss_ctc 17.775364 loss_rnnt 13.285271 hw_loss 0.475296 lr 0.00041895 rank 7
2023-02-22 08:09:18,118 DEBUG TRAIN Batch 17/600 loss 6.558701 loss_att 6.873777 loss_ctc 8.675221 loss_rnnt 5.842906 hw_loss 0.694833 lr 0.00041898 rank 6
2023-02-22 08:09:18,119 DEBUG TRAIN Batch 17/600 loss 9.033952 loss_att 9.075830 loss_ctc 11.755487 loss_rnnt 8.367879 hw_loss 0.552798 lr 0.00041899 rank 3
2023-02-22 08:09:18,120 DEBUG TRAIN Batch 17/600 loss 10.168154 loss_att 11.302347 loss_ctc 15.732702 loss_rnnt 8.988117 hw_loss 0.396109 lr 0.00041904 rank 1
2023-02-22 08:09:18,126 DEBUG TRAIN Batch 17/600 loss 9.168312 loss_att 10.830594 loss_ctc 11.645488 loss_rnnt 8.220530 hw_loss 0.534442 lr 0.00041904 rank 4
2023-02-22 08:09:18,170 DEBUG TRAIN Batch 17/600 loss 6.297377 loss_att 6.810297 loss_ctc 8.074008 loss_rnnt 5.696000 hw_loss 0.491079 lr 0.00041908 rank 0
2023-02-22 08:10:32,753 DEBUG TRAIN Batch 17/700 loss 14.000454 loss_att 15.168287 loss_ctc 16.990402 loss_rnnt 13.260154 hw_loss 0.202638 lr 0.00041883 rank 6
2023-02-22 08:10:32,754 DEBUG TRAIN Batch 17/700 loss 15.702808 loss_att 18.289539 loss_ctc 18.213863 loss_rnnt 14.758643 hw_loss 0.172522 lr 0.00041884 rank 2
2023-02-22 08:10:32,756 DEBUG TRAIN Batch 17/700 loss 4.652083 loss_att 8.052681 loss_ctc 6.410933 loss_rnnt 3.538790 hw_loss 0.372487 lr 0.00041893 rank 0
2023-02-22 08:10:32,758 DEBUG TRAIN Batch 17/700 loss 13.922343 loss_att 19.273718 loss_ctc 24.063625 loss_rnnt 11.425337 hw_loss 0.139800 lr 0.00041881 rank 5
2023-02-22 08:10:32,761 DEBUG TRAIN Batch 17/700 loss 8.188454 loss_att 10.272468 loss_ctc 12.457324 loss_rnnt 6.906319 hw_loss 0.555281 lr 0.00041889 rank 1
2023-02-22 08:10:32,776 DEBUG TRAIN Batch 17/700 loss 3.578187 loss_att 6.468777 loss_ctc 6.992845 loss_rnnt 2.420202 hw_loss 0.233586 lr 0.00041889 rank 4
2023-02-22 08:10:32,797 DEBUG TRAIN Batch 17/700 loss 4.654141 loss_att 8.792604 loss_ctc 8.329843 loss_rnnt 3.228448 hw_loss 0.202326 lr 0.00041884 rank 3
2023-02-22 08:10:32,828 DEBUG TRAIN Batch 17/700 loss 15.737198 loss_att 19.727457 loss_ctc 19.400688 loss_rnnt 14.317299 hw_loss 0.250090 lr 0.00041880 rank 7
2023-02-22 08:11:45,758 DEBUG TRAIN Batch 17/800 loss 11.650571 loss_att 12.816124 loss_ctc 15.197654 loss_rnnt 10.802729 hw_loss 0.265849 lr 0.00041870 rank 2
2023-02-22 08:11:45,760 DEBUG TRAIN Batch 17/800 loss 11.223783 loss_att 16.294851 loss_ctc 17.910301 loss_rnnt 9.178028 hw_loss 0.262511 lr 0.00041869 rank 3
2023-02-22 08:11:45,764 DEBUG TRAIN Batch 17/800 loss 11.572725 loss_att 15.492072 loss_ctc 14.881405 loss_rnnt 10.164078 hw_loss 0.344290 lr 0.00041869 rank 6
2023-02-22 08:11:45,765 DEBUG TRAIN Batch 17/800 loss 7.568268 loss_att 8.992013 loss_ctc 8.981079 loss_rnnt 7.005385 hw_loss 0.168298 lr 0.00041875 rank 1
2023-02-22 08:11:45,768 DEBUG TRAIN Batch 17/800 loss 14.696548 loss_att 18.291252 loss_ctc 22.541449 loss_rnnt 12.705131 hw_loss 0.424669 lr 0.00041878 rank 0
2023-02-22 08:11:45,768 DEBUG TRAIN Batch 17/800 loss 3.763865 loss_att 6.724701 loss_ctc 5.111907 loss_rnnt 2.899191 hw_loss 0.173939 lr 0.00041865 rank 7
2023-02-22 08:11:45,769 DEBUG TRAIN Batch 17/800 loss 8.808544 loss_att 9.790184 loss_ctc 14.538054 loss_rnnt 7.678482 hw_loss 0.318376 lr 0.00041875 rank 4
2023-02-22 08:11:45,770 DEBUG TRAIN Batch 17/800 loss 11.540833 loss_att 12.328287 loss_ctc 13.084932 loss_rnnt 11.091830 hw_loss 0.160559 lr 0.00041867 rank 5
2023-02-22 08:12:58,148 DEBUG TRAIN Batch 17/900 loss 4.851575 loss_att 11.619974 loss_ctc 7.194874 loss_rnnt 3.053030 hw_loss 0.248296 lr 0.00041864 rank 0
2023-02-22 08:12:58,150 DEBUG TRAIN Batch 17/900 loss 10.667053 loss_att 15.455214 loss_ctc 12.358301 loss_rnnt 9.353170 hw_loss 0.245158 lr 0.00041860 rank 1
2023-02-22 08:12:58,152 DEBUG TRAIN Batch 17/900 loss 9.600442 loss_att 12.803326 loss_ctc 17.413769 loss_rnnt 7.716512 hw_loss 0.377956 lr 0.00041855 rank 2
2023-02-22 08:12:58,153 DEBUG TRAIN Batch 17/900 loss 5.374761 loss_att 5.985050 loss_ctc 5.521693 loss_rnnt 5.116754 hw_loss 0.218172 lr 0.00041854 rank 6
2023-02-22 08:12:58,153 DEBUG TRAIN Batch 17/900 loss 10.917655 loss_att 15.927380 loss_ctc 15.322721 loss_rnnt 9.196880 hw_loss 0.246540 lr 0.00041851 rank 7
2023-02-22 08:12:58,154 DEBUG TRAIN Batch 17/900 loss 9.800951 loss_att 12.054540 loss_ctc 11.922169 loss_rnnt 8.995335 hw_loss 0.135131 lr 0.00041855 rank 3
2023-02-22 08:12:58,153 DEBUG TRAIN Batch 17/900 loss 19.894661 loss_att 22.566252 loss_ctc 29.410271 loss_rnnt 17.907316 hw_loss 0.345524 lr 0.00041852 rank 5
2023-02-22 08:12:58,158 DEBUG TRAIN Batch 17/900 loss 7.965574 loss_att 10.828659 loss_ctc 9.638103 loss_rnnt 7.016922 hw_loss 0.286933 lr 0.00041860 rank 4
2023-02-22 08:14:11,432 DEBUG TRAIN Batch 17/1000 loss 13.509185 loss_att 14.634383 loss_ctc 17.517227 loss_rnnt 12.558764 hw_loss 0.358078 lr 0.00041845 rank 4
2023-02-22 08:14:11,439 DEBUG TRAIN Batch 17/1000 loss 17.802078 loss_att 19.606323 loss_ctc 24.077070 loss_rnnt 16.440948 hw_loss 0.306780 lr 0.00041837 rank 5
2023-02-22 08:14:11,445 DEBUG TRAIN Batch 17/1000 loss 6.585847 loss_att 9.889282 loss_ctc 9.059240 loss_rnnt 5.487787 hw_loss 0.201726 lr 0.00041839 rank 6
2023-02-22 08:14:11,446 DEBUG TRAIN Batch 17/1000 loss 8.331677 loss_att 11.698491 loss_ctc 11.989144 loss_rnnt 7.092623 hw_loss 0.146303 lr 0.00041845 rank 1
2023-02-22 08:14:11,445 DEBUG TRAIN Batch 17/1000 loss 9.144066 loss_att 13.050901 loss_ctc 12.321226 loss_rnnt 7.802144 hw_loss 0.256750 lr 0.00041840 rank 3
2023-02-22 08:14:11,446 DEBUG TRAIN Batch 17/1000 loss 10.370609 loss_att 11.685450 loss_ctc 14.122234 loss_rnnt 9.497295 hw_loss 0.206493 lr 0.00041840 rank 2
2023-02-22 08:14:11,448 DEBUG TRAIN Batch 17/1000 loss 11.136294 loss_att 17.272543 loss_ctc 18.000799 loss_rnnt 8.836334 hw_loss 0.295206 lr 0.00041836 rank 7
2023-02-22 08:14:11,448 DEBUG TRAIN Batch 17/1000 loss 7.708725 loss_att 10.572831 loss_ctc 13.317394 loss_rnnt 6.276355 hw_loss 0.209488 lr 0.00041849 rank 0
2023-02-22 08:15:25,459 DEBUG TRAIN Batch 17/1100 loss 17.647818 loss_att 17.876308 loss_ctc 23.096043 loss_rnnt 16.802961 hw_loss 0.136366 lr 0.00041823 rank 5
2023-02-22 08:15:25,465 DEBUG TRAIN Batch 17/1100 loss 10.757387 loss_att 11.436348 loss_ctc 16.114283 loss_rnnt 9.702284 hw_loss 0.384483 lr 0.00041831 rank 1
2023-02-22 08:15:25,471 DEBUG TRAIN Batch 17/1100 loss 4.871590 loss_att 7.855523 loss_ctc 5.831720 loss_rnnt 3.962266 hw_loss 0.345974 lr 0.00041825 rank 3
2023-02-22 08:15:25,473 DEBUG TRAIN Batch 17/1100 loss 8.101960 loss_att 12.596889 loss_ctc 9.561193 loss_rnnt 6.904923 hw_loss 0.194038 lr 0.00041826 rank 2
2023-02-22 08:15:25,478 DEBUG TRAIN Batch 17/1100 loss 10.485705 loss_att 13.113912 loss_ctc 15.394470 loss_rnnt 9.146734 hw_loss 0.297802 lr 0.00041825 rank 6
2023-02-22 08:15:25,479 DEBUG TRAIN Batch 17/1100 loss 31.191404 loss_att 32.354172 loss_ctc 35.903587 loss_rnnt 30.153034 hw_loss 0.332855 lr 0.00041821 rank 7
2023-02-22 08:15:25,487 DEBUG TRAIN Batch 17/1100 loss 4.963797 loss_att 7.386016 loss_ctc 6.618464 loss_rnnt 4.093500 hw_loss 0.309807 lr 0.00041834 rank 0
2023-02-22 08:15:25,526 DEBUG TRAIN Batch 17/1100 loss 6.479974 loss_att 10.439740 loss_ctc 10.476277 loss_rnnt 4.985812 hw_loss 0.317565 lr 0.00041831 rank 4
2023-02-22 08:16:38,061 DEBUG TRAIN Batch 17/1200 loss 7.906421 loss_att 9.103819 loss_ctc 10.035571 loss_rnnt 7.268213 hw_loss 0.215329 lr 0.00041811 rank 2
2023-02-22 08:16:38,068 DEBUG TRAIN Batch 17/1200 loss 9.044611 loss_att 10.744957 loss_ctc 9.352212 loss_rnnt 8.529899 hw_loss 0.250555 lr 0.00041811 rank 3
2023-02-22 08:16:38,069 DEBUG TRAIN Batch 17/1200 loss 14.382849 loss_att 17.076645 loss_ctc 18.782537 loss_rnnt 13.116012 hw_loss 0.265225 lr 0.00041816 rank 4
2023-02-22 08:16:38,070 DEBUG TRAIN Batch 17/1200 loss 10.762081 loss_att 11.971053 loss_ctc 16.905371 loss_rnnt 9.564500 hw_loss 0.256276 lr 0.00041816 rank 1
2023-02-22 08:16:38,073 DEBUG TRAIN Batch 17/1200 loss 11.419384 loss_att 13.963146 loss_ctc 14.588478 loss_rnnt 10.338943 hw_loss 0.279641 lr 0.00041808 rank 5
2023-02-22 08:16:38,073 DEBUG TRAIN Batch 17/1200 loss 7.284250 loss_att 7.433923 loss_ctc 9.483831 loss_rnnt 6.788515 hw_loss 0.323480 lr 0.00041807 rank 7
2023-02-22 08:16:38,074 DEBUG TRAIN Batch 17/1200 loss 27.640951 loss_att 27.310837 loss_ctc 38.941883 loss_rnnt 26.005827 hw_loss 0.364419 lr 0.00041810 rank 6
2023-02-22 08:16:38,075 DEBUG TRAIN Batch 17/1200 loss 8.273815 loss_att 9.801867 loss_ctc 10.917237 loss_rnnt 7.376305 hw_loss 0.448955 lr 0.00041820 rank 0
2023-02-22 08:17:50,726 DEBUG TRAIN Batch 17/1300 loss 14.629238 loss_att 14.169519 loss_ctc 18.703016 loss_rnnt 13.842949 hw_loss 0.628243 lr 0.00041796 rank 2
2023-02-22 08:17:50,730 DEBUG TRAIN Batch 17/1300 loss 13.280889 loss_att 16.070456 loss_ctc 15.282421 loss_rnnt 12.273657 hw_loss 0.342090 lr 0.00041796 rank 3
2023-02-22 08:17:50,733 DEBUG TRAIN Batch 17/1300 loss 12.728026 loss_att 15.194639 loss_ctc 19.010756 loss_rnnt 11.284613 hw_loss 0.210740 lr 0.00041801 rank 1
2023-02-22 08:17:50,737 DEBUG TRAIN Batch 17/1300 loss 8.981810 loss_att 10.504824 loss_ctc 11.963342 loss_rnnt 8.134611 hw_loss 0.271983 lr 0.00041793 rank 5
2023-02-22 08:17:50,737 DEBUG TRAIN Batch 17/1300 loss 7.088437 loss_att 10.560472 loss_ctc 12.720385 loss_rnnt 5.558299 hw_loss 0.159009 lr 0.00041796 rank 6
2023-02-22 08:17:50,737 DEBUG TRAIN Batch 17/1300 loss 9.804590 loss_att 12.529440 loss_ctc 11.248893 loss_rnnt 8.923555 hw_loss 0.269047 lr 0.00041805 rank 0
2023-02-22 08:17:50,739 DEBUG TRAIN Batch 17/1300 loss 15.023734 loss_att 18.970755 loss_ctc 21.096359 loss_rnnt 13.299666 hw_loss 0.234337 lr 0.00041792 rank 7
2023-02-22 08:17:50,743 DEBUG TRAIN Batch 17/1300 loss 16.950592 loss_att 19.400887 loss_ctc 23.669613 loss_rnnt 15.438209 hw_loss 0.237104 lr 0.00041801 rank 4
2023-02-22 08:19:04,499 DEBUG TRAIN Batch 17/1400 loss 11.097401 loss_att 14.650401 loss_ctc 16.298138 loss_rnnt 9.568706 hw_loss 0.233743 lr 0.00041790 rank 0
2023-02-22 08:19:04,498 DEBUG TRAIN Batch 17/1400 loss 6.512786 loss_att 7.949974 loss_ctc 6.906898 loss_rnnt 6.054147 hw_loss 0.222475 lr 0.00041787 rank 4
2023-02-22 08:19:04,510 DEBUG TRAIN Batch 17/1400 loss 6.736344 loss_att 7.925968 loss_ctc 8.886956 loss_rnnt 6.135661 hw_loss 0.142519 lr 0.00041778 rank 7
2023-02-22 08:19:04,511 DEBUG TRAIN Batch 17/1400 loss 6.353161 loss_att 7.916548 loss_ctc 8.700087 loss_rnnt 5.654285 hw_loss 0.137391 lr 0.00041782 rank 2
2023-02-22 08:19:04,511 DEBUG TRAIN Batch 17/1400 loss 16.053753 loss_att 16.854210 loss_ctc 20.230198 loss_rnnt 15.197794 hw_loss 0.260637 lr 0.00041782 rank 3
2023-02-22 08:19:04,511 DEBUG TRAIN Batch 17/1400 loss 10.139946 loss_att 11.244665 loss_ctc 16.290737 loss_rnnt 8.855603 hw_loss 0.456173 lr 0.00041781 rank 6
2023-02-22 08:19:04,514 DEBUG TRAIN Batch 17/1400 loss 3.859964 loss_att 6.674764 loss_ctc 6.952337 loss_rnnt 2.695936 hw_loss 0.353911 lr 0.00041787 rank 1
2023-02-22 08:19:04,518 DEBUG TRAIN Batch 17/1400 loss 8.293846 loss_att 10.905936 loss_ctc 10.163704 loss_rnnt 7.362735 hw_loss 0.298835 lr 0.00041779 rank 5
2023-02-22 08:20:16,855 DEBUG TRAIN Batch 17/1500 loss 2.313773 loss_att 5.938828 loss_ctc 3.173010 loss_rnnt 1.317786 hw_loss 0.293271 lr 0.00041767 rank 2
2023-02-22 08:20:16,855 DEBUG TRAIN Batch 17/1500 loss 19.106703 loss_att 21.033415 loss_ctc 20.851349 loss_rnnt 18.312607 hw_loss 0.330254 lr 0.00041767 rank 3
2023-02-22 08:20:16,858 DEBUG TRAIN Batch 17/1500 loss 10.059263 loss_att 13.002419 loss_ctc 13.316076 loss_rnnt 8.936749 hw_loss 0.186828 lr 0.00041772 rank 4
2023-02-22 08:20:16,859 DEBUG TRAIN Batch 17/1500 loss 9.770407 loss_att 16.796940 loss_ctc 14.985045 loss_rnnt 7.591499 hw_loss 0.146841 lr 0.00041766 rank 6
2023-02-22 08:20:16,863 DEBUG TRAIN Batch 17/1500 loss 5.822944 loss_att 8.831065 loss_ctc 9.803820 loss_rnnt 4.612258 hw_loss 0.146770 lr 0.00041764 rank 5
2023-02-22 08:20:16,863 DEBUG TRAIN Batch 17/1500 loss 5.785677 loss_att 8.671955 loss_ctc 8.391309 loss_rnnt 4.745807 hw_loss 0.215996 lr 0.00041772 rank 1
2023-02-22 08:20:16,863 DEBUG TRAIN Batch 17/1500 loss 9.215672 loss_att 10.317959 loss_ctc 11.635155 loss_rnnt 8.629185 hw_loss 0.081434 lr 0.00041763 rank 7
2023-02-22 08:20:16,865 DEBUG TRAIN Batch 17/1500 loss 8.033117 loss_att 10.467975 loss_ctc 9.095459 loss_rnnt 7.232318 hw_loss 0.322842 lr 0.00041776 rank 0
2023-02-22 08:21:29,157 DEBUG TRAIN Batch 17/1600 loss 12.223039 loss_att 11.996230 loss_ctc 14.060726 loss_rnnt 11.894261 hw_loss 0.242088 lr 0.00041752 rank 3
2023-02-22 08:21:29,159 DEBUG TRAIN Batch 17/1600 loss 5.478111 loss_att 8.927687 loss_ctc 8.387444 loss_rnnt 4.221807 hw_loss 0.334647 lr 0.00041753 rank 2
2023-02-22 08:21:29,160 DEBUG TRAIN Batch 17/1600 loss 9.851356 loss_att 12.378132 loss_ctc 11.123155 loss_rnnt 9.057312 hw_loss 0.223340 lr 0.00041761 rank 0
2023-02-22 08:21:29,162 DEBUG TRAIN Batch 17/1600 loss 13.783813 loss_att 15.760918 loss_ctc 15.070957 loss_rnnt 13.050238 hw_loss 0.312254 lr 0.00041749 rank 7
2023-02-22 08:21:29,163 DEBUG TRAIN Batch 17/1600 loss 13.883467 loss_att 16.546747 loss_ctc 18.415472 loss_rnnt 12.634372 hw_loss 0.210323 lr 0.00041758 rank 4
2023-02-22 08:21:29,163 DEBUG TRAIN Batch 17/1600 loss 6.869509 loss_att 9.046286 loss_ctc 9.109713 loss_rnnt 6.067811 hw_loss 0.126843 lr 0.00041758 rank 1
2023-02-22 08:21:29,164 DEBUG TRAIN Batch 17/1600 loss 12.457956 loss_att 15.072052 loss_ctc 18.837688 loss_rnnt 10.947756 hw_loss 0.256404 lr 0.00041752 rank 6
2023-02-22 08:21:29,218 DEBUG TRAIN Batch 17/1600 loss 8.564801 loss_att 13.328723 loss_ctc 11.820558 loss_rnnt 7.013344 hw_loss 0.308571 lr 0.00041750 rank 5
2023-02-22 08:22:42,332 DEBUG TRAIN Batch 17/1700 loss 7.040388 loss_att 10.968701 loss_ctc 11.084083 loss_rnnt 5.551621 hw_loss 0.307396 lr 0.00041738 rank 3
2023-02-22 08:22:42,334 DEBUG TRAIN Batch 17/1700 loss 8.661602 loss_att 11.214063 loss_ctc 12.649379 loss_rnnt 7.483944 hw_loss 0.253990 lr 0.00041737 rank 6
2023-02-22 08:22:42,335 DEBUG TRAIN Batch 17/1700 loss 7.180664 loss_att 11.646029 loss_ctc 9.872257 loss_rnnt 5.794886 hw_loss 0.250922 lr 0.00041738 rank 2
2023-02-22 08:22:42,336 DEBUG TRAIN Batch 17/1700 loss 9.765567 loss_att 11.879168 loss_ctc 14.186489 loss_rnnt 8.575601 hw_loss 0.333355 lr 0.00041743 rank 1
2023-02-22 08:22:42,336 DEBUG TRAIN Batch 17/1700 loss 11.440173 loss_att 12.042557 loss_ctc 16.064978 loss_rnnt 10.615295 hw_loss 0.164549 lr 0.00041734 rank 7
2023-02-22 08:22:42,339 DEBUG TRAIN Batch 17/1700 loss 19.084034 loss_att 24.598766 loss_ctc 27.595890 loss_rnnt 16.701342 hw_loss 0.271556 lr 0.00041747 rank 0
2023-02-22 08:22:42,342 DEBUG TRAIN Batch 17/1700 loss 22.869059 loss_att 25.789070 loss_ctc 35.157009 loss_rnnt 20.541765 hw_loss 0.196679 lr 0.00041735 rank 5
2023-02-22 08:22:42,383 DEBUG TRAIN Batch 17/1700 loss 11.533046 loss_att 16.424801 loss_ctc 13.825699 loss_rnnt 10.155049 hw_loss 0.176170 lr 0.00041743 rank 4
2023-02-22 08:23:56,830 DEBUG TRAIN Batch 17/1800 loss 14.498830 loss_att 18.524353 loss_ctc 19.453766 loss_rnnt 12.872037 hw_loss 0.301932 lr 0.00041723 rank 2
2023-02-22 08:23:56,836 DEBUG TRAIN Batch 17/1800 loss 9.618669 loss_att 11.918903 loss_ctc 13.308243 loss_rnnt 8.520123 hw_loss 0.274793 lr 0.00041732 rank 0
2023-02-22 08:23:56,835 DEBUG TRAIN Batch 17/1800 loss 12.612575 loss_att 13.274915 loss_ctc 17.533268 loss_rnnt 11.650625 hw_loss 0.325105 lr 0.00041723 rank 3
2023-02-22 08:23:56,838 DEBUG TRAIN Batch 17/1800 loss 16.016754 loss_att 17.501631 loss_ctc 21.015814 loss_rnnt 14.796550 hw_loss 0.481292 lr 0.00041719 rank 7
2023-02-22 08:23:56,838 DEBUG TRAIN Batch 17/1800 loss 18.567652 loss_att 19.212036 loss_ctc 23.265598 loss_rnnt 17.668852 hw_loss 0.269121 lr 0.00041723 rank 6
2023-02-22 08:23:56,839 DEBUG TRAIN Batch 17/1800 loss 16.170538 loss_att 16.707249 loss_ctc 18.407938 loss_rnnt 15.641828 hw_loss 0.230718 lr 0.00041729 rank 1
2023-02-22 08:23:56,839 DEBUG TRAIN Batch 17/1800 loss 13.026844 loss_att 15.278538 loss_ctc 18.029888 loss_rnnt 11.796913 hw_loss 0.210973 lr 0.00041729 rank 4
2023-02-22 08:23:56,841 DEBUG TRAIN Batch 17/1800 loss 15.864939 loss_att 18.215530 loss_ctc 23.738369 loss_rnnt 14.170684 hw_loss 0.326898 lr 0.00041721 rank 5
2023-02-22 08:25:09,389 DEBUG TRAIN Batch 17/1900 loss 11.244170 loss_att 14.055957 loss_ctc 16.032703 loss_rnnt 9.949901 hw_loss 0.175201 lr 0.00041714 rank 1
2023-02-22 08:25:09,392 DEBUG TRAIN Batch 17/1900 loss 11.601047 loss_att 14.096495 loss_ctc 17.467117 loss_rnnt 10.160595 hw_loss 0.298536 lr 0.00041709 rank 2
2023-02-22 08:25:09,393 DEBUG TRAIN Batch 17/1900 loss 15.455021 loss_att 18.987949 loss_ctc 21.682735 loss_rnnt 13.819407 hw_loss 0.184998 lr 0.00041708 rank 6
2023-02-22 08:25:09,394 DEBUG TRAIN Batch 17/1900 loss 10.672456 loss_att 10.326633 loss_ctc 12.035296 loss_rnnt 10.242271 hw_loss 0.595570 lr 0.00041705 rank 7
2023-02-22 08:25:09,396 DEBUG TRAIN Batch 17/1900 loss 5.386868 loss_att 6.018588 loss_ctc 8.443149 loss_rnnt 4.657938 hw_loss 0.365778 lr 0.00041709 rank 3
2023-02-22 08:25:09,399 DEBUG TRAIN Batch 17/1900 loss 10.644821 loss_att 11.798213 loss_ctc 14.561894 loss_rnnt 9.616095 hw_loss 0.517072 lr 0.00041718 rank 0
2023-02-22 08:25:09,401 DEBUG TRAIN Batch 17/1900 loss 16.008556 loss_att 15.053570 loss_ctc 22.627090 loss_rnnt 15.032638 hw_loss 0.533335 lr 0.00041714 rank 4
2023-02-22 08:25:09,405 DEBUG TRAIN Batch 17/1900 loss 12.608135 loss_att 14.998855 loss_ctc 16.559532 loss_rnnt 11.436946 hw_loss 0.311610 lr 0.00041706 rank 5
2023-02-22 08:26:21,549 DEBUG TRAIN Batch 17/2000 loss 5.862283 loss_att 9.355171 loss_ctc 6.767460 loss_rnnt 4.915409 hw_loss 0.239260 lr 0.00041703 rank 0
2023-02-22 08:26:21,552 DEBUG TRAIN Batch 17/2000 loss 7.963936 loss_att 10.900859 loss_ctc 10.303850 loss_rnnt 6.970392 hw_loss 0.176572 lr 0.00041700 rank 1
2023-02-22 08:26:21,562 DEBUG TRAIN Batch 17/2000 loss 7.552360 loss_att 7.179693 loss_ctc 6.064092 loss_rnnt 7.739978 hw_loss 0.160033 lr 0.00041690 rank 7
2023-02-22 08:26:21,562 DEBUG TRAIN Batch 17/2000 loss 8.402005 loss_att 10.229724 loss_ctc 9.838228 loss_rnnt 7.667819 hw_loss 0.332148 lr 0.00041694 rank 6
2023-02-22 08:26:21,563 DEBUG TRAIN Batch 17/2000 loss 18.521544 loss_att 23.368137 loss_ctc 31.314583 loss_rnnt 15.725304 hw_loss 0.227217 lr 0.00041694 rank 2
2023-02-22 08:26:21,569 DEBUG TRAIN Batch 17/2000 loss 6.646815 loss_att 12.344189 loss_ctc 10.013748 loss_rnnt 4.940424 hw_loss 0.221236 lr 0.00041694 rank 3
2023-02-22 08:26:21,574 DEBUG TRAIN Batch 17/2000 loss 13.972578 loss_att 18.081030 loss_ctc 21.779654 loss_rnnt 12.033440 hw_loss 0.143446 lr 0.00041692 rank 5
2023-02-22 08:26:21,613 DEBUG TRAIN Batch 17/2000 loss 6.168453 loss_att 10.503306 loss_ctc 8.979024 loss_rnnt 4.820379 hw_loss 0.199425 lr 0.00041700 rank 4
2023-02-22 08:27:36,091 DEBUG TRAIN Batch 17/2100 loss 8.663486 loss_att 12.834171 loss_ctc 13.973227 loss_rnnt 7.061131 hw_loss 0.112973 lr 0.00041689 rank 0
2023-02-22 08:27:36,101 DEBUG TRAIN Batch 17/2100 loss 5.991250 loss_att 7.944504 loss_ctc 9.450293 loss_rnnt 4.884332 hw_loss 0.478240 lr 0.00041680 rank 2
2023-02-22 08:27:36,101 DEBUG TRAIN Batch 17/2100 loss 29.930374 loss_att 32.522720 loss_ctc 38.026340 loss_rnnt 28.227377 hw_loss 0.197002 lr 0.00041677 rank 5
2023-02-22 08:27:36,104 DEBUG TRAIN Batch 17/2100 loss 3.271696 loss_att 8.197834 loss_ctc 4.090561 loss_rnnt 2.036458 hw_loss 0.264052 lr 0.00041685 rank 4
2023-02-22 08:27:36,105 DEBUG TRAIN Batch 17/2100 loss 8.056596 loss_att 12.552137 loss_ctc 12.025725 loss_rnnt 6.527759 hw_loss 0.188460 lr 0.00041685 rank 1
2023-02-22 08:27:36,105 DEBUG TRAIN Batch 17/2100 loss 10.171992 loss_att 14.573782 loss_ctc 13.100196 loss_rnnt 8.788085 hw_loss 0.212104 lr 0.00041680 rank 3
2023-02-22 08:27:36,106 DEBUG TRAIN Batch 17/2100 loss 23.630678 loss_att 25.332563 loss_ctc 26.254711 loss_rnnt 22.900646 hw_loss 0.074594 lr 0.00041679 rank 6
2023-02-22 08:27:36,134 DEBUG TRAIN Batch 17/2100 loss 9.863916 loss_att 11.453653 loss_ctc 11.537153 loss_rnnt 9.079154 hw_loss 0.456970 lr 0.00041676 rank 7
2023-02-22 08:28:48,919 DEBUG TRAIN Batch 17/2200 loss 15.291806 loss_att 19.361698 loss_ctc 20.248590 loss_rnnt 13.693040 hw_loss 0.232279 lr 0.00041666 rank 2
2023-02-22 08:28:48,930 DEBUG TRAIN Batch 17/2200 loss 21.101692 loss_att 22.913734 loss_ctc 24.854633 loss_rnnt 20.140099 hw_loss 0.185231 lr 0.00041674 rank 0
2023-02-22 08:28:48,930 DEBUG TRAIN Batch 17/2200 loss 8.131173 loss_att 10.851768 loss_ctc 10.009678 loss_rnnt 7.217477 hw_loss 0.223329 lr 0.00041665 rank 3
2023-02-22 08:28:48,932 DEBUG TRAIN Batch 17/2200 loss 12.160861 loss_att 15.896891 loss_ctc 17.486931 loss_rnnt 10.596263 hw_loss 0.201091 lr 0.00041665 rank 6
2023-02-22 08:28:48,933 DEBUG TRAIN Batch 17/2200 loss 9.956793 loss_att 12.836241 loss_ctc 14.025791 loss_rnnt 8.683268 hw_loss 0.290817 lr 0.00041661 rank 7
2023-02-22 08:28:48,933 DEBUG TRAIN Batch 17/2200 loss 14.969028 loss_att 19.254915 loss_ctc 23.353964 loss_rnnt 12.895869 hw_loss 0.183727 lr 0.00041671 rank 4
2023-02-22 08:28:48,937 DEBUG TRAIN Batch 17/2200 loss 24.056725 loss_att 27.995583 loss_ctc 33.138596 loss_rnnt 21.984406 hw_loss 0.138058 lr 0.00041671 rank 1
2023-02-22 08:28:48,945 DEBUG TRAIN Batch 17/2200 loss 5.340213 loss_att 8.052868 loss_ctc 9.250891 loss_rnnt 4.233782 hw_loss 0.079644 lr 0.00041663 rank 5
2023-02-22 08:30:00,494 DEBUG TRAIN Batch 17/2300 loss 10.021379 loss_att 14.275389 loss_ctc 15.159844 loss_rnnt 8.404357 hw_loss 0.152048 lr 0.00041651 rank 2
2023-02-22 08:30:00,504 DEBUG TRAIN Batch 17/2300 loss 13.288691 loss_att 14.789366 loss_ctc 16.679390 loss_rnnt 12.424260 hw_loss 0.210378 lr 0.00041650 rank 6
2023-02-22 08:30:00,506 DEBUG TRAIN Batch 17/2300 loss 6.541212 loss_att 10.536951 loss_ctc 5.992839 loss_rnnt 5.670977 hw_loss 0.270382 lr 0.00041648 rank 5
2023-02-22 08:30:00,510 DEBUG TRAIN Batch 17/2300 loss 14.402724 loss_att 14.330063 loss_ctc 17.670130 loss_rnnt 13.853691 hw_loss 0.239835 lr 0.00041651 rank 3
2023-02-22 08:30:00,511 DEBUG TRAIN Batch 17/2300 loss 7.806937 loss_att 12.632257 loss_ctc 10.860748 loss_rnnt 6.209191 hw_loss 0.422825 lr 0.00041656 rank 4
2023-02-22 08:30:00,512 DEBUG TRAIN Batch 17/2300 loss 12.575337 loss_att 15.172586 loss_ctc 14.781035 loss_rnnt 11.629045 hw_loss 0.248901 lr 0.00041656 rank 1
2023-02-22 08:30:00,513 DEBUG TRAIN Batch 17/2300 loss 9.874065 loss_att 10.690553 loss_ctc 11.783419 loss_rnnt 9.341097 hw_loss 0.215795 lr 0.00041660 rank 0
2023-02-22 08:30:00,515 DEBUG TRAIN Batch 17/2300 loss 9.476558 loss_att 12.249290 loss_ctc 14.529935 loss_rnnt 8.054901 hw_loss 0.362487 lr 0.00041647 rank 7
2023-02-22 08:31:13,202 DEBUG TRAIN Batch 17/2400 loss 9.558770 loss_att 12.480625 loss_ctc 14.669161 loss_rnnt 8.147723 hw_loss 0.272420 lr 0.00041642 rank 4
2023-02-22 08:31:13,206 DEBUG TRAIN Batch 17/2400 loss 11.661540 loss_att 12.488536 loss_ctc 13.600760 loss_rnnt 11.072520 hw_loss 0.309483 lr 0.00041636 rank 6
2023-02-22 08:31:13,208 DEBUG TRAIN Batch 17/2400 loss 6.770728 loss_att 10.857365 loss_ctc 9.341075 loss_rnnt 5.503160 hw_loss 0.201616 lr 0.00041634 rank 5
2023-02-22 08:31:13,210 DEBUG TRAIN Batch 17/2400 loss 11.524954 loss_att 12.710766 loss_ctc 14.015776 loss_rnnt 10.859893 hw_loss 0.179604 lr 0.00041636 rank 3
2023-02-22 08:31:13,221 DEBUG TRAIN Batch 17/2400 loss 8.945821 loss_att 14.222934 loss_ctc 14.349019 loss_rnnt 7.054383 hw_loss 0.216729 lr 0.00041633 rank 7
2023-02-22 08:31:13,229 DEBUG TRAIN Batch 17/2400 loss 8.977045 loss_att 12.315367 loss_ctc 10.200961 loss_rnnt 7.980251 hw_loss 0.311139 lr 0.00041642 rank 1
2023-02-22 08:31:13,233 DEBUG TRAIN Batch 17/2400 loss 7.871451 loss_att 10.351061 loss_ctc 8.970533 loss_rnnt 7.077694 hw_loss 0.283670 lr 0.00041637 rank 2
2023-02-22 08:31:13,260 DEBUG TRAIN Batch 17/2400 loss 8.707107 loss_att 9.863890 loss_ctc 11.366772 loss_rnnt 7.908945 hw_loss 0.397842 lr 0.00041645 rank 0
2023-02-22 08:32:29,347 DEBUG TRAIN Batch 17/2500 loss 14.078664 loss_att 15.666101 loss_ctc 23.187017 loss_rnnt 12.345944 hw_loss 0.376471 lr 0.00041622 rank 2
2023-02-22 08:32:29,349 DEBUG TRAIN Batch 17/2500 loss 12.853294 loss_att 12.600446 loss_ctc 15.966259 loss_rnnt 12.343563 hw_loss 0.272323 lr 0.00041622 rank 3
2023-02-22 08:32:29,349 DEBUG TRAIN Batch 17/2500 loss 8.012093 loss_att 9.872665 loss_ctc 9.834992 loss_rnnt 7.263054 hw_loss 0.251007 lr 0.00041621 rank 6
2023-02-22 08:32:29,350 DEBUG TRAIN Batch 17/2500 loss 6.406686 loss_att 8.948652 loss_ctc 10.816258 loss_rnnt 5.173295 hw_loss 0.256976 lr 0.00041618 rank 7
2023-02-22 08:32:29,354 DEBUG TRAIN Batch 17/2500 loss 18.079626 loss_att 17.210831 loss_ctc 22.787285 loss_rnnt 17.475140 hw_loss 0.282299 lr 0.00041627 rank 4
2023-02-22 08:32:29,355 DEBUG TRAIN Batch 17/2500 loss 15.263907 loss_att 14.682562 loss_ctc 17.700235 loss_rnnt 14.822390 hw_loss 0.436766 lr 0.00041631 rank 0
2023-02-22 08:32:29,356 DEBUG TRAIN Batch 17/2500 loss 11.506274 loss_att 12.344419 loss_ctc 10.796260 loss_rnnt 11.243173 hw_loss 0.356515 lr 0.00041627 rank 1
2023-02-22 08:32:29,358 DEBUG TRAIN Batch 17/2500 loss 26.478716 loss_att 24.192862 loss_ctc 34.024742 loss_rnnt 25.771774 hw_loss 0.296209 lr 0.00041619 rank 5
2023-02-22 08:33:41,787 DEBUG TRAIN Batch 17/2600 loss 18.585123 loss_att 23.867012 loss_ctc 26.296446 loss_rnnt 16.417255 hw_loss 0.156211 lr 0.00041608 rank 3
2023-02-22 08:33:41,794 DEBUG TRAIN Batch 17/2600 loss 16.562132 loss_att 20.525677 loss_ctc 22.128576 loss_rnnt 14.813522 hw_loss 0.400700 lr 0.00041608 rank 2
2023-02-22 08:33:41,800 DEBUG TRAIN Batch 17/2600 loss 7.717613 loss_att 12.303896 loss_ctc 11.549974 loss_rnnt 6.201333 hw_loss 0.165077 lr 0.00041616 rank 0
2023-02-22 08:33:41,802 DEBUG TRAIN Batch 17/2600 loss 6.038390 loss_att 7.940102 loss_ctc 7.983873 loss_rnnt 5.246762 hw_loss 0.284789 lr 0.00041607 rank 6
2023-02-22 08:33:41,802 DEBUG TRAIN Batch 17/2600 loss 16.797146 loss_att 17.673874 loss_ctc 25.081495 loss_rnnt 15.443501 hw_loss 0.138228 lr 0.00041613 rank 1
2023-02-22 08:33:41,804 DEBUG TRAIN Batch 17/2600 loss 11.903318 loss_att 12.470607 loss_ctc 15.701725 loss_rnnt 11.066586 hw_loss 0.406538 lr 0.00041605 rank 5
2023-02-22 08:33:41,808 DEBUG TRAIN Batch 17/2600 loss 6.645710 loss_att 15.113440 loss_ctc 7.464745 loss_rnnt 4.736028 hw_loss 0.200498 lr 0.00041613 rank 4
2023-02-22 08:33:41,852 DEBUG TRAIN Batch 17/2600 loss 20.633511 loss_att 25.640217 loss_ctc 31.537169 loss_rnnt 18.049652 hw_loss 0.241305 lr 0.00041604 rank 7
2023-02-22 08:34:54,241 DEBUG TRAIN Batch 17/2700 loss 12.491639 loss_att 15.697522 loss_ctc 18.051554 loss_rnnt 10.981531 hw_loss 0.239266 lr 0.00041593 rank 2
2023-02-22 08:34:54,244 DEBUG TRAIN Batch 17/2700 loss 10.806304 loss_att 13.781713 loss_ctc 15.810537 loss_rnnt 9.379478 hw_loss 0.308464 lr 0.00041593 rank 6
2023-02-22 08:34:54,245 DEBUG TRAIN Batch 17/2700 loss 26.594500 loss_att 27.403788 loss_ctc 29.298712 loss_rnnt 25.958855 hw_loss 0.212298 lr 0.00041593 rank 3
2023-02-22 08:34:54,245 DEBUG TRAIN Batch 17/2700 loss 5.032068 loss_att 9.446568 loss_ctc 7.199211 loss_rnnt 3.706825 hw_loss 0.287607 lr 0.00041598 rank 1
2023-02-22 08:34:54,247 DEBUG TRAIN Batch 17/2700 loss 3.201003 loss_att 7.567739 loss_ctc 6.574980 loss_rnnt 1.761809 hw_loss 0.217467 lr 0.00041598 rank 4
2023-02-22 08:34:54,247 DEBUG TRAIN Batch 17/2700 loss 5.759919 loss_att 8.661301 loss_ctc 8.543120 loss_rnnt 4.687619 hw_loss 0.226742 lr 0.00041602 rank 0
2023-02-22 08:34:54,249 DEBUG TRAIN Batch 17/2700 loss 5.013902 loss_att 8.091832 loss_ctc 7.318443 loss_rnnt 3.863609 hw_loss 0.426441 lr 0.00041589 rank 7
2023-02-22 08:34:54,302 DEBUG TRAIN Batch 17/2700 loss 11.552069 loss_att 17.273209 loss_ctc 17.980637 loss_rnnt 9.419847 hw_loss 0.245344 lr 0.00041590 rank 5
2023-02-22 08:36:08,221 DEBUG TRAIN Batch 17/2800 loss 17.611908 loss_att 21.146833 loss_ctc 25.777002 loss_rnnt 15.705503 hw_loss 0.207639 lr 0.00041588 rank 0
2023-02-22 08:36:08,236 DEBUG TRAIN Batch 17/2800 loss 13.717699 loss_att 17.795231 loss_ctc 17.644623 loss_rnnt 12.206673 hw_loss 0.322367 lr 0.00041584 rank 1
2023-02-22 08:36:08,237 DEBUG TRAIN Batch 17/2800 loss 18.762030 loss_att 21.960537 loss_ctc 29.313286 loss_rnnt 16.610558 hw_loss 0.196759 lr 0.00041579 rank 2
2023-02-22 08:36:08,238 DEBUG TRAIN Batch 17/2800 loss 9.432434 loss_att 13.877041 loss_ctc 15.563448 loss_rnnt 7.650149 hw_loss 0.142302 lr 0.00041579 rank 3
2023-02-22 08:36:08,242 DEBUG TRAIN Batch 17/2800 loss 6.567772 loss_att 9.053196 loss_ctc 9.757483 loss_rnnt 5.565433 hw_loss 0.149926 lr 0.00041578 rank 6
2023-02-22 08:36:08,261 DEBUG TRAIN Batch 17/2800 loss 6.853454 loss_att 12.515457 loss_ctc 9.786777 loss_rnnt 5.188201 hw_loss 0.265765 lr 0.00041575 rank 7
2023-02-22 08:36:08,270 DEBUG TRAIN Batch 17/2800 loss 8.836781 loss_att 10.295528 loss_ctc 12.012562 loss_rnnt 7.995151 hw_loss 0.237079 lr 0.00041584 rank 4
2023-02-22 08:36:08,275 DEBUG TRAIN Batch 17/2800 loss 2.765120 loss_att 5.804999 loss_ctc 4.646195 loss_rnnt 1.801135 hw_loss 0.197248 lr 0.00041576 rank 5
2023-02-22 08:37:22,638 DEBUG TRAIN Batch 17/2900 loss 12.215490 loss_att 13.539646 loss_ctc 13.505378 loss_rnnt 11.629328 hw_loss 0.280023 lr 0.00041565 rank 2
2023-02-22 08:37:22,654 DEBUG TRAIN Batch 17/2900 loss 16.262854 loss_att 17.525139 loss_ctc 18.323761 loss_rnnt 15.497681 hw_loss 0.446116 lr 0.00041564 rank 6
2023-02-22 08:37:22,658 DEBUG TRAIN Batch 17/2900 loss 7.491261 loss_att 9.141447 loss_ctc 8.540129 loss_rnnt 6.893834 hw_loss 0.239137 lr 0.00041564 rank 3
2023-02-22 08:37:22,658 DEBUG TRAIN Batch 17/2900 loss 15.327785 loss_att 19.018024 loss_ctc 24.466436 loss_rnnt 13.249294 hw_loss 0.228666 lr 0.00041562 rank 5
2023-02-22 08:37:22,662 DEBUG TRAIN Batch 17/2900 loss 8.666329 loss_att 11.888210 loss_ctc 11.550415 loss_rnnt 7.526980 hw_loss 0.207053 lr 0.00041573 rank 0
2023-02-22 08:37:22,662 DEBUG TRAIN Batch 17/2900 loss 5.602347 loss_att 9.048656 loss_ctc 9.254233 loss_rnnt 4.275134 hw_loss 0.283188 lr 0.00041570 rank 1
2023-02-22 08:37:22,667 DEBUG TRAIN Batch 17/2900 loss 8.627752 loss_att 12.257799 loss_ctc 10.300228 loss_rnnt 7.513773 hw_loss 0.309323 lr 0.00041570 rank 4
2023-02-22 08:37:22,708 DEBUG TRAIN Batch 17/2900 loss 5.449432 loss_att 7.858602 loss_ctc 7.851828 loss_rnnt 4.402537 hw_loss 0.458890 lr 0.00041561 rank 7
2023-02-22 08:38:35,257 DEBUG TRAIN Batch 17/3000 loss 18.165506 loss_att 19.469580 loss_ctc 28.031483 loss_rnnt 16.487511 hw_loss 0.190723 lr 0.00041550 rank 2
2023-02-22 08:38:35,258 DEBUG TRAIN Batch 17/3000 loss 7.125806 loss_att 8.855340 loss_ctc 8.162516 loss_rnnt 6.465642 hw_loss 0.330053 lr 0.00041550 rank 6
2023-02-22 08:38:35,258 DEBUG TRAIN Batch 17/3000 loss 9.072625 loss_att 11.716642 loss_ctc 15.662852 loss_rnnt 7.548455 hw_loss 0.218755 lr 0.00041547 rank 5
2023-02-22 08:38:35,262 DEBUG TRAIN Batch 17/3000 loss 6.380281 loss_att 10.334241 loss_ctc 9.373207 loss_rnnt 5.049085 hw_loss 0.265026 lr 0.00041555 rank 1
2023-02-22 08:38:35,262 DEBUG TRAIN Batch 17/3000 loss 9.609710 loss_att 12.955118 loss_ctc 13.794012 loss_rnnt 8.177513 hw_loss 0.384765 lr 0.00041559 rank 0
2023-02-22 08:38:35,264 DEBUG TRAIN Batch 17/3000 loss 4.662118 loss_att 6.704242 loss_ctc 5.351938 loss_rnnt 3.979954 hw_loss 0.340806 lr 0.00041550 rank 3
2023-02-22 08:38:35,264 DEBUG TRAIN Batch 17/3000 loss 15.597312 loss_att 17.228384 loss_ctc 17.683117 loss_rnnt 14.857716 hw_loss 0.253642 lr 0.00041546 rank 7
2023-02-22 08:38:35,310 DEBUG TRAIN Batch 17/3000 loss 12.342711 loss_att 17.059097 loss_ctc 19.098862 loss_rnnt 10.380890 hw_loss 0.220732 lr 0.00041555 rank 4
2023-02-22 08:39:47,349 DEBUG TRAIN Batch 17/3100 loss 7.119068 loss_att 9.589583 loss_ctc 10.949360 loss_rnnt 5.943520 hw_loss 0.320136 lr 0.00041541 rank 4
2023-02-22 08:39:47,354 DEBUG TRAIN Batch 17/3100 loss 12.823696 loss_att 12.408192 loss_ctc 18.688232 loss_rnnt 12.008656 hw_loss 0.217882 lr 0.00041535 rank 6
2023-02-22 08:39:47,358 DEBUG TRAIN Batch 17/3100 loss 9.972332 loss_att 12.337873 loss_ctc 10.663492 loss_rnnt 9.323649 hw_loss 0.156412 lr 0.00041545 rank 0
2023-02-22 08:39:47,358 DEBUG TRAIN Batch 17/3100 loss 13.658462 loss_att 16.083250 loss_ctc 18.582001 loss_rnnt 12.421150 hw_loss 0.179779 lr 0.00041536 rank 3
2023-02-22 08:39:47,358 DEBUG TRAIN Batch 17/3100 loss 14.221893 loss_att 17.107122 loss_ctc 20.983448 loss_rnnt 12.539225 hw_loss 0.382651 lr 0.00041536 rank 2
2023-02-22 08:39:47,360 DEBUG TRAIN Batch 17/3100 loss 5.208109 loss_att 6.798168 loss_ctc 7.353771 loss_rnnt 4.473850 hw_loss 0.244051 lr 0.00041541 rank 1
2023-02-22 08:39:47,362 DEBUG TRAIN Batch 17/3100 loss 7.432436 loss_att 9.920355 loss_ctc 11.159176 loss_rnnt 6.269037 hw_loss 0.316718 lr 0.00041532 rank 7
2023-02-22 08:39:47,363 DEBUG TRAIN Batch 17/3100 loss 11.272142 loss_att 15.281537 loss_ctc 20.362175 loss_rnnt 9.168651 hw_loss 0.168015 lr 0.00041533 rank 5
2023-02-22 08:41:02,791 DEBUG TRAIN Batch 17/3200 loss 2.163388 loss_att 5.525121 loss_ctc 2.849449 loss_rnnt 1.265756 hw_loss 0.250895 lr 0.00041522 rank 2
2023-02-22 08:41:02,797 DEBUG TRAIN Batch 17/3200 loss 6.339335 loss_att 9.658481 loss_ctc 9.868184 loss_rnnt 5.103614 hw_loss 0.190085 lr 0.00041521 rank 6
2023-02-22 08:41:02,797 DEBUG TRAIN Batch 17/3200 loss 11.806800 loss_att 11.475185 loss_ctc 13.749636 loss_rnnt 11.489493 hw_loss 0.233594 lr 0.00041521 rank 3
2023-02-22 08:41:02,797 DEBUG TRAIN Batch 17/3200 loss 13.401061 loss_att 13.475746 loss_ctc 15.667125 loss_rnnt 12.928748 hw_loss 0.291065 lr 0.00041530 rank 0
2023-02-22 08:41:02,800 DEBUG TRAIN Batch 17/3200 loss 7.930753 loss_att 7.735306 loss_ctc 9.402991 loss_rnnt 7.587149 hw_loss 0.349491 lr 0.00041518 rank 7
2023-02-22 08:41:02,803 DEBUG TRAIN Batch 17/3200 loss 16.442142 loss_att 19.681170 loss_ctc 23.159557 loss_rnnt 14.691757 hw_loss 0.387984 lr 0.00041519 rank 5
2023-02-22 08:41:02,834 DEBUG TRAIN Batch 17/3200 loss 9.997411 loss_att 10.692165 loss_ctc 12.375792 loss_rnnt 9.429358 hw_loss 0.209970 lr 0.00041527 rank 4
2023-02-22 08:41:02,842 DEBUG TRAIN Batch 17/3200 loss 7.825428 loss_att 8.327862 loss_ctc 7.166644 loss_rnnt 7.684639 hw_loss 0.240263 lr 0.00041527 rank 1
2023-02-22 08:42:15,125 DEBUG TRAIN Batch 17/3300 loss 22.623503 loss_att 20.577906 loss_ctc 31.706097 loss_rnnt 21.662016 hw_loss 0.299238 lr 0.00041512 rank 4
2023-02-22 08:42:15,134 DEBUG TRAIN Batch 17/3300 loss 9.767934 loss_att 15.983000 loss_ctc 15.288719 loss_rnnt 7.676867 hw_loss 0.209904 lr 0.00041507 rank 2
2023-02-22 08:42:15,135 DEBUG TRAIN Batch 17/3300 loss 18.700361 loss_att 19.604731 loss_ctc 24.208960 loss_rnnt 17.609024 hw_loss 0.329967 lr 0.00041507 rank 3
2023-02-22 08:42:15,137 DEBUG TRAIN Batch 17/3300 loss 10.574919 loss_att 14.481210 loss_ctc 14.037219 loss_rnnt 9.111053 hw_loss 0.414314 lr 0.00041516 rank 0
2023-02-22 08:42:15,139 DEBUG TRAIN Batch 17/3300 loss 4.413083 loss_att 9.730224 loss_ctc 4.921959 loss_rnnt 3.181925 hw_loss 0.187274 lr 0.00041507 rank 6
2023-02-22 08:42:15,143 DEBUG TRAIN Batch 17/3300 loss 7.031281 loss_att 9.246906 loss_ctc 9.460620 loss_rnnt 6.165525 hw_loss 0.185100 lr 0.00041512 rank 1
2023-02-22 08:42:15,146 DEBUG TRAIN Batch 17/3300 loss 4.516498 loss_att 8.216183 loss_ctc 6.908218 loss_rnnt 3.393499 hw_loss 0.120309 lr 0.00041504 rank 5
2023-02-22 08:42:15,161 DEBUG TRAIN Batch 17/3300 loss 10.205763 loss_att 13.484528 loss_ctc 18.465607 loss_rnnt 8.303960 hw_loss 0.271382 lr 0.00041503 rank 7
2023-02-22 08:43:27,694 DEBUG TRAIN Batch 17/3400 loss 7.106467 loss_att 10.514243 loss_ctc 13.692097 loss_rnnt 5.487528 hw_loss 0.111187 lr 0.00041490 rank 5
2023-02-22 08:43:27,704 DEBUG TRAIN Batch 17/3400 loss 7.596624 loss_att 8.884924 loss_ctc 11.355892 loss_rnnt 6.737622 hw_loss 0.187699 lr 0.00041492 rank 6
2023-02-22 08:43:27,704 DEBUG TRAIN Batch 17/3400 loss 11.562574 loss_att 15.085319 loss_ctc 15.200153 loss_rnnt 10.288023 hw_loss 0.159359 lr 0.00041493 rank 3
2023-02-22 08:43:27,705 DEBUG TRAIN Batch 17/3400 loss 11.545738 loss_att 14.378160 loss_ctc 17.344454 loss_rnnt 10.090172 hw_loss 0.217350 lr 0.00041498 rank 1
2023-02-22 08:43:27,706 DEBUG TRAIN Batch 17/3400 loss 9.516387 loss_att 11.121562 loss_ctc 10.321263 loss_rnnt 8.926945 hw_loss 0.302045 lr 0.00041498 rank 4
2023-02-22 08:43:27,708 DEBUG TRAIN Batch 17/3400 loss 9.548464 loss_att 10.834854 loss_ctc 13.748110 loss_rnnt 8.500667 hw_loss 0.432312 lr 0.00041502 rank 0
2023-02-22 08:43:27,711 DEBUG TRAIN Batch 17/3400 loss 5.505173 loss_att 10.056852 loss_ctc 11.064097 loss_rnnt 3.666714 hw_loss 0.350498 lr 0.00041493 rank 2
2023-02-22 08:43:27,712 DEBUG TRAIN Batch 17/3400 loss 15.271257 loss_att 15.954653 loss_ctc 21.977238 loss_rnnt 14.175962 hw_loss 0.120911 lr 0.00041489 rank 7
2023-02-22 08:44:40,483 DEBUG TRAIN Batch 17/3500 loss 13.890522 loss_att 16.740757 loss_ctc 17.331179 loss_rnnt 12.741598 hw_loss 0.225230 lr 0.00041475 rank 7
2023-02-22 08:44:40,485 DEBUG TRAIN Batch 17/3500 loss 10.991000 loss_att 15.137788 loss_ctc 17.931698 loss_rnnt 9.109446 hw_loss 0.237696 lr 0.00041476 rank 5
2023-02-22 08:44:40,491 DEBUG TRAIN Batch 17/3500 loss 5.469687 loss_att 11.282930 loss_ctc 7.642869 loss_rnnt 3.838511 hw_loss 0.335195 lr 0.00041484 rank 4
2023-02-22 08:44:40,490 DEBUG TRAIN Batch 17/3500 loss 11.619324 loss_att 14.055923 loss_ctc 14.959536 loss_rnnt 10.546217 hw_loss 0.263294 lr 0.00041478 rank 6
2023-02-22 08:44:40,492 DEBUG TRAIN Batch 17/3500 loss 16.861225 loss_att 18.454346 loss_ctc 18.076511 loss_rnnt 16.251358 hw_loss 0.242257 lr 0.00041479 rank 2
2023-02-22 08:44:40,493 DEBUG TRAIN Batch 17/3500 loss 6.913242 loss_att 8.874383 loss_ctc 8.412087 loss_rnnt 6.133489 hw_loss 0.351897 lr 0.00041484 rank 1
2023-02-22 08:44:40,493 DEBUG TRAIN Batch 17/3500 loss 10.093911 loss_att 12.124646 loss_ctc 14.669265 loss_rnnt 8.928743 hw_loss 0.279325 lr 0.00041479 rank 3
2023-02-22 08:44:40,499 DEBUG TRAIN Batch 17/3500 loss 8.915608 loss_att 11.825921 loss_ctc 11.472181 loss_rnnt 7.829994 hw_loss 0.305015 lr 0.00041487 rank 0
2023-02-22 08:45:54,432 DEBUG TRAIN Batch 17/3600 loss 11.339609 loss_att 13.527847 loss_ctc 13.156812 loss_rnnt 10.432665 hw_loss 0.425630 lr 0.00041464 rank 2
2023-02-22 08:45:54,433 DEBUG TRAIN Batch 17/3600 loss 5.066986 loss_att 7.578868 loss_ctc 7.276252 loss_rnnt 4.010118 hw_loss 0.487355 lr 0.00041464 rank 3
2023-02-22 08:45:54,435 DEBUG TRAIN Batch 17/3600 loss 4.191253 loss_att 7.792347 loss_ctc 4.663193 loss_rnnt 3.299935 hw_loss 0.202827 lr 0.00041460 rank 7
2023-02-22 08:45:54,438 DEBUG TRAIN Batch 17/3600 loss 9.735883 loss_att 9.651317 loss_ctc 14.380523 loss_rnnt 8.950226 hw_loss 0.343660 lr 0.00041464 rank 6
2023-02-22 08:45:54,440 DEBUG TRAIN Batch 17/3600 loss 7.894582 loss_att 11.586325 loss_ctc 11.737480 loss_rnnt 6.448622 hw_loss 0.366048 lr 0.00041469 rank 4
2023-02-22 08:45:54,441 DEBUG TRAIN Batch 17/3600 loss 12.330997 loss_att 16.461107 loss_ctc 18.125391 loss_rnnt 10.652162 hw_loss 0.150425 lr 0.00041469 rank 1
2023-02-22 08:45:54,442 DEBUG TRAIN Batch 17/3600 loss 4.920482 loss_att 6.897784 loss_ctc 5.095266 loss_rnnt 4.337004 hw_loss 0.308836 lr 0.00041462 rank 5
2023-02-22 08:45:54,443 DEBUG TRAIN Batch 17/3600 loss 10.855678 loss_att 15.361307 loss_ctc 14.756627 loss_rnnt 9.279411 hw_loss 0.290652 lr 0.00041473 rank 0
2023-02-22 08:47:07,922 DEBUG TRAIN Batch 17/3700 loss 14.316280 loss_att 17.114740 loss_ctc 20.312672 loss_rnnt 12.794504 hw_loss 0.304810 lr 0.00041455 rank 4
2023-02-22 08:47:07,923 DEBUG TRAIN Batch 17/3700 loss 5.315843 loss_att 8.053551 loss_ctc 9.430523 loss_rnnt 4.105139 hw_loss 0.214760 lr 0.00041450 rank 3
2023-02-22 08:47:07,923 DEBUG TRAIN Batch 17/3700 loss 15.497192 loss_att 18.964100 loss_ctc 21.020435 loss_rnnt 13.853641 hw_loss 0.400760 lr 0.00041450 rank 2
2023-02-22 08:47:07,925 DEBUG TRAIN Batch 17/3700 loss 9.395886 loss_att 10.564160 loss_ctc 10.578259 loss_rnnt 8.914688 hw_loss 0.168550 lr 0.00041447 rank 5
2023-02-22 08:47:07,926 DEBUG TRAIN Batch 17/3700 loss 13.380803 loss_att 15.551523 loss_ctc 19.279169 loss_rnnt 12.004934 hw_loss 0.291145 lr 0.00041459 rank 0
2023-02-22 08:47:07,927 DEBUG TRAIN Batch 17/3700 loss 19.485207 loss_att 20.571569 loss_ctc 25.244539 loss_rnnt 18.373434 hw_loss 0.237354 lr 0.00041449 rank 6
2023-02-22 08:47:07,930 DEBUG TRAIN Batch 17/3700 loss 6.283041 loss_att 8.705133 loss_ctc 10.003777 loss_rnnt 5.198672 hw_loss 0.194723 lr 0.00041455 rank 1
2023-02-22 08:47:07,932 DEBUG TRAIN Batch 17/3700 loss 9.441809 loss_att 11.505326 loss_ctc 12.804338 loss_rnnt 8.444165 hw_loss 0.256130 lr 0.00041446 rank 7
2023-02-22 08:48:21,756 DEBUG TRAIN Batch 17/3800 loss 14.685293 loss_att 14.651235 loss_ctc 19.196924 loss_rnnt 13.856441 hw_loss 0.438965 lr 0.00041432 rank 7
2023-02-22 08:48:21,763 DEBUG TRAIN Batch 17/3800 loss 10.220415 loss_att 15.239780 loss_ctc 12.808761 loss_rnnt 8.691235 hw_loss 0.337866 lr 0.00041436 rank 2
2023-02-22 08:48:21,765 DEBUG TRAIN Batch 17/3800 loss 7.741776 loss_att 8.813667 loss_ctc 10.619446 loss_rnnt 6.954086 hw_loss 0.355541 lr 0.00041433 rank 5
2023-02-22 08:48:21,766 DEBUG TRAIN Batch 17/3800 loss 15.747980 loss_att 19.262690 loss_ctc 18.885569 loss_rnnt 14.533413 hw_loss 0.174901 lr 0.00041436 rank 3
2023-02-22 08:48:21,768 DEBUG TRAIN Batch 17/3800 loss 7.704028 loss_att 9.061247 loss_ctc 11.178088 loss_rnnt 6.759710 hw_loss 0.393123 lr 0.00041441 rank 4
2023-02-22 08:48:21,768 DEBUG TRAIN Batch 17/3800 loss 13.996485 loss_att 15.167824 loss_ctc 16.350752 loss_rnnt 13.320688 hw_loss 0.239295 lr 0.00041435 rank 6
2023-02-22 08:48:21,775 DEBUG TRAIN Batch 17/3800 loss 12.031217 loss_att 12.818174 loss_ctc 18.573168 loss_rnnt 10.691820 hw_loss 0.580769 lr 0.00041444 rank 0
2023-02-22 08:48:21,784 DEBUG TRAIN Batch 17/3800 loss 8.893351 loss_att 8.575281 loss_ctc 12.934970 loss_rnnt 8.227120 hw_loss 0.358051 lr 0.00041441 rank 1
2023-02-22 08:49:37,135 DEBUG TRAIN Batch 17/3900 loss 9.506913 loss_att 10.960008 loss_ctc 16.415075 loss_rnnt 8.154364 hw_loss 0.264081 lr 0.00041427 rank 1
2023-02-22 08:49:37,151 DEBUG TRAIN Batch 17/3900 loss 15.750897 loss_att 17.255470 loss_ctc 21.599936 loss_rnnt 14.544083 hw_loss 0.236302 lr 0.00041421 rank 6
2023-02-22 08:49:37,151 DEBUG TRAIN Batch 17/3900 loss 11.570964 loss_att 18.243723 loss_ctc 17.937492 loss_rnnt 9.261402 hw_loss 0.236513 lr 0.00041422 rank 2
2023-02-22 08:49:37,151 DEBUG TRAIN Batch 17/3900 loss 10.506698 loss_att 13.500021 loss_ctc 14.895976 loss_rnnt 9.196602 hw_loss 0.236614 lr 0.00041427 rank 4
2023-02-22 08:49:37,165 DEBUG TRAIN Batch 17/3900 loss 6.901212 loss_att 9.720957 loss_ctc 8.317679 loss_rnnt 5.982326 hw_loss 0.311390 lr 0.00041418 rank 7
2023-02-22 08:49:37,177 DEBUG TRAIN Batch 17/3900 loss 8.344562 loss_att 10.399255 loss_ctc 10.362320 loss_rnnt 7.449365 hw_loss 0.403544 lr 0.00041419 rank 5
2023-02-22 08:49:37,189 DEBUG TRAIN Batch 17/3900 loss 9.677373 loss_att 13.581921 loss_ctc 12.254063 loss_rnnt 8.465654 hw_loss 0.163596 lr 0.00041422 rank 3
2023-02-22 08:49:37,201 DEBUG TRAIN Batch 17/3900 loss 8.907221 loss_att 10.768457 loss_ctc 13.839478 loss_rnnt 7.774437 hw_loss 0.192942 lr 0.00041430 rank 0
2023-02-22 08:50:49,293 DEBUG TRAIN Batch 17/4000 loss 3.758044 loss_att 5.739818 loss_ctc 4.118268 loss_rnnt 3.201672 hw_loss 0.209975 lr 0.00041407 rank 3
2023-02-22 08:50:49,296 DEBUG TRAIN Batch 17/4000 loss 5.734080 loss_att 7.785435 loss_ctc 6.862836 loss_rnnt 5.054376 hw_loss 0.222999 lr 0.00041407 rank 6
2023-02-22 08:50:49,298 DEBUG TRAIN Batch 17/4000 loss 6.351140 loss_att 8.265846 loss_ctc 8.021431 loss_rnnt 5.613037 hw_loss 0.248357 lr 0.00041408 rank 2
2023-02-22 08:50:49,300 DEBUG TRAIN Batch 17/4000 loss 7.269150 loss_att 9.302164 loss_ctc 9.680683 loss_rnnt 6.362489 hw_loss 0.334727 lr 0.00041413 rank 4
2023-02-22 08:50:49,301 DEBUG TRAIN Batch 17/4000 loss 22.279100 loss_att 26.059532 loss_ctc 30.268494 loss_rnnt 20.356453 hw_loss 0.189955 lr 0.00041404 rank 7
2023-02-22 08:50:49,302 DEBUG TRAIN Batch 17/4000 loss 10.249563 loss_att 13.620484 loss_ctc 13.924403 loss_rnnt 8.978410 hw_loss 0.200608 lr 0.00041416 rank 0
2023-02-22 08:50:49,302 DEBUG TRAIN Batch 17/4000 loss 9.991474 loss_att 11.346944 loss_ctc 12.836249 loss_rnnt 9.241148 hw_loss 0.187366 lr 0.00041405 rank 5
2023-02-22 08:50:49,304 DEBUG TRAIN Batch 17/4000 loss 10.777987 loss_att 13.141129 loss_ctc 14.898878 loss_rnnt 9.604666 hw_loss 0.283577 lr 0.00041413 rank 1
2023-02-22 08:52:01,913 DEBUG TRAIN Batch 17/4100 loss 8.034986 loss_att 10.826449 loss_ctc 11.277493 loss_rnnt 6.943123 hw_loss 0.189818 lr 0.00041393 rank 2
2023-02-22 08:52:01,917 DEBUG TRAIN Batch 17/4100 loss 5.032051 loss_att 9.195592 loss_ctc 6.596868 loss_rnnt 3.798073 hw_loss 0.361178 lr 0.00041393 rank 3
2023-02-22 08:52:01,919 DEBUG TRAIN Batch 17/4100 loss 13.247685 loss_att 14.283289 loss_ctc 15.150382 loss_rnnt 12.666404 hw_loss 0.225878 lr 0.00041389 rank 7
2023-02-22 08:52:01,919 DEBUG TRAIN Batch 17/4100 loss 13.163291 loss_att 14.678398 loss_ctc 17.360966 loss_rnnt 12.128651 hw_loss 0.322368 lr 0.00041393 rank 6
2023-02-22 08:52:01,920 DEBUG TRAIN Batch 17/4100 loss 14.545311 loss_att 18.772892 loss_ctc 16.936954 loss_rnnt 13.291046 hw_loss 0.168493 lr 0.00041391 rank 5
2023-02-22 08:52:01,924 DEBUG TRAIN Batch 17/4100 loss 3.490489 loss_att 7.523300 loss_ctc 8.422937 loss_rnnt 1.883996 hw_loss 0.266759 lr 0.00041398 rank 1
2023-02-22 08:52:01,923 DEBUG TRAIN Batch 17/4100 loss 9.255417 loss_att 14.100965 loss_ctc 13.582939 loss_rnnt 7.641515 hw_loss 0.127106 lr 0.00041402 rank 0
2023-02-22 08:52:01,925 DEBUG TRAIN Batch 17/4100 loss 10.121932 loss_att 12.850723 loss_ctc 13.859047 loss_rnnt 8.926769 hw_loss 0.283357 lr 0.00041398 rank 4
2023-02-22 08:53:15,495 DEBUG TRAIN Batch 17/4200 loss 9.761222 loss_att 11.595114 loss_ctc 12.738867 loss_rnnt 8.878798 hw_loss 0.222426 lr 0.00041379 rank 3
2023-02-22 08:53:15,498 DEBUG TRAIN Batch 17/4200 loss 5.246209 loss_att 8.844151 loss_ctc 7.531120 loss_rnnt 4.099153 hw_loss 0.230274 lr 0.00041384 rank 4
2023-02-22 08:53:15,498 DEBUG TRAIN Batch 17/4200 loss 7.969678 loss_att 10.881063 loss_ctc 10.367048 loss_rnnt 6.921892 hw_loss 0.273487 lr 0.00041384 rank 1
2023-02-22 08:53:15,504 DEBUG TRAIN Batch 17/4200 loss 11.450194 loss_att 15.729660 loss_ctc 15.683640 loss_rnnt 9.943297 hw_loss 0.162269 lr 0.00041379 rank 2
2023-02-22 08:53:15,510 DEBUG TRAIN Batch 17/4200 loss 11.092971 loss_att 12.558331 loss_ctc 14.825699 loss_rnnt 10.130535 hw_loss 0.321875 lr 0.00041378 rank 6
2023-02-22 08:53:15,535 DEBUG TRAIN Batch 17/4200 loss 10.744802 loss_att 13.912500 loss_ctc 16.297829 loss_rnnt 9.195893 hw_loss 0.328058 lr 0.00041375 rank 7
2023-02-22 08:53:15,539 DEBUG TRAIN Batch 17/4200 loss 8.108057 loss_att 11.424505 loss_ctc 13.151287 loss_rnnt 6.592360 hw_loss 0.337455 lr 0.00041376 rank 5
2023-02-22 08:53:15,552 DEBUG TRAIN Batch 17/4200 loss 17.198793 loss_att 22.032677 loss_ctc 25.513853 loss_rnnt 15.005555 hw_loss 0.220854 lr 0.00041388 rank 0
2023-02-22 08:54:29,313 DEBUG TRAIN Batch 17/4300 loss 16.406000 loss_att 16.844578 loss_ctc 20.119446 loss_rnnt 15.622211 hw_loss 0.376777 lr 0.00041365 rank 2
2023-02-22 08:54:29,315 DEBUG TRAIN Batch 17/4300 loss 20.037643 loss_att 23.228558 loss_ctc 33.076706 loss_rnnt 17.491331 hw_loss 0.317977 lr 0.00041361 rank 7
2023-02-22 08:54:29,326 DEBUG TRAIN Batch 17/4300 loss 5.478977 loss_att 7.806133 loss_ctc 6.170554 loss_rnnt 4.763797 hw_loss 0.295385 lr 0.00041365 rank 3
2023-02-22 08:54:29,328 DEBUG TRAIN Batch 17/4300 loss 14.963849 loss_att 12.834002 loss_ctc 14.190885 loss_rnnt 15.275526 hw_loss 0.407541 lr 0.00041370 rank 4
2023-02-22 08:54:29,331 DEBUG TRAIN Batch 17/4300 loss 10.858200 loss_att 15.643167 loss_ctc 16.172815 loss_rnnt 9.033316 hw_loss 0.298643 lr 0.00041370 rank 1
2023-02-22 08:54:29,331 DEBUG TRAIN Batch 17/4300 loss 12.353370 loss_att 13.957571 loss_ctc 16.096067 loss_rnnt 11.357626 hw_loss 0.329770 lr 0.00041364 rank 6
2023-02-22 08:54:29,334 DEBUG TRAIN Batch 17/4300 loss 11.216087 loss_att 14.628872 loss_ctc 14.277237 loss_rnnt 10.028838 hw_loss 0.181009 lr 0.00041373 rank 0
2023-02-22 08:54:29,379 DEBUG TRAIN Batch 17/4300 loss 20.612913 loss_att 21.824799 loss_ctc 23.865496 loss_rnnt 19.713453 hw_loss 0.418888 lr 0.00041362 rank 5
2023-02-22 08:55:42,532 DEBUG TRAIN Batch 17/4400 loss 7.618949 loss_att 7.856393 loss_ctc 9.484024 loss_rnnt 6.965115 hw_loss 0.670628 lr 0.00041351 rank 2
2023-02-22 08:55:42,533 DEBUG TRAIN Batch 17/4400 loss 7.318978 loss_att 7.915380 loss_ctc 9.295199 loss_rnnt 6.617527 hw_loss 0.597515 lr 0.00041351 rank 3
2023-02-22 08:55:42,534 DEBUG TRAIN Batch 17/4400 loss 7.186307 loss_att 7.379491 loss_ctc 8.588116 loss_rnnt 6.649868 hw_loss 0.582929 lr 0.00041350 rank 6
2023-02-22 08:55:42,535 DEBUG TRAIN Batch 17/4400 loss 13.675550 loss_att 15.162318 loss_ctc 20.037525 loss_rnnt 12.391017 hw_loss 0.260465 lr 0.00041359 rank 0
2023-02-22 08:55:42,539 DEBUG TRAIN Batch 17/4400 loss 8.494340 loss_att 11.962883 loss_ctc 12.385535 loss_rnnt 7.079401 hw_loss 0.379509 lr 0.00041356 rank 4
2023-02-22 08:55:42,540 DEBUG TRAIN Batch 17/4400 loss 13.897088 loss_att 14.085544 loss_ctc 20.636389 loss_rnnt 12.742784 hw_loss 0.408823 lr 0.00041347 rank 7
2023-02-22 08:55:42,540 DEBUG TRAIN Batch 17/4400 loss 15.553765 loss_att 15.208980 loss_ctc 17.783701 loss_rnnt 15.081038 hw_loss 0.458174 lr 0.00041356 rank 1
2023-02-22 08:55:42,586 DEBUG TRAIN Batch 17/4400 loss 7.309914 loss_att 10.581638 loss_ctc 10.720308 loss_rnnt 6.092078 hw_loss 0.203947 lr 0.00041348 rank 5
2023-02-22 08:56:54,898 DEBUG TRAIN Batch 17/4500 loss 6.013241 loss_att 8.001547 loss_ctc 12.276997 loss_rnnt 4.736840 hw_loss 0.081699 lr 0.00041337 rank 2
2023-02-22 08:56:54,903 DEBUG TRAIN Batch 17/4500 loss 7.946221 loss_att 12.214313 loss_ctc 14.340083 loss_rnnt 6.153941 hw_loss 0.161525 lr 0.00041337 rank 3
2023-02-22 08:56:54,904 DEBUG TRAIN Batch 17/4500 loss 5.815584 loss_att 8.562902 loss_ctc 11.839572 loss_rnnt 4.188296 hw_loss 0.514923 lr 0.00041342 rank 4
2023-02-22 08:56:54,908 DEBUG TRAIN Batch 17/4500 loss 18.185347 loss_att 20.942661 loss_ctc 17.892590 loss_rnnt 17.478466 hw_loss 0.364592 lr 0.00041345 rank 0
2023-02-22 08:56:54,906 DEBUG TRAIN Batch 17/4500 loss 12.472142 loss_att 12.956619 loss_ctc 15.630529 loss_rnnt 11.808887 hw_loss 0.272329 lr 0.00041336 rank 6
2023-02-22 08:56:54,907 DEBUG TRAIN Batch 17/4500 loss 8.467650 loss_att 9.062261 loss_ctc 11.834148 loss_rnnt 7.642087 hw_loss 0.483327 lr 0.00041333 rank 7
2023-02-22 08:56:54,908 DEBUG TRAIN Batch 17/4500 loss 8.752746 loss_att 14.453609 loss_ctc 11.367950 loss_rnnt 7.145845 hw_loss 0.221313 lr 0.00041334 rank 5
2023-02-22 08:56:54,912 DEBUG TRAIN Batch 17/4500 loss 18.390562 loss_att 18.364624 loss_ctc 24.474684 loss_rnnt 17.428152 hw_loss 0.293215 lr 0.00041342 rank 1
2023-02-22 08:58:09,140 DEBUG TRAIN Batch 17/4600 loss 11.421595 loss_att 13.083384 loss_ctc 18.948917 loss_rnnt 9.975734 hw_loss 0.205988 lr 0.00041323 rank 2
2023-02-22 08:58:09,143 DEBUG TRAIN Batch 17/4600 loss 9.841476 loss_att 14.136915 loss_ctc 13.102064 loss_rnnt 8.384639 hw_loss 0.305634 lr 0.00041328 rank 1
2023-02-22 08:58:09,143 DEBUG TRAIN Batch 17/4600 loss 8.911218 loss_att 9.419897 loss_ctc 14.034267 loss_rnnt 8.085510 hw_loss 0.076684 lr 0.00041322 rank 3
2023-02-22 08:58:09,147 DEBUG TRAIN Batch 17/4600 loss 8.328896 loss_att 8.630253 loss_ctc 9.639753 loss_rnnt 7.979758 hw_loss 0.213910 lr 0.00041322 rank 6
2023-02-22 08:58:09,148 DEBUG TRAIN Batch 17/4600 loss 10.539525 loss_att 9.801695 loss_ctc 13.902100 loss_rnnt 9.985026 hw_loss 0.475729 lr 0.00041320 rank 5
2023-02-22 08:58:09,149 DEBUG TRAIN Batch 17/4600 loss 7.102367 loss_att 10.854370 loss_ctc 10.120310 loss_rnnt 5.767236 hw_loss 0.341884 lr 0.00041328 rank 4
2023-02-22 08:58:09,177 DEBUG TRAIN Batch 17/4600 loss 12.854730 loss_att 16.789829 loss_ctc 12.892482 loss_rnnt 11.992764 hw_loss 0.131085 lr 0.00041319 rank 7
2023-02-22 08:58:09,207 DEBUG TRAIN Batch 17/4600 loss 5.707904 loss_att 8.284592 loss_ctc 9.782631 loss_rnnt 4.570764 hw_loss 0.147198 lr 0.00041331 rank 0
2023-02-22 08:59:22,793 DEBUG TRAIN Batch 17/4700 loss 8.456739 loss_att 12.331047 loss_ctc 16.058748 loss_rnnt 6.506887 hw_loss 0.302604 lr 0.00041308 rank 3
2023-02-22 08:59:22,796 DEBUG TRAIN Batch 17/4700 loss 9.705959 loss_att 12.847327 loss_ctc 11.595426 loss_rnnt 8.563096 hw_loss 0.492490 lr 0.00041313 rank 4
2023-02-22 08:59:22,800 DEBUG TRAIN Batch 17/4700 loss 6.524426 loss_att 10.841996 loss_ctc 10.156593 loss_rnnt 4.993348 hw_loss 0.343640 lr 0.00041308 rank 6
2023-02-22 08:59:22,801 DEBUG TRAIN Batch 17/4700 loss 11.722929 loss_att 15.536221 loss_ctc 16.839417 loss_rnnt 10.189392 hw_loss 0.166276 lr 0.00041305 rank 7
2023-02-22 08:59:22,802 DEBUG TRAIN Batch 17/4700 loss 16.740089 loss_att 18.699074 loss_ctc 22.424484 loss_rnnt 15.384452 hw_loss 0.386105 lr 0.00041317 rank 0
2023-02-22 08:59:22,804 DEBUG TRAIN Batch 17/4700 loss 7.747149 loss_att 13.960001 loss_ctc 11.490044 loss_rnnt 5.827957 hw_loss 0.332943 lr 0.00041308 rank 2
2023-02-22 08:59:22,804 DEBUG TRAIN Batch 17/4700 loss 6.621438 loss_att 9.982044 loss_ctc 9.858289 loss_rnnt 5.247985 hw_loss 0.505783 lr 0.00041313 rank 1
2023-02-22 08:59:22,862 DEBUG TRAIN Batch 17/4700 loss 11.314952 loss_att 13.202003 loss_ctc 12.226707 loss_rnnt 10.679802 hw_loss 0.255325 lr 0.00041306 rank 5
2023-02-22 09:00:35,398 DEBUG TRAIN Batch 17/4800 loss 9.772435 loss_att 14.922298 loss_ctc 19.140017 loss_rnnt 7.383094 hw_loss 0.206920 lr 0.00041294 rank 3
2023-02-22 09:00:35,401 DEBUG TRAIN Batch 17/4800 loss 8.904903 loss_att 10.059975 loss_ctc 10.210084 loss_rnnt 8.262156 hw_loss 0.445703 lr 0.00041294 rank 2
2023-02-22 09:00:35,402 DEBUG TRAIN Batch 17/4800 loss 3.481601 loss_att 6.810695 loss_ctc 4.711246 loss_rnnt 2.545217 hw_loss 0.199899 lr 0.00041294 rank 6
2023-02-22 09:00:35,403 DEBUG TRAIN Batch 17/4800 loss 13.727896 loss_att 19.855173 loss_ctc 14.268291 loss_rnnt 12.299933 hw_loss 0.244601 lr 0.00041292 rank 5
2023-02-22 09:00:35,406 DEBUG TRAIN Batch 17/4800 loss 9.723325 loss_att 15.823334 loss_ctc 14.760623 loss_rnnt 7.668071 hw_loss 0.306772 lr 0.00041303 rank 0
2023-02-22 09:00:35,406 DEBUG TRAIN Batch 17/4800 loss 7.111733 loss_att 10.214417 loss_ctc 12.227012 loss_rnnt 5.727701 hw_loss 0.152735 lr 0.00041299 rank 1
2023-02-22 09:00:35,422 DEBUG TRAIN Batch 17/4800 loss 12.061482 loss_att 12.935253 loss_ctc 15.314229 loss_rnnt 11.353147 hw_loss 0.187279 lr 0.00041299 rank 4
2023-02-22 09:00:35,450 DEBUG TRAIN Batch 17/4800 loss 15.675925 loss_att 20.824575 loss_ctc 19.712099 loss_rnnt 13.932467 hw_loss 0.329197 lr 0.00041290 rank 7
2023-02-22 09:01:47,707 DEBUG TRAIN Batch 17/4900 loss 9.867434 loss_att 11.547168 loss_ctc 14.475989 loss_rnnt 8.789475 hw_loss 0.239133 lr 0.00041276 rank 7
2023-02-22 09:01:47,712 DEBUG TRAIN Batch 17/4900 loss 10.123148 loss_att 12.860339 loss_ctc 15.048769 loss_rnnt 8.796646 hw_loss 0.229338 lr 0.00041278 rank 5
2023-02-22 09:01:47,715 DEBUG TRAIN Batch 17/4900 loss 8.620501 loss_att 10.549500 loss_ctc 10.824780 loss_rnnt 7.843904 hw_loss 0.181673 lr 0.00041280 rank 6
2023-02-22 09:01:47,715 DEBUG TRAIN Batch 17/4900 loss 22.785713 loss_att 22.380207 loss_ctc 24.037128 loss_rnnt 22.554260 hw_loss 0.273185 lr 0.00041280 rank 2
2023-02-22 09:01:47,716 DEBUG TRAIN Batch 17/4900 loss 10.797861 loss_att 11.831540 loss_ctc 10.863127 loss_rnnt 10.366602 hw_loss 0.404665 lr 0.00041280 rank 3
2023-02-22 09:01:47,719 DEBUG TRAIN Batch 17/4900 loss 19.626640 loss_att 21.832310 loss_ctc 25.809021 loss_rnnt 18.271288 hw_loss 0.168561 lr 0.00041285 rank 4
2023-02-22 09:01:47,721 DEBUG TRAIN Batch 17/4900 loss 14.521984 loss_att 18.195839 loss_ctc 22.670837 loss_rnnt 12.505005 hw_loss 0.366927 lr 0.00041285 rank 1
2023-02-22 09:01:47,746 DEBUG TRAIN Batch 17/4900 loss 12.255473 loss_att 14.249039 loss_ctc 17.953243 loss_rnnt 10.955453 hw_loss 0.265507 lr 0.00041289 rank 0
2023-02-22 09:03:02,771 DEBUG TRAIN Batch 17/5000 loss 13.929992 loss_att 15.230615 loss_ctc 18.237780 loss_rnnt 12.895109 hw_loss 0.375725 lr 0.00041266 rank 2
2023-02-22 09:03:02,773 DEBUG TRAIN Batch 17/5000 loss 9.142739 loss_att 10.623728 loss_ctc 11.444274 loss_rnnt 8.318981 hw_loss 0.413793 lr 0.00041271 rank 1
2023-02-22 09:03:02,774 DEBUG TRAIN Batch 17/5000 loss 15.773951 loss_att 16.489771 loss_ctc 20.286844 loss_rnnt 14.769959 hw_loss 0.485825 lr 0.00041266 rank 3
2023-02-22 09:03:02,777 DEBUG TRAIN Batch 17/5000 loss 8.676138 loss_att 8.737929 loss_ctc 10.934652 loss_rnnt 8.153709 hw_loss 0.391752 lr 0.00041266 rank 6
2023-02-22 09:03:02,779 DEBUG TRAIN Batch 17/5000 loss 11.895911 loss_att 12.163960 loss_ctc 18.155617 loss_rnnt 10.831041 hw_loss 0.331185 lr 0.00041271 rank 4
2023-02-22 09:03:02,779 DEBUG TRAIN Batch 17/5000 loss 11.536600 loss_att 14.180641 loss_ctc 17.910267 loss_rnnt 10.040049 hw_loss 0.221103 lr 0.00041262 rank 7
2023-02-22 09:03:02,779 DEBUG TRAIN Batch 17/5000 loss 10.101254 loss_att 12.390377 loss_ctc 17.517517 loss_rnnt 8.523552 hw_loss 0.245702 lr 0.00041263 rank 5
2023-02-22 09:03:02,781 DEBUG TRAIN Batch 17/5000 loss 11.582958 loss_att 13.072308 loss_ctc 14.059178 loss_rnnt 10.845054 hw_loss 0.206010 lr 0.00041275 rank 0
2023-02-22 09:04:14,940 DEBUG TRAIN Batch 17/5100 loss 7.308400 loss_att 14.896744 loss_ctc 12.095516 loss_rnnt 5.084971 hw_loss 0.126520 lr 0.00041257 rank 4
2023-02-22 09:04:14,946 DEBUG TRAIN Batch 17/5100 loss 5.163264 loss_att 7.722120 loss_ctc 6.034390 loss_rnnt 4.370501 hw_loss 0.309078 lr 0.00041252 rank 2
2023-02-22 09:04:14,949 DEBUG TRAIN Batch 17/5100 loss 6.363597 loss_att 8.888154 loss_ctc 10.725039 loss_rnnt 5.118705 hw_loss 0.297103 lr 0.00041252 rank 6
2023-02-22 09:04:14,952 DEBUG TRAIN Batch 17/5100 loss 10.807503 loss_att 11.330619 loss_ctc 13.427120 loss_rnnt 10.144409 hw_loss 0.392227 lr 0.00041248 rank 7
2023-02-22 09:04:14,953 DEBUG TRAIN Batch 17/5100 loss 19.255203 loss_att 17.394381 loss_ctc 24.969166 loss_rnnt 18.768845 hw_loss 0.181239 lr 0.00041252 rank 3
2023-02-22 09:04:14,957 DEBUG TRAIN Batch 17/5100 loss 5.960104 loss_att 8.967285 loss_ctc 10.083750 loss_rnnt 4.648897 hw_loss 0.299908 lr 0.00041261 rank 0
2023-02-22 09:04:14,959 DEBUG TRAIN Batch 17/5100 loss 17.512615 loss_att 19.969746 loss_ctc 22.562878 loss_rnnt 16.093044 hw_loss 0.477704 lr 0.00041249 rank 5
2023-02-22 09:04:14,962 DEBUG TRAIN Batch 17/5100 loss 6.049242 loss_att 8.788525 loss_ctc 10.455838 loss_rnnt 4.755079 hw_loss 0.297674 lr 0.00041257 rank 1
2023-02-22 09:05:27,719 DEBUG TRAIN Batch 17/5200 loss 3.317953 loss_att 5.947775 loss_ctc 4.240480 loss_rnnt 2.491431 hw_loss 0.332913 lr 0.00041238 rank 2
2023-02-22 09:05:27,723 DEBUG TRAIN Batch 17/5200 loss 2.056876 loss_att 4.370562 loss_ctc 2.864095 loss_rnnt 1.370980 hw_loss 0.216620 lr 0.00041247 rank 0
2023-02-22 09:05:27,724 DEBUG TRAIN Batch 17/5200 loss 12.586623 loss_att 15.353540 loss_ctc 18.176817 loss_rnnt 11.083610 hw_loss 0.383009 lr 0.00041238 rank 3
2023-02-22 09:05:27,724 DEBUG TRAIN Batch 17/5200 loss 7.247321 loss_att 10.399355 loss_ctc 9.672863 loss_rnnt 6.130521 hw_loss 0.305603 lr 0.00041243 rank 1
2023-02-22 09:05:27,725 DEBUG TRAIN Batch 17/5200 loss 9.606092 loss_att 11.536839 loss_ctc 17.602453 loss_rnnt 8.036967 hw_loss 0.218989 lr 0.00041234 rank 7
2023-02-22 09:05:27,726 DEBUG TRAIN Batch 17/5200 loss 12.605789 loss_att 17.289541 loss_ctc 15.057722 loss_rnnt 11.288717 hw_loss 0.100120 lr 0.00041237 rank 6
2023-02-22 09:05:27,728 DEBUG TRAIN Batch 17/5200 loss 9.863791 loss_att 13.157536 loss_ctc 17.194979 loss_rnnt 8.123743 hw_loss 0.194639 lr 0.00041243 rank 4
2023-02-22 09:05:27,736 DEBUG TRAIN Batch 17/5200 loss 13.382794 loss_att 14.094938 loss_ctc 18.415722 loss_rnnt 12.313209 hw_loss 0.480189 lr 0.00041235 rank 5
2023-02-22 09:06:41,881 DEBUG TRAIN Batch 17/5300 loss 8.609716 loss_att 10.585550 loss_ctc 13.189507 loss_rnnt 7.440241 hw_loss 0.306881 lr 0.00041224 rank 3
2023-02-22 09:06:41,881 DEBUG TRAIN Batch 17/5300 loss 14.227002 loss_att 14.667544 loss_ctc 19.569044 loss_rnnt 13.179771 hw_loss 0.462844 lr 0.00041233 rank 0
2023-02-22 09:06:41,886 DEBUG TRAIN Batch 17/5300 loss 11.193504 loss_att 14.136951 loss_ctc 14.685530 loss_rnnt 9.987636 hw_loss 0.284207 lr 0.00041224 rank 2
2023-02-22 09:06:41,891 DEBUG TRAIN Batch 17/5300 loss 11.083213 loss_att 14.923784 loss_ctc 19.850430 loss_rnnt 9.104570 hw_loss 0.077936 lr 0.00041220 rank 7
2023-02-22 09:06:41,890 DEBUG TRAIN Batch 17/5300 loss 6.805156 loss_att 7.997541 loss_ctc 8.632965 loss_rnnt 6.196165 hw_loss 0.237762 lr 0.00041223 rank 6
2023-02-22 09:06:41,898 DEBUG TRAIN Batch 17/5300 loss 7.153721 loss_att 9.650238 loss_ctc 9.679305 loss_rnnt 6.189110 hw_loss 0.241057 lr 0.00041229 rank 4
2023-02-22 09:06:41,899 DEBUG TRAIN Batch 17/5300 loss 6.931748 loss_att 10.157318 loss_ctc 9.230480 loss_rnnt 5.908792 hw_loss 0.133772 lr 0.00041229 rank 1
2023-02-22 09:06:41,928 DEBUG TRAIN Batch 17/5300 loss 19.766407 loss_att 21.647398 loss_ctc 23.602751 loss_rnnt 18.732458 hw_loss 0.274198 lr 0.00041221 rank 5
2023-02-22 09:07:55,310 DEBUG TRAIN Batch 17/5400 loss 14.315066 loss_att 17.529465 loss_ctc 18.259672 loss_rnnt 13.035331 hw_loss 0.207955 lr 0.00041210 rank 3
2023-02-22 09:07:55,311 DEBUG TRAIN Batch 17/5400 loss 14.317181 loss_att 16.850830 loss_ctc 18.346386 loss_rnnt 13.162806 hw_loss 0.207032 lr 0.00041210 rank 2
2023-02-22 09:07:55,314 DEBUG TRAIN Batch 17/5400 loss 4.393677 loss_att 9.055798 loss_ctc 5.909408 loss_rnnt 3.143786 hw_loss 0.216319 lr 0.00041206 rank 7
2023-02-22 09:07:55,315 DEBUG TRAIN Batch 17/5400 loss 8.689536 loss_att 11.345531 loss_ctc 11.344503 loss_rnnt 7.688266 hw_loss 0.217642 lr 0.00041215 rank 1
2023-02-22 09:07:55,315 DEBUG TRAIN Batch 17/5400 loss 19.802485 loss_att 23.180838 loss_ctc 29.557234 loss_rnnt 17.664326 hw_loss 0.303480 lr 0.00041219 rank 0
2023-02-22 09:07:55,319 DEBUG TRAIN Batch 17/5400 loss 7.804146 loss_att 10.852439 loss_ctc 12.350332 loss_rnnt 6.462301 hw_loss 0.236305 lr 0.00041215 rank 4
2023-02-22 09:07:55,319 DEBUG TRAIN Batch 17/5400 loss 8.072720 loss_att 11.706820 loss_ctc 9.755468 loss_rnnt 7.051705 hw_loss 0.130925 lr 0.00041207 rank 5
2023-02-22 09:07:55,335 DEBUG TRAIN Batch 17/5400 loss 5.860659 loss_att 8.447845 loss_ctc 6.478306 loss_rnnt 5.044246 hw_loss 0.406167 lr 0.00041209 rank 6
2023-02-22 09:09:07,481 DEBUG TRAIN Batch 17/5500 loss 5.318627 loss_att 7.387519 loss_ctc 12.286074 loss_rnnt 3.843585 hw_loss 0.248008 lr 0.00041193 rank 5
2023-02-22 09:09:07,497 DEBUG TRAIN Batch 17/5500 loss 24.707451 loss_att 27.157612 loss_ctc 28.820057 loss_rnnt 23.574989 hw_loss 0.176401 lr 0.00041192 rank 7
2023-02-22 09:09:07,498 DEBUG TRAIN Batch 17/5500 loss 5.559012 loss_att 6.875180 loss_ctc 8.392443 loss_rnnt 4.824773 hw_loss 0.174778 lr 0.00041196 rank 2
2023-02-22 09:09:07,501 DEBUG TRAIN Batch 17/5500 loss 12.826976 loss_att 16.465534 loss_ctc 18.751064 loss_rnnt 11.129396 hw_loss 0.337476 lr 0.00041201 rank 4
2023-02-22 09:09:07,501 DEBUG TRAIN Batch 17/5500 loss 14.954188 loss_att 17.162182 loss_ctc 21.424847 loss_rnnt 13.465429 hw_loss 0.345761 lr 0.00041196 rank 3
2023-02-22 09:09:07,501 DEBUG TRAIN Batch 17/5500 loss 15.992641 loss_att 19.463322 loss_ctc 20.772854 loss_rnnt 14.500307 hw_loss 0.301567 lr 0.00041195 rank 6
2023-02-22 09:09:07,507 DEBUG TRAIN Batch 17/5500 loss 10.733060 loss_att 13.192287 loss_ctc 13.547300 loss_rnnt 9.729273 hw_loss 0.256331 lr 0.00041205 rank 0
2023-02-22 09:09:07,555 DEBUG TRAIN Batch 17/5500 loss 21.222109 loss_att 22.160511 loss_ctc 27.187094 loss_rnnt 20.075619 hw_loss 0.306522 lr 0.00041201 rank 1
2023-02-22 09:10:20,080 DEBUG TRAIN Batch 17/5600 loss 15.111423 loss_att 17.752728 loss_ctc 21.948767 loss_rnnt 13.479102 hw_loss 0.360774 lr 0.00041182 rank 2
2023-02-22 09:10:20,086 DEBUG TRAIN Batch 17/5600 loss 10.588248 loss_att 12.789890 loss_ctc 16.764715 loss_rnnt 9.147960 hw_loss 0.330809 lr 0.00041187 rank 1
2023-02-22 09:10:20,087 DEBUG TRAIN Batch 17/5600 loss 12.742944 loss_att 17.905958 loss_ctc 17.082859 loss_rnnt 10.866019 hw_loss 0.498122 lr 0.00041179 rank 5
2023-02-22 09:10:20,088 DEBUG TRAIN Batch 17/5600 loss 10.757109 loss_att 14.993440 loss_ctc 13.416097 loss_rnnt 9.413416 hw_loss 0.266053 lr 0.00041178 rank 7
2023-02-22 09:10:20,091 DEBUG TRAIN Batch 17/5600 loss 9.853883 loss_att 12.221781 loss_ctc 16.195263 loss_rnnt 8.367653 hw_loss 0.313375 lr 0.00041182 rank 3
2023-02-22 09:10:20,092 DEBUG TRAIN Batch 17/5600 loss 11.969527 loss_att 15.278454 loss_ctc 16.682928 loss_rnnt 10.498256 hw_loss 0.339436 lr 0.00041181 rank 6
2023-02-22 09:10:20,094 DEBUG TRAIN Batch 17/5600 loss 13.434277 loss_att 15.899433 loss_ctc 19.371008 loss_rnnt 11.962764 hw_loss 0.350470 lr 0.00041187 rank 4
2023-02-22 09:10:20,097 DEBUG TRAIN Batch 17/5600 loss 12.704845 loss_att 14.688602 loss_ctc 18.128674 loss_rnnt 11.454012 hw_loss 0.245447 lr 0.00041191 rank 0
2023-02-22 09:11:35,396 DEBUG TRAIN Batch 17/5700 loss 10.778317 loss_att 17.482672 loss_ctc 12.918671 loss_rnnt 9.045084 hw_loss 0.200593 lr 0.00041168 rank 3
2023-02-22 09:11:35,398 DEBUG TRAIN Batch 17/5700 loss 5.724833 loss_att 23.682426 loss_ctc 5.200415 loss_rnnt 2.091650 hw_loss 0.209227 lr 0.00041168 rank 2
2023-02-22 09:11:35,399 DEBUG TRAIN Batch 17/5700 loss 2.237947 loss_att 5.100055 loss_ctc 4.949201 loss_rnnt 1.167886 hw_loss 0.255261 lr 0.00041168 rank 6
2023-02-22 09:11:35,400 DEBUG TRAIN Batch 17/5700 loss 7.239634 loss_att 9.800417 loss_ctc 10.757305 loss_rnnt 6.133342 hw_loss 0.234587 lr 0.00041177 rank 0
2023-02-22 09:11:35,402 DEBUG TRAIN Batch 17/5700 loss 8.562966 loss_att 9.899616 loss_ctc 12.750325 loss_rnnt 7.555297 hw_loss 0.341299 lr 0.00041173 rank 4
2023-02-22 09:11:35,406 DEBUG TRAIN Batch 17/5700 loss 15.313334 loss_att 18.968380 loss_ctc 20.935032 loss_rnnt 13.658924 hw_loss 0.325952 lr 0.00041165 rank 5
2023-02-22 09:11:35,410 DEBUG TRAIN Batch 17/5700 loss 16.326509 loss_att 18.758558 loss_ctc 21.725122 loss_rnnt 14.976084 hw_loss 0.270378 lr 0.00041164 rank 7
2023-02-22 09:11:35,435 DEBUG TRAIN Batch 17/5700 loss 12.290695 loss_att 14.109509 loss_ctc 15.198284 loss_rnnt 11.444064 hw_loss 0.178479 lr 0.00041173 rank 1
2023-02-22 09:12:47,644 DEBUG TRAIN Batch 17/5800 loss 6.292078 loss_att 11.416777 loss_ctc 8.444815 loss_rnnt 4.876846 hw_loss 0.193614 lr 0.00041154 rank 2
2023-02-22 09:12:47,645 DEBUG TRAIN Batch 17/5800 loss 8.072491 loss_att 13.091106 loss_ctc 13.905520 loss_rnnt 6.102180 hw_loss 0.354096 lr 0.00041154 rank 3
2023-02-22 09:12:47,645 DEBUG TRAIN Batch 17/5800 loss 19.874056 loss_att 22.254986 loss_ctc 24.802242 loss_rnnt 18.657015 hw_loss 0.157058 lr 0.00041150 rank 7
2023-02-22 09:12:47,650 DEBUG TRAIN Batch 17/5800 loss 3.522741 loss_att 6.954932 loss_ctc 7.654532 loss_rnnt 2.159132 hw_loss 0.236748 lr 0.00041159 rank 1
2023-02-22 09:12:47,652 DEBUG TRAIN Batch 17/5800 loss 9.518993 loss_att 9.530636 loss_ctc 13.550639 loss_rnnt 8.819548 hw_loss 0.299183 lr 0.00041159 rank 4
2023-02-22 09:12:47,653 DEBUG TRAIN Batch 17/5800 loss 4.679198 loss_att 7.584540 loss_ctc 5.564628 loss_rnnt 3.832733 hw_loss 0.276262 lr 0.00041163 rank 0
2023-02-22 09:12:47,653 DEBUG TRAIN Batch 17/5800 loss 9.298869 loss_att 12.344282 loss_ctc 13.638698 loss_rnnt 7.948750 hw_loss 0.304487 lr 0.00041154 rank 6
2023-02-22 09:12:47,654 DEBUG TRAIN Batch 17/5800 loss 11.870521 loss_att 14.375965 loss_ctc 15.410349 loss_rnnt 10.775679 hw_loss 0.228330 lr 0.00041151 rank 5
2023-02-22 09:14:00,003 DEBUG TRAIN Batch 17/5900 loss 13.447127 loss_att 13.421110 loss_ctc 15.664801 loss_rnnt 12.990515 hw_loss 0.311488 lr 0.00041138 rank 5
2023-02-22 09:14:00,006 DEBUG TRAIN Batch 17/5900 loss 16.382441 loss_att 19.066128 loss_ctc 23.238018 loss_rnnt 14.672801 hw_loss 0.485297 lr 0.00041140 rank 6
2023-02-22 09:14:00,009 DEBUG TRAIN Batch 17/5900 loss 12.020355 loss_att 16.696423 loss_ctc 18.945286 loss_rnnt 9.996983 hw_loss 0.309068 lr 0.00041140 rank 2
2023-02-22 09:14:00,011 DEBUG TRAIN Batch 17/5900 loss 5.306406 loss_att 7.674919 loss_ctc 10.001258 loss_rnnt 4.023784 hw_loss 0.343010 lr 0.00041140 rank 3
2023-02-22 09:14:00,012 DEBUG TRAIN Batch 17/5900 loss 11.019258 loss_att 14.227365 loss_ctc 13.547293 loss_rnnt 9.890662 hw_loss 0.281066 lr 0.00041145 rank 1
2023-02-22 09:14:00,013 DEBUG TRAIN Batch 17/5900 loss 11.686120 loss_att 13.800703 loss_ctc 14.824923 loss_rnnt 10.713940 hw_loss 0.245168 lr 0.00041149 rank 0
2023-02-22 09:14:00,018 DEBUG TRAIN Batch 17/5900 loss 12.060638 loss_att 14.872184 loss_ctc 15.155752 loss_rnnt 10.942908 hw_loss 0.267637 lr 0.00041145 rank 4
2023-02-22 09:14:00,041 DEBUG TRAIN Batch 17/5900 loss 11.175107 loss_att 13.140325 loss_ctc 12.883438 loss_rnnt 10.411773 hw_loss 0.267216 lr 0.00041136 rank 7
2023-02-22 09:15:13,988 DEBUG TRAIN Batch 17/6000 loss 12.797693 loss_att 15.478853 loss_ctc 16.430403 loss_rnnt 11.683260 hw_loss 0.175948 lr 0.00041131 rank 4
2023-02-22 09:15:13,994 DEBUG TRAIN Batch 17/6000 loss 20.917109 loss_att 24.755539 loss_ctc 29.702206 loss_rnnt 18.834293 hw_loss 0.269596 lr 0.00041126 rank 2
2023-02-22 09:15:13,999 DEBUG TRAIN Batch 17/6000 loss 10.219125 loss_att 13.473093 loss_ctc 15.282699 loss_rnnt 8.827301 hw_loss 0.123538 lr 0.00041135 rank 0
2023-02-22 09:15:13,999 DEBUG TRAIN Batch 17/6000 loss 10.395270 loss_att 14.420942 loss_ctc 16.704666 loss_rnnt 8.557274 hw_loss 0.359269 lr 0.00041126 rank 3
2023-02-22 09:15:14,000 DEBUG TRAIN Batch 17/6000 loss 10.789925 loss_att 13.194367 loss_ctc 14.373175 loss_rnnt 9.718468 hw_loss 0.211502 lr 0.00041126 rank 6
2023-02-22 09:15:14,000 DEBUG TRAIN Batch 17/6000 loss 8.770952 loss_att 11.529652 loss_ctc 12.007846 loss_rnnt 7.646799 hw_loss 0.264052 lr 0.00041123 rank 7
2023-02-22 09:15:14,002 DEBUG TRAIN Batch 17/6000 loss 5.902130 loss_att 8.034508 loss_ctc 8.317813 loss_rnnt 5.050610 hw_loss 0.193037 lr 0.00041131 rank 1
2023-02-22 09:15:14,043 DEBUG TRAIN Batch 17/6000 loss 5.835157 loss_att 7.795783 loss_ctc 8.511184 loss_rnnt 4.958173 hw_loss 0.240104 lr 0.00041124 rank 5
2023-02-22 09:16:27,846 DEBUG TRAIN Batch 17/6100 loss 10.489166 loss_att 11.416241 loss_ctc 14.816411 loss_rnnt 9.642395 hw_loss 0.158235 lr 0.00041121 rank 0
2023-02-22 09:16:27,850 DEBUG TRAIN Batch 17/6100 loss 17.783173 loss_att 20.945507 loss_ctc 27.883596 loss_rnnt 15.610564 hw_loss 0.362659 lr 0.00041110 rank 5
2023-02-22 09:16:27,860 DEBUG TRAIN Batch 17/6100 loss 8.146307 loss_att 10.142253 loss_ctc 10.486809 loss_rnnt 7.327533 hw_loss 0.201597 lr 0.00041112 rank 3
2023-02-22 09:16:27,862 DEBUG TRAIN Batch 17/6100 loss 10.771589 loss_att 13.412906 loss_ctc 12.742463 loss_rnnt 9.901125 hw_loss 0.148906 lr 0.00041112 rank 6
2023-02-22 09:16:27,865 DEBUG TRAIN Batch 17/6100 loss 10.931101 loss_att 13.625924 loss_ctc 17.778820 loss_rnnt 9.306110 hw_loss 0.324368 lr 0.00041113 rank 2
2023-02-22 09:16:27,870 DEBUG TRAIN Batch 17/6100 loss 1.902986 loss_att 3.728890 loss_ctc 1.899443 loss_rnnt 1.432341 hw_loss 0.198632 lr 0.00041117 rank 1
2023-02-22 09:16:27,877 DEBUG TRAIN Batch 17/6100 loss 6.823369 loss_att 9.799391 loss_ctc 9.761873 loss_rnnt 5.666800 hw_loss 0.317934 lr 0.00041109 rank 7
2023-02-22 09:16:27,880 DEBUG TRAIN Batch 17/6100 loss 2.328318 loss_att 4.666233 loss_ctc 3.554465 loss_rnnt 1.535887 hw_loss 0.302553 lr 0.00041117 rank 4
2023-02-22 09:17:40,437 DEBUG TRAIN Batch 17/6200 loss 10.905693 loss_att 12.950369 loss_ctc 14.752735 loss_rnnt 9.867733 hw_loss 0.217661 lr 0.00041095 rank 7
2023-02-22 09:17:40,437 DEBUG TRAIN Batch 17/6200 loss 15.000835 loss_att 18.110100 loss_ctc 18.836058 loss_rnnt 13.754381 hw_loss 0.212321 lr 0.00041098 rank 6
2023-02-22 09:17:40,439 DEBUG TRAIN Batch 17/6200 loss 9.868163 loss_att 12.039424 loss_ctc 12.788589 loss_rnnt 8.848785 hw_loss 0.367003 lr 0.00041107 rank 0
2023-02-22 09:17:40,440 DEBUG TRAIN Batch 17/6200 loss 9.266877 loss_att 12.262482 loss_ctc 12.298308 loss_rnnt 8.089615 hw_loss 0.326157 lr 0.00041099 rank 2
2023-02-22 09:17:40,442 DEBUG TRAIN Batch 17/6200 loss 12.127213 loss_att 17.645723 loss_ctc 15.087555 loss_rnnt 10.500173 hw_loss 0.241170 lr 0.00041098 rank 3
2023-02-22 09:17:40,445 DEBUG TRAIN Batch 17/6200 loss 7.360180 loss_att 9.735451 loss_ctc 9.732279 loss_rnnt 6.403486 hw_loss 0.310050 lr 0.00041103 rank 4
2023-02-22 09:17:40,470 DEBUG TRAIN Batch 17/6200 loss 19.917782 loss_att 20.521255 loss_ctc 24.296425 loss_rnnt 19.043974 hw_loss 0.317429 lr 0.00041103 rank 1
2023-02-22 09:17:40,483 DEBUG TRAIN Batch 17/6200 loss 7.542738 loss_att 10.134948 loss_ctc 10.213303 loss_rnnt 6.521983 hw_loss 0.274196 lr 0.00041096 rank 5
2023-02-22 09:18:52,776 DEBUG TRAIN Batch 17/6300 loss 13.153814 loss_att 12.733865 loss_ctc 17.088337 loss_rnnt 12.553004 hw_loss 0.300369 lr 0.00041085 rank 2
2023-02-22 09:18:52,782 DEBUG TRAIN Batch 17/6300 loss 15.661966 loss_att 17.135981 loss_ctc 22.637484 loss_rnnt 14.228751 hw_loss 0.390644 lr 0.00041090 rank 4
2023-02-22 09:18:52,782 DEBUG TRAIN Batch 17/6300 loss 16.938986 loss_att 16.376064 loss_ctc 21.325148 loss_rnnt 16.307463 hw_loss 0.298664 lr 0.00041085 rank 3
2023-02-22 09:18:52,782 DEBUG TRAIN Batch 17/6300 loss 10.199883 loss_att 13.652412 loss_ctc 12.943849 loss_rnnt 8.985425 hw_loss 0.296419 lr 0.00041082 rank 5
2023-02-22 09:18:52,783 DEBUG TRAIN Batch 17/6300 loss 10.262149 loss_att 15.113579 loss_ctc 12.490214 loss_rnnt 8.801217 hw_loss 0.362943 lr 0.00041084 rank 6
2023-02-22 09:18:52,790 DEBUG TRAIN Batch 17/6300 loss 18.311445 loss_att 21.117928 loss_ctc 27.616865 loss_rnnt 16.324690 hw_loss 0.346379 lr 0.00041090 rank 1
2023-02-22 09:18:52,795 DEBUG TRAIN Batch 17/6300 loss 11.990165 loss_att 12.276939 loss_ctc 14.106206 loss_rnnt 11.512348 hw_loss 0.259353 lr 0.00041081 rank 7
2023-02-22 09:18:52,835 DEBUG TRAIN Batch 17/6300 loss 8.451717 loss_att 8.782170 loss_ctc 10.975265 loss_rnnt 7.897102 hw_loss 0.285095 lr 0.00041093 rank 0
2023-02-22 09:20:07,738 DEBUG TRAIN Batch 17/6400 loss 13.546957 loss_att 17.807837 loss_ctc 16.358894 loss_rnnt 12.231650 hw_loss 0.165386 lr 0.00041071 rank 2
2023-02-22 09:20:07,740 DEBUG TRAIN Batch 17/6400 loss 9.053503 loss_att 10.072542 loss_ctc 12.665441 loss_rnnt 8.070672 hw_loss 0.557682 lr 0.00041067 rank 7
2023-02-22 09:20:07,745 DEBUG TRAIN Batch 17/6400 loss 3.900824 loss_att 6.811998 loss_ctc 8.195052 loss_rnnt 2.618456 hw_loss 0.239191 lr 0.00041070 rank 6
2023-02-22 09:20:07,746 DEBUG TRAIN Batch 17/6400 loss 3.776679 loss_att 7.736125 loss_ctc 4.620008 loss_rnnt 2.772378 hw_loss 0.187439 lr 0.00041076 rank 4
2023-02-22 09:20:07,747 DEBUG TRAIN Batch 17/6400 loss 9.330806 loss_att 12.773546 loss_ctc 14.886996 loss_rnnt 7.777238 hw_loss 0.232864 lr 0.00041079 rank 0
2023-02-22 09:20:07,752 DEBUG TRAIN Batch 17/6400 loss 11.273977 loss_att 13.158062 loss_ctc 12.892084 loss_rnnt 10.595287 hw_loss 0.161487 lr 0.00041076 rank 1
2023-02-22 09:20:07,774 DEBUG TRAIN Batch 17/6400 loss 3.813125 loss_att 6.771404 loss_ctc 6.812803 loss_rnnt 2.660682 hw_loss 0.301556 lr 0.00041071 rank 3
2023-02-22 09:20:07,795 DEBUG TRAIN Batch 17/6400 loss 10.618150 loss_att 14.129516 loss_ctc 13.684376 loss_rnnt 9.341860 hw_loss 0.309724 lr 0.00041068 rank 5
2023-02-22 09:21:21,060 DEBUG TRAIN Batch 17/6500 loss 18.571119 loss_att 18.863155 loss_ctc 25.451305 loss_rnnt 17.446514 hw_loss 0.279074 lr 0.00041057 rank 2
2023-02-22 09:21:21,061 DEBUG TRAIN Batch 17/6500 loss 3.290968 loss_att 4.982953 loss_ctc 3.012058 loss_rnnt 2.827906 hw_loss 0.303474 lr 0.00041057 rank 3
2023-02-22 09:21:21,062 DEBUG TRAIN Batch 17/6500 loss 11.027861 loss_att 13.599419 loss_ctc 15.431890 loss_rnnt 9.845299 hw_loss 0.151960 lr 0.00041065 rank 0
2023-02-22 09:21:21,063 DEBUG TRAIN Batch 17/6500 loss 6.786780 loss_att 11.112823 loss_ctc 10.544024 loss_rnnt 5.307477 hw_loss 0.212116 lr 0.00041053 rank 7
2023-02-22 09:21:21,063 DEBUG TRAIN Batch 17/6500 loss 6.443237 loss_att 9.124544 loss_ctc 9.928766 loss_rnnt 5.289022 hw_loss 0.287280 lr 0.00041062 rank 4
2023-02-22 09:21:21,064 DEBUG TRAIN Batch 17/6500 loss 10.010235 loss_att 11.050265 loss_ctc 11.909500 loss_rnnt 9.355124 hw_loss 0.363508 lr 0.00041062 rank 1
2023-02-22 09:21:21,066 DEBUG TRAIN Batch 17/6500 loss 2.691735 loss_att 5.397895 loss_ctc 4.664009 loss_rnnt 1.734161 hw_loss 0.287572 lr 0.00041056 rank 6
2023-02-22 09:21:21,066 DEBUG TRAIN Batch 17/6500 loss 7.870044 loss_att 10.023573 loss_ctc 10.278360 loss_rnnt 6.994411 hw_loss 0.232161 lr 0.00041054 rank 5
2023-02-22 09:22:33,462 DEBUG TRAIN Batch 17/6600 loss 14.168998 loss_att 15.342675 loss_ctc 22.109226 loss_rnnt 12.774726 hw_loss 0.189073 lr 0.00041043 rank 2
2023-02-22 09:22:33,463 DEBUG TRAIN Batch 17/6600 loss 9.331868 loss_att 13.115577 loss_ctc 11.665824 loss_rnnt 8.162070 hw_loss 0.190991 lr 0.00041043 rank 3
2023-02-22 09:22:33,467 DEBUG TRAIN Batch 17/6600 loss 9.970575 loss_att 14.759949 loss_ctc 14.384216 loss_rnnt 8.327562 hw_loss 0.181224 lr 0.00041043 rank 6
2023-02-22 09:22:33,468 DEBUG TRAIN Batch 17/6600 loss 14.443257 loss_att 17.773766 loss_ctc 21.188610 loss_rnnt 12.716274 hw_loss 0.302813 lr 0.00041048 rank 1
2023-02-22 09:22:33,469 DEBUG TRAIN Batch 17/6600 loss 12.431885 loss_att 14.653664 loss_ctc 17.127853 loss_rnnt 11.261089 hw_loss 0.188081 lr 0.00041039 rank 7
2023-02-22 09:22:33,472 DEBUG TRAIN Batch 17/6600 loss 11.196134 loss_att 13.820322 loss_ctc 16.764380 loss_rnnt 9.853263 hw_loss 0.141750 lr 0.00041048 rank 4
2023-02-22 09:22:33,473 DEBUG TRAIN Batch 17/6600 loss 18.723658 loss_att 22.669785 loss_ctc 27.781773 loss_rnnt 16.638998 hw_loss 0.164409 lr 0.00041052 rank 0
2023-02-22 09:22:33,474 DEBUG TRAIN Batch 17/6600 loss 8.078506 loss_att 11.194880 loss_ctc 9.514254 loss_rnnt 7.125397 hw_loss 0.259501 lr 0.00041040 rank 5
2023-02-22 09:23:47,104 DEBUG TRAIN Batch 17/6700 loss 5.887253 loss_att 8.644118 loss_ctc 8.241714 loss_rnnt 4.868755 hw_loss 0.287244 lr 0.00041027 rank 5
2023-02-22 09:23:47,113 DEBUG TRAIN Batch 17/6700 loss 12.066411 loss_att 15.206690 loss_ctc 17.576885 loss_rnnt 10.570135 hw_loss 0.250295 lr 0.00041038 rank 0
2023-02-22 09:23:47,114 DEBUG TRAIN Batch 17/6700 loss 8.694041 loss_att 10.927583 loss_ctc 9.952271 loss_rnnt 8.013868 hw_loss 0.123189 lr 0.00041029 rank 2
2023-02-22 09:23:47,115 DEBUG TRAIN Batch 17/6700 loss 15.217941 loss_att 20.237963 loss_ctc 18.920034 loss_rnnt 13.563722 hw_loss 0.293633 lr 0.00041034 rank 1
2023-02-22 09:23:47,116 DEBUG TRAIN Batch 17/6700 loss 3.336656 loss_att 6.188259 loss_ctc 7.334166 loss_rnnt 2.119277 hw_loss 0.213857 lr 0.00041034 rank 4
2023-02-22 09:23:47,120 DEBUG TRAIN Batch 17/6700 loss 7.612585 loss_att 10.069592 loss_ctc 11.333984 loss_rnnt 6.444535 hw_loss 0.338365 lr 0.00041029 rank 3
2023-02-22 09:23:47,122 DEBUG TRAIN Batch 17/6700 loss 6.853528 loss_att 10.146485 loss_ctc 9.176020 loss_rnnt 5.793241 hw_loss 0.172555 lr 0.00041026 rank 7
2023-02-22 09:23:47,123 DEBUG TRAIN Batch 17/6700 loss 9.533581 loss_att 13.324358 loss_ctc 14.382498 loss_rnnt 7.954334 hw_loss 0.327317 lr 0.00041029 rank 6
2023-02-22 09:25:01,196 DEBUG TRAIN Batch 17/6800 loss 6.059494 loss_att 11.335605 loss_ctc 7.667213 loss_rnnt 4.643546 hw_loss 0.274432 lr 0.00041020 rank 1
2023-02-22 09:25:01,204 DEBUG TRAIN Batch 17/6800 loss 7.005462 loss_att 9.232252 loss_ctc 9.867844 loss_rnnt 6.027592 hw_loss 0.282865 lr 0.00041015 rank 6
2023-02-22 09:25:01,205 DEBUG TRAIN Batch 17/6800 loss 8.774186 loss_att 12.455139 loss_ctc 13.649023 loss_rnnt 7.177286 hw_loss 0.395118 lr 0.00041024 rank 0
2023-02-22 09:25:01,207 DEBUG TRAIN Batch 17/6800 loss 8.041985 loss_att 9.872836 loss_ctc 11.162827 loss_rnnt 7.106661 hw_loss 0.286951 lr 0.00041013 rank 5
2023-02-22 09:25:01,207 DEBUG TRAIN Batch 17/6800 loss 4.815341 loss_att 10.098553 loss_ctc 9.989538 loss_rnnt 2.933540 hw_loss 0.253624 lr 0.00041016 rank 2
2023-02-22 09:25:01,211 DEBUG TRAIN Batch 17/6800 loss 16.759542 loss_att 21.809635 loss_ctc 25.052380 loss_rnnt 14.480856 hw_loss 0.305543 lr 0.00041015 rank 3
2023-02-22 09:25:01,212 DEBUG TRAIN Batch 17/6800 loss 18.473593 loss_att 18.285046 loss_ctc 27.249809 loss_rnnt 17.198608 hw_loss 0.267242 lr 0.00041012 rank 7
2023-02-22 09:25:01,254 DEBUG TRAIN Batch 17/6800 loss 5.341152 loss_att 8.213873 loss_ctc 6.787045 loss_rnnt 4.404799 hw_loss 0.316918 lr 0.00041020 rank 4
2023-02-22 09:26:13,708 DEBUG TRAIN Batch 17/6900 loss 11.096090 loss_att 14.793114 loss_ctc 15.809507 loss_rnnt 9.588980 hw_loss 0.261092 lr 0.00040999 rank 5
2023-02-22 09:26:13,708 DEBUG TRAIN Batch 17/6900 loss 18.628942 loss_att 18.537014 loss_ctc 22.283909 loss_rnnt 17.964977 hw_loss 0.365669 lr 0.00041002 rank 3
2023-02-22 09:26:13,711 DEBUG TRAIN Batch 17/6900 loss 6.023877 loss_att 8.132230 loss_ctc 6.105520 loss_rnnt 5.498290 hw_loss 0.174434 lr 0.00041002 rank 2
2023-02-22 09:26:13,712 DEBUG TRAIN Batch 17/6900 loss 5.588774 loss_att 7.843008 loss_ctc 7.422825 loss_rnnt 4.743865 hw_loss 0.280354 lr 0.00041001 rank 6
2023-02-22 09:26:13,714 DEBUG TRAIN Batch 17/6900 loss 17.113682 loss_att 18.107573 loss_ctc 24.511221 loss_rnnt 15.715740 hw_loss 0.399046 lr 0.00041007 rank 1
2023-02-22 09:26:13,714 DEBUG TRAIN Batch 17/6900 loss 5.855959 loss_att 8.967751 loss_ctc 8.058215 loss_rnnt 4.795155 hw_loss 0.271524 lr 0.00041010 rank 0
2023-02-22 09:26:13,715 DEBUG TRAIN Batch 17/6900 loss 7.074797 loss_att 9.018719 loss_ctc 7.435519 loss_rnnt 6.469029 hw_loss 0.316662 lr 0.00041007 rank 4
2023-02-22 09:26:13,762 DEBUG TRAIN Batch 17/6900 loss 12.186469 loss_att 15.104948 loss_ctc 15.969411 loss_rnnt 10.972189 hw_loss 0.236612 lr 0.00040998 rank 7
2023-02-22 09:27:27,035 DEBUG TRAIN Batch 17/7000 loss 6.437644 loss_att 6.785644 loss_ctc 7.625468 loss_rnnt 6.016284 hw_loss 0.362595 lr 0.00040988 rank 2
2023-02-22 09:27:27,037 DEBUG TRAIN Batch 17/7000 loss 12.757151 loss_att 17.357380 loss_ctc 22.570374 loss_rnnt 10.340258 hw_loss 0.353282 lr 0.00040993 rank 1
2023-02-22 09:27:27,042 DEBUG TRAIN Batch 17/7000 loss 7.936471 loss_att 9.399846 loss_ctc 11.020599 loss_rnnt 7.100627 hw_loss 0.247408 lr 0.00040984 rank 7
2023-02-22 09:27:27,046 DEBUG TRAIN Batch 17/7000 loss 9.489923 loss_att 11.826898 loss_ctc 13.186919 loss_rnnt 8.402417 hw_loss 0.238460 lr 0.00040985 rank 5
2023-02-22 09:27:27,054 DEBUG TRAIN Batch 17/7000 loss 7.007189 loss_att 7.827172 loss_ctc 8.856014 loss_rnnt 6.445430 hw_loss 0.283600 lr 0.00040996 rank 0
2023-02-22 09:27:27,055 DEBUG TRAIN Batch 17/7000 loss 15.656851 loss_att 16.834312 loss_ctc 21.044842 loss_rnnt 14.412669 hw_loss 0.544296 lr 0.00040987 rank 6
2023-02-22 09:27:27,061 DEBUG TRAIN Batch 17/7000 loss 8.244198 loss_att 8.162525 loss_ctc 11.243213 loss_rnnt 7.709578 hw_loss 0.283287 lr 0.00040988 rank 3
2023-02-22 09:27:27,087 DEBUG TRAIN Batch 17/7000 loss 13.386026 loss_att 11.726300 loss_ctc 16.278334 loss_rnnt 13.001971 hw_loss 0.619423 lr 0.00040993 rank 4
2023-02-22 09:28:41,836 DEBUG TRAIN Batch 17/7100 loss 15.003670 loss_att 18.651318 loss_ctc 19.222694 loss_rnnt 13.603041 hw_loss 0.203554 lr 0.00040971 rank 5
2023-02-22 09:28:41,846 DEBUG TRAIN Batch 17/7100 loss 4.772924 loss_att 6.859461 loss_ctc 5.538501 loss_rnnt 4.133744 hw_loss 0.224615 lr 0.00040970 rank 7
2023-02-22 09:28:41,846 DEBUG TRAIN Batch 17/7100 loss 2.790936 loss_att 6.351994 loss_ctc 5.188477 loss_rnnt 1.509874 hw_loss 0.467210 lr 0.00040974 rank 2
2023-02-22 09:28:41,848 DEBUG TRAIN Batch 17/7100 loss 5.487146 loss_att 8.031679 loss_ctc 6.703852 loss_rnnt 4.725517 hw_loss 0.169679 lr 0.00040979 rank 4
2023-02-22 09:28:41,848 DEBUG TRAIN Batch 17/7100 loss 14.230567 loss_att 17.471958 loss_ctc 17.516953 loss_rnnt 13.052752 hw_loss 0.171282 lr 0.00040983 rank 0
2023-02-22 09:28:41,850 DEBUG TRAIN Batch 17/7100 loss 14.657959 loss_att 16.487682 loss_ctc 20.934774 loss_rnnt 13.314276 hw_loss 0.264059 lr 0.00040974 rank 3
2023-02-22 09:28:41,850 DEBUG TRAIN Batch 17/7100 loss 5.387928 loss_att 6.849526 loss_ctc 6.604631 loss_rnnt 4.761250 hw_loss 0.322743 lr 0.00040974 rank 6
2023-02-22 09:28:41,856 DEBUG TRAIN Batch 17/7100 loss 5.752123 loss_att 9.411209 loss_ctc 7.845391 loss_rnnt 4.648407 hw_loss 0.173991 lr 0.00040979 rank 1
2023-02-22 09:29:55,313 DEBUG TRAIN Batch 17/7200 loss 16.690138 loss_att 15.578663 loss_ctc 19.058483 loss_rnnt 16.481993 hw_loss 0.214993 lr 0.00040957 rank 7
2023-02-22 09:29:55,314 DEBUG TRAIN Batch 17/7200 loss 15.135328 loss_att 17.993454 loss_ctc 20.192595 loss_rnnt 13.763638 hw_loss 0.235806 lr 0.00040960 rank 2
2023-02-22 09:29:55,315 DEBUG TRAIN Batch 17/7200 loss 12.396680 loss_att 14.282490 loss_ctc 16.689217 loss_rnnt 11.320546 hw_loss 0.237439 lr 0.00040960 rank 6
2023-02-22 09:29:55,316 DEBUG TRAIN Batch 17/7200 loss 14.160624 loss_att 18.824888 loss_ctc 21.668465 loss_rnnt 12.043081 hw_loss 0.344334 lr 0.00040960 rank 3
2023-02-22 09:29:55,321 DEBUG TRAIN Batch 17/7200 loss 12.909964 loss_att 14.245544 loss_ctc 18.191153 loss_rnnt 11.801399 hw_loss 0.257417 lr 0.00040958 rank 5
2023-02-22 09:29:55,324 DEBUG TRAIN Batch 17/7200 loss 4.230096 loss_att 7.299047 loss_ctc 7.011381 loss_rnnt 3.150287 hw_loss 0.178465 lr 0.00040965 rank 1
2023-02-22 09:29:55,323 DEBUG TRAIN Batch 17/7200 loss 6.527258 loss_att 9.896071 loss_ctc 8.728720 loss_rnnt 5.461423 hw_loss 0.184769 lr 0.00040969 rank 0
2023-02-22 09:29:55,366 DEBUG TRAIN Batch 17/7200 loss 4.807421 loss_att 11.593575 loss_ctc 4.846684 loss_rnnt 3.204374 hw_loss 0.451089 lr 0.00040965 rank 4
2023-02-22 09:31:07,636 DEBUG TRAIN Batch 17/7300 loss 8.041524 loss_att 10.345304 loss_ctc 11.269814 loss_rnnt 6.993650 hw_loss 0.293771 lr 0.00040947 rank 2
2023-02-22 09:31:07,638 DEBUG TRAIN Batch 17/7300 loss 9.714362 loss_att 16.244280 loss_ctc 16.176369 loss_rnnt 7.402524 hw_loss 0.270474 lr 0.00040947 rank 3
2023-02-22 09:31:07,640 DEBUG TRAIN Batch 17/7300 loss 3.668159 loss_att 7.705132 loss_ctc 5.514928 loss_rnnt 2.490536 hw_loss 0.232484 lr 0.00040944 rank 5
2023-02-22 09:31:07,640 DEBUG TRAIN Batch 17/7300 loss 11.743634 loss_att 12.955719 loss_ctc 17.037676 loss_rnnt 10.628522 hw_loss 0.312793 lr 0.00040946 rank 6
2023-02-22 09:31:07,641 DEBUG TRAIN Batch 17/7300 loss 10.031645 loss_att 11.648088 loss_ctc 12.032047 loss_rnnt 9.324783 hw_loss 0.219097 lr 0.00040952 rank 4
2023-02-22 09:31:07,646 DEBUG TRAIN Batch 17/7300 loss 21.987638 loss_att 24.291100 loss_ctc 30.597120 loss_rnnt 20.158983 hw_loss 0.412561 lr 0.00040952 rank 1
2023-02-22 09:31:07,647 DEBUG TRAIN Batch 17/7300 loss 17.727301 loss_att 20.643215 loss_ctc 23.160511 loss_rnnt 16.290098 hw_loss 0.242982 lr 0.00040943 rank 7
2023-02-22 09:31:07,693 DEBUG TRAIN Batch 17/7300 loss 15.485744 loss_att 17.351303 loss_ctc 19.959476 loss_rnnt 14.356964 hw_loss 0.298443 lr 0.00040955 rank 0
2023-02-22 09:32:20,571 DEBUG TRAIN Batch 17/7400 loss 17.407639 loss_att 19.536833 loss_ctc 22.582850 loss_rnnt 16.177052 hw_loss 0.215100 lr 0.00040929 rank 7
2023-02-22 09:32:20,581 DEBUG TRAIN Batch 17/7400 loss 9.909244 loss_att 12.827060 loss_ctc 13.421927 loss_rnnt 8.784557 hw_loss 0.136435 lr 0.00040930 rank 5
2023-02-22 09:32:20,582 DEBUG TRAIN Batch 17/7400 loss 4.806720 loss_att 8.505270 loss_ctc 7.132758 loss_rnnt 3.621753 hw_loss 0.253348 lr 0.00040938 rank 1
2023-02-22 09:32:20,585 DEBUG TRAIN Batch 17/7400 loss 6.426277 loss_att 11.705305 loss_ctc 10.865490 loss_rnnt 4.683784 hw_loss 0.177736 lr 0.00040932 rank 6
2023-02-22 09:32:20,587 DEBUG TRAIN Batch 17/7400 loss 5.183936 loss_att 7.878533 loss_ctc 8.223202 loss_rnnt 4.101433 hw_loss 0.259401 lr 0.00040933 rank 3
2023-02-22 09:32:20,588 DEBUG TRAIN Batch 17/7400 loss 13.861054 loss_att 17.493292 loss_ctc 20.219376 loss_rnnt 12.066657 hw_loss 0.412827 lr 0.00040933 rank 2
2023-02-22 09:32:20,621 DEBUG TRAIN Batch 17/7400 loss 4.642037 loss_att 9.177046 loss_ctc 6.647942 loss_rnnt 3.344377 hw_loss 0.231009 lr 0.00040938 rank 4
2023-02-22 09:32:20,621 DEBUG TRAIN Batch 17/7400 loss 4.208794 loss_att 6.764099 loss_ctc 6.271551 loss_rnnt 3.326785 hw_loss 0.179837 lr 0.00040941 rank 0
2023-02-22 09:33:36,131 DEBUG TRAIN Batch 17/7500 loss 3.517628 loss_att 4.754207 loss_ctc 3.340540 loss_rnnt 3.179263 hw_loss 0.214989 lr 0.00040919 rank 2
2023-02-22 09:33:36,138 DEBUG TRAIN Batch 17/7500 loss 7.626868 loss_att 10.068834 loss_ctc 11.243686 loss_rnnt 6.533201 hw_loss 0.230684 lr 0.00040919 rank 3
2023-02-22 09:33:36,138 DEBUG TRAIN Batch 17/7500 loss 11.447094 loss_att 11.496138 loss_ctc 14.904839 loss_rnnt 10.885553 hw_loss 0.170059 lr 0.00040919 rank 6
2023-02-22 09:33:36,139 DEBUG TRAIN Batch 17/7500 loss 9.328954 loss_att 12.751664 loss_ctc 12.176111 loss_rnnt 8.160301 hw_loss 0.195918 lr 0.00040928 rank 0
2023-02-22 09:33:36,142 DEBUG TRAIN Batch 17/7500 loss 4.371874 loss_att 5.035123 loss_ctc 5.882011 loss_rnnt 3.870030 hw_loss 0.314705 lr 0.00040924 rank 1
2023-02-22 09:33:36,147 DEBUG TRAIN Batch 17/7500 loss 21.361340 loss_att 24.152925 loss_ctc 30.197399 loss_rnnt 19.516270 hw_loss 0.203647 lr 0.00040915 rank 7
2023-02-22 09:33:36,147 DEBUG TRAIN Batch 17/7500 loss 4.200611 loss_att 6.382608 loss_ctc 5.636543 loss_rnnt 3.468638 hw_loss 0.195217 lr 0.00040924 rank 4
2023-02-22 09:33:36,150 DEBUG TRAIN Batch 17/7500 loss 7.039679 loss_att 8.235641 loss_ctc 10.769165 loss_rnnt 6.167739 hw_loss 0.254029 lr 0.00040917 rank 5
2023-02-22 09:34:48,870 DEBUG TRAIN Batch 17/7600 loss 11.920838 loss_att 12.860697 loss_ctc 16.247026 loss_rnnt 10.920806 hw_loss 0.441066 lr 0.00040906 rank 2
2023-02-22 09:34:48,871 DEBUG TRAIN Batch 17/7600 loss 15.911825 loss_att 18.892178 loss_ctc 21.320793 loss_rnnt 14.429321 hw_loss 0.309820 lr 0.00040902 rank 7
2023-02-22 09:34:48,874 DEBUG TRAIN Batch 17/7600 loss 7.948711 loss_att 9.183737 loss_ctc 10.309819 loss_rnnt 7.195795 hw_loss 0.358306 lr 0.00040910 rank 4
2023-02-22 09:34:48,876 DEBUG TRAIN Batch 17/7600 loss 7.209330 loss_att 9.797674 loss_ctc 10.277666 loss_rnnt 6.022969 hw_loss 0.486712 lr 0.00040905 rank 3
2023-02-22 09:34:48,876 DEBUG TRAIN Batch 17/7600 loss 10.444889 loss_att 11.631055 loss_ctc 10.243551 loss_rnnt 10.008083 hw_loss 0.424533 lr 0.00040903 rank 5
2023-02-22 09:34:48,877 DEBUG TRAIN Batch 17/7600 loss 6.631403 loss_att 7.846227 loss_ctc 8.766768 loss_rnnt 5.908422 hw_loss 0.366188 lr 0.00040914 rank 0
2023-02-22 09:34:48,881 DEBUG TRAIN Batch 17/7600 loss 11.849822 loss_att 14.880175 loss_ctc 18.442429 loss_rnnt 10.161749 hw_loss 0.380604 lr 0.00040905 rank 6
2023-02-22 09:34:48,924 DEBUG TRAIN Batch 17/7600 loss 18.509411 loss_att 22.232893 loss_ctc 25.972939 loss_rnnt 16.629395 hw_loss 0.262841 lr 0.00040910 rank 1
2023-02-22 09:36:02,362 DEBUG TRAIN Batch 17/7700 loss 18.545191 loss_att 20.525303 loss_ctc 25.940947 loss_rnnt 17.067854 hw_loss 0.178524 lr 0.00040892 rank 2
2023-02-22 09:36:02,366 DEBUG TRAIN Batch 17/7700 loss 8.102365 loss_att 11.060189 loss_ctc 15.624118 loss_rnnt 6.388986 hw_loss 0.222965 lr 0.00040892 rank 3
2023-02-22 09:36:02,370 DEBUG TRAIN Batch 17/7700 loss 9.367548 loss_att 12.073080 loss_ctc 12.676726 loss_rnnt 8.269071 hw_loss 0.217775 lr 0.00040897 rank 4
2023-02-22 09:36:02,371 DEBUG TRAIN Batch 17/7700 loss 16.726450 loss_att 19.027405 loss_ctc 22.865776 loss_rnnt 15.334066 hw_loss 0.213032 lr 0.00040891 rank 6
2023-02-22 09:36:02,372 DEBUG TRAIN Batch 17/7700 loss 11.263439 loss_att 11.339075 loss_ctc 14.021625 loss_rnnt 10.718620 hw_loss 0.303627 lr 0.00040888 rank 7
2023-02-22 09:36:02,373 DEBUG TRAIN Batch 17/7700 loss 6.950500 loss_att 9.111433 loss_ctc 11.953938 loss_rnnt 5.695968 hw_loss 0.291038 lr 0.00040889 rank 5
2023-02-22 09:36:02,376 DEBUG TRAIN Batch 17/7700 loss 21.498838 loss_att 23.680517 loss_ctc 25.108791 loss_rnnt 20.425835 hw_loss 0.291264 lr 0.00040897 rank 1
2023-02-22 09:36:02,380 DEBUG TRAIN Batch 17/7700 loss 7.369765 loss_att 21.448755 loss_ctc 7.023143 loss_rnnt 4.473019 hw_loss 0.238432 lr 0.00040900 rank 0
2023-02-22 09:37:18,035 DEBUG TRAIN Batch 17/7800 loss 13.555115 loss_att 16.326035 loss_ctc 17.113106 loss_rnnt 12.409252 hw_loss 0.219902 lr 0.00040878 rank 2
2023-02-22 09:37:18,039 DEBUG TRAIN Batch 17/7800 loss 6.105512 loss_att 7.565685 loss_ctc 6.845938 loss_rnnt 5.561603 hw_loss 0.287160 lr 0.00040886 rank 0
2023-02-22 09:37:18,039 DEBUG TRAIN Batch 17/7800 loss 12.226812 loss_att 16.952360 loss_ctc 22.353390 loss_rnnt 9.837765 hw_loss 0.175738 lr 0.00040878 rank 3
2023-02-22 09:37:18,039 DEBUG TRAIN Batch 17/7800 loss 13.344504 loss_att 13.763866 loss_ctc 17.296600 loss_rnnt 12.592194 hw_loss 0.265298 lr 0.00040876 rank 5
2023-02-22 09:37:18,040 DEBUG TRAIN Batch 17/7800 loss 7.825020 loss_att 11.454658 loss_ctc 10.230413 loss_rnnt 6.640024 hw_loss 0.259406 lr 0.00040874 rank 7
2023-02-22 09:37:18,042 DEBUG TRAIN Batch 17/7800 loss 5.491372 loss_att 9.132284 loss_ctc 7.881654 loss_rnnt 4.279445 hw_loss 0.309452 lr 0.00040878 rank 6
2023-02-22 09:37:18,043 DEBUG TRAIN Batch 17/7800 loss 15.242067 loss_att 16.384066 loss_ctc 20.837666 loss_rnnt 14.139871 hw_loss 0.239468 lr 0.00040883 rank 1
2023-02-22 09:37:18,081 DEBUG TRAIN Batch 17/7800 loss 12.777865 loss_att 17.884342 loss_ctc 22.610439 loss_rnnt 10.388965 hw_loss 0.106118 lr 0.00040883 rank 4
2023-02-22 09:38:31,436 DEBUG TRAIN Batch 17/7900 loss 4.213652 loss_att 7.647160 loss_ctc 5.335323 loss_rnnt 3.256875 hw_loss 0.225975 lr 0.00040864 rank 3
2023-02-22 09:38:31,450 DEBUG TRAIN Batch 17/7900 loss 8.185686 loss_att 11.563818 loss_ctc 11.234987 loss_rnnt 6.977779 hw_loss 0.235701 lr 0.00040861 rank 7
2023-02-22 09:38:31,451 DEBUG TRAIN Batch 17/7900 loss 7.023796 loss_att 9.946913 loss_ctc 10.746179 loss_rnnt 5.807256 hw_loss 0.254249 lr 0.00040869 rank 1
2023-02-22 09:38:31,452 DEBUG TRAIN Batch 17/7900 loss 6.573347 loss_att 9.432703 loss_ctc 8.258108 loss_rnnt 5.651553 hw_loss 0.234914 lr 0.00040865 rank 2
2023-02-22 09:38:31,453 DEBUG TRAIN Batch 17/7900 loss 13.098962 loss_att 15.011944 loss_ctc 15.128243 loss_rnnt 12.345879 hw_loss 0.187341 lr 0.00040864 rank 6
2023-02-22 09:38:31,457 DEBUG TRAIN Batch 17/7900 loss 9.500931 loss_att 15.388451 loss_ctc 14.251200 loss_rnnt 7.575037 hw_loss 0.215664 lr 0.00040873 rank 0
2023-02-22 09:38:31,459 DEBUG TRAIN Batch 17/7900 loss 9.993715 loss_att 9.819476 loss_ctc 12.857971 loss_rnnt 9.478810 hw_loss 0.314722 lr 0.00040862 rank 5
2023-02-22 09:38:31,499 DEBUG TRAIN Batch 17/7900 loss 19.897429 loss_att 20.062073 loss_ctc 30.728695 loss_rnnt 18.290890 hw_loss 0.242698 lr 0.00040869 rank 4
2023-02-22 09:39:44,198 DEBUG TRAIN Batch 17/8000 loss 10.931556 loss_att 13.462534 loss_ctc 12.754419 loss_rnnt 10.083095 hw_loss 0.186031 lr 0.00040856 rank 1
2023-02-22 09:39:44,197 DEBUG TRAIN Batch 17/8000 loss 10.603596 loss_att 11.753538 loss_ctc 14.026952 loss_rnnt 9.693570 hw_loss 0.419230 lr 0.00040850 rank 6
2023-02-22 09:39:44,202 DEBUG TRAIN Batch 17/8000 loss 7.693882 loss_att 14.310102 loss_ctc 11.326166 loss_rnnt 5.700080 hw_loss 0.349224 lr 0.00040851 rank 2
2023-02-22 09:39:44,201 DEBUG TRAIN Batch 17/8000 loss 4.769901 loss_att 7.763584 loss_ctc 7.520543 loss_rnnt 3.713686 hw_loss 0.170112 lr 0.00040847 rank 7
2023-02-22 09:39:44,201 DEBUG TRAIN Batch 17/8000 loss 10.636970 loss_att 14.613216 loss_ctc 14.507991 loss_rnnt 9.183273 hw_loss 0.266834 lr 0.00040859 rank 0
2023-02-22 09:39:44,203 DEBUG TRAIN Batch 17/8000 loss 6.559384 loss_att 9.687081 loss_ctc 9.715251 loss_rnnt 5.306815 hw_loss 0.386714 lr 0.00040856 rank 4
2023-02-22 09:39:44,205 DEBUG TRAIN Batch 17/8000 loss 9.568178 loss_att 12.874270 loss_ctc 14.009809 loss_rnnt 8.223518 hw_loss 0.171044 lr 0.00040851 rank 3
2023-02-22 09:39:44,251 DEBUG TRAIN Batch 17/8000 loss 8.287039 loss_att 9.867773 loss_ctc 13.364325 loss_rnnt 7.177860 hw_loss 0.217614 lr 0.00040848 rank 5
2023-02-22 09:40:57,407 DEBUG TRAIN Batch 17/8100 loss 4.267696 loss_att 9.105743 loss_ctc 6.427962 loss_rnnt 2.876756 hw_loss 0.253678 lr 0.00040835 rank 5
2023-02-22 09:40:57,406 DEBUG TRAIN Batch 17/8100 loss 10.640451 loss_att 11.945821 loss_ctc 13.010221 loss_rnnt 9.943997 hw_loss 0.223896 lr 0.00040837 rank 6
2023-02-22 09:40:57,410 DEBUG TRAIN Batch 17/8100 loss 8.776802 loss_att 10.758265 loss_ctc 11.895270 loss_rnnt 7.814742 hw_loss 0.281198 lr 0.00040842 rank 4
2023-02-22 09:40:57,410 DEBUG TRAIN Batch 17/8100 loss 7.053990 loss_att 9.857907 loss_ctc 9.381780 loss_rnnt 6.016887 hw_loss 0.311151 lr 0.00040837 rank 3
2023-02-22 09:40:57,437 DEBUG TRAIN Batch 17/8100 loss 11.874000 loss_att 14.063117 loss_ctc 19.911673 loss_rnnt 10.154506 hw_loss 0.393714 lr 0.00040842 rank 1
2023-02-22 09:40:57,448 DEBUG TRAIN Batch 17/8100 loss 10.645040 loss_att 13.988661 loss_ctc 12.321630 loss_rnnt 9.647333 hw_loss 0.197694 lr 0.00040846 rank 0
2023-02-22 09:40:57,454 DEBUG TRAIN Batch 17/8100 loss 17.811985 loss_att 22.340979 loss_ctc 25.264297 loss_rnnt 15.748594 hw_loss 0.307407 lr 0.00040834 rank 7
2023-02-22 09:40:57,474 DEBUG TRAIN Batch 17/8100 loss 10.289792 loss_att 13.162474 loss_ctc 14.727489 loss_rnnt 8.975242 hw_loss 0.278104 lr 0.00040837 rank 2
2023-02-22 09:42:11,138 DEBUG TRAIN Batch 17/8200 loss 8.067630 loss_att 8.625574 loss_ctc 10.196751 loss_rnnt 7.413157 hw_loss 0.485626 lr 0.00040823 rank 6
2023-02-22 09:42:11,141 DEBUG TRAIN Batch 17/8200 loss 7.428915 loss_att 10.190304 loss_ctc 11.047845 loss_rnnt 6.209286 hw_loss 0.346550 lr 0.00040821 rank 5
2023-02-22 09:42:11,141 DEBUG TRAIN Batch 17/8200 loss 15.630428 loss_att 17.556372 loss_ctc 20.038496 loss_rnnt 14.500607 hw_loss 0.294166 lr 0.00040824 rank 3
2023-02-22 09:42:11,145 DEBUG TRAIN Batch 17/8200 loss 15.841454 loss_att 19.436693 loss_ctc 21.619278 loss_rnnt 14.259764 hw_loss 0.172997 lr 0.00040829 rank 1
2023-02-22 09:42:11,145 DEBUG TRAIN Batch 17/8200 loss 10.410695 loss_att 12.938391 loss_ctc 16.021797 loss_rnnt 8.986011 hw_loss 0.320623 lr 0.00040829 rank 4
2023-02-22 09:42:11,160 DEBUG TRAIN Batch 17/8200 loss 5.082797 loss_att 7.772192 loss_ctc 6.784290 loss_rnnt 4.189427 hw_loss 0.241170 lr 0.00040820 rank 7
2023-02-22 09:42:11,170 DEBUG TRAIN Batch 17/8200 loss 12.351910 loss_att 13.578014 loss_ctc 18.367254 loss_rnnt 11.208899 hw_loss 0.179519 lr 0.00040824 rank 2
2023-02-22 09:42:11,179 DEBUG TRAIN Batch 17/8200 loss 17.162710 loss_att 19.261629 loss_ctc 23.278366 loss_rnnt 15.781405 hw_loss 0.273940 lr 0.00040832 rank 0
2023-02-22 09:43:23,902 DEBUG TRAIN Batch 17/8300 loss 8.734073 loss_att 14.364843 loss_ctc 11.618976 loss_rnnt 7.109938 hw_loss 0.212488 lr 0.00040810 rank 3
2023-02-22 09:43:23,907 DEBUG TRAIN Batch 17/8300 loss 16.609278 loss_att 16.173237 loss_ctc 20.510914 loss_rnnt 16.096125 hw_loss 0.150265 lr 0.00040809 rank 6
2023-02-22 09:43:23,910 DEBUG TRAIN Batch 17/8300 loss 20.435663 loss_att 24.293514 loss_ctc 24.181475 loss_rnnt 18.976532 hw_loss 0.352722 lr 0.00040806 rank 7
2023-02-22 09:43:23,910 DEBUG TRAIN Batch 17/8300 loss 5.667140 loss_att 9.749754 loss_ctc 8.552372 loss_rnnt 4.349853 hw_loss 0.217626 lr 0.00040815 rank 4
2023-02-22 09:43:23,913 DEBUG TRAIN Batch 17/8300 loss 11.130482 loss_att 10.477996 loss_ctc 15.638474 loss_rnnt 10.440069 hw_loss 0.412208 lr 0.00040810 rank 2
2023-02-22 09:43:23,917 DEBUG TRAIN Batch 17/8300 loss 13.438642 loss_att 14.283451 loss_ctc 18.128559 loss_rnnt 12.379505 hw_loss 0.496597 lr 0.00040818 rank 0
2023-02-22 09:43:23,918 DEBUG TRAIN Batch 17/8300 loss 4.270855 loss_att 8.771198 loss_ctc 6.047789 loss_rnnt 2.936194 hw_loss 0.370627 lr 0.00040815 rank 1
2023-02-22 09:44:11,476 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 4
2023-02-22 09:44:11,477 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 1
2023-02-22 09:44:11,482 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 2
2023-02-22 09:44:11,482 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 0
2023-02-22 09:44:11,483 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 5
2023-02-22 09:44:11,484 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 6
2023-02-22 09:44:11,488 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 7
2023-02-22 09:44:11,502 DEBUG CV Batch 17/0 loss 2.233512 loss_att 2.088781 loss_ctc 2.745239 loss_rnnt 1.764232 hw_loss 0.806243 history loss 2.150790 rank 3
2023-02-22 09:44:22,847 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 1
2023-02-22 09:44:22,870 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 3
2023-02-22 09:44:22,884 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 0
2023-02-22 09:44:22,897 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 7
2023-02-22 09:44:22,909 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 4
2023-02-22 09:44:22,996 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 2
2023-02-22 09:44:23,035 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 5
2023-02-22 09:44:23,295 DEBUG CV Batch 17/100 loss 7.704442 loss_att 8.594866 loss_ctc 10.352205 loss_rnnt 7.028274 hw_loss 0.271966 history loss 3.805641 rank 6
2023-02-22 09:44:36,283 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 1
2023-02-22 09:44:36,365 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 4
2023-02-22 09:44:36,382 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 7
2023-02-22 09:44:36,384 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 0
2023-02-22 09:44:36,455 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 5
2023-02-22 09:44:36,497 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 3
2023-02-22 09:44:36,637 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 2
2023-02-22 09:44:37,189 DEBUG CV Batch 17/200 loss 8.087636 loss_att 12.991946 loss_ctc 10.798918 loss_rnnt 6.611179 hw_loss 0.251421 history loss 4.333894 rank 6
2023-02-22 09:44:48,411 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 4
2023-02-22 09:44:48,723 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 7
2023-02-22 09:44:48,815 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 5
2023-02-22 09:44:48,923 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 2
2023-02-22 09:44:49,006 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 3
2023-02-22 09:44:49,021 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 0
2023-02-22 09:44:49,104 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 1
2023-02-22 09:44:49,736 DEBUG CV Batch 17/300 loss 5.553491 loss_att 5.484013 loss_ctc 7.178908 loss_rnnt 5.100930 hw_loss 0.468252 history loss 4.484785 rank 6
2023-02-22 09:45:00,587 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 4
2023-02-22 09:45:00,854 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 7
2023-02-22 09:45:00,864 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 5
2023-02-22 09:45:01,325 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 2
2023-02-22 09:45:01,346 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 3
2023-02-22 09:45:01,441 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 0
2023-02-22 09:45:01,442 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 1
2023-02-22 09:45:02,110 DEBUG CV Batch 17/400 loss 17.018530 loss_att 88.871407 loss_ctc 5.634700 loss_rnnt 4.074458 hw_loss 0.171261 history loss 5.527904 rank 6
2023-02-22 09:45:11,330 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 4
2023-02-22 09:45:11,606 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 7
2023-02-22 09:45:12,149 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 2
2023-02-22 09:45:12,272 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 3
2023-02-22 09:45:12,340 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 1
2023-02-22 09:45:12,405 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 5
2023-02-22 09:45:12,456 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 0
2023-02-22 09:45:13,193 DEBUG CV Batch 17/500 loss 6.074411 loss_att 6.285329 loss_ctc 7.439919 loss_rnnt 5.672006 hw_loss 0.334037 history loss 6.339097 rank 6
2023-02-22 09:45:23,560 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 4
2023-02-22 09:45:23,913 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 7
2023-02-22 09:45:24,517 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 2
2023-02-22 09:45:24,525 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 1
2023-02-22 09:45:24,623 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 3
2023-02-22 09:45:24,923 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 5
2023-02-22 09:45:25,027 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 0
2023-02-22 09:45:25,886 DEBUG CV Batch 17/600 loss 8.662387 loss_att 9.159275 loss_ctc 11.167494 loss_rnnt 7.955646 hw_loss 0.512530 history loss 7.311375 rank 6
2023-02-22 09:45:34,924 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 4
2023-02-22 09:45:35,333 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 7
2023-02-22 09:45:36,104 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 1
2023-02-22 09:45:36,143 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 2
2023-02-22 09:45:36,308 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 3
2023-02-22 09:45:36,475 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 5
2023-02-22 09:45:36,637 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 0
2023-02-22 09:45:37,743 DEBUG CV Batch 17/700 loss 14.459531 loss_att 45.510147 loss_ctc 13.007103 loss_rnnt 8.358062 hw_loss 0.159381 history loss 8.018874 rank 6
2023-02-22 09:45:46,301 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 4
2023-02-22 09:45:46,907 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 7
2023-02-22 09:45:47,529 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 1
2023-02-22 09:45:47,696 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 2
2023-02-22 09:45:47,883 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 3
2023-02-22 09:45:48,043 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 5
2023-02-22 09:45:48,518 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 0
2023-02-22 09:45:49,518 DEBUG CV Batch 17/800 loss 12.257914 loss_att 12.380379 loss_ctc 18.984375 loss_rnnt 11.148425 hw_loss 0.352753 history loss 7.453210 rank 6
2023-02-22 09:45:59,670 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 4
2023-02-22 09:46:00,322 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 7
2023-02-22 09:46:00,864 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 1
2023-02-22 09:46:01,331 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 2
2023-02-22 09:46:01,515 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 5
2023-02-22 09:46:01,588 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 3
2023-02-22 09:46:02,769 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 0
2023-02-22 09:46:03,301 DEBUG CV Batch 17/900 loss 14.404254 loss_att 16.151375 loss_ctc 25.383305 loss_rnnt 12.472960 hw_loss 0.221245 history loss 7.227644 rank 6
2023-02-22 09:46:12,116 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 4
2023-02-22 09:46:12,861 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 7
2023-02-22 09:46:13,649 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 1
2023-02-22 09:46:13,892 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 2
2023-02-22 09:46:14,023 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 5
2023-02-22 09:46:14,050 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 3
2023-02-22 09:46:15,571 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 0
2023-02-22 09:46:16,195 DEBUG CV Batch 17/1000 loss 4.361094 loss_att 5.325448 loss_ctc 5.187039 loss_rnnt 3.887161 hw_loss 0.320503 history loss 6.976348 rank 6
2023-02-22 09:46:24,057 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 4
2023-02-22 09:46:25,045 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 7
2023-02-22 09:46:25,758 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 1
2023-02-22 09:46:26,138 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 5
2023-02-22 09:46:26,243 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 2
2023-02-22 09:46:26,341 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 3
2023-02-22 09:46:27,858 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 0
2023-02-22 09:46:28,582 DEBUG CV Batch 17/1100 loss 7.509400 loss_att 6.316817 loss_ctc 9.120743 loss_rnnt 7.255735 hw_loss 0.520005 history loss 6.972625 rank 6
2023-02-22 09:46:34,838 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 4
2023-02-22 09:46:36,345 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 7
2023-02-22 09:46:36,870 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 1
2023-02-22 09:46:36,983 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 5
2023-02-22 09:46:37,293 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 2
2023-02-22 09:46:37,338 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 3
2023-02-22 09:46:39,045 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 0
2023-02-22 09:46:39,949 DEBUG CV Batch 17/1200 loss 9.293211 loss_att 9.472457 loss_ctc 10.446464 loss_rnnt 8.884223 hw_loss 0.411323 history loss 7.318496 rank 6
2023-02-22 09:46:46,843 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 4
2023-02-22 09:46:48,751 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 7
2023-02-22 09:46:49,213 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 1
2023-02-22 09:46:49,342 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 5
2023-02-22 09:46:49,660 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 3
2023-02-22 09:46:49,704 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 2
2023-02-22 09:46:51,603 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 0
2023-02-22 09:46:52,511 DEBUG CV Batch 17/1300 loss 5.857572 loss_att 5.989379 loss_ctc 7.640817 loss_rnnt 5.358765 hw_loss 0.440022 history loss 7.640665 rank 6
2023-02-22 09:46:58,244 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 4
2023-02-22 09:47:00,167 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 7
2023-02-22 09:47:00,645 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 1
2023-02-22 09:47:01,179 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 5
2023-02-22 09:47:01,268 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 3
2023-02-22 09:47:01,510 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 2
2023-02-22 09:47:03,236 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 0
2023-02-22 09:47:04,253 DEBUG CV Batch 17/1400 loss 8.436186 loss_att 18.095440 loss_ctc 7.911213 loss_rnnt 6.482542 hw_loss 0.172105 history loss 7.985077 rank 6
2023-02-22 09:47:09,827 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 4
2023-02-22 09:47:11,986 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 7
2023-02-22 09:47:12,321 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 1
2023-02-22 09:47:13,011 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 3
2023-02-22 09:47:13,059 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 5
2023-02-22 09:47:13,338 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 2
2023-02-22 09:47:15,331 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 0
2023-02-22 09:47:16,350 DEBUG CV Batch 17/1500 loss 6.682001 loss_att 7.243780 loss_ctc 7.749134 loss_rnnt 6.319401 hw_loss 0.202426 history loss 7.800100 rank 6
2023-02-22 09:47:22,876 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 4
2023-02-22 09:47:25,417 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 1
2023-02-22 09:47:25,520 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 7
2023-02-22 09:47:26,284 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 5
2023-02-22 09:47:26,328 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 3
2023-02-22 09:47:26,692 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 2
2023-02-22 09:47:28,655 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 0
2023-02-22 09:47:29,814 DEBUG CV Batch 17/1600 loss 9.042374 loss_att 14.905036 loss_ctc 12.114915 loss_rnnt 7.384328 hw_loss 0.142203 history loss 7.720308 rank 6
2023-02-22 09:47:35,622 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 4
2023-02-22 09:47:37,852 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 1
2023-02-22 09:47:38,294 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 7
2023-02-22 09:47:38,825 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 5
2023-02-22 09:47:38,832 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 3
2023-02-22 09:47:39,302 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 2
2023-02-22 09:47:41,414 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 0
2023-02-22 09:47:42,346 DEBUG CV Batch 17/1700 loss 9.644264 loss_att 9.568712 loss_ctc 14.998472 loss_rnnt 8.770271 hw_loss 0.328517 history loss 7.609910 rank 6
2023-02-22 09:47:44,794 INFO Epoch 17 CV info cv_loss 7.579307382102302
2023-02-22 09:47:44,794 INFO Epoch 18 TRAIN info lr 0.0004080959630667931
2023-02-22 09:47:44,796 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:47:46,909 INFO Epoch 17 CV info cv_loss 7.579307382067843
2023-02-22 09:47:46,910 INFO Epoch 18 TRAIN info lr 0.00040806742065796166
2023-02-22 09:47:46,915 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:47:47,577 INFO Epoch 17 CV info cv_loss 7.57930738213676
2023-02-22 09:47:47,577 INFO Epoch 18 TRAIN info lr 0.0004080320907335282
2023-02-22 09:47:47,582 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:47:47,876 INFO Epoch 17 CV info cv_loss 7.579307380034789
2023-02-22 09:47:47,877 INFO Epoch 18 TRAIN info lr 0.0004080511133986676
2023-02-22 09:47:47,879 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:47:48,075 INFO Epoch 17 CV info cv_loss 7.579307382610565
2023-02-22 09:47:48,075 INFO Epoch 18 TRAIN info lr 0.00040807557502080483
2023-02-22 09:47:48,081 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:47:48,436 INFO Epoch 17 CV info cv_loss 7.579307382309053
2023-02-22 09:47:48,436 INFO Epoch 18 TRAIN info lr 0.0004080524722622718
2023-02-22 09:47:48,441 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:47:50,799 INFO Epoch 17 CV info cv_loss 7.579307381326984
2023-02-22 09:47:50,800 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/17.pt
2023-02-22 09:47:51,438 INFO Epoch 18 TRAIN info lr 0.000408138108047309
2023-02-22 09:47:51,442 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:47:51,629 INFO Epoch 17 CV info cv_loss 7.579307383403111
2023-02-22 09:47:51,629 INFO Epoch 18 TRAIN info lr 0.0004080185047442814
2023-02-22 09:47:51,635 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 09:48:51,733 DEBUG TRAIN Batch 18/0 loss 9.410781 loss_att 9.458387 loss_ctc 12.409656 loss_rnnt 8.703009 hw_loss 0.559502 lr 0.00040803 rank 7
2023-02-22 09:48:51,733 DEBUG TRAIN Batch 18/0 loss 5.287748 loss_att 5.477991 loss_ctc 7.653286 loss_rnnt 4.721363 hw_loss 0.399247 lr 0.00040805 rank 3
2023-02-22 09:48:51,734 DEBUG TRAIN Batch 18/0 loss 9.257807 loss_att 9.268620 loss_ctc 11.350769 loss_rnnt 8.722862 hw_loss 0.475727 lr 0.00040807 rank 5
2023-02-22 09:48:51,736 DEBUG TRAIN Batch 18/0 loss 7.566181 loss_att 7.334408 loss_ctc 10.435399 loss_rnnt 7.014441 hw_loss 0.404122 lr 0.00040809 rank 4
2023-02-22 09:48:51,746 DEBUG TRAIN Batch 18/0 loss 10.404791 loss_att 9.997725 loss_ctc 11.887676 loss_rnnt 10.032471 hw_loss 0.480028 lr 0.00040807 rank 1
2023-02-22 09:48:51,763 DEBUG TRAIN Batch 18/0 loss 9.695098 loss_att 8.961419 loss_ctc 13.360406 loss_rnnt 9.096951 hw_loss 0.480328 lr 0.00040802 rank 6
2023-02-22 09:48:51,771 DEBUG TRAIN Batch 18/0 loss 11.433415 loss_att 9.997481 loss_ctc 13.193285 loss_rnnt 11.164585 hw_loss 0.602565 lr 0.00040805 rank 2
2023-02-22 09:48:51,781 DEBUG TRAIN Batch 18/0 loss 13.156860 loss_att 12.218110 loss_ctc 14.703669 loss_rnnt 12.878284 hw_loss 0.487659 lr 0.00040814 rank 0
2023-02-22 09:50:02,851 DEBUG TRAIN Batch 18/100 loss 18.946529 loss_att 21.304188 loss_ctc 32.933586 loss_rnnt 16.491867 hw_loss 0.221607 lr 0.00040788 rank 6
2023-02-22 09:50:02,853 DEBUG TRAIN Batch 18/100 loss 6.824690 loss_att 9.790870 loss_ctc 14.632256 loss_rnnt 5.058512 hw_loss 0.247375 lr 0.00040791 rank 3
2023-02-22 09:50:02,854 DEBUG TRAIN Batch 18/100 loss 11.778498 loss_att 14.570215 loss_ctc 11.747625 loss_rnnt 11.080279 hw_loss 0.269983 lr 0.00040792 rank 2
2023-02-22 09:50:02,856 DEBUG TRAIN Batch 18/100 loss 4.691318 loss_att 8.302628 loss_ctc 4.674081 loss_rnnt 3.824860 hw_loss 0.274677 lr 0.00040789 rank 7
2023-02-22 09:50:02,858 DEBUG TRAIN Batch 18/100 loss 15.646498 loss_att 18.881662 loss_ctc 18.351763 loss_rnnt 14.538933 hw_loss 0.187180 lr 0.00040793 rank 1
2023-02-22 09:50:02,862 DEBUG TRAIN Batch 18/100 loss 5.058630 loss_att 7.713658 loss_ctc 3.825755 loss_rnnt 4.546203 hw_loss 0.273382 lr 0.00040796 rank 4
2023-02-22 09:50:02,863 DEBUG TRAIN Batch 18/100 loss 12.320743 loss_att 14.780066 loss_ctc 14.530481 loss_rnnt 11.445166 hw_loss 0.167030 lr 0.00040800 rank 0
2023-02-22 09:50:02,866 DEBUG TRAIN Batch 18/100 loss 5.181837 loss_att 9.843492 loss_ctc 6.602354 loss_rnnt 3.852565 hw_loss 0.389136 lr 0.00040794 rank 5
2023-02-22 09:51:14,680 DEBUG TRAIN Batch 18/200 loss 5.358953 loss_att 7.994486 loss_ctc 6.866508 loss_rnnt 4.446576 hw_loss 0.345493 lr 0.00040778 rank 2
2023-02-22 09:51:14,680 DEBUG TRAIN Batch 18/200 loss 9.819751 loss_att 11.071085 loss_ctc 8.793349 loss_rnnt 9.591559 hw_loss 0.215210 lr 0.00040776 rank 7
2023-02-22 09:51:14,681 DEBUG TRAIN Batch 18/200 loss 8.370770 loss_att 9.256258 loss_ctc 12.532340 loss_rnnt 7.521539 hw_loss 0.219855 lr 0.00040778 rank 3
2023-02-22 09:51:14,684 DEBUG TRAIN Batch 18/200 loss 8.036315 loss_att 10.357779 loss_ctc 11.867678 loss_rnnt 6.949364 hw_loss 0.209643 lr 0.00040775 rank 6
2023-02-22 09:51:14,685 DEBUG TRAIN Batch 18/200 loss 4.561641 loss_att 6.922606 loss_ctc 8.436834 loss_rnnt 3.387789 hw_loss 0.346812 lr 0.00040780 rank 5
2023-02-22 09:51:14,689 DEBUG TRAIN Batch 18/200 loss 9.749024 loss_att 11.205958 loss_ctc 12.460585 loss_rnnt 8.869857 hw_loss 0.424200 lr 0.00040787 rank 0
2023-02-22 09:51:14,690 DEBUG TRAIN Batch 18/200 loss 8.989339 loss_att 11.749332 loss_ctc 15.930059 loss_rnnt 7.416705 hw_loss 0.178512 lr 0.00040782 rank 4
2023-02-22 09:51:14,742 DEBUG TRAIN Batch 18/200 loss 5.855430 loss_att 7.143990 loss_ctc 6.640192 loss_rnnt 5.309883 hw_loss 0.343499 lr 0.00040779 rank 1
2023-02-22 09:52:27,935 DEBUG TRAIN Batch 18/300 loss 13.018422 loss_att 17.631798 loss_ctc 16.718731 loss_rnnt 11.385031 hw_loss 0.407517 lr 0.00040766 rank 1
2023-02-22 09:52:27,940 DEBUG TRAIN Batch 18/300 loss 5.787077 loss_att 7.151907 loss_ctc 7.596717 loss_rnnt 5.013783 hw_loss 0.485705 lr 0.00040773 rank 0
2023-02-22 09:52:27,943 DEBUG TRAIN Batch 18/300 loss 3.491029 loss_att 5.804442 loss_ctc 5.265755 loss_rnnt 2.603645 hw_loss 0.352634 lr 0.00040764 rank 2
2023-02-22 09:52:27,951 DEBUG TRAIN Batch 18/300 loss 12.620458 loss_att 13.128654 loss_ctc 13.468323 loss_rnnt 12.269456 hw_loss 0.255587 lr 0.00040767 rank 5
2023-02-22 09:52:27,953 DEBUG TRAIN Batch 18/300 loss 10.422730 loss_att 13.218948 loss_ctc 12.639988 loss_rnnt 9.422086 hw_loss 0.273311 lr 0.00040761 rank 6
2023-02-22 09:52:27,961 DEBUG TRAIN Batch 18/300 loss 20.740862 loss_att 21.045208 loss_ctc 29.170477 loss_rnnt 19.393105 hw_loss 0.305510 lr 0.00040762 rank 7
2023-02-22 09:52:27,970 DEBUG TRAIN Batch 18/300 loss 19.254967 loss_att 23.143873 loss_ctc 23.771242 loss_rnnt 17.733952 hw_loss 0.264496 lr 0.00040764 rank 3
2023-02-22 09:52:27,996 DEBUG TRAIN Batch 18/300 loss 3.001750 loss_att 5.314292 loss_ctc 5.660962 loss_rnnt 2.108218 hw_loss 0.143366 lr 0.00040769 rank 4
2023-02-22 09:53:41,638 DEBUG TRAIN Batch 18/400 loss 13.066936 loss_att 15.306890 loss_ctc 15.350815 loss_rnnt 12.144682 hw_loss 0.318273 lr 0.00040751 rank 3
2023-02-22 09:53:41,640 DEBUG TRAIN Batch 18/400 loss 9.260520 loss_att 13.417614 loss_ctc 11.414300 loss_rnnt 8.019798 hw_loss 0.229000 lr 0.00040751 rank 2
2023-02-22 09:53:41,640 DEBUG TRAIN Batch 18/400 loss 11.949095 loss_att 15.833217 loss_ctc 15.583787 loss_rnnt 10.586164 hw_loss 0.190278 lr 0.00040749 rank 7
2023-02-22 09:53:41,643 DEBUG TRAIN Batch 18/400 loss 16.717663 loss_att 20.198196 loss_ctc 19.943432 loss_rnnt 15.485269 hw_loss 0.199099 lr 0.00040747 rank 6
2023-02-22 09:53:41,646 DEBUG TRAIN Batch 18/400 loss 12.341168 loss_att 15.791809 loss_ctc 17.628199 loss_rnnt 10.837372 hw_loss 0.203870 lr 0.00040759 rank 0
2023-02-22 09:53:41,648 DEBUG TRAIN Batch 18/400 loss 9.934403 loss_att 13.329967 loss_ctc 13.598286 loss_rnnt 8.653255 hw_loss 0.212846 lr 0.00040753 rank 5
2023-02-22 09:53:41,680 DEBUG TRAIN Batch 18/400 loss 10.305314 loss_att 12.145164 loss_ctc 14.007573 loss_rnnt 9.303943 hw_loss 0.262065 lr 0.00040752 rank 1
2023-02-22 09:53:41,717 DEBUG TRAIN Batch 18/400 loss 6.538880 loss_att 9.440227 loss_ctc 7.600282 loss_rnnt 5.669934 hw_loss 0.275916 lr 0.00040755 rank 4
2023-02-22 09:54:53,653 DEBUG TRAIN Batch 18/500 loss 8.160935 loss_att 9.955822 loss_ctc 10.204893 loss_rnnt 7.326880 hw_loss 0.379783 lr 0.00040734 rank 6
2023-02-22 09:54:53,667 DEBUG TRAIN Batch 18/500 loss 6.960689 loss_att 8.150921 loss_ctc 11.919411 loss_rnnt 5.916430 hw_loss 0.271967 lr 0.00040737 rank 3
2023-02-22 09:54:53,669 DEBUG TRAIN Batch 18/500 loss 4.956813 loss_att 8.954819 loss_ctc 6.699237 loss_rnnt 3.802328 hw_loss 0.229800 lr 0.00040735 rank 7
2023-02-22 09:54:53,672 DEBUG TRAIN Batch 18/500 loss 8.665862 loss_att 11.148537 loss_ctc 11.393688 loss_rnnt 7.702998 hw_loss 0.192411 lr 0.00040742 rank 4
2023-02-22 09:54:53,672 DEBUG TRAIN Batch 18/500 loss 6.770714 loss_att 9.446562 loss_ctc 8.468845 loss_rnnt 5.846234 hw_loss 0.305422 lr 0.00040737 rank 2
2023-02-22 09:54:53,673 DEBUG TRAIN Batch 18/500 loss 11.849787 loss_att 14.010159 loss_ctc 15.673116 loss_rnnt 10.717163 hw_loss 0.357701 lr 0.00040740 rank 5
2023-02-22 09:54:53,677 DEBUG TRAIN Batch 18/500 loss 11.391388 loss_att 12.618478 loss_ctc 14.061288 loss_rnnt 10.631080 hw_loss 0.297945 lr 0.00040746 rank 0
2023-02-22 09:54:53,719 DEBUG TRAIN Batch 18/500 loss 11.923715 loss_att 14.476189 loss_ctc 17.917980 loss_rnnt 10.495243 hw_loss 0.222640 lr 0.00040739 rank 1
2023-02-22 09:56:06,661 DEBUG TRAIN Batch 18/600 loss 11.406171 loss_att 11.044481 loss_ctc 15.224283 loss_rnnt 10.758279 hw_loss 0.395902 lr 0.00040724 rank 2
2023-02-22 09:56:06,671 DEBUG TRAIN Batch 18/600 loss 15.229116 loss_att 15.955191 loss_ctc 21.099112 loss_rnnt 14.140625 hw_loss 0.301145 lr 0.00040726 rank 5
2023-02-22 09:56:06,671 DEBUG TRAIN Batch 18/600 loss 11.191747 loss_att 14.463968 loss_ctc 16.587437 loss_rnnt 9.675725 hw_loss 0.266534 lr 0.00040732 rank 0
2023-02-22 09:56:06,672 DEBUG TRAIN Batch 18/600 loss 9.150405 loss_att 13.770441 loss_ctc 13.751984 loss_rnnt 7.391341 hw_loss 0.415338 lr 0.00040724 rank 3
2023-02-22 09:56:06,672 DEBUG TRAIN Batch 18/600 loss 4.451684 loss_att 5.814506 loss_ctc 4.265865 loss_rnnt 4.110576 hw_loss 0.174973 lr 0.00040720 rank 6
2023-02-22 09:56:06,673 DEBUG TRAIN Batch 18/600 loss 9.247057 loss_att 9.979886 loss_ctc 12.613667 loss_rnnt 8.472327 hw_loss 0.336157 lr 0.00040728 rank 4
2023-02-22 09:56:06,674 DEBUG TRAIN Batch 18/600 loss 10.378791 loss_att 11.456045 loss_ctc 16.090559 loss_rnnt 9.200518 hw_loss 0.377349 lr 0.00040722 rank 7
2023-02-22 09:56:06,677 DEBUG TRAIN Batch 18/600 loss 10.175695 loss_att 10.678965 loss_ctc 12.978259 loss_rnnt 9.449239 hw_loss 0.472739 lr 0.00040725 rank 1
2023-02-22 09:57:21,583 DEBUG TRAIN Batch 18/700 loss 7.036322 loss_att 12.043237 loss_ctc 9.243209 loss_rnnt 5.525710 hw_loss 0.403082 lr 0.00040713 rank 5
2023-02-22 09:57:21,584 DEBUG TRAIN Batch 18/700 loss 5.792702 loss_att 8.916271 loss_ctc 8.910072 loss_rnnt 4.623813 hw_loss 0.240987 lr 0.00040710 rank 2
2023-02-22 09:57:21,587 DEBUG TRAIN Batch 18/700 loss 17.354860 loss_att 19.573307 loss_ctc 21.548069 loss_rnnt 16.222820 hw_loss 0.242353 lr 0.00040710 rank 3
2023-02-22 09:57:21,590 DEBUG TRAIN Batch 18/700 loss 5.933407 loss_att 13.412618 loss_ctc 7.166131 loss_rnnt 4.141009 hw_loss 0.247859 lr 0.00040707 rank 6
2023-02-22 09:57:21,594 DEBUG TRAIN Batch 18/700 loss 4.412130 loss_att 8.987698 loss_ctc 7.650723 loss_rnnt 2.969393 hw_loss 0.179645 lr 0.00040712 rank 1
2023-02-22 09:57:21,596 DEBUG TRAIN Batch 18/700 loss 9.829711 loss_att 11.969574 loss_ctc 14.440429 loss_rnnt 8.666307 hw_loss 0.226255 lr 0.00040719 rank 0
2023-02-22 09:57:21,599 DEBUG TRAIN Batch 18/700 loss 4.231630 loss_att 6.666967 loss_ctc 5.131544 loss_rnnt 3.496104 hw_loss 0.240881 lr 0.00040715 rank 4
2023-02-22 09:57:21,602 DEBUG TRAIN Batch 18/700 loss 5.818270 loss_att 8.878323 loss_ctc 6.835142 loss_rnnt 4.954772 hw_loss 0.217319 lr 0.00040708 rank 7
2023-02-22 09:58:34,721 DEBUG TRAIN Batch 18/800 loss 7.291659 loss_att 11.284393 loss_ctc 11.040190 loss_rnnt 5.896249 hw_loss 0.181987 lr 0.00040695 rank 7
2023-02-22 09:58:34,722 DEBUG TRAIN Batch 18/800 loss 6.584884 loss_att 10.499571 loss_ctc 9.965788 loss_rnnt 5.229736 hw_loss 0.227668 lr 0.00040697 rank 2
2023-02-22 09:58:34,722 DEBUG TRAIN Batch 18/800 loss 7.628799 loss_att 9.553076 loss_ctc 9.448674 loss_rnnt 6.849903 hw_loss 0.283859 lr 0.00040697 rank 3
2023-02-22 09:58:34,726 DEBUG TRAIN Batch 18/800 loss 8.742024 loss_att 12.972037 loss_ctc 8.795436 loss_rnnt 7.775080 hw_loss 0.213414 lr 0.00040699 rank 5
2023-02-22 09:58:34,729 DEBUG TRAIN Batch 18/800 loss 7.725336 loss_att 10.744689 loss_ctc 10.990078 loss_rnnt 6.555517 hw_loss 0.244967 lr 0.00040705 rank 0
2023-02-22 09:58:34,730 DEBUG TRAIN Batch 18/800 loss 10.067235 loss_att 13.527298 loss_ctc 13.058256 loss_rnnt 8.906307 hw_loss 0.131461 lr 0.00040701 rank 4
2023-02-22 09:58:34,731 DEBUG TRAIN Batch 18/800 loss 20.603241 loss_att 22.678997 loss_ctc 25.496609 loss_rnnt 19.377708 hw_loss 0.296122 lr 0.00040693 rank 6
2023-02-22 09:58:34,733 DEBUG TRAIN Batch 18/800 loss 16.572069 loss_att 18.899715 loss_ctc 22.590542 loss_rnnt 15.226474 hw_loss 0.145507 lr 0.00040698 rank 1
2023-02-22 09:59:47,046 DEBUG TRAIN Batch 18/900 loss 11.454481 loss_att 16.871508 loss_ctc 16.127785 loss_rnnt 9.569241 hw_loss 0.335113 lr 0.00040681 rank 7
2023-02-22 09:59:47,054 DEBUG TRAIN Batch 18/900 loss 7.345207 loss_att 9.976112 loss_ctc 8.502527 loss_rnnt 6.502789 hw_loss 0.303614 lr 0.00040683 rank 2
2023-02-22 09:59:47,055 DEBUG TRAIN Batch 18/900 loss 9.692446 loss_att 12.815243 loss_ctc 17.671120 loss_rnnt 7.852852 hw_loss 0.283522 lr 0.00040683 rank 3
2023-02-22 09:59:47,057 DEBUG TRAIN Batch 18/900 loss 11.284658 loss_att 14.130627 loss_ctc 14.080229 loss_rnnt 10.207085 hw_loss 0.254321 lr 0.00040680 rank 6
2023-02-22 09:59:47,058 DEBUG TRAIN Batch 18/900 loss 13.878520 loss_att 16.427198 loss_ctc 16.201172 loss_rnnt 12.965851 hw_loss 0.174838 lr 0.00040688 rank 4
2023-02-22 09:59:47,060 DEBUG TRAIN Batch 18/900 loss 8.123503 loss_att 10.657743 loss_ctc 12.371831 loss_rnnt 6.997357 hw_loss 0.099102 lr 0.00040692 rank 0
2023-02-22 09:59:47,065 DEBUG TRAIN Batch 18/900 loss 13.488675 loss_att 18.553989 loss_ctc 20.593689 loss_rnnt 11.320422 hw_loss 0.389728 lr 0.00040685 rank 1
2023-02-22 09:59:47,118 DEBUG TRAIN Batch 18/900 loss 11.174092 loss_att 15.275979 loss_ctc 14.798445 loss_rnnt 9.701559 hw_loss 0.316703 lr 0.00040686 rank 5
2023-02-22 10:00:59,892 DEBUG TRAIN Batch 18/1000 loss 8.787862 loss_att 12.635896 loss_ctc 13.116456 loss_rnnt 7.373758 hw_loss 0.126284 lr 0.00040674 rank 4
2023-02-22 10:00:59,895 DEBUG TRAIN Batch 18/1000 loss 6.293977 loss_att 10.491766 loss_ctc 11.093203 loss_rnnt 4.690925 hw_loss 0.231746 lr 0.00040678 rank 0
2023-02-22 10:00:59,895 DEBUG TRAIN Batch 18/1000 loss 11.942792 loss_att 14.477262 loss_ctc 18.816320 loss_rnnt 10.427256 hw_loss 0.172823 lr 0.00040667 rank 6
2023-02-22 10:00:59,897 DEBUG TRAIN Batch 18/1000 loss 4.259752 loss_att 7.518515 loss_ctc 5.686188 loss_rnnt 3.306117 hw_loss 0.209420 lr 0.00040671 rank 1
2023-02-22 10:00:59,897 DEBUG TRAIN Batch 18/1000 loss 4.179637 loss_att 7.717534 loss_ctc 6.530696 loss_rnnt 3.017312 hw_loss 0.264883 lr 0.00040670 rank 3
2023-02-22 10:00:59,898 DEBUG TRAIN Batch 18/1000 loss 9.387983 loss_att 12.668303 loss_ctc 11.244446 loss_rnnt 8.391676 hw_loss 0.173839 lr 0.00040670 rank 2
2023-02-22 10:00:59,898 DEBUG TRAIN Batch 18/1000 loss 4.301818 loss_att 8.508739 loss_ctc 6.660505 loss_rnnt 3.048217 hw_loss 0.183234 lr 0.00040668 rank 7
2023-02-22 10:00:59,899 DEBUG TRAIN Batch 18/1000 loss 4.737192 loss_att 8.138462 loss_ctc 8.368154 loss_rnnt 3.419824 hw_loss 0.286849 lr 0.00040672 rank 5
2023-02-22 10:02:14,039 DEBUG TRAIN Batch 18/1100 loss 6.164798 loss_att 7.481311 loss_ctc 6.948473 loss_rnnt 5.664397 hw_loss 0.248642 lr 0.00040656 rank 2
2023-02-22 10:02:14,041 DEBUG TRAIN Batch 18/1100 loss 8.891826 loss_att 11.801584 loss_ctc 11.467227 loss_rnnt 7.857119 hw_loss 0.205066 lr 0.00040661 rank 4
2023-02-22 10:02:14,044 DEBUG TRAIN Batch 18/1100 loss 15.912010 loss_att 17.881662 loss_ctc 25.505390 loss_rnnt 14.063199 hw_loss 0.329557 lr 0.00040654 rank 7
2023-02-22 10:02:14,045 DEBUG TRAIN Batch 18/1100 loss 12.919691 loss_att 14.729602 loss_ctc 15.965097 loss_rnnt 12.001672 hw_loss 0.281217 lr 0.00040656 rank 3
2023-02-22 10:02:14,046 DEBUG TRAIN Batch 18/1100 loss 11.033938 loss_att 13.238174 loss_ctc 14.599054 loss_rnnt 10.030806 hw_loss 0.163007 lr 0.00040658 rank 1
2023-02-22 10:02:14,049 DEBUG TRAIN Batch 18/1100 loss 15.622413 loss_att 19.283745 loss_ctc 23.263662 loss_rnnt 13.809509 hw_loss 0.115881 lr 0.00040665 rank 0
2023-02-22 10:02:14,049 DEBUG TRAIN Batch 18/1100 loss 8.900920 loss_att 10.423881 loss_ctc 11.217637 loss_rnnt 8.073067 hw_loss 0.401936 lr 0.00040653 rank 6
2023-02-22 10:02:14,051 DEBUG TRAIN Batch 18/1100 loss 11.273353 loss_att 15.060386 loss_ctc 16.054113 loss_rnnt 9.744991 hw_loss 0.250349 lr 0.00040659 rank 5
2023-02-22 10:03:26,958 DEBUG TRAIN Batch 18/1200 loss 4.407456 loss_att 6.483362 loss_ctc 5.879035 loss_rnnt 3.638203 hw_loss 0.295991 lr 0.00040640 rank 6
2023-02-22 10:03:26,959 DEBUG TRAIN Batch 18/1200 loss 6.566112 loss_att 7.536347 loss_ctc 9.058583 loss_rnnt 5.900029 hw_loss 0.261947 lr 0.00040643 rank 2
2023-02-22 10:03:26,961 DEBUG TRAIN Batch 18/1200 loss 7.010147 loss_att 8.983668 loss_ctc 9.400687 loss_rnnt 6.147869 hw_loss 0.279066 lr 0.00040643 rank 3
2023-02-22 10:03:26,963 DEBUG TRAIN Batch 18/1200 loss 13.312927 loss_att 13.514827 loss_ctc 18.380733 loss_rnnt 12.472366 hw_loss 0.233388 lr 0.00040641 rank 7
2023-02-22 10:03:26,964 DEBUG TRAIN Batch 18/1200 loss 9.367650 loss_att 10.513053 loss_ctc 13.274343 loss_rnnt 8.458474 hw_loss 0.298505 lr 0.00040644 rank 1
2023-02-22 10:03:26,967 DEBUG TRAIN Batch 18/1200 loss 5.954935 loss_att 8.406818 loss_ctc 9.797374 loss_rnnt 4.776161 hw_loss 0.330134 lr 0.00040647 rank 4
2023-02-22 10:03:26,971 DEBUG TRAIN Batch 18/1200 loss 5.984727 loss_att 6.516262 loss_ctc 10.193550 loss_rnnt 5.181528 hw_loss 0.254468 lr 0.00040651 rank 0
2023-02-22 10:03:27,014 DEBUG TRAIN Batch 18/1200 loss 7.477805 loss_att 11.380901 loss_ctc 12.319478 loss_rnnt 5.832847 hw_loss 0.410217 lr 0.00040645 rank 5
2023-02-22 10:04:38,673 DEBUG TRAIN Batch 18/1300 loss 4.466248 loss_att 7.175425 loss_ctc 5.400613 loss_rnnt 3.632068 hw_loss 0.314554 lr 0.00040630 rank 2
2023-02-22 10:04:38,675 DEBUG TRAIN Batch 18/1300 loss 10.949791 loss_att 15.791105 loss_ctc 15.285870 loss_rnnt 9.259198 hw_loss 0.270348 lr 0.00040626 rank 6
2023-02-22 10:04:38,676 DEBUG TRAIN Batch 18/1300 loss 13.785971 loss_att 13.870825 loss_ctc 17.402225 loss_rnnt 13.123762 hw_loss 0.305757 lr 0.00040631 rank 1
2023-02-22 10:04:38,678 DEBUG TRAIN Batch 18/1300 loss 7.816313 loss_att 9.038288 loss_ctc 11.665837 loss_rnnt 6.856600 hw_loss 0.378839 lr 0.00040632 rank 5
2023-02-22 10:04:38,677 DEBUG TRAIN Batch 18/1300 loss 10.464151 loss_att 13.977160 loss_ctc 14.872909 loss_rnnt 9.035957 hw_loss 0.258296 lr 0.00040634 rank 4
2023-02-22 10:04:38,678 DEBUG TRAIN Batch 18/1300 loss 14.810050 loss_att 14.597567 loss_ctc 17.277761 loss_rnnt 14.347466 hw_loss 0.330099 lr 0.00040629 rank 3
2023-02-22 10:04:38,681 DEBUG TRAIN Batch 18/1300 loss 2.004018 loss_att 5.666846 loss_ctc 4.059733 loss_rnnt 0.808954 hw_loss 0.353254 lr 0.00040628 rank 7
2023-02-22 10:04:38,690 DEBUG TRAIN Batch 18/1300 loss 18.408468 loss_att 19.711235 loss_ctc 25.761425 loss_rnnt 16.951839 hw_loss 0.404399 lr 0.00040638 rank 0
2023-02-22 10:05:53,125 DEBUG TRAIN Batch 18/1400 loss 7.162183 loss_att 10.620376 loss_ctc 5.496789 loss_rnnt 6.617186 hw_loss 0.141397 lr 0.00040614 rank 7
2023-02-22 10:05:53,126 DEBUG TRAIN Batch 18/1400 loss 3.932575 loss_att 7.872615 loss_ctc 6.250429 loss_rnnt 2.737674 hw_loss 0.183462 lr 0.00040620 rank 4
2023-02-22 10:05:53,128 DEBUG TRAIN Batch 18/1400 loss 16.184839 loss_att 20.112709 loss_ctc 16.049021 loss_rnnt 15.292744 hw_loss 0.233686 lr 0.00040625 rank 0
2023-02-22 10:05:53,128 DEBUG TRAIN Batch 18/1400 loss 14.152478 loss_att 18.083879 loss_ctc 21.342514 loss_rnnt 12.295630 hw_loss 0.209807 lr 0.00040618 rank 5
2023-02-22 10:05:53,129 DEBUG TRAIN Batch 18/1400 loss 5.196423 loss_att 9.674857 loss_ctc 8.021559 loss_rnnt 3.842785 hw_loss 0.152373 lr 0.00040613 rank 6
2023-02-22 10:05:53,129 DEBUG TRAIN Batch 18/1400 loss 12.025587 loss_att 13.248774 loss_ctc 12.867824 loss_rnnt 11.477238 hw_loss 0.358901 lr 0.00040616 rank 2
2023-02-22 10:05:53,180 DEBUG TRAIN Batch 18/1400 loss 3.139252 loss_att 6.388771 loss_ctc 6.046282 loss_rnnt 1.994882 hw_loss 0.200367 lr 0.00040616 rank 3
2023-02-22 10:05:53,186 DEBUG TRAIN Batch 18/1400 loss 9.245289 loss_att 10.893671 loss_ctc 12.053737 loss_rnnt 8.397579 hw_loss 0.269201 lr 0.00040618 rank 1
2023-02-22 10:07:05,957 DEBUG TRAIN Batch 18/1500 loss 9.606625 loss_att 11.354033 loss_ctc 14.917638 loss_rnnt 8.361197 hw_loss 0.352145 lr 0.00040603 rank 2
2023-02-22 10:07:05,961 DEBUG TRAIN Batch 18/1500 loss 7.696178 loss_att 10.590607 loss_ctc 12.439962 loss_rnnt 6.422391 hw_loss 0.116995 lr 0.00040601 rank 7
2023-02-22 10:07:05,962 DEBUG TRAIN Batch 18/1500 loss 9.954535 loss_att 12.330063 loss_ctc 14.172324 loss_rnnt 8.691179 hw_loss 0.423520 lr 0.00040604 rank 1
2023-02-22 10:07:05,965 DEBUG TRAIN Batch 18/1500 loss 9.908850 loss_att 9.930785 loss_ctc 17.593899 loss_rnnt 8.757029 hw_loss 0.230175 lr 0.00040603 rank 3
2023-02-22 10:07:05,966 DEBUG TRAIN Batch 18/1500 loss 6.962511 loss_att 10.316302 loss_ctc 10.818698 loss_rnnt 5.605176 hw_loss 0.323284 lr 0.00040599 rank 6
2023-02-22 10:07:05,969 DEBUG TRAIN Batch 18/1500 loss 9.006991 loss_att 13.800406 loss_ctc 10.053814 loss_rnnt 7.708583 hw_loss 0.375281 lr 0.00040611 rank 0
2023-02-22 10:07:05,969 DEBUG TRAIN Batch 18/1500 loss 13.067264 loss_att 15.838842 loss_ctc 18.472488 loss_rnnt 11.599499 hw_loss 0.361411 lr 0.00040607 rank 4
2023-02-22 10:07:06,017 DEBUG TRAIN Batch 18/1500 loss 7.482533 loss_att 8.453046 loss_ctc 10.927737 loss_rnnt 6.645909 hw_loss 0.343425 lr 0.00040605 rank 5
2023-02-22 10:08:18,192 DEBUG TRAIN Batch 18/1600 loss 13.303402 loss_att 15.632714 loss_ctc 13.865425 loss_rnnt 12.632582 hw_loss 0.243793 lr 0.00040586 rank 6
2023-02-22 10:08:18,202 DEBUG TRAIN Batch 18/1600 loss 7.435365 loss_att 10.217472 loss_ctc 10.604727 loss_rnnt 6.395024 hw_loss 0.115007 lr 0.00040591 rank 1
2023-02-22 10:08:18,202 DEBUG TRAIN Batch 18/1600 loss 6.969414 loss_att 9.175179 loss_ctc 9.388500 loss_rnnt 6.082088 hw_loss 0.231804 lr 0.00040589 rank 3
2023-02-22 10:08:18,205 DEBUG TRAIN Batch 18/1600 loss 5.770616 loss_att 8.947950 loss_ctc 10.596437 loss_rnnt 4.330739 hw_loss 0.301813 lr 0.00040587 rank 7
2023-02-22 10:08:18,205 DEBUG TRAIN Batch 18/1600 loss 10.486320 loss_att 14.600040 loss_ctc 16.644369 loss_rnnt 8.707401 hw_loss 0.253315 lr 0.00040589 rank 2
2023-02-22 10:08:18,207 DEBUG TRAIN Batch 18/1600 loss 8.188310 loss_att 10.551188 loss_ctc 11.444019 loss_rnnt 7.124598 hw_loss 0.294455 lr 0.00040594 rank 4
2023-02-22 10:08:18,207 DEBUG TRAIN Batch 18/1600 loss 10.741652 loss_att 12.836205 loss_ctc 12.888343 loss_rnnt 9.845945 hw_loss 0.357317 lr 0.00040592 rank 5
2023-02-22 10:08:18,251 DEBUG TRAIN Batch 18/1600 loss 6.948413 loss_att 9.894001 loss_ctc 6.641137 loss_rnnt 6.247282 hw_loss 0.286844 lr 0.00040598 rank 0
2023-02-22 10:09:31,013 DEBUG TRAIN Batch 18/1700 loss 9.815285 loss_att 11.777250 loss_ctc 15.933831 loss_rnnt 8.483514 hw_loss 0.231695 lr 0.00040576 rank 2
2023-02-22 10:09:31,013 DEBUG TRAIN Batch 18/1700 loss 16.620970 loss_att 17.659056 loss_ctc 21.697136 loss_rnnt 15.653034 hw_loss 0.156556 lr 0.00040576 rank 3
2023-02-22 10:09:31,015 DEBUG TRAIN Batch 18/1700 loss 12.834576 loss_att 16.644999 loss_ctc 16.423500 loss_rnnt 11.450991 hw_loss 0.268081 lr 0.00040578 rank 5
2023-02-22 10:09:31,017 DEBUG TRAIN Batch 18/1700 loss 12.468542 loss_att 18.929956 loss_ctc 21.011383 loss_rnnt 9.928435 hw_loss 0.203960 lr 0.00040584 rank 0
2023-02-22 10:09:31,020 DEBUG TRAIN Batch 18/1700 loss 8.142963 loss_att 10.110774 loss_ctc 8.681528 loss_rnnt 7.613833 hw_loss 0.119551 lr 0.00040580 rank 4
2023-02-22 10:09:31,022 DEBUG TRAIN Batch 18/1700 loss 7.795673 loss_att 12.196158 loss_ctc 11.682416 loss_rnnt 6.263373 hw_loss 0.251195 lr 0.00040573 rank 6
2023-02-22 10:09:31,045 DEBUG TRAIN Batch 18/1700 loss 5.407415 loss_att 6.962635 loss_ctc 7.938306 loss_rnnt 4.617040 hw_loss 0.266024 lr 0.00040574 rank 7
2023-02-22 10:09:31,071 DEBUG TRAIN Batch 18/1700 loss 11.096395 loss_att 15.818737 loss_ctc 18.127518 loss_rnnt 9.092961 hw_loss 0.227777 lr 0.00040578 rank 1
2023-02-22 10:10:46,313 DEBUG TRAIN Batch 18/1800 loss 7.812014 loss_att 11.993587 loss_ctc 8.227538 loss_rnnt 6.702832 hw_loss 0.407745 lr 0.00040563 rank 2
2023-02-22 10:10:46,318 DEBUG TRAIN Batch 18/1800 loss 9.206964 loss_att 12.493618 loss_ctc 11.827293 loss_rnnt 8.034306 hw_loss 0.311157 lr 0.00040563 rank 3
2023-02-22 10:10:46,319 DEBUG TRAIN Batch 18/1800 loss 12.828175 loss_att 15.642817 loss_ctc 19.440212 loss_rnnt 11.170550 hw_loss 0.399548 lr 0.00040567 rank 4
2023-02-22 10:10:46,319 DEBUG TRAIN Batch 18/1800 loss 8.829732 loss_att 12.075485 loss_ctc 15.394704 loss_rnnt 7.128807 hw_loss 0.330833 lr 0.00040561 rank 7
2023-02-22 10:10:46,319 DEBUG TRAIN Batch 18/1800 loss 9.454354 loss_att 11.666548 loss_ctc 14.760686 loss_rnnt 8.110885 hw_loss 0.362852 lr 0.00040559 rank 6
2023-02-22 10:10:46,324 DEBUG TRAIN Batch 18/1800 loss 11.783162 loss_att 13.549693 loss_ctc 14.600405 loss_rnnt 10.976458 hw_loss 0.145810 lr 0.00040564 rank 1
2023-02-22 10:10:46,325 DEBUG TRAIN Batch 18/1800 loss 16.304041 loss_att 18.184275 loss_ctc 22.395390 loss_rnnt 14.993275 hw_loss 0.229761 lr 0.00040565 rank 5
2023-02-22 10:10:46,368 DEBUG TRAIN Batch 18/1800 loss 10.076129 loss_att 13.104452 loss_ctc 14.597791 loss_rnnt 8.653064 hw_loss 0.402209 lr 0.00040571 rank 0
2023-02-22 10:11:59,208 DEBUG TRAIN Batch 18/1900 loss 8.740677 loss_att 11.148235 loss_ctc 13.471927 loss_rnnt 7.468038 hw_loss 0.300551 lr 0.00040549 rank 3
2023-02-22 10:11:59,208 DEBUG TRAIN Batch 18/1900 loss 11.253032 loss_att 12.559693 loss_ctc 13.331520 loss_rnnt 10.525235 hw_loss 0.354999 lr 0.00040549 rank 2
2023-02-22 10:11:59,210 DEBUG TRAIN Batch 18/1900 loss 14.369682 loss_att 13.825962 loss_ctc 16.135345 loss_rnnt 13.922607 hw_loss 0.600743 lr 0.00040551 rank 1
2023-02-22 10:11:59,213 DEBUG TRAIN Batch 18/1900 loss 6.638509 loss_att 9.962089 loss_ctc 9.601517 loss_rnnt 5.449386 hw_loss 0.242513 lr 0.00040546 rank 6
2023-02-22 10:11:59,215 DEBUG TRAIN Batch 18/1900 loss 5.470306 loss_att 9.361234 loss_ctc 9.200672 loss_rnnt 4.110394 hw_loss 0.158147 lr 0.00040547 rank 7
2023-02-22 10:11:59,216 DEBUG TRAIN Batch 18/1900 loss 8.498077 loss_att 10.138078 loss_ctc 12.218922 loss_rnnt 7.455485 hw_loss 0.409649 lr 0.00040552 rank 5
2023-02-22 10:11:59,218 DEBUG TRAIN Batch 18/1900 loss 8.967278 loss_att 13.465631 loss_ctc 10.875708 loss_rnnt 7.647977 hw_loss 0.309702 lr 0.00040558 rank 0
2023-02-22 10:11:59,263 DEBUG TRAIN Batch 18/1900 loss 11.491961 loss_att 12.829358 loss_ctc 17.779766 loss_rnnt 10.190104 hw_loss 0.367506 lr 0.00040554 rank 4
2023-02-22 10:13:11,599 DEBUG TRAIN Batch 18/2000 loss 10.138254 loss_att 11.975979 loss_ctc 11.819702 loss_rnnt 9.374151 hw_loss 0.323183 lr 0.00040537 rank 1
2023-02-22 10:13:11,602 DEBUG TRAIN Batch 18/2000 loss 9.821948 loss_att 15.880159 loss_ctc 19.667744 loss_rnnt 7.186122 hw_loss 0.208894 lr 0.00040534 rank 7
2023-02-22 10:13:11,601 DEBUG TRAIN Batch 18/2000 loss 4.473029 loss_att 7.485289 loss_ctc 6.571817 loss_rnnt 3.487769 hw_loss 0.193068 lr 0.00040533 rank 6
2023-02-22 10:13:11,603 DEBUG TRAIN Batch 18/2000 loss 5.766383 loss_att 11.127035 loss_ctc 8.829848 loss_rnnt 4.200885 hw_loss 0.159196 lr 0.00040536 rank 3
2023-02-22 10:13:11,604 DEBUG TRAIN Batch 18/2000 loss 9.010359 loss_att 10.655579 loss_ctc 13.449774 loss_rnnt 8.003141 hw_loss 0.161722 lr 0.00040536 rank 2
2023-02-22 10:13:11,605 DEBUG TRAIN Batch 18/2000 loss 19.369226 loss_att 23.655319 loss_ctc 23.399656 loss_rnnt 17.899944 hw_loss 0.140008 lr 0.00040544 rank 0
2023-02-22 10:13:11,605 DEBUG TRAIN Batch 18/2000 loss 7.304426 loss_att 9.832754 loss_ctc 7.648484 loss_rnnt 6.596824 hw_loss 0.292617 lr 0.00040538 rank 5
2023-02-22 10:13:11,608 DEBUG TRAIN Batch 18/2000 loss 8.495358 loss_att 12.658333 loss_ctc 10.456630 loss_rnnt 7.225891 hw_loss 0.328818 lr 0.00040540 rank 4
2023-02-22 10:14:25,806 DEBUG TRAIN Batch 18/2100 loss 7.184539 loss_att 9.395403 loss_ctc 7.912383 loss_rnnt 6.544613 hw_loss 0.188827 lr 0.00040523 rank 2
2023-02-22 10:14:25,812 DEBUG TRAIN Batch 18/2100 loss 13.457539 loss_att 15.393066 loss_ctc 16.312412 loss_rnnt 12.518372 hw_loss 0.321398 lr 0.00040523 rank 3
2023-02-22 10:14:25,815 DEBUG TRAIN Batch 18/2100 loss 6.322084 loss_att 10.170334 loss_ctc 10.644386 loss_rnnt 4.848423 hw_loss 0.239445 lr 0.00040519 rank 6
2023-02-22 10:14:25,816 DEBUG TRAIN Batch 18/2100 loss 13.421418 loss_att 18.645624 loss_ctc 22.928398 loss_rnnt 10.936843 hw_loss 0.322756 lr 0.00040531 rank 0
2023-02-22 10:14:25,815 DEBUG TRAIN Batch 18/2100 loss 5.125981 loss_att 8.159885 loss_ctc 4.568433 loss_rnnt 4.455564 hw_loss 0.258704 lr 0.00040527 rank 4
2023-02-22 10:14:25,816 DEBUG TRAIN Batch 18/2100 loss 2.362041 loss_att 5.771128 loss_ctc 4.461873 loss_rnnt 1.324684 hw_loss 0.141678 lr 0.00040524 rank 1
2023-02-22 10:14:25,839 DEBUG TRAIN Batch 18/2100 loss 6.108144 loss_att 9.663614 loss_ctc 12.727671 loss_rnnt 4.442901 hw_loss 0.134149 lr 0.00040521 rank 7
2023-02-22 10:14:25,847 DEBUG TRAIN Batch 18/2100 loss 10.105096 loss_att 13.757456 loss_ctc 15.133940 loss_rnnt 8.540745 hw_loss 0.306312 lr 0.00040525 rank 5
2023-02-22 10:15:39,086 DEBUG TRAIN Batch 18/2200 loss 11.684405 loss_att 15.451448 loss_ctc 13.011415 loss_rnnt 10.640542 hw_loss 0.212849 lr 0.00040509 rank 2
2023-02-22 10:15:39,087 DEBUG TRAIN Batch 18/2200 loss 11.179645 loss_att 14.368806 loss_ctc 15.338070 loss_rnnt 9.907899 hw_loss 0.148981 lr 0.00040506 rank 6
2023-02-22 10:15:39,090 DEBUG TRAIN Batch 18/2200 loss 11.934024 loss_att 14.112616 loss_ctc 15.772392 loss_rnnt 10.811412 hw_loss 0.328332 lr 0.00040512 rank 5
2023-02-22 10:15:39,091 DEBUG TRAIN Batch 18/2200 loss 4.769008 loss_att 8.477064 loss_ctc 7.510425 loss_rnnt 3.460494 hw_loss 0.377587 lr 0.00040511 rank 1
2023-02-22 10:15:39,091 DEBUG TRAIN Batch 18/2200 loss 14.398947 loss_att 17.155697 loss_ctc 21.767052 loss_rnnt 12.746058 hw_loss 0.223357 lr 0.00040518 rank 0
2023-02-22 10:15:39,093 DEBUG TRAIN Batch 18/2200 loss 14.100085 loss_att 17.202396 loss_ctc 18.477758 loss_rnnt 12.728541 hw_loss 0.313860 lr 0.00040509 rank 3
2023-02-22 10:15:39,094 DEBUG TRAIN Batch 18/2200 loss 13.827629 loss_att 18.137804 loss_ctc 23.206114 loss_rnnt 11.584867 hw_loss 0.244242 lr 0.00040514 rank 4
2023-02-22 10:15:39,095 DEBUG TRAIN Batch 18/2200 loss 5.734684 loss_att 11.532779 loss_ctc 9.807384 loss_rnnt 3.773123 hw_loss 0.485467 lr 0.00040507 rank 7
2023-02-22 10:16:50,913 DEBUG TRAIN Batch 18/2300 loss 8.817894 loss_att 13.198891 loss_ctc 10.481409 loss_rnnt 7.625559 hw_loss 0.176875 lr 0.00040496 rank 2
2023-02-22 10:16:50,915 DEBUG TRAIN Batch 18/2300 loss 8.693913 loss_att 9.508677 loss_ctc 10.715439 loss_rnnt 8.103479 hw_loss 0.296146 lr 0.00040500 rank 4
2023-02-22 10:16:50,919 DEBUG TRAIN Batch 18/2300 loss 5.541876 loss_att 8.140569 loss_ctc 8.119431 loss_rnnt 4.623817 hw_loss 0.102461 lr 0.00040498 rank 1
2023-02-22 10:16:50,921 DEBUG TRAIN Batch 18/2300 loss 19.644533 loss_att 22.606014 loss_ctc 27.845558 loss_rnnt 17.845257 hw_loss 0.212832 lr 0.00040493 rank 6
2023-02-22 10:16:50,921 DEBUG TRAIN Batch 18/2300 loss 9.569014 loss_att 10.994872 loss_ctc 12.917141 loss_rnnt 8.662643 hw_loss 0.327717 lr 0.00040496 rank 3
2023-02-22 10:16:50,922 DEBUG TRAIN Batch 18/2300 loss 4.517393 loss_att 7.154509 loss_ctc 8.316898 loss_rnnt 3.322015 hw_loss 0.302538 lr 0.00040494 rank 7
2023-02-22 10:16:50,924 DEBUG TRAIN Batch 18/2300 loss 20.031868 loss_att 21.250950 loss_ctc 23.160265 loss_rnnt 19.287849 hw_loss 0.155777 lr 0.00040504 rank 0
2023-02-22 10:16:50,926 DEBUG TRAIN Batch 18/2300 loss 10.747011 loss_att 13.812123 loss_ctc 12.696076 loss_rnnt 9.791025 hw_loss 0.155790 lr 0.00040498 rank 5
2023-02-22 10:18:03,437 DEBUG TRAIN Batch 18/2400 loss 6.977597 loss_att 12.588876 loss_ctc 10.048506 loss_rnnt 5.360039 hw_loss 0.160964 lr 0.00040483 rank 3
2023-02-22 10:18:03,440 DEBUG TRAIN Batch 18/2400 loss 8.871306 loss_att 12.220331 loss_ctc 13.494596 loss_rnnt 7.404809 hw_loss 0.337975 lr 0.00040491 rank 0
2023-02-22 10:18:03,442 DEBUG TRAIN Batch 18/2400 loss 10.585551 loss_att 11.396193 loss_ctc 11.248941 loss_rnnt 10.204499 hw_loss 0.244634 lr 0.00040484 rank 1
2023-02-22 10:18:03,443 DEBUG TRAIN Batch 18/2400 loss 12.961384 loss_att 15.709341 loss_ctc 20.987411 loss_rnnt 11.209927 hw_loss 0.246990 lr 0.00040487 rank 4
2023-02-22 10:18:03,444 DEBUG TRAIN Batch 18/2400 loss 7.541416 loss_att 10.943060 loss_ctc 12.289784 loss_rnnt 6.106414 hw_loss 0.227918 lr 0.00040480 rank 6
2023-02-22 10:18:03,445 DEBUG TRAIN Batch 18/2400 loss 9.998549 loss_att 11.633444 loss_ctc 14.351427 loss_rnnt 8.938065 hw_loss 0.287104 lr 0.00040483 rank 2
2023-02-22 10:18:03,484 DEBUG TRAIN Batch 18/2400 loss 10.270145 loss_att 13.333062 loss_ctc 13.281982 loss_rnnt 9.167334 hw_loss 0.166220 lr 0.00040485 rank 5
2023-02-22 10:18:03,495 DEBUG TRAIN Batch 18/2400 loss 11.137025 loss_att 14.326097 loss_ctc 16.243366 loss_rnnt 9.642417 hw_loss 0.329903 lr 0.00040481 rank 7
2023-02-22 10:19:19,333 DEBUG TRAIN Batch 18/2500 loss 11.924939 loss_att 13.321499 loss_ctc 17.408987 loss_rnnt 10.696010 hw_loss 0.409520 lr 0.00040470 rank 2
2023-02-22 10:19:19,340 DEBUG TRAIN Batch 18/2500 loss 8.183069 loss_att 12.348101 loss_ctc 13.035398 loss_rnnt 6.543008 hw_loss 0.300144 lr 0.00040469 rank 3
2023-02-22 10:19:19,342 DEBUG TRAIN Batch 18/2500 loss 15.435212 loss_att 20.717899 loss_ctc 19.987440 loss_rnnt 13.609471 hw_loss 0.304199 lr 0.00040474 rank 4
2023-02-22 10:19:19,346 DEBUG TRAIN Batch 18/2500 loss 16.734262 loss_att 16.684803 loss_ctc 27.833546 loss_rnnt 15.037526 hw_loss 0.425106 lr 0.00040466 rank 6
2023-02-22 10:19:19,347 DEBUG TRAIN Batch 18/2500 loss 11.852384 loss_att 12.550755 loss_ctc 15.437345 loss_rnnt 11.043051 hw_loss 0.359370 lr 0.00040472 rank 5
2023-02-22 10:19:19,349 DEBUG TRAIN Batch 18/2500 loss 9.631443 loss_att 13.276148 loss_ctc 16.330082 loss_rnnt 7.867273 hw_loss 0.266396 lr 0.00040471 rank 1
2023-02-22 10:19:19,348 DEBUG TRAIN Batch 18/2500 loss 13.354106 loss_att 18.257341 loss_ctc 22.683441 loss_rnnt 11.055011 hw_loss 0.139759 lr 0.00040468 rank 7
2023-02-22 10:19:19,380 DEBUG TRAIN Batch 18/2500 loss 9.580976 loss_att 12.221190 loss_ctc 15.164482 loss_rnnt 8.238593 hw_loss 0.131013 lr 0.00040478 rank 0
2023-02-22 10:20:31,682 DEBUG TRAIN Batch 18/2600 loss 13.708652 loss_att 17.136795 loss_ctc 21.657471 loss_rnnt 11.838183 hw_loss 0.234370 lr 0.00040453 rank 6
2023-02-22 10:20:31,683 DEBUG TRAIN Batch 18/2600 loss 2.617851 loss_att 6.201820 loss_ctc 4.781269 loss_rnnt 1.548223 hw_loss 0.120709 lr 0.00040456 rank 2
2023-02-22 10:20:31,686 DEBUG TRAIN Batch 18/2600 loss 3.566482 loss_att 6.683625 loss_ctc 3.076440 loss_rnnt 2.884634 hw_loss 0.232047 lr 0.00040459 rank 5
2023-02-22 10:20:31,689 DEBUG TRAIN Batch 18/2600 loss 12.547273 loss_att 16.612017 loss_ctc 15.158538 loss_rnnt 11.292789 hw_loss 0.175064 lr 0.00040461 rank 4
2023-02-22 10:20:31,689 DEBUG TRAIN Batch 18/2600 loss 13.858362 loss_att 16.826859 loss_ctc 15.214407 loss_rnnt 12.896788 hw_loss 0.350758 lr 0.00040465 rank 0
2023-02-22 10:20:31,689 DEBUG TRAIN Batch 18/2600 loss 3.986329 loss_att 6.359524 loss_ctc 5.683126 loss_rnnt 3.177693 hw_loss 0.202046 lr 0.00040454 rank 7
2023-02-22 10:20:31,689 DEBUG TRAIN Batch 18/2600 loss 10.471417 loss_att 11.278379 loss_ctc 15.602933 loss_rnnt 9.415078 hw_loss 0.395146 lr 0.00040458 rank 1
2023-02-22 10:20:31,692 DEBUG TRAIN Batch 18/2600 loss 6.701067 loss_att 10.476467 loss_ctc 10.463306 loss_rnnt 5.375480 hw_loss 0.129142 lr 0.00040456 rank 3
2023-02-22 10:21:45,050 DEBUG TRAIN Batch 18/2700 loss 7.319554 loss_att 12.052317 loss_ctc 8.037372 loss_rnnt 6.176058 hw_loss 0.189815 lr 0.00040443 rank 2
2023-02-22 10:21:45,053 DEBUG TRAIN Batch 18/2700 loss 3.328635 loss_att 5.764879 loss_ctc 3.939127 loss_rnnt 2.624471 hw_loss 0.254093 lr 0.00040451 rank 0
2023-02-22 10:21:45,054 DEBUG TRAIN Batch 18/2700 loss 7.584696 loss_att 12.038130 loss_ctc 15.779707 loss_rnnt 5.536756 hw_loss 0.121097 lr 0.00040441 rank 7
2023-02-22 10:21:45,057 DEBUG TRAIN Batch 18/2700 loss 11.087569 loss_att 15.213896 loss_ctc 17.045202 loss_rnnt 9.404675 hw_loss 0.118647 lr 0.00040443 rank 3
2023-02-22 10:21:45,059 DEBUG TRAIN Batch 18/2700 loss 8.442873 loss_att 14.277073 loss_ctc 13.028793 loss_rnnt 6.495573 hw_loss 0.316883 lr 0.00040445 rank 5
2023-02-22 10:21:45,061 DEBUG TRAIN Batch 18/2700 loss 7.367039 loss_att 15.218552 loss_ctc 7.352113 loss_rnnt 5.689354 hw_loss 0.205075 lr 0.00040440 rank 6
2023-02-22 10:21:45,064 DEBUG TRAIN Batch 18/2700 loss 7.010124 loss_att 8.278791 loss_ctc 12.897835 loss_rnnt 5.851753 hw_loss 0.224266 lr 0.00040447 rank 4
2023-02-22 10:21:45,108 DEBUG TRAIN Batch 18/2700 loss 7.987234 loss_att 8.182703 loss_ctc 9.678065 loss_rnnt 7.547980 hw_loss 0.327592 lr 0.00040445 rank 1
2023-02-22 10:22:59,266 DEBUG TRAIN Batch 18/2800 loss 19.825325 loss_att 20.493347 loss_ctc 24.349913 loss_rnnt 18.931828 hw_loss 0.293657 lr 0.00040432 rank 5
2023-02-22 10:22:59,274 DEBUG TRAIN Batch 18/2800 loss 7.817952 loss_att 10.998869 loss_ctc 12.617616 loss_rnnt 6.424629 hw_loss 0.219721 lr 0.00040428 rank 7
2023-02-22 10:22:59,276 DEBUG TRAIN Batch 18/2800 loss 9.872508 loss_att 13.018918 loss_ctc 12.797693 loss_rnnt 8.655107 hw_loss 0.371424 lr 0.00040427 rank 6
2023-02-22 10:22:59,278 DEBUG TRAIN Batch 18/2800 loss 10.020885 loss_att 12.013568 loss_ctc 12.046445 loss_rnnt 9.161454 hw_loss 0.357786 lr 0.00040430 rank 2
2023-02-22 10:22:59,279 DEBUG TRAIN Batch 18/2800 loss 5.058629 loss_att 8.382998 loss_ctc 6.975563 loss_rnnt 4.043047 hw_loss 0.178345 lr 0.00040434 rank 4
2023-02-22 10:22:59,280 DEBUG TRAIN Batch 18/2800 loss 8.811888 loss_att 10.346478 loss_ctc 12.284084 loss_rnnt 7.928123 hw_loss 0.213540 lr 0.00040438 rank 0
2023-02-22 10:22:59,281 DEBUG TRAIN Batch 18/2800 loss 9.073248 loss_att 12.664662 loss_ctc 11.275207 loss_rnnt 7.940507 hw_loss 0.226619 lr 0.00040430 rank 3
2023-02-22 10:22:59,289 DEBUG TRAIN Batch 18/2800 loss 15.993004 loss_att 18.044096 loss_ctc 20.233791 loss_rnnt 14.882624 hw_loss 0.252604 lr 0.00040431 rank 1
2023-02-22 10:24:13,957 DEBUG TRAIN Batch 18/2900 loss 10.365432 loss_att 13.422106 loss_ctc 14.224043 loss_rnnt 9.109407 hw_loss 0.244142 lr 0.00040415 rank 7
2023-02-22 10:24:13,968 DEBUG TRAIN Batch 18/2900 loss 15.975121 loss_att 19.728855 loss_ctc 21.738850 loss_rnnt 14.314896 hw_loss 0.264337 lr 0.00040417 rank 2
2023-02-22 10:24:13,971 DEBUG TRAIN Batch 18/2900 loss 12.437039 loss_att 16.903721 loss_ctc 19.683586 loss_rnnt 10.458477 hw_loss 0.223161 lr 0.00040418 rank 1
2023-02-22 10:24:13,973 DEBUG TRAIN Batch 18/2900 loss 5.910536 loss_att 9.593727 loss_ctc 8.293763 loss_rnnt 4.771311 hw_loss 0.159043 lr 0.00040413 rank 6
2023-02-22 10:24:13,973 DEBUG TRAIN Batch 18/2900 loss 11.651640 loss_att 13.527893 loss_ctc 15.715540 loss_rnnt 10.562361 hw_loss 0.322829 lr 0.00040425 rank 0
2023-02-22 10:24:13,974 DEBUG TRAIN Batch 18/2900 loss 6.268926 loss_att 10.693874 loss_ctc 8.304705 loss_rnnt 5.012787 hw_loss 0.186960 lr 0.00040417 rank 3
2023-02-22 10:24:13,977 DEBUG TRAIN Batch 18/2900 loss 9.764291 loss_att 13.472694 loss_ctc 13.107788 loss_rnnt 8.416046 hw_loss 0.301432 lr 0.00040419 rank 5
2023-02-22 10:24:13,980 DEBUG TRAIN Batch 18/2900 loss 7.985770 loss_att 10.236979 loss_ctc 11.814475 loss_rnnt 6.849343 hw_loss 0.329421 lr 0.00040421 rank 4
2023-02-22 10:25:25,369 DEBUG TRAIN Batch 18/3000 loss 24.807178 loss_att 25.708317 loss_ctc 28.336880 loss_rnnt 23.945129 hw_loss 0.395991 lr 0.00040400 rank 6
2023-02-22 10:25:25,373 DEBUG TRAIN Batch 18/3000 loss 3.247418 loss_att 5.538330 loss_ctc 4.790964 loss_rnnt 2.457125 hw_loss 0.236820 lr 0.00040403 rank 2
2023-02-22 10:25:25,374 DEBUG TRAIN Batch 18/3000 loss 11.866862 loss_att 15.580668 loss_ctc 15.466000 loss_rnnt 10.467551 hw_loss 0.331247 lr 0.00040403 rank 3
2023-02-22 10:25:25,378 DEBUG TRAIN Batch 18/3000 loss 10.769596 loss_att 12.374814 loss_ctc 12.641574 loss_rnnt 10.056636 hw_loss 0.266849 lr 0.00040401 rank 7
2023-02-22 10:25:25,378 DEBUG TRAIN Batch 18/3000 loss 13.338891 loss_att 13.020156 loss_ctc 19.366585 loss_rnnt 12.461201 hw_loss 0.258271 lr 0.00040412 rank 0
2023-02-22 10:25:25,380 DEBUG TRAIN Batch 18/3000 loss 15.731116 loss_att 17.511707 loss_ctc 22.682444 loss_rnnt 14.276598 hw_loss 0.321667 lr 0.00040408 rank 4
2023-02-22 10:25:25,419 DEBUG TRAIN Batch 18/3000 loss 6.820956 loss_att 8.716348 loss_ctc 9.499044 loss_rnnt 5.940578 hw_loss 0.270413 lr 0.00040406 rank 5
2023-02-22 10:25:25,442 DEBUG TRAIN Batch 18/3000 loss 14.709729 loss_att 14.825040 loss_ctc 20.677135 loss_rnnt 13.797687 hw_loss 0.174987 lr 0.00040405 rank 1
2023-02-22 10:26:38,547 DEBUG TRAIN Batch 18/3100 loss 19.799976 loss_att 24.371902 loss_ctc 29.260450 loss_rnnt 17.424902 hw_loss 0.373674 lr 0.00040390 rank 2
2023-02-22 10:26:38,554 DEBUG TRAIN Batch 18/3100 loss 9.421913 loss_att 9.279375 loss_ctc 12.087591 loss_rnnt 8.947809 hw_loss 0.275976 lr 0.00040388 rank 7
2023-02-22 10:26:38,554 DEBUG TRAIN Batch 18/3100 loss 12.774246 loss_att 15.549543 loss_ctc 16.488729 loss_rnnt 11.550261 hw_loss 0.325614 lr 0.00040390 rank 3
2023-02-22 10:26:38,555 DEBUG TRAIN Batch 18/3100 loss 6.637591 loss_att 8.854092 loss_ctc 10.281441 loss_rnnt 5.551046 hw_loss 0.295123 lr 0.00040393 rank 5
2023-02-22 10:26:38,558 DEBUG TRAIN Batch 18/3100 loss 20.744297 loss_att 23.980562 loss_ctc 24.136982 loss_rnnt 19.458260 hw_loss 0.349548 lr 0.00040387 rank 6
2023-02-22 10:26:38,559 DEBUG TRAIN Batch 18/3100 loss 7.060109 loss_att 8.017509 loss_ctc 9.349517 loss_rnnt 6.397645 hw_loss 0.310742 lr 0.00040399 rank 0
2023-02-22 10:26:38,572 DEBUG TRAIN Batch 18/3100 loss 12.102678 loss_att 15.821136 loss_ctc 15.541983 loss_rnnt 10.715416 hw_loss 0.346869 lr 0.00040394 rank 4
2023-02-22 10:26:38,603 DEBUG TRAIN Batch 18/3100 loss 4.759417 loss_att 8.383926 loss_ctc 9.160158 loss_rnnt 3.224267 hw_loss 0.419029 lr 0.00040392 rank 1
2023-02-22 10:27:55,257 DEBUG TRAIN Batch 18/3200 loss 8.115130 loss_att 8.020189 loss_ctc 10.115862 loss_rnnt 7.645609 hw_loss 0.415773 lr 0.00040377 rank 2
2023-02-22 10:27:55,267 DEBUG TRAIN Batch 18/3200 loss 8.286419 loss_att 9.118714 loss_ctc 10.111624 loss_rnnt 7.691948 hw_loss 0.346222 lr 0.00040379 rank 1
2023-02-22 10:27:55,267 DEBUG TRAIN Batch 18/3200 loss 8.200130 loss_att 7.641470 loss_ctc 8.736660 loss_rnnt 8.010058 hw_loss 0.431751 lr 0.00040379 rank 5
2023-02-22 10:27:55,268 DEBUG TRAIN Batch 18/3200 loss 19.021616 loss_att 23.064138 loss_ctc 25.853392 loss_rnnt 17.160513 hw_loss 0.265678 lr 0.00040385 rank 0
2023-02-22 10:27:55,281 DEBUG TRAIN Batch 18/3200 loss 12.366744 loss_att 11.292673 loss_ctc 13.164968 loss_rnnt 12.212106 hw_loss 0.493168 lr 0.00040381 rank 4
2023-02-22 10:27:55,293 DEBUG TRAIN Batch 18/3200 loss 8.753150 loss_att 9.099116 loss_ctc 12.044847 loss_rnnt 8.134276 hw_loss 0.207728 lr 0.00040374 rank 6
2023-02-22 10:27:55,300 DEBUG TRAIN Batch 18/3200 loss 8.221779 loss_att 8.917768 loss_ctc 9.804309 loss_rnnt 7.636036 hw_loss 0.441637 lr 0.00040377 rank 3
2023-02-22 10:27:55,301 DEBUG TRAIN Batch 18/3200 loss 12.747244 loss_att 14.569925 loss_ctc 14.925647 loss_rnnt 11.922829 hw_loss 0.317671 lr 0.00040375 rank 7
2023-02-22 10:29:08,098 DEBUG TRAIN Batch 18/3300 loss 6.472239 loss_att 11.620108 loss_ctc 7.023674 loss_rnnt 5.283589 hw_loss 0.160408 lr 0.00040364 rank 2
2023-02-22 10:29:08,101 DEBUG TRAIN Batch 18/3300 loss 8.621420 loss_att 14.503173 loss_ctc 12.751612 loss_rnnt 6.706509 hw_loss 0.352253 lr 0.00040365 rank 1
2023-02-22 10:29:08,101 DEBUG TRAIN Batch 18/3300 loss 9.308673 loss_att 13.104626 loss_ctc 12.041952 loss_rnnt 8.007502 hw_loss 0.332891 lr 0.00040366 rank 5
2023-02-22 10:29:08,105 DEBUG TRAIN Batch 18/3300 loss 14.609749 loss_att 18.357952 loss_ctc 22.726120 loss_rnnt 12.610195 hw_loss 0.314492 lr 0.00040368 rank 4
2023-02-22 10:29:08,105 DEBUG TRAIN Batch 18/3300 loss 7.410056 loss_att 9.176715 loss_ctc 9.125117 loss_rnnt 6.721450 hw_loss 0.199873 lr 0.00040364 rank 3
2023-02-22 10:29:08,107 DEBUG TRAIN Batch 18/3300 loss 2.248740 loss_att 5.559767 loss_ctc 4.697137 loss_rnnt 1.078368 hw_loss 0.340714 lr 0.00040361 rank 6
2023-02-22 10:29:08,107 DEBUG TRAIN Batch 18/3300 loss 8.757252 loss_att 12.742401 loss_ctc 17.553358 loss_rnnt 6.646508 hw_loss 0.264188 lr 0.00040372 rank 0
2023-02-22 10:29:08,153 DEBUG TRAIN Batch 18/3300 loss 3.388137 loss_att 7.451082 loss_ctc 4.938932 loss_rnnt 2.291031 hw_loss 0.145770 lr 0.00040362 rank 7
2023-02-22 10:30:20,401 DEBUG TRAIN Batch 18/3400 loss 23.046715 loss_att 26.520864 loss_ctc 37.143486 loss_rnnt 20.353512 hw_loss 0.222755 lr 0.00040359 rank 0
2023-02-22 10:30:20,403 DEBUG TRAIN Batch 18/3400 loss 15.607729 loss_att 16.590570 loss_ctc 21.475231 loss_rnnt 14.473385 hw_loss 0.291454 lr 0.00040349 rank 7
2023-02-22 10:30:20,403 DEBUG TRAIN Batch 18/3400 loss 7.902735 loss_att 15.203287 loss_ctc 11.176864 loss_rnnt 5.833860 hw_loss 0.322901 lr 0.00040353 rank 5
2023-02-22 10:30:20,403 DEBUG TRAIN Batch 18/3400 loss 8.710413 loss_att 10.409798 loss_ctc 17.290306 loss_rnnt 7.031754 hw_loss 0.365243 lr 0.00040348 rank 6
2023-02-22 10:30:20,404 DEBUG TRAIN Batch 18/3400 loss 11.843191 loss_att 14.127583 loss_ctc 17.479488 loss_rnnt 10.542043 hw_loss 0.173930 lr 0.00040351 rank 3
2023-02-22 10:30:20,406 DEBUG TRAIN Batch 18/3400 loss 5.070680 loss_att 7.309947 loss_ctc 6.724428 loss_rnnt 4.216584 hw_loss 0.348267 lr 0.00040351 rank 2
2023-02-22 10:30:20,407 DEBUG TRAIN Batch 18/3400 loss 10.084082 loss_att 14.442772 loss_ctc 16.198160 loss_rnnt 8.259886 hw_loss 0.257336 lr 0.00040355 rank 4
2023-02-22 10:30:20,449 DEBUG TRAIN Batch 18/3400 loss 2.723828 loss_att 5.355627 loss_ctc 4.183903 loss_rnnt 1.895940 hw_loss 0.200346 lr 0.00040352 rank 1
2023-02-22 10:31:33,833 DEBUG TRAIN Batch 18/3500 loss 4.074212 loss_att 6.417486 loss_ctc 7.157361 loss_rnnt 3.071854 hw_loss 0.229905 lr 0.00040338 rank 3
2023-02-22 10:31:33,840 DEBUG TRAIN Batch 18/3500 loss 13.093940 loss_att 17.413677 loss_ctc 20.283976 loss_rnnt 11.127779 hw_loss 0.269138 lr 0.00040338 rank 2
2023-02-22 10:31:33,843 DEBUG TRAIN Batch 18/3500 loss 6.131592 loss_att 8.261319 loss_ctc 11.549767 loss_rnnt 4.801519 hw_loss 0.340695 lr 0.00040339 rank 1
2023-02-22 10:31:33,844 DEBUG TRAIN Batch 18/3500 loss 10.551352 loss_att 15.855555 loss_ctc 17.043058 loss_rnnt 8.452078 hw_loss 0.324135 lr 0.00040334 rank 6
2023-02-22 10:31:33,851 DEBUG TRAIN Batch 18/3500 loss 5.885252 loss_att 8.806722 loss_ctc 10.139734 loss_rnnt 4.624568 hw_loss 0.204613 lr 0.00040340 rank 5
2023-02-22 10:31:33,859 DEBUG TRAIN Batch 18/3500 loss 12.170415 loss_att 13.407082 loss_ctc 18.508232 loss_rnnt 10.984785 hw_loss 0.174852 lr 0.00040336 rank 7
2023-02-22 10:31:33,861 DEBUG TRAIN Batch 18/3500 loss 7.773602 loss_att 12.306520 loss_ctc 8.390450 loss_rnnt 6.665192 hw_loss 0.224212 lr 0.00040342 rank 4
2023-02-22 10:31:33,862 DEBUG TRAIN Batch 18/3500 loss 10.969584 loss_att 14.721328 loss_ctc 16.743677 loss_rnnt 9.271835 hw_loss 0.332850 lr 0.00040346 rank 0
2023-02-22 10:32:47,972 DEBUG TRAIN Batch 18/3600 loss 14.339661 loss_att 16.691429 loss_ctc 19.678495 loss_rnnt 12.949092 hw_loss 0.390693 lr 0.00040326 rank 1
2023-02-22 10:32:47,977 DEBUG TRAIN Batch 18/3600 loss 3.352433 loss_att 8.074754 loss_ctc 6.696185 loss_rnnt 1.819146 hw_loss 0.268106 lr 0.00040321 rank 6
2023-02-22 10:32:47,978 DEBUG TRAIN Batch 18/3600 loss 13.202719 loss_att 16.160278 loss_ctc 19.743042 loss_rnnt 11.609398 hw_loss 0.243312 lr 0.00040329 rank 4
2023-02-22 10:32:47,979 DEBUG TRAIN Batch 18/3600 loss 6.506474 loss_att 8.290523 loss_ctc 8.984541 loss_rnnt 5.628247 hw_loss 0.358139 lr 0.00040327 rank 5
2023-02-22 10:32:47,981 DEBUG TRAIN Batch 18/3600 loss 6.920244 loss_att 9.623301 loss_ctc 8.575776 loss_rnnt 6.039291 hw_loss 0.224256 lr 0.00040325 rank 2
2023-02-22 10:32:47,981 DEBUG TRAIN Batch 18/3600 loss 12.332916 loss_att 14.715611 loss_ctc 16.412861 loss_rnnt 11.197371 hw_loss 0.215651 lr 0.00040333 rank 0
2023-02-22 10:32:47,992 DEBUG TRAIN Batch 18/3600 loss 8.959280 loss_att 12.330194 loss_ctc 14.269828 loss_rnnt 7.465681 hw_loss 0.208769 lr 0.00040324 rank 3
2023-02-22 10:32:48,030 DEBUG TRAIN Batch 18/3600 loss 19.328308 loss_att 23.071692 loss_ctc 28.739742 loss_rnnt 17.162262 hw_loss 0.304711 lr 0.00040323 rank 7
2023-02-22 10:34:00,953 DEBUG TRAIN Batch 18/3700 loss 9.153831 loss_att 11.796741 loss_ctc 12.329831 loss_rnnt 8.059624 hw_loss 0.266549 lr 0.00040311 rank 2
2023-02-22 10:34:00,958 DEBUG TRAIN Batch 18/3700 loss 12.023521 loss_att 15.115734 loss_ctc 13.654243 loss_rnnt 11.011757 hw_loss 0.329799 lr 0.00040308 rank 6
2023-02-22 10:34:00,958 DEBUG TRAIN Batch 18/3700 loss 10.605040 loss_att 13.311883 loss_ctc 17.347120 loss_rnnt 9.072285 hw_loss 0.173331 lr 0.00040316 rank 4
2023-02-22 10:34:00,962 DEBUG TRAIN Batch 18/3700 loss 3.025860 loss_att 4.849123 loss_ctc 6.078294 loss_rnnt 2.126372 hw_loss 0.239707 lr 0.00040309 rank 7
2023-02-22 10:34:00,964 DEBUG TRAIN Batch 18/3700 loss 17.543856 loss_att 18.985287 loss_ctc 24.075741 loss_rnnt 16.282234 hw_loss 0.192032 lr 0.00040320 rank 0
2023-02-22 10:34:00,966 DEBUG TRAIN Batch 18/3700 loss 11.482944 loss_att 12.586369 loss_ctc 17.971443 loss_rnnt 10.271330 hw_loss 0.235865 lr 0.00040311 rank 3
2023-02-22 10:34:00,967 DEBUG TRAIN Batch 18/3700 loss 4.646648 loss_att 8.914944 loss_ctc 7.344849 loss_rnnt 3.345119 hw_loss 0.165207 lr 0.00040314 rank 5
2023-02-22 10:34:00,969 DEBUG TRAIN Batch 18/3700 loss 14.294530 loss_att 14.271748 loss_ctc 18.008316 loss_rnnt 13.648669 hw_loss 0.291085 lr 0.00040313 rank 1
2023-02-22 10:35:13,449 DEBUG TRAIN Batch 18/3800 loss 8.683659 loss_att 10.819360 loss_ctc 13.041006 loss_rnnt 7.520535 hw_loss 0.290629 lr 0.00040303 rank 4
2023-02-22 10:35:13,461 DEBUG TRAIN Batch 18/3800 loss 7.557745 loss_att 8.331413 loss_ctc 10.454261 loss_rnnt 6.870822 hw_loss 0.273725 lr 0.00040298 rank 3
2023-02-22 10:35:13,468 DEBUG TRAIN Batch 18/3800 loss 8.167586 loss_att 9.437131 loss_ctc 9.935101 loss_rnnt 7.502995 hw_loss 0.328153 lr 0.00040298 rank 2
2023-02-22 10:35:13,467 DEBUG TRAIN Batch 18/3800 loss 6.839906 loss_att 8.036281 loss_ctc 11.413675 loss_rnnt 5.757459 hw_loss 0.437507 lr 0.00040295 rank 6
2023-02-22 10:35:13,470 DEBUG TRAIN Batch 18/3800 loss 8.107059 loss_att 8.708092 loss_ctc 9.290939 loss_rnnt 7.594047 hw_loss 0.440541 lr 0.00040301 rank 5
2023-02-22 10:35:13,471 DEBUG TRAIN Batch 18/3800 loss 14.418819 loss_att 17.213970 loss_ctc 19.262627 loss_rnnt 13.096014 hw_loss 0.221128 lr 0.00040296 rank 7
2023-02-22 10:35:13,475 DEBUG TRAIN Batch 18/3800 loss 7.848206 loss_att 9.596439 loss_ctc 10.963965 loss_rnnt 6.841847 hw_loss 0.452393 lr 0.00040300 rank 1
2023-02-22 10:35:13,518 DEBUG TRAIN Batch 18/3800 loss 8.702757 loss_att 12.877474 loss_ctc 10.720934 loss_rnnt 7.463643 hw_loss 0.253275 lr 0.00040307 rank 0
2023-02-22 10:36:28,280 DEBUG TRAIN Batch 18/3900 loss 3.406017 loss_att 7.628814 loss_ctc 7.660248 loss_rnnt 1.871861 hw_loss 0.229435 lr 0.00040294 rank 0
2023-02-22 10:36:28,282 DEBUG TRAIN Batch 18/3900 loss 8.984502 loss_att 9.550997 loss_ctc 9.365006 loss_rnnt 8.713200 hw_loss 0.201129 lr 0.00040289 rank 4
2023-02-22 10:36:28,282 DEBUG TRAIN Batch 18/3900 loss 6.008564 loss_att 9.690950 loss_ctc 10.121479 loss_rnnt 4.556426 hw_loss 0.313634 lr 0.00040283 rank 7
2023-02-22 10:36:28,283 DEBUG TRAIN Batch 18/3900 loss 13.618740 loss_att 17.236773 loss_ctc 21.021736 loss_rnnt 11.735001 hw_loss 0.324499 lr 0.00040285 rank 3
2023-02-22 10:36:28,285 DEBUG TRAIN Batch 18/3900 loss 10.786952 loss_att 14.172149 loss_ctc 15.607964 loss_rnnt 9.294817 hw_loss 0.323053 lr 0.00040287 rank 1
2023-02-22 10:36:28,286 DEBUG TRAIN Batch 18/3900 loss 7.517434 loss_att 11.240110 loss_ctc 13.975082 loss_rnnt 5.787367 hw_loss 0.233459 lr 0.00040285 rank 2
2023-02-22 10:36:28,290 DEBUG TRAIN Batch 18/3900 loss 5.544426 loss_att 8.868752 loss_ctc 8.527479 loss_rnnt 4.239163 hw_loss 0.454982 lr 0.00040287 rank 5
2023-02-22 10:36:28,319 DEBUG TRAIN Batch 18/3900 loss 6.448021 loss_att 10.313175 loss_ctc 8.226649 loss_rnnt 5.356662 hw_loss 0.152209 lr 0.00040282 rank 6
2023-02-22 10:37:41,253 DEBUG TRAIN Batch 18/4000 loss 10.080523 loss_att 14.890999 loss_ctc 15.532832 loss_rnnt 8.267159 hw_loss 0.233051 lr 0.00040270 rank 7
2023-02-22 10:37:41,256 DEBUG TRAIN Batch 18/4000 loss 5.939100 loss_att 7.919571 loss_ctc 5.270459 loss_rnnt 5.414897 hw_loss 0.407364 lr 0.00040272 rank 2
2023-02-22 10:37:41,257 DEBUG TRAIN Batch 18/4000 loss 7.568640 loss_att 10.709253 loss_ctc 10.050913 loss_rnnt 6.452836 hw_loss 0.293834 lr 0.00040269 rank 6
2023-02-22 10:37:41,261 DEBUG TRAIN Batch 18/4000 loss 10.214620 loss_att 10.140693 loss_ctc 15.077398 loss_rnnt 9.363770 hw_loss 0.407371 lr 0.00040280 rank 0
2023-02-22 10:37:41,261 DEBUG TRAIN Batch 18/4000 loss 5.244640 loss_att 8.806176 loss_ctc 7.815605 loss_rnnt 4.007677 hw_loss 0.340988 lr 0.00040274 rank 1
2023-02-22 10:37:41,261 DEBUG TRAIN Batch 18/4000 loss 7.423854 loss_att 10.880300 loss_ctc 8.771873 loss_rnnt 6.440592 hw_loss 0.210447 lr 0.00040276 rank 4
2023-02-22 10:37:41,261 DEBUG TRAIN Batch 18/4000 loss 8.599155 loss_att 12.055461 loss_ctc 13.237647 loss_rnnt 7.132564 hw_loss 0.294119 lr 0.00040272 rank 3
2023-02-22 10:37:41,274 DEBUG TRAIN Batch 18/4000 loss 13.483772 loss_att 16.894506 loss_ctc 15.647751 loss_rnnt 12.425962 hw_loss 0.163374 lr 0.00040274 rank 5
2023-02-22 10:38:52,938 DEBUG TRAIN Batch 18/4100 loss 9.673522 loss_att 14.056913 loss_ctc 16.126160 loss_rnnt 7.812339 hw_loss 0.232786 lr 0.00040259 rank 2
2023-02-22 10:38:52,942 DEBUG TRAIN Batch 18/4100 loss 24.928768 loss_att 29.242451 loss_ctc 31.089512 loss_rnnt 23.045340 hw_loss 0.373613 lr 0.00040267 rank 0
2023-02-22 10:38:52,941 DEBUG TRAIN Batch 18/4100 loss 10.726694 loss_att 12.460007 loss_ctc 13.224096 loss_rnnt 9.890424 hw_loss 0.293663 lr 0.00040256 rank 6
2023-02-22 10:38:52,942 DEBUG TRAIN Batch 18/4100 loss 5.229607 loss_att 9.175464 loss_ctc 9.706985 loss_rnnt 3.675144 hw_loss 0.315577 lr 0.00040263 rank 4
2023-02-22 10:38:52,943 DEBUG TRAIN Batch 18/4100 loss 11.582633 loss_att 14.164697 loss_ctc 12.069921 loss_rnnt 10.890509 hw_loss 0.207638 lr 0.00040259 rank 3
2023-02-22 10:38:52,947 DEBUG TRAIN Batch 18/4100 loss 9.954944 loss_att 15.029058 loss_ctc 15.114548 loss_rnnt 8.135305 hw_loss 0.219128 lr 0.00040261 rank 5
2023-02-22 10:38:52,948 DEBUG TRAIN Batch 18/4100 loss 6.080139 loss_att 9.400568 loss_ctc 11.650881 loss_rnnt 4.505682 hw_loss 0.314258 lr 0.00040261 rank 1
2023-02-22 10:38:52,990 DEBUG TRAIN Batch 18/4100 loss 8.994909 loss_att 12.760330 loss_ctc 11.777207 loss_rnnt 7.701605 hw_loss 0.317335 lr 0.00040257 rank 7
2023-02-22 10:40:06,316 DEBUG TRAIN Batch 18/4200 loss 17.481611 loss_att 22.753748 loss_ctc 25.488073 loss_rnnt 15.225518 hw_loss 0.251506 lr 0.00040250 rank 4
2023-02-22 10:40:06,328 DEBUG TRAIN Batch 18/4200 loss 8.163301 loss_att 9.296242 loss_ctc 12.881689 loss_rnnt 7.173150 hw_loss 0.252084 lr 0.00040248 rank 5
2023-02-22 10:40:06,328 DEBUG TRAIN Batch 18/4200 loss 13.862032 loss_att 16.339859 loss_ctc 23.654388 loss_rnnt 11.852375 hw_loss 0.390829 lr 0.00040246 rank 2
2023-02-22 10:40:06,328 DEBUG TRAIN Batch 18/4200 loss 16.318005 loss_att 16.674911 loss_ctc 17.466669 loss_rnnt 15.956461 hw_loss 0.256885 lr 0.00040248 rank 1
2023-02-22 10:40:06,330 DEBUG TRAIN Batch 18/4200 loss 10.547298 loss_att 13.366129 loss_ctc 17.300766 loss_rnnt 8.880545 hw_loss 0.379734 lr 0.00040244 rank 7
2023-02-22 10:40:06,331 DEBUG TRAIN Batch 18/4200 loss 14.080597 loss_att 15.189001 loss_ctc 15.685980 loss_rnnt 13.467725 hw_loss 0.332136 lr 0.00040254 rank 0
2023-02-22 10:40:06,331 DEBUG TRAIN Batch 18/4200 loss 27.474525 loss_att 26.368027 loss_ctc 38.021202 loss_rnnt 26.100098 hw_loss 0.355321 lr 0.00040246 rank 3
2023-02-22 10:40:06,336 DEBUG TRAIN Batch 18/4200 loss 10.902025 loss_att 14.228930 loss_ctc 17.954317 loss_rnnt 9.163191 hw_loss 0.249652 lr 0.00040243 rank 6
2023-02-22 10:41:21,026 DEBUG TRAIN Batch 18/4300 loss 4.884353 loss_att 8.382156 loss_ctc 8.807521 loss_rnnt 3.535483 hw_loss 0.236661 lr 0.00040233 rank 3
2023-02-22 10:41:21,029 DEBUG TRAIN Batch 18/4300 loss 12.354445 loss_att 15.476617 loss_ctc 14.887759 loss_rnnt 11.267514 hw_loss 0.233851 lr 0.00040231 rank 7
2023-02-22 10:41:21,030 DEBUG TRAIN Batch 18/4300 loss 4.788104 loss_att 7.858781 loss_ctc 5.776438 loss_rnnt 3.989748 hw_loss 0.098328 lr 0.00040237 rank 4
2023-02-22 10:41:21,031 DEBUG TRAIN Batch 18/4300 loss 5.429620 loss_att 8.205309 loss_ctc 8.898582 loss_rnnt 4.284177 hw_loss 0.239582 lr 0.00040233 rank 2
2023-02-22 10:41:21,031 DEBUG TRAIN Batch 18/4300 loss 8.407781 loss_att 9.899266 loss_ctc 9.063506 loss_rnnt 7.879830 hw_loss 0.266669 lr 0.00040230 rank 6
2023-02-22 10:41:21,033 DEBUG TRAIN Batch 18/4300 loss 19.780752 loss_att 21.818993 loss_ctc 28.432402 loss_rnnt 18.021444 hw_loss 0.371449 lr 0.00040241 rank 0
2023-02-22 10:41:21,037 DEBUG TRAIN Batch 18/4300 loss 8.316046 loss_att 9.900724 loss_ctc 11.878654 loss_rnnt 7.447958 hw_loss 0.142760 lr 0.00040235 rank 5
2023-02-22 10:41:21,038 DEBUG TRAIN Batch 18/4300 loss 7.719278 loss_att 13.444506 loss_ctc 12.818132 loss_rnnt 5.744923 hw_loss 0.280243 lr 0.00040234 rank 1
2023-02-22 10:42:33,140 DEBUG TRAIN Batch 18/4400 loss 5.139280 loss_att 7.188633 loss_ctc 8.284177 loss_rnnt 4.144910 hw_loss 0.309712 lr 0.00040220 rank 2
2023-02-22 10:42:33,141 DEBUG TRAIN Batch 18/4400 loss 6.962630 loss_att 9.705858 loss_ctc 10.884033 loss_rnnt 5.735126 hw_loss 0.292510 lr 0.00040217 rank 6
2023-02-22 10:42:33,141 DEBUG TRAIN Batch 18/4400 loss 13.622915 loss_att 13.818987 loss_ctc 16.629751 loss_rnnt 13.037710 hw_loss 0.272023 lr 0.00040224 rank 4
2023-02-22 10:42:33,141 DEBUG TRAIN Batch 18/4400 loss 9.663237 loss_att 11.493111 loss_ctc 11.413264 loss_rnnt 8.742443 hw_loss 0.602776 lr 0.00040220 rank 3
2023-02-22 10:42:33,142 DEBUG TRAIN Batch 18/4400 loss 7.131489 loss_att 7.450103 loss_ctc 9.155887 loss_rnnt 6.591712 hw_loss 0.386501 lr 0.00040222 rank 5
2023-02-22 10:42:33,142 DEBUG TRAIN Batch 18/4400 loss 7.239174 loss_att 7.453016 loss_ctc 8.292617 loss_rnnt 6.889601 hw_loss 0.311897 lr 0.00040221 rank 1
2023-02-22 10:42:33,145 DEBUG TRAIN Batch 18/4400 loss 4.440206 loss_att 8.227513 loss_ctc 4.312416 loss_rnnt 3.532947 hw_loss 0.312817 lr 0.00040218 rank 7
2023-02-22 10:42:33,147 DEBUG TRAIN Batch 18/4400 loss 11.719839 loss_att 11.465729 loss_ctc 13.308833 loss_rnnt 11.389796 hw_loss 0.316874 lr 0.00040228 rank 0
2023-02-22 10:43:46,162 DEBUG TRAIN Batch 18/4500 loss 23.104414 loss_att 28.202394 loss_ctc 35.042709 loss_rnnt 20.419228 hw_loss 0.138407 lr 0.00040204 rank 6
2023-02-22 10:43:46,172 DEBUG TRAIN Batch 18/4500 loss 14.325034 loss_att 17.808838 loss_ctc 21.679573 loss_rnnt 12.586456 hw_loss 0.114773 lr 0.00040207 rank 3
2023-02-22 10:43:46,177 DEBUG TRAIN Batch 18/4500 loss 10.672813 loss_att 14.236744 loss_ctc 12.444484 loss_rnnt 9.593162 hw_loss 0.244955 lr 0.00040211 rank 4
2023-02-22 10:43:46,180 DEBUG TRAIN Batch 18/4500 loss 7.948893 loss_att 10.581940 loss_ctc 11.348885 loss_rnnt 6.803690 hw_loss 0.309865 lr 0.00040207 rank 2
2023-02-22 10:43:46,181 DEBUG TRAIN Batch 18/4500 loss 5.644560 loss_att 9.525549 loss_ctc 9.955216 loss_rnnt 4.161226 hw_loss 0.248216 lr 0.00040208 rank 1
2023-02-22 10:43:46,183 DEBUG TRAIN Batch 18/4500 loss 5.102079 loss_att 9.601018 loss_ctc 7.940495 loss_rnnt 3.691473 hw_loss 0.248182 lr 0.00040205 rank 7
2023-02-22 10:43:46,187 DEBUG TRAIN Batch 18/4500 loss 4.240601 loss_att 5.916264 loss_ctc 4.449632 loss_rnnt 3.745052 hw_loss 0.248521 lr 0.00040215 rank 0
2023-02-22 10:43:46,187 DEBUG TRAIN Batch 18/4500 loss 10.715658 loss_att 14.358782 loss_ctc 19.132172 loss_rnnt 8.669131 hw_loss 0.366939 lr 0.00040209 rank 5
2023-02-22 10:45:01,643 DEBUG TRAIN Batch 18/4600 loss 12.897254 loss_att 16.025110 loss_ctc 19.163460 loss_rnnt 11.217151 hw_loss 0.410698 lr 0.00040195 rank 1
2023-02-22 10:45:01,650 DEBUG TRAIN Batch 18/4600 loss 23.448580 loss_att 25.227850 loss_ctc 50.390697 loss_rnnt 19.363106 hw_loss 0.257505 lr 0.00040196 rank 5
2023-02-22 10:45:01,651 DEBUG TRAIN Batch 18/4600 loss 5.566544 loss_att 7.634836 loss_ctc 7.230901 loss_rnnt 4.792514 hw_loss 0.259607 lr 0.00040202 rank 0
2023-02-22 10:45:01,656 DEBUG TRAIN Batch 18/4600 loss 18.536903 loss_att 23.439035 loss_ctc 18.845570 loss_rnnt 17.355398 hw_loss 0.299860 lr 0.00040194 rank 3
2023-02-22 10:45:01,659 DEBUG TRAIN Batch 18/4600 loss 3.166124 loss_att 4.861737 loss_ctc 4.198318 loss_rnnt 2.499271 hw_loss 0.356444 lr 0.00040198 rank 4
2023-02-22 10:45:01,661 DEBUG TRAIN Batch 18/4600 loss 7.587215 loss_att 9.941905 loss_ctc 11.161273 loss_rnnt 6.536937 hw_loss 0.192747 lr 0.00040194 rank 2
2023-02-22 10:45:01,665 DEBUG TRAIN Batch 18/4600 loss 14.500975 loss_att 15.751678 loss_ctc 23.587637 loss_rnnt 12.878692 hw_loss 0.301101 lr 0.00040192 rank 7
2023-02-22 10:45:01,665 DEBUG TRAIN Batch 18/4600 loss 5.632612 loss_att 9.276438 loss_ctc 10.503290 loss_rnnt 4.140956 hw_loss 0.212749 lr 0.00040191 rank 6
2023-02-22 10:46:14,735 DEBUG TRAIN Batch 18/4700 loss 5.167660 loss_att 9.448101 loss_ctc 6.928810 loss_rnnt 3.857759 hw_loss 0.410610 lr 0.00040181 rank 2
2023-02-22 10:46:14,738 DEBUG TRAIN Batch 18/4700 loss 15.396447 loss_att 16.464073 loss_ctc 18.848045 loss_rnnt 14.565973 hw_loss 0.293877 lr 0.00040178 rank 6
2023-02-22 10:46:14,742 DEBUG TRAIN Batch 18/4700 loss 5.939228 loss_att 8.788212 loss_ctc 9.947948 loss_rnnt 4.719016 hw_loss 0.217348 lr 0.00040179 rank 7
2023-02-22 10:46:14,745 DEBUG TRAIN Batch 18/4700 loss 11.765589 loss_att 17.847221 loss_ctc 17.504339 loss_rnnt 9.640863 hw_loss 0.268562 lr 0.00040181 rank 3
2023-02-22 10:46:14,746 DEBUG TRAIN Batch 18/4700 loss 4.697773 loss_att 6.606403 loss_ctc 5.831988 loss_rnnt 3.987961 hw_loss 0.331608 lr 0.00040185 rank 4
2023-02-22 10:46:14,749 DEBUG TRAIN Batch 18/4700 loss 12.139630 loss_att 14.216791 loss_ctc 15.679977 loss_rnnt 11.031740 hw_loss 0.413271 lr 0.00040189 rank 0
2023-02-22 10:46:14,751 DEBUG TRAIN Batch 18/4700 loss 3.365722 loss_att 8.930951 loss_ctc 8.241648 loss_rnnt 1.419967 hw_loss 0.342349 lr 0.00040183 rank 5
2023-02-22 10:46:14,792 DEBUG TRAIN Batch 18/4700 loss 10.455633 loss_att 13.438013 loss_ctc 13.734360 loss_rnnt 9.329978 hw_loss 0.172529 lr 0.00040182 rank 1
2023-02-22 10:47:27,447 DEBUG TRAIN Batch 18/4800 loss 16.993553 loss_att 17.915956 loss_ctc 20.657349 loss_rnnt 16.227551 hw_loss 0.174405 lr 0.00040168 rank 2
2023-02-22 10:47:27,449 DEBUG TRAIN Batch 18/4800 loss 10.341040 loss_att 12.309350 loss_ctc 14.978521 loss_rnnt 9.200211 hw_loss 0.241567 lr 0.00040165 rank 6
2023-02-22 10:47:27,452 DEBUG TRAIN Batch 18/4800 loss 13.092966 loss_att 18.629641 loss_ctc 18.392424 loss_rnnt 11.111315 hw_loss 0.314479 lr 0.00040168 rank 3
2023-02-22 10:47:27,452 DEBUG TRAIN Batch 18/4800 loss 7.076572 loss_att 9.513380 loss_ctc 8.225834 loss_rnnt 6.304202 hw_loss 0.247077 lr 0.00040166 rank 7
2023-02-22 10:47:27,455 DEBUG TRAIN Batch 18/4800 loss 11.654748 loss_att 13.262730 loss_ctc 17.510748 loss_rnnt 10.430276 hw_loss 0.228892 lr 0.00040176 rank 0
2023-02-22 10:47:27,456 DEBUG TRAIN Batch 18/4800 loss 7.700306 loss_att 11.017051 loss_ctc 15.619450 loss_rnnt 5.829762 hw_loss 0.283704 lr 0.00040172 rank 4
2023-02-22 10:47:27,460 DEBUG TRAIN Batch 18/4800 loss 17.847939 loss_att 23.599514 loss_ctc 24.110180 loss_rnnt 15.786937 hw_loss 0.141977 lr 0.00040170 rank 1
2023-02-22 10:47:27,508 DEBUG TRAIN Batch 18/4800 loss 10.904856 loss_att 15.423673 loss_ctc 15.176944 loss_rnnt 9.300462 hw_loss 0.245660 lr 0.00040170 rank 5
2023-02-22 10:48:40,704 DEBUG TRAIN Batch 18/4900 loss 8.874825 loss_att 10.866369 loss_ctc 12.590097 loss_rnnt 7.862675 hw_loss 0.222134 lr 0.00040155 rank 2
2023-02-22 10:48:40,711 DEBUG TRAIN Batch 18/4900 loss 14.943934 loss_att 16.810497 loss_ctc 21.889585 loss_rnnt 13.505889 hw_loss 0.259963 lr 0.00040153 rank 7
2023-02-22 10:48:40,712 DEBUG TRAIN Batch 18/4900 loss 11.920131 loss_att 14.219392 loss_ctc 16.534412 loss_rnnt 10.711889 hw_loss 0.249660 lr 0.00040157 rank 1
2023-02-22 10:48:40,714 DEBUG TRAIN Batch 18/4900 loss 16.174086 loss_att 19.064234 loss_ctc 23.352837 loss_rnnt 14.487954 hw_loss 0.283005 lr 0.00040152 rank 6
2023-02-22 10:48:40,716 DEBUG TRAIN Batch 18/4900 loss 36.644577 loss_att 36.421970 loss_ctc 45.691502 loss_rnnt 35.256081 hw_loss 0.425176 lr 0.00040155 rank 3
2023-02-22 10:48:40,716 DEBUG TRAIN Batch 18/4900 loss 7.189182 loss_att 8.541740 loss_ctc 10.533924 loss_rnnt 6.390826 hw_loss 0.153524 lr 0.00040159 rank 4
2023-02-22 10:48:40,717 DEBUG TRAIN Batch 18/4900 loss 14.148354 loss_att 13.337627 loss_ctc 18.275414 loss_rnnt 13.666678 hw_loss 0.175400 lr 0.00040163 rank 0
2023-02-22 10:48:40,729 DEBUG TRAIN Batch 18/4900 loss 14.197408 loss_att 15.237465 loss_ctc 25.789143 loss_rnnt 12.255000 hw_loss 0.354059 lr 0.00040157 rank 5
2023-02-22 10:49:55,771 DEBUG TRAIN Batch 18/5000 loss 7.566629 loss_att 9.386901 loss_ctc 11.638907 loss_rnnt 6.543742 hw_loss 0.217241 lr 0.00040142 rank 2
2023-02-22 10:49:55,773 DEBUG TRAIN Batch 18/5000 loss 11.329242 loss_att 13.436377 loss_ctc 15.238273 loss_rnnt 10.224639 hw_loss 0.303695 lr 0.00040139 rank 6
2023-02-22 10:49:55,780 DEBUG TRAIN Batch 18/5000 loss 7.526042 loss_att 11.409515 loss_ctc 10.984910 loss_rnnt 6.166116 hw_loss 0.228841 lr 0.00040144 rank 1
2023-02-22 10:49:55,780 DEBUG TRAIN Batch 18/5000 loss 7.632913 loss_att 8.694666 loss_ctc 12.908808 loss_rnnt 6.515491 hw_loss 0.378036 lr 0.00040142 rank 3
2023-02-22 10:49:55,781 DEBUG TRAIN Batch 18/5000 loss 21.435663 loss_att 25.378242 loss_ctc 27.840418 loss_rnnt 19.643806 hw_loss 0.280075 lr 0.00040144 rank 5
2023-02-22 10:49:55,782 DEBUG TRAIN Batch 18/5000 loss 3.927435 loss_att 4.818407 loss_ctc 6.941068 loss_rnnt 3.244372 hw_loss 0.193221 lr 0.00040140 rank 7
2023-02-22 10:49:55,800 DEBUG TRAIN Batch 18/5000 loss 10.837825 loss_att 13.387104 loss_ctc 16.221594 loss_rnnt 9.523563 hw_loss 0.162317 lr 0.00040146 rank 4
2023-02-22 10:49:55,849 DEBUG TRAIN Batch 18/5000 loss 9.652395 loss_att 13.153343 loss_ctc 14.132069 loss_rnnt 8.168983 hw_loss 0.348623 lr 0.00040150 rank 0
2023-02-22 10:51:08,067 DEBUG TRAIN Batch 18/5100 loss 6.195958 loss_att 5.904764 loss_ctc 8.005796 loss_rnnt 5.715781 hw_loss 0.557069 lr 0.00040129 rank 3
2023-02-22 10:51:08,069 DEBUG TRAIN Batch 18/5100 loss 5.914743 loss_att 9.515955 loss_ctc 4.761320 loss_rnnt 5.285483 hw_loss 0.117763 lr 0.00040126 rank 6
2023-02-22 10:51:08,071 DEBUG TRAIN Batch 18/5100 loss 12.636045 loss_att 14.692933 loss_ctc 16.043888 loss_rnnt 11.732229 hw_loss 0.071359 lr 0.00040127 rank 7
2023-02-22 10:51:08,073 DEBUG TRAIN Batch 18/5100 loss 14.982729 loss_att 17.876955 loss_ctc 17.700766 loss_rnnt 13.927511 hw_loss 0.213690 lr 0.00040129 rank 2
2023-02-22 10:51:08,075 DEBUG TRAIN Batch 18/5100 loss 3.295191 loss_att 5.488082 loss_ctc 5.704685 loss_rnnt 2.485779 hw_loss 0.092941 lr 0.00040133 rank 4
2023-02-22 10:51:08,077 DEBUG TRAIN Batch 18/5100 loss 13.195069 loss_att 14.582880 loss_ctc 15.863969 loss_rnnt 12.442303 hw_loss 0.223783 lr 0.00040131 rank 1
2023-02-22 10:51:08,079 DEBUG TRAIN Batch 18/5100 loss 10.351406 loss_att 11.509653 loss_ctc 13.407986 loss_rnnt 9.465607 hw_loss 0.462387 lr 0.00040131 rank 5
2023-02-22 10:51:08,081 DEBUG TRAIN Batch 18/5100 loss 9.640570 loss_att 13.910973 loss_ctc 15.389658 loss_rnnt 7.941146 hw_loss 0.147746 lr 0.00040137 rank 0
2023-02-22 10:52:20,277 DEBUG TRAIN Batch 18/5200 loss 11.531837 loss_att 19.075451 loss_ctc 20.022245 loss_rnnt 8.794024 hw_loss 0.181942 lr 0.00040113 rank 6
2023-02-22 10:52:20,277 DEBUG TRAIN Batch 18/5200 loss 7.859440 loss_att 11.947048 loss_ctc 9.931280 loss_rnnt 6.679331 hw_loss 0.161892 lr 0.00040116 rank 2
2023-02-22 10:52:20,278 DEBUG TRAIN Batch 18/5200 loss 6.895626 loss_att 8.342849 loss_ctc 8.905269 loss_rnnt 6.231249 hw_loss 0.200589 lr 0.00040120 rank 4
2023-02-22 10:52:20,282 DEBUG TRAIN Batch 18/5200 loss 12.569920 loss_att 16.342503 loss_ctc 17.510036 loss_rnnt 11.094984 hw_loss 0.115757 lr 0.00040114 rank 7
2023-02-22 10:52:20,281 DEBUG TRAIN Batch 18/5200 loss 8.459386 loss_att 11.913466 loss_ctc 14.206016 loss_rnnt 6.871646 hw_loss 0.245076 lr 0.00040116 rank 3
2023-02-22 10:52:20,283 DEBUG TRAIN Batch 18/5200 loss 14.533973 loss_att 13.594003 loss_ctc 14.107229 loss_rnnt 14.629128 hw_loss 0.280758 lr 0.00040118 rank 1
2023-02-22 10:52:20,288 DEBUG TRAIN Batch 18/5200 loss 18.147305 loss_att 19.869389 loss_ctc 24.666653 loss_rnnt 16.735235 hw_loss 0.372013 lr 0.00040119 rank 5
2023-02-22 10:52:20,330 DEBUG TRAIN Batch 18/5200 loss 4.054141 loss_att 8.776244 loss_ctc 5.386024 loss_rnnt 2.774842 hw_loss 0.294925 lr 0.00040124 rank 0
2023-02-22 10:53:34,457 DEBUG TRAIN Batch 18/5300 loss 6.568414 loss_att 8.540526 loss_ctc 11.080913 loss_rnnt 5.455509 hw_loss 0.219028 lr 0.00040105 rank 1
2023-02-22 10:53:34,461 DEBUG TRAIN Batch 18/5300 loss 13.174855 loss_att 16.856310 loss_ctc 19.503168 loss_rnnt 11.437502 hw_loss 0.294912 lr 0.00040102 rank 7
2023-02-22 10:53:34,474 DEBUG TRAIN Batch 18/5300 loss 5.041514 loss_att 8.321024 loss_ctc 4.925948 loss_rnnt 4.287766 hw_loss 0.212352 lr 0.00040108 rank 4
2023-02-22 10:53:34,474 DEBUG TRAIN Batch 18/5300 loss 8.987492 loss_att 14.805210 loss_ctc 14.579887 loss_rnnt 7.006135 hw_loss 0.135301 lr 0.00040100 rank 6
2023-02-22 10:53:34,477 DEBUG TRAIN Batch 18/5300 loss 7.972763 loss_att 13.747236 loss_ctc 18.609663 loss_rnnt 5.215425 hw_loss 0.345356 lr 0.00040103 rank 2
2023-02-22 10:53:34,478 DEBUG TRAIN Batch 18/5300 loss 7.320475 loss_att 9.434920 loss_ctc 7.169765 loss_rnnt 6.684449 hw_loss 0.437308 lr 0.00040106 rank 5
2023-02-22 10:53:34,478 DEBUG TRAIN Batch 18/5300 loss 14.209641 loss_att 16.902332 loss_ctc 20.169464 loss_rnnt 12.719324 hw_loss 0.294627 lr 0.00040112 rank 0
2023-02-22 10:53:34,479 DEBUG TRAIN Batch 18/5300 loss 5.428057 loss_att 7.530890 loss_ctc 6.407663 loss_rnnt 4.665948 hw_loss 0.395490 lr 0.00040103 rank 3
2023-02-22 10:54:47,784 DEBUG TRAIN Batch 18/5400 loss 5.152136 loss_att 7.611813 loss_ctc 7.344143 loss_rnnt 4.227783 hw_loss 0.262782 lr 0.00040091 rank 2
2023-02-22 10:54:47,791 DEBUG TRAIN Batch 18/5400 loss 5.360410 loss_att 7.475977 loss_ctc 9.494911 loss_rnnt 4.237291 hw_loss 0.278885 lr 0.00040092 rank 1
2023-02-22 10:54:47,791 DEBUG TRAIN Batch 18/5400 loss 6.164500 loss_att 11.672799 loss_ctc 9.783570 loss_rnnt 4.516564 hw_loss 0.119500 lr 0.00040095 rank 4
2023-02-22 10:54:47,793 DEBUG TRAIN Batch 18/5400 loss 21.197041 loss_att 21.807505 loss_ctc 26.569973 loss_rnnt 20.271196 hw_loss 0.163799 lr 0.00040090 rank 3
2023-02-22 10:54:47,794 DEBUG TRAIN Batch 18/5400 loss 13.687926 loss_att 14.522671 loss_ctc 16.465666 loss_rnnt 12.999752 hw_loss 0.282861 lr 0.00040089 rank 7
2023-02-22 10:54:47,794 DEBUG TRAIN Batch 18/5400 loss 14.027834 loss_att 15.898513 loss_ctc 17.687363 loss_rnnt 13.076015 hw_loss 0.168273 lr 0.00040087 rank 6
2023-02-22 10:54:47,801 DEBUG TRAIN Batch 18/5400 loss 9.103962 loss_att 10.811170 loss_ctc 13.841675 loss_rnnt 7.987382 hw_loss 0.268956 lr 0.00040093 rank 5
2023-02-22 10:54:47,844 DEBUG TRAIN Batch 18/5400 loss 16.422031 loss_att 22.567244 loss_ctc 20.494091 loss_rnnt 14.520161 hw_loss 0.243539 lr 0.00040099 rank 0
2023-02-22 10:56:00,568 DEBUG TRAIN Batch 18/5500 loss 4.281429 loss_att 6.829972 loss_ctc 7.432083 loss_rnnt 3.231367 hw_loss 0.225498 lr 0.00040078 rank 3
2023-02-22 10:56:00,581 DEBUG TRAIN Batch 18/5500 loss 5.840696 loss_att 9.557997 loss_ctc 9.736832 loss_rnnt 4.402443 hw_loss 0.328703 lr 0.00040078 rank 2
2023-02-22 10:56:00,581 DEBUG TRAIN Batch 18/5500 loss 10.442803 loss_att 12.245588 loss_ctc 15.581909 loss_rnnt 9.216923 hw_loss 0.337704 lr 0.00040080 rank 5
2023-02-22 10:56:00,581 DEBUG TRAIN Batch 18/5500 loss 12.234450 loss_att 15.117838 loss_ctc 14.611721 loss_rnnt 11.168052 hw_loss 0.323907 lr 0.00040082 rank 4
2023-02-22 10:56:00,585 DEBUG TRAIN Batch 18/5500 loss 4.277344 loss_att 6.263093 loss_ctc 7.257833 loss_rnnt 3.333217 hw_loss 0.280458 lr 0.00040074 rank 6
2023-02-22 10:56:00,587 DEBUG TRAIN Batch 18/5500 loss 9.779819 loss_att 12.931016 loss_ctc 13.475811 loss_rnnt 8.552549 hw_loss 0.195431 lr 0.00040086 rank 0
2023-02-22 10:56:00,591 DEBUG TRAIN Batch 18/5500 loss 10.671229 loss_att 13.181757 loss_ctc 15.442391 loss_rnnt 9.366019 hw_loss 0.313033 lr 0.00040079 rank 1
2023-02-22 10:56:00,639 DEBUG TRAIN Batch 18/5500 loss 8.585199 loss_att 12.046255 loss_ctc 11.253101 loss_rnnt 7.345644 hw_loss 0.359298 lr 0.00040076 rank 7
2023-02-22 10:57:13,171 DEBUG TRAIN Batch 18/5600 loss 5.078491 loss_att 6.499426 loss_ctc 6.706494 loss_rnnt 4.475238 hw_loss 0.191246 lr 0.00040065 rank 3
2023-02-22 10:57:13,172 DEBUG TRAIN Batch 18/5600 loss 4.536288 loss_att 8.256002 loss_ctc 5.900720 loss_rnnt 3.434211 hw_loss 0.330393 lr 0.00040065 rank 2
2023-02-22 10:57:13,173 DEBUG TRAIN Batch 18/5600 loss 21.265196 loss_att 25.168753 loss_ctc 28.860258 loss_rnnt 19.304909 hw_loss 0.312939 lr 0.00040066 rank 1
2023-02-22 10:57:13,174 DEBUG TRAIN Batch 18/5600 loss 17.001423 loss_att 16.526314 loss_ctc 20.746073 loss_rnnt 16.385395 hw_loss 0.397056 lr 0.00040063 rank 7
2023-02-22 10:57:13,175 DEBUG TRAIN Batch 18/5600 loss 9.527406 loss_att 11.639103 loss_ctc 11.762729 loss_rnnt 8.677908 hw_loss 0.242090 lr 0.00040062 rank 6
2023-02-22 10:57:13,178 DEBUG TRAIN Batch 18/5600 loss 12.924005 loss_att 13.602606 loss_ctc 20.062983 loss_rnnt 11.643801 hw_loss 0.361162 lr 0.00040073 rank 0
2023-02-22 10:57:13,193 DEBUG TRAIN Batch 18/5600 loss 12.114370 loss_att 14.068198 loss_ctc 17.580441 loss_rnnt 10.751677 hw_loss 0.455850 lr 0.00040067 rank 5
2023-02-22 10:57:13,199 DEBUG TRAIN Batch 18/5600 loss 11.590503 loss_att 13.373034 loss_ctc 16.054543 loss_rnnt 10.487579 hw_loss 0.283520 lr 0.00040069 rank 4
2023-02-22 10:58:29,590 DEBUG TRAIN Batch 18/5700 loss 9.248532 loss_att 9.361638 loss_ctc 12.449025 loss_rnnt 8.585787 hw_loss 0.400109 lr 0.00040049 rank 6
2023-02-22 10:58:29,600 DEBUG TRAIN Batch 18/5700 loss 5.568638 loss_att 6.685067 loss_ctc 6.419396 loss_rnnt 4.973807 hw_loss 0.483957 lr 0.00040052 rank 3
2023-02-22 10:58:29,600 DEBUG TRAIN Batch 18/5700 loss 18.587261 loss_att 21.130493 loss_ctc 27.697302 loss_rnnt 16.726347 hw_loss 0.257995 lr 0.00040052 rank 2
2023-02-22 10:58:29,602 DEBUG TRAIN Batch 18/5700 loss 6.696077 loss_att 10.357394 loss_ctc 9.849360 loss_rnnt 5.423189 hw_loss 0.225350 lr 0.00040050 rank 7
2023-02-22 10:58:29,607 DEBUG TRAIN Batch 18/5700 loss 6.239282 loss_att 9.635433 loss_ctc 8.495129 loss_rnnt 5.066133 hw_loss 0.362136 lr 0.00040054 rank 5
2023-02-22 10:58:29,607 DEBUG TRAIN Batch 18/5700 loss 7.599034 loss_att 10.457716 loss_ctc 11.106868 loss_rnnt 6.428311 hw_loss 0.246141 lr 0.00040053 rank 1
2023-02-22 10:58:29,607 DEBUG TRAIN Batch 18/5700 loss 9.643955 loss_att 14.688877 loss_ctc 14.987617 loss_rnnt 7.783577 hw_loss 0.260449 lr 0.00040060 rank 0
2023-02-22 10:58:29,612 DEBUG TRAIN Batch 18/5700 loss 6.591507 loss_att 8.881468 loss_ctc 11.714327 loss_rnnt 5.277273 hw_loss 0.324748 lr 0.00040056 rank 4
2023-02-22 10:59:42,940 DEBUG TRAIN Batch 18/5800 loss 8.873854 loss_att 10.962959 loss_ctc 8.851273 loss_rnnt 8.333827 hw_loss 0.234780 lr 0.00040036 rank 6
2023-02-22 10:59:42,940 DEBUG TRAIN Batch 18/5800 loss 7.304845 loss_att 9.909507 loss_ctc 12.120457 loss_rnnt 6.036283 hw_loss 0.197903 lr 0.00040039 rank 2
2023-02-22 10:59:42,945 DEBUG TRAIN Batch 18/5800 loss 7.135051 loss_att 9.830585 loss_ctc 10.471474 loss_rnnt 6.033348 hw_loss 0.220763 lr 0.00040041 rank 1
2023-02-22 10:59:42,945 DEBUG TRAIN Batch 18/5800 loss 8.860053 loss_att 14.547609 loss_ctc 11.047206 loss_rnnt 7.287704 hw_loss 0.268534 lr 0.00040043 rank 4
2023-02-22 10:59:42,949 DEBUG TRAIN Batch 18/5800 loss 5.970600 loss_att 8.907929 loss_ctc 6.141909 loss_rnnt 5.212368 hw_loss 0.277360 lr 0.00040039 rank 3
2023-02-22 10:59:42,949 DEBUG TRAIN Batch 18/5800 loss 7.566640 loss_att 8.877333 loss_ctc 8.585582 loss_rnnt 7.042795 hw_loss 0.235967 lr 0.00040037 rank 7
2023-02-22 10:59:42,951 DEBUG TRAIN Batch 18/5800 loss 18.470816 loss_att 21.551119 loss_ctc 24.424801 loss_rnnt 16.812664 hw_loss 0.465428 lr 0.00040047 rank 0
2023-02-22 10:59:42,965 DEBUG TRAIN Batch 18/5800 loss 6.157746 loss_att 9.977409 loss_ctc 9.591169 loss_rnnt 4.797304 hw_loss 0.260098 lr 0.00040041 rank 5
2023-02-22 11:00:54,241 DEBUG TRAIN Batch 18/5900 loss 11.236221 loss_att 17.271196 loss_ctc 15.127327 loss_rnnt 9.374849 hw_loss 0.254177 lr 0.00040026 rank 2
2023-02-22 11:00:54,242 DEBUG TRAIN Batch 18/5900 loss 10.125304 loss_att 16.263708 loss_ctc 12.103667 loss_rnnt 8.544333 hw_loss 0.167831 lr 0.00040023 rank 6
2023-02-22 11:00:54,246 DEBUG TRAIN Batch 18/5900 loss 8.337372 loss_att 14.935852 loss_ctc 13.016121 loss_rnnt 6.237417 hw_loss 0.293298 lr 0.00040024 rank 7
2023-02-22 11:00:54,247 DEBUG TRAIN Batch 18/5900 loss 5.782009 loss_att 7.369511 loss_ctc 6.831846 loss_rnnt 5.180419 hw_loss 0.270207 lr 0.00040026 rank 3
2023-02-22 11:00:54,247 DEBUG TRAIN Batch 18/5900 loss 6.491465 loss_att 11.581923 loss_ctc 10.174891 loss_rnnt 4.753922 hw_loss 0.428112 lr 0.00040030 rank 4
2023-02-22 11:00:54,253 DEBUG TRAIN Batch 18/5900 loss 7.281225 loss_att 8.796447 loss_ctc 9.896552 loss_rnnt 6.530410 hw_loss 0.185737 lr 0.00040028 rank 5
2023-02-22 11:00:54,284 DEBUG TRAIN Batch 18/5900 loss 9.589575 loss_att 13.568648 loss_ctc 13.185024 loss_rnnt 8.094718 hw_loss 0.411841 lr 0.00040034 rank 0
2023-02-22 11:00:54,324 DEBUG TRAIN Batch 18/5900 loss 10.615260 loss_att 15.692556 loss_ctc 13.878451 loss_rnnt 8.946342 hw_loss 0.409437 lr 0.00040028 rank 1
2023-02-22 11:02:08,975 DEBUG TRAIN Batch 18/6000 loss 12.290139 loss_att 16.163248 loss_ctc 16.109985 loss_rnnt 10.858597 hw_loss 0.276765 lr 0.00040022 rank 0
2023-02-22 11:02:08,977 DEBUG TRAIN Batch 18/6000 loss 12.032453 loss_att 14.202694 loss_ctc 12.530149 loss_rnnt 11.349223 hw_loss 0.342792 lr 0.00040013 rank 3
2023-02-22 11:02:08,978 DEBUG TRAIN Batch 18/6000 loss 9.191524 loss_att 13.678842 loss_ctc 14.122465 loss_rnnt 7.571547 hw_loss 0.121977 lr 0.00040010 rank 6
2023-02-22 11:02:08,978 DEBUG TRAIN Batch 18/6000 loss 8.402528 loss_att 9.987394 loss_ctc 11.850844 loss_rnnt 7.494276 hw_loss 0.246568 lr 0.00040013 rank 2
2023-02-22 11:02:08,984 DEBUG TRAIN Batch 18/6000 loss 10.761776 loss_att 11.657472 loss_ctc 14.786226 loss_rnnt 9.785469 hw_loss 0.488578 lr 0.00040016 rank 5
2023-02-22 11:02:08,992 DEBUG TRAIN Batch 18/6000 loss 13.880527 loss_att 18.540878 loss_ctc 20.615831 loss_rnnt 11.985321 hw_loss 0.122052 lr 0.00040012 rank 7
2023-02-22 11:02:09,006 DEBUG TRAIN Batch 18/6000 loss 18.466906 loss_att 20.256355 loss_ctc 20.619724 loss_rnnt 17.694038 hw_loss 0.239876 lr 0.00040018 rank 4
2023-02-22 11:02:09,040 DEBUG TRAIN Batch 18/6000 loss 7.291311 loss_att 8.924526 loss_ctc 7.608915 loss_rnnt 6.753824 hw_loss 0.315930 lr 0.00040015 rank 1
2023-02-22 11:03:22,632 DEBUG TRAIN Batch 18/6100 loss 8.176626 loss_att 11.852707 loss_ctc 9.137582 loss_rnnt 7.107574 hw_loss 0.385701 lr 0.00040001 rank 2
2023-02-22 11:03:22,632 DEBUG TRAIN Batch 18/6100 loss 11.260010 loss_att 15.423424 loss_ctc 21.483681 loss_rnnt 8.911191 hw_loss 0.286838 lr 0.00039997 rank 6
2023-02-22 11:03:22,640 DEBUG TRAIN Batch 18/6100 loss 7.765578 loss_att 12.926819 loss_ctc 10.921932 loss_rnnt 6.147685 hw_loss 0.308996 lr 0.00040002 rank 1
2023-02-22 11:03:22,641 DEBUG TRAIN Batch 18/6100 loss 17.538780 loss_att 18.633558 loss_ctc 24.703373 loss_rnnt 16.172016 hw_loss 0.360992 lr 0.00039999 rank 7
2023-02-22 11:03:22,641 DEBUG TRAIN Batch 18/6100 loss 5.234691 loss_att 9.348886 loss_ctc 10.692684 loss_rnnt 3.478297 hw_loss 0.385918 lr 0.00040009 rank 0
2023-02-22 11:03:22,642 DEBUG TRAIN Batch 18/6100 loss 13.144306 loss_att 15.148300 loss_ctc 19.112606 loss_rnnt 11.830982 hw_loss 0.218910 lr 0.00040001 rank 3
2023-02-22 11:03:22,643 DEBUG TRAIN Batch 18/6100 loss 5.992361 loss_att 8.601721 loss_ctc 7.060936 loss_rnnt 5.181056 hw_loss 0.275541 lr 0.00040003 rank 5
2023-02-22 11:03:22,686 DEBUG TRAIN Batch 18/6100 loss 16.309366 loss_att 15.470478 loss_ctc 18.028946 loss_rnnt 16.102045 hw_loss 0.273413 lr 0.00040005 rank 4
2023-02-22 11:04:35,255 DEBUG TRAIN Batch 18/6200 loss 8.237510 loss_att 9.405781 loss_ctc 10.889180 loss_rnnt 7.441380 hw_loss 0.391724 lr 0.00039988 rank 2
2023-02-22 11:04:35,258 DEBUG TRAIN Batch 18/6200 loss 7.110307 loss_att 9.617445 loss_ctc 8.370880 loss_rnnt 6.284071 hw_loss 0.293871 lr 0.00039986 rank 7
2023-02-22 11:04:35,259 DEBUG TRAIN Batch 18/6200 loss 11.743002 loss_att 13.584869 loss_ctc 17.646614 loss_rnnt 10.452826 hw_loss 0.252478 lr 0.00039988 rank 3
2023-02-22 11:04:35,261 DEBUG TRAIN Batch 18/6200 loss 6.537166 loss_att 8.948322 loss_ctc 10.964311 loss_rnnt 5.363209 hw_loss 0.190199 lr 0.00039992 rank 4
2023-02-22 11:04:35,263 DEBUG TRAIN Batch 18/6200 loss 11.027815 loss_att 13.206023 loss_ctc 15.366203 loss_rnnt 9.918024 hw_loss 0.179431 lr 0.00039985 rank 6
2023-02-22 11:04:35,267 DEBUG TRAIN Batch 18/6200 loss 12.902795 loss_att 14.751568 loss_ctc 20.617744 loss_rnnt 11.351398 hw_loss 0.286845 lr 0.00039989 rank 1
2023-02-22 11:04:35,267 DEBUG TRAIN Batch 18/6200 loss 7.001782 loss_att 9.220927 loss_ctc 9.243650 loss_rnnt 6.185949 hw_loss 0.137041 lr 0.00039990 rank 5
2023-02-22 11:04:35,268 DEBUG TRAIN Batch 18/6200 loss 12.367809 loss_att 12.669769 loss_ctc 18.829229 loss_rnnt 11.302049 hw_loss 0.269708 lr 0.00039996 rank 0
2023-02-22 11:05:48,066 DEBUG TRAIN Batch 18/6300 loss 6.385264 loss_att 8.260887 loss_ctc 10.226089 loss_rnnt 5.220369 hw_loss 0.520616 lr 0.00039975 rank 3
2023-02-22 11:05:48,069 DEBUG TRAIN Batch 18/6300 loss 6.219069 loss_att 7.196275 loss_ctc 9.651196 loss_rnnt 5.393691 hw_loss 0.323101 lr 0.00039972 rank 6
2023-02-22 11:05:48,073 DEBUG TRAIN Batch 18/6300 loss 13.510554 loss_att 17.017519 loss_ctc 24.215582 loss_rnnt 11.153465 hw_loss 0.428174 lr 0.00039973 rank 7
2023-02-22 11:05:48,074 DEBUG TRAIN Batch 18/6300 loss 13.742636 loss_att 17.035072 loss_ctc 20.524473 loss_rnnt 12.036758 hw_loss 0.268398 lr 0.00039975 rank 2
2023-02-22 11:05:48,074 DEBUG TRAIN Batch 18/6300 loss 15.599266 loss_att 14.411777 loss_ctc 20.213802 loss_rnnt 14.971227 hw_loss 0.469247 lr 0.00039983 rank 0
2023-02-22 11:05:48,074 DEBUG TRAIN Batch 18/6300 loss 9.468972 loss_att 12.403842 loss_ctc 14.181262 loss_rnnt 8.136336 hw_loss 0.220044 lr 0.00039979 rank 4
2023-02-22 11:05:48,073 DEBUG TRAIN Batch 18/6300 loss 9.593225 loss_att 12.767324 loss_ctc 13.785898 loss_rnnt 8.275297 hw_loss 0.232659 lr 0.00039976 rank 1
2023-02-22 11:05:48,074 DEBUG TRAIN Batch 18/6300 loss 10.574671 loss_att 14.713150 loss_ctc 17.344561 loss_rnnt 8.640505 hw_loss 0.382161 lr 0.00039977 rank 5
2023-02-22 11:07:03,049 DEBUG TRAIN Batch 18/6400 loss 8.806272 loss_att 8.422825 loss_ctc 11.697549 loss_rnnt 8.220027 hw_loss 0.520182 lr 0.00039962 rank 2
2023-02-22 11:07:03,055 DEBUG TRAIN Batch 18/6400 loss 19.425785 loss_att 24.004696 loss_ctc 23.471004 loss_rnnt 17.818882 hw_loss 0.284546 lr 0.00039959 rank 6
2023-02-22 11:07:03,055 DEBUG TRAIN Batch 18/6400 loss 9.349429 loss_att 15.824553 loss_ctc 15.157977 loss_rnnt 7.204390 hw_loss 0.141643 lr 0.00039960 rank 7
2023-02-22 11:07:03,059 DEBUG TRAIN Batch 18/6400 loss 11.783473 loss_att 11.784871 loss_ctc 15.350453 loss_rnnt 11.064217 hw_loss 0.456336 lr 0.00039966 rank 4
2023-02-22 11:07:03,061 DEBUG TRAIN Batch 18/6400 loss 14.972591 loss_att 18.727163 loss_ctc 19.687298 loss_rnnt 13.511267 hw_loss 0.153343 lr 0.00039964 rank 5
2023-02-22 11:07:03,062 DEBUG TRAIN Batch 18/6400 loss 5.953331 loss_att 10.228093 loss_ctc 5.991937 loss_rnnt 4.915751 hw_loss 0.332778 lr 0.00039962 rank 3
2023-02-22 11:07:03,062 DEBUG TRAIN Batch 18/6400 loss 12.800154 loss_att 13.630726 loss_ctc 14.573767 loss_rnnt 12.271647 hw_loss 0.236081 lr 0.00039970 rank 0
2023-02-22 11:07:03,065 DEBUG TRAIN Batch 18/6400 loss 11.047987 loss_att 11.099232 loss_ctc 14.595827 loss_rnnt 10.157205 hw_loss 0.764041 lr 0.00039964 rank 1
2023-02-22 11:08:15,132 DEBUG TRAIN Batch 18/6500 loss 4.404645 loss_att 8.178059 loss_ctc 7.722444 loss_rnnt 3.107421 hw_loss 0.187814 lr 0.00039950 rank 2
2023-02-22 11:08:15,138 DEBUG TRAIN Batch 18/6500 loss 5.577341 loss_att 7.065681 loss_ctc 7.328378 loss_rnnt 4.908320 hw_loss 0.258525 lr 0.00039949 rank 3
2023-02-22 11:08:15,140 DEBUG TRAIN Batch 18/6500 loss 9.540429 loss_att 11.382546 loss_ctc 13.509311 loss_rnnt 8.548537 hw_loss 0.176784 lr 0.00039958 rank 0
2023-02-22 11:08:15,140 DEBUG TRAIN Batch 18/6500 loss 11.360806 loss_att 14.955754 loss_ctc 16.550592 loss_rnnt 9.773037 hw_loss 0.331514 lr 0.00039946 rank 6
2023-02-22 11:08:15,141 DEBUG TRAIN Batch 18/6500 loss 5.279292 loss_att 7.266419 loss_ctc 7.260639 loss_rnnt 4.550548 hw_loss 0.125885 lr 0.00039951 rank 1
2023-02-22 11:08:15,142 DEBUG TRAIN Batch 18/6500 loss 4.242363 loss_att 6.910661 loss_ctc 8.539515 loss_rnnt 3.053443 hw_loss 0.154326 lr 0.00039948 rank 7
2023-02-22 11:08:15,144 DEBUG TRAIN Batch 18/6500 loss 19.389099 loss_att 24.950455 loss_ctc 30.076893 loss_rnnt 16.712303 hw_loss 0.261537 lr 0.00039952 rank 5
2023-02-22 11:08:15,146 DEBUG TRAIN Batch 18/6500 loss 35.653877 loss_att 40.044666 loss_ctc 48.309570 loss_rnnt 33.013863 hw_loss 0.139564 lr 0.00039954 rank 4
2023-02-22 11:09:27,860 DEBUG TRAIN Batch 18/6600 loss 7.864511 loss_att 8.881378 loss_ctc 8.567033 loss_rnnt 7.389446 hw_loss 0.333791 lr 0.00039935 rank 7
2023-02-22 11:09:27,867 DEBUG TRAIN Batch 18/6600 loss 12.238153 loss_att 14.261599 loss_ctc 14.259318 loss_rnnt 11.451044 hw_loss 0.211742 lr 0.00039945 rank 0
2023-02-22 11:09:27,876 DEBUG TRAIN Batch 18/6600 loss 9.385930 loss_att 13.214883 loss_ctc 12.325106 loss_rnnt 8.040160 hw_loss 0.352668 lr 0.00039937 rank 3
2023-02-22 11:09:27,878 DEBUG TRAIN Batch 18/6600 loss 13.711864 loss_att 17.824184 loss_ctc 22.711226 loss_rnnt 11.488986 hw_loss 0.375933 lr 0.00039937 rank 2
2023-02-22 11:09:27,882 DEBUG TRAIN Batch 18/6600 loss 12.404224 loss_att 17.718090 loss_ctc 22.533453 loss_rnnt 9.855206 hw_loss 0.254400 lr 0.00039941 rank 4
2023-02-22 11:09:27,883 DEBUG TRAIN Batch 18/6600 loss 11.795918 loss_att 15.712158 loss_ctc 10.929619 loss_rnnt 10.918677 hw_loss 0.392808 lr 0.00039934 rank 6
2023-02-22 11:09:27,885 DEBUG TRAIN Batch 18/6600 loss 9.695417 loss_att 11.930050 loss_ctc 13.755789 loss_rnnt 8.640806 hw_loss 0.124315 lr 0.00039939 rank 5
2023-02-22 11:09:27,935 DEBUG TRAIN Batch 18/6600 loss 7.881033 loss_att 13.968212 loss_ctc 13.994652 loss_rnnt 5.800258 hw_loss 0.090357 lr 0.00039938 rank 1
2023-02-22 11:10:42,028 DEBUG TRAIN Batch 18/6700 loss 18.883562 loss_att 23.127609 loss_ctc 25.723911 loss_rnnt 16.854095 hw_loss 0.503644 lr 0.00039922 rank 7
2023-02-22 11:10:42,037 DEBUG TRAIN Batch 18/6700 loss 12.328924 loss_att 15.908556 loss_ctc 18.916845 loss_rnnt 10.583382 hw_loss 0.283551 lr 0.00039924 rank 3
2023-02-22 11:10:42,038 DEBUG TRAIN Batch 18/6700 loss 14.002153 loss_att 19.321236 loss_ctc 21.529524 loss_rnnt 11.839026 hw_loss 0.179365 lr 0.00039932 rank 0
2023-02-22 11:10:42,039 DEBUG TRAIN Batch 18/6700 loss 9.771356 loss_att 12.232151 loss_ctc 12.863306 loss_rnnt 8.718255 hw_loss 0.278775 lr 0.00039925 rank 1
2023-02-22 11:10:42,042 DEBUG TRAIN Batch 18/6700 loss 7.364180 loss_att 10.704960 loss_ctc 7.616371 loss_rnnt 6.473757 hw_loss 0.353703 lr 0.00039924 rank 2
2023-02-22 11:10:42,042 DEBUG TRAIN Batch 18/6700 loss 7.955437 loss_att 9.000507 loss_ctc 9.623392 loss_rnnt 7.378360 hw_loss 0.273130 lr 0.00039928 rank 4
2023-02-22 11:10:42,043 DEBUG TRAIN Batch 18/6700 loss 5.191988 loss_att 7.941471 loss_ctc 8.210711 loss_rnnt 4.015957 hw_loss 0.419320 lr 0.00039921 rank 6
2023-02-22 11:10:42,062 DEBUG TRAIN Batch 18/6700 loss 8.370975 loss_att 13.583321 loss_ctc 8.943830 loss_rnnt 7.165594 hw_loss 0.162244 lr 0.00039926 rank 5
2023-02-22 11:11:56,667 DEBUG TRAIN Batch 18/6800 loss 7.382946 loss_att 10.598654 loss_ctc 11.638790 loss_rnnt 6.065652 hw_loss 0.200073 lr 0.00039911 rank 2
2023-02-22 11:11:56,673 DEBUG TRAIN Batch 18/6800 loss 4.828699 loss_att 7.418102 loss_ctc 5.564940 loss_rnnt 4.106330 hw_loss 0.199356 lr 0.00039913 rank 1
2023-02-22 11:11:56,675 DEBUG TRAIN Batch 18/6800 loss 15.438293 loss_att 17.741310 loss_ctc 18.206280 loss_rnnt 14.497776 hw_loss 0.207838 lr 0.00039911 rank 3
2023-02-22 11:11:56,678 DEBUG TRAIN Batch 18/6800 loss 19.130047 loss_att 20.845989 loss_ctc 25.097775 loss_rnnt 17.895500 hw_loss 0.179366 lr 0.00039913 rank 5
2023-02-22 11:11:56,678 DEBUG TRAIN Batch 18/6800 loss 13.776117 loss_att 15.920176 loss_ctc 13.452362 loss_rnnt 13.197622 hw_loss 0.361598 lr 0.00039919 rank 0
2023-02-22 11:11:56,679 DEBUG TRAIN Batch 18/6800 loss 18.406761 loss_att 20.291012 loss_ctc 22.158524 loss_rnnt 17.395531 hw_loss 0.251521 lr 0.00039908 rank 6
2023-02-22 11:11:56,679 DEBUG TRAIN Batch 18/6800 loss 6.512539 loss_att 9.413308 loss_ctc 10.213838 loss_rnnt 5.234217 hw_loss 0.383740 lr 0.00039909 rank 7
2023-02-22 11:11:56,726 DEBUG TRAIN Batch 18/6800 loss 6.751719 loss_att 9.513889 loss_ctc 11.433825 loss_rnnt 5.457903 hw_loss 0.219563 lr 0.00039915 rank 4
2023-02-22 11:13:09,809 DEBUG TRAIN Batch 18/6900 loss 9.889832 loss_att 12.543673 loss_ctc 13.509185 loss_rnnt 8.696083 hw_loss 0.338251 lr 0.00039898 rank 3
2023-02-22 11:13:09,810 DEBUG TRAIN Batch 18/6900 loss 6.901975 loss_att 8.924882 loss_ctc 11.973940 loss_rnnt 5.741282 hw_loss 0.149718 lr 0.00039899 rank 2
2023-02-22 11:13:09,814 DEBUG TRAIN Batch 18/6900 loss 20.756016 loss_att 24.127562 loss_ctc 29.378286 loss_rnnt 18.826515 hw_loss 0.197914 lr 0.00039901 rank 5
2023-02-22 11:13:09,814 DEBUG TRAIN Batch 18/6900 loss 15.299117 loss_att 17.945351 loss_ctc 20.297632 loss_rnnt 13.999205 hw_loss 0.195369 lr 0.00039897 rank 7
2023-02-22 11:13:09,814 DEBUG TRAIN Batch 18/6900 loss 12.810441 loss_att 14.697293 loss_ctc 12.136162 loss_rnnt 12.387781 hw_loss 0.253484 lr 0.00039895 rank 6
2023-02-22 11:13:09,815 DEBUG TRAIN Batch 18/6900 loss 4.556940 loss_att 5.208356 loss_ctc 6.007156 loss_rnnt 4.114888 hw_loss 0.222014 lr 0.00039900 rank 1
2023-02-22 11:13:09,816 DEBUG TRAIN Batch 18/6900 loss 15.608310 loss_att 19.632898 loss_ctc 17.317347 loss_rnnt 14.443825 hw_loss 0.246929 lr 0.00039903 rank 4
2023-02-22 11:13:09,821 DEBUG TRAIN Batch 18/6900 loss 11.167624 loss_att 11.216526 loss_ctc 15.456940 loss_rnnt 10.428544 hw_loss 0.295108 lr 0.00039907 rank 0
2023-02-22 11:14:23,257 DEBUG TRAIN Batch 18/7000 loss 8.068167 loss_att 9.519055 loss_ctc 11.621901 loss_rnnt 7.135174 hw_loss 0.316844 lr 0.00039886 rank 2
2023-02-22 11:14:23,259 DEBUG TRAIN Batch 18/7000 loss 7.747772 loss_att 10.421709 loss_ctc 10.160301 loss_rnnt 6.780445 hw_loss 0.207880 lr 0.00039888 rank 5
2023-02-22 11:14:23,261 DEBUG TRAIN Batch 18/7000 loss 6.184824 loss_att 15.035015 loss_ctc 10.885885 loss_rnnt 3.609254 hw_loss 0.335105 lr 0.00039886 rank 3
2023-02-22 11:14:23,261 DEBUG TRAIN Batch 18/7000 loss 9.737423 loss_att 12.449599 loss_ctc 12.573489 loss_rnnt 8.686030 hw_loss 0.245279 lr 0.00039890 rank 4
2023-02-22 11:14:23,261 DEBUG TRAIN Batch 18/7000 loss 4.241296 loss_att 6.910173 loss_ctc 7.051450 loss_rnnt 3.140059 hw_loss 0.361451 lr 0.00039884 rank 7
2023-02-22 11:14:23,263 DEBUG TRAIN Batch 18/7000 loss 7.783115 loss_att 12.114656 loss_ctc 13.852680 loss_rnnt 5.941873 hw_loss 0.310610 lr 0.00039883 rank 6
2023-02-22 11:14:23,267 DEBUG TRAIN Batch 18/7000 loss 7.583830 loss_att 9.598459 loss_ctc 13.432350 loss_rnnt 6.222982 hw_loss 0.333974 lr 0.00039894 rank 0
2023-02-22 11:14:23,316 DEBUG TRAIN Batch 18/7000 loss 10.121426 loss_att 10.404697 loss_ctc 14.097049 loss_rnnt 9.369399 hw_loss 0.309915 lr 0.00039887 rank 1
2023-02-22 11:15:39,006 DEBUG TRAIN Batch 18/7100 loss 5.284109 loss_att 8.667273 loss_ctc 5.386640 loss_rnnt 4.487654 hw_loss 0.199034 lr 0.00039873 rank 2
2023-02-22 11:15:39,009 DEBUG TRAIN Batch 18/7100 loss 15.507168 loss_att 17.214724 loss_ctc 18.996571 loss_rnnt 14.484921 hw_loss 0.404029 lr 0.00039881 rank 0
2023-02-22 11:15:39,020 DEBUG TRAIN Batch 18/7100 loss 23.604582 loss_att 23.720161 loss_ctc 28.580801 loss_rnnt 22.834694 hw_loss 0.156142 lr 0.00039877 rank 4
2023-02-22 11:15:39,021 DEBUG TRAIN Batch 18/7100 loss 9.533744 loss_att 11.659545 loss_ctc 14.869884 loss_rnnt 8.272999 hw_loss 0.232688 lr 0.00039873 rank 3
2023-02-22 11:15:39,021 DEBUG TRAIN Batch 18/7100 loss 7.407400 loss_att 12.471025 loss_ctc 10.565028 loss_rnnt 5.789812 hw_loss 0.344712 lr 0.00039870 rank 6
2023-02-22 11:15:39,022 DEBUG TRAIN Batch 18/7100 loss 4.710980 loss_att 7.151271 loss_ctc 8.254738 loss_rnnt 3.709995 hw_loss 0.075799 lr 0.00039871 rank 7
2023-02-22 11:15:39,056 DEBUG TRAIN Batch 18/7100 loss 8.834186 loss_att 12.526354 loss_ctc 13.130439 loss_rnnt 7.413815 hw_loss 0.204569 lr 0.00039875 rank 1
2023-02-22 11:15:39,099 DEBUG TRAIN Batch 18/7100 loss 8.417568 loss_att 11.876832 loss_ctc 15.204937 loss_rnnt 6.751286 hw_loss 0.130215 lr 0.00039875 rank 5
2023-02-22 11:16:52,350 DEBUG TRAIN Batch 18/7200 loss 3.019753 loss_att 6.030623 loss_ctc 3.051954 loss_rnnt 2.266660 hw_loss 0.274922 lr 0.00039865 rank 4
2023-02-22 11:16:52,369 DEBUG TRAIN Batch 18/7200 loss 7.643631 loss_att 9.413513 loss_ctc 11.186529 loss_rnnt 6.634763 hw_loss 0.342197 lr 0.00039860 rank 3
2023-02-22 11:16:52,370 DEBUG TRAIN Batch 18/7200 loss 5.259344 loss_att 9.222898 loss_ctc 8.952421 loss_rnnt 3.897704 hw_loss 0.143473 lr 0.00039859 rank 7
2023-02-22 11:16:52,371 DEBUG TRAIN Batch 18/7200 loss 11.873201 loss_att 13.946184 loss_ctc 16.566818 loss_rnnt 10.684677 hw_loss 0.277710 lr 0.00039869 rank 0
2023-02-22 11:16:52,374 DEBUG TRAIN Batch 18/7200 loss 3.319590 loss_att 6.345469 loss_ctc 6.032465 loss_rnnt 2.248430 hw_loss 0.195502 lr 0.00039862 rank 1
2023-02-22 11:16:52,374 DEBUG TRAIN Batch 18/7200 loss 9.773538 loss_att 14.456141 loss_ctc 15.893070 loss_rnnt 7.785744 hw_loss 0.441252 lr 0.00039857 rank 6
2023-02-22 11:16:52,376 DEBUG TRAIN Batch 18/7200 loss 6.310596 loss_att 9.758165 loss_ctc 5.087955 loss_rnnt 5.608112 hw_loss 0.329979 lr 0.00039861 rank 2
2023-02-22 11:16:52,378 DEBUG TRAIN Batch 18/7200 loss 9.263480 loss_att 12.040819 loss_ctc 14.948166 loss_rnnt 7.785490 hw_loss 0.308557 lr 0.00039863 rank 5
2023-02-22 11:18:04,157 DEBUG TRAIN Batch 18/7300 loss 7.568595 loss_att 8.923652 loss_ctc 7.975876 loss_rnnt 7.110329 hw_loss 0.249282 lr 0.00039845 rank 6
2023-02-22 11:18:04,159 DEBUG TRAIN Batch 18/7300 loss 17.152948 loss_att 16.604246 loss_ctc 20.839939 loss_rnnt 16.611721 hw_loss 0.298814 lr 0.00039848 rank 3
2023-02-22 11:18:04,163 DEBUG TRAIN Batch 18/7300 loss 3.783296 loss_att 7.919014 loss_ctc 4.493610 loss_rnnt 2.653535 hw_loss 0.389828 lr 0.00039852 rank 4
2023-02-22 11:18:04,163 DEBUG TRAIN Batch 18/7300 loss 6.033804 loss_att 8.164856 loss_ctc 8.600975 loss_rnnt 5.125806 hw_loss 0.261558 lr 0.00039849 rank 1
2023-02-22 11:18:04,162 DEBUG TRAIN Batch 18/7300 loss 14.324763 loss_att 16.113026 loss_ctc 15.362159 loss_rnnt 13.703303 hw_loss 0.235289 lr 0.00039846 rank 7
2023-02-22 11:18:04,164 DEBUG TRAIN Batch 18/7300 loss 8.541230 loss_att 9.529125 loss_ctc 11.884991 loss_rnnt 7.765438 hw_loss 0.248211 lr 0.00039856 rank 0
2023-02-22 11:18:04,164 DEBUG TRAIN Batch 18/7300 loss 22.394539 loss_att 22.570637 loss_ctc 28.884434 loss_rnnt 21.400951 hw_loss 0.174471 lr 0.00039850 rank 5
2023-02-22 11:18:04,168 DEBUG TRAIN Batch 18/7300 loss 7.817575 loss_att 10.743162 loss_ctc 8.870281 loss_rnnt 6.972126 hw_loss 0.224947 lr 0.00039848 rank 2
2023-02-22 11:19:17,381 DEBUG TRAIN Batch 18/7400 loss 10.740938 loss_att 13.381108 loss_ctc 14.886210 loss_rnnt 9.492699 hw_loss 0.314068 lr 0.00039835 rank 2
2023-02-22 11:19:17,382 DEBUG TRAIN Batch 18/7400 loss 9.270963 loss_att 12.516588 loss_ctc 11.004110 loss_rnnt 8.268342 hw_loss 0.229517 lr 0.00039837 rank 1
2023-02-22 11:19:17,384 DEBUG TRAIN Batch 18/7400 loss 13.273904 loss_att 16.688572 loss_ctc 16.279171 loss_rnnt 12.048253 hw_loss 0.266279 lr 0.00039835 rank 3
2023-02-22 11:19:17,383 DEBUG TRAIN Batch 18/7400 loss 7.067120 loss_att 8.887206 loss_ctc 9.010130 loss_rnnt 6.319058 hw_loss 0.234330 lr 0.00039832 rank 6
2023-02-22 11:19:17,384 DEBUG TRAIN Batch 18/7400 loss 9.084981 loss_att 11.216901 loss_ctc 14.514123 loss_rnnt 7.818932 hw_loss 0.217088 lr 0.00039843 rank 0
2023-02-22 11:19:17,385 DEBUG TRAIN Batch 18/7400 loss 14.217681 loss_att 18.620213 loss_ctc 20.801872 loss_rnnt 12.331204 hw_loss 0.240146 lr 0.00039837 rank 5
2023-02-22 11:19:17,403 DEBUG TRAIN Batch 18/7400 loss 19.414551 loss_att 19.631012 loss_ctc 26.134048 loss_rnnt 18.324238 hw_loss 0.283289 lr 0.00039833 rank 7
2023-02-22 11:19:17,424 DEBUG TRAIN Batch 18/7400 loss 13.530520 loss_att 16.716450 loss_ctc 17.099512 loss_rnnt 12.272013 hw_loss 0.272729 lr 0.00039839 rank 4
2023-02-22 11:20:31,894 DEBUG TRAIN Batch 18/7500 loss 10.812521 loss_att 12.509920 loss_ctc 14.021400 loss_rnnt 9.852024 hw_loss 0.362189 lr 0.00039819 rank 6
2023-02-22 11:20:31,894 DEBUG TRAIN Batch 18/7500 loss 8.743654 loss_att 9.597735 loss_ctc 14.066698 loss_rnnt 7.759435 hw_loss 0.194371 lr 0.00039823 rank 3
2023-02-22 11:20:31,894 DEBUG TRAIN Batch 18/7500 loss 17.337328 loss_att 18.127424 loss_ctc 27.247158 loss_rnnt 15.657982 hw_loss 0.375029 lr 0.00039823 rank 2
2023-02-22 11:20:31,901 DEBUG TRAIN Batch 18/7500 loss 10.639750 loss_att 13.339211 loss_ctc 13.228251 loss_rnnt 9.640434 hw_loss 0.214291 lr 0.00039825 rank 5
2023-02-22 11:20:31,901 DEBUG TRAIN Batch 18/7500 loss 5.736820 loss_att 6.392219 loss_ctc 5.816767 loss_rnnt 5.355184 hw_loss 0.449806 lr 0.00039821 rank 7
2023-02-22 11:20:31,902 DEBUG TRAIN Batch 18/7500 loss 5.839612 loss_att 8.026002 loss_ctc 9.243265 loss_rnnt 4.801749 hw_loss 0.275182 lr 0.00039824 rank 1
2023-02-22 11:20:31,903 DEBUG TRAIN Batch 18/7500 loss 6.340244 loss_att 8.450592 loss_ctc 9.780353 loss_rnnt 5.325926 hw_loss 0.250439 lr 0.00039831 rank 0
2023-02-22 11:20:31,948 DEBUG TRAIN Batch 18/7500 loss 4.378925 loss_att 8.163161 loss_ctc 6.751748 loss_rnnt 3.240434 hw_loss 0.122377 lr 0.00039827 rank 4
2023-02-22 11:21:44,228 DEBUG TRAIN Batch 18/7600 loss 11.797321 loss_att 12.109261 loss_ctc 16.597013 loss_rnnt 10.918452 hw_loss 0.330980 lr 0.00039810 rank 2
2023-02-22 11:21:44,228 DEBUG TRAIN Batch 18/7600 loss 7.751623 loss_att 10.607298 loss_ctc 11.917482 loss_rnnt 6.498813 hw_loss 0.236674 lr 0.00039812 rank 5
2023-02-22 11:21:44,228 DEBUG TRAIN Batch 18/7600 loss 7.554228 loss_att 8.683939 loss_ctc 9.653628 loss_rnnt 6.846644 hw_loss 0.378229 lr 0.00039807 rank 6
2023-02-22 11:21:44,230 DEBUG TRAIN Batch 18/7600 loss 11.972276 loss_att 11.703969 loss_ctc 16.223928 loss_rnnt 11.197865 hw_loss 0.489721 lr 0.00039810 rank 3
2023-02-22 11:21:44,230 DEBUG TRAIN Batch 18/7600 loss 16.866594 loss_att 21.150101 loss_ctc 26.511580 loss_rnnt 14.563049 hw_loss 0.301584 lr 0.00039811 rank 1
2023-02-22 11:21:44,231 DEBUG TRAIN Batch 18/7600 loss 10.264264 loss_att 13.364032 loss_ctc 12.501841 loss_rnnt 9.194833 hw_loss 0.283378 lr 0.00039814 rank 4
2023-02-22 11:21:44,232 DEBUG TRAIN Batch 18/7600 loss 4.486814 loss_att 7.353187 loss_ctc 7.643700 loss_rnnt 3.435469 hw_loss 0.107159 lr 0.00039818 rank 0
2023-02-22 11:21:44,234 DEBUG TRAIN Batch 18/7600 loss 7.801535 loss_att 10.545802 loss_ctc 10.471317 loss_rnnt 6.728250 hw_loss 0.315864 lr 0.00039808 rank 7
2023-02-22 11:22:56,587 DEBUG TRAIN Batch 18/7700 loss 12.033762 loss_att 13.743498 loss_ctc 14.323902 loss_rnnt 11.264719 hw_loss 0.228267 lr 0.00039799 rank 1
2023-02-22 11:22:56,590 DEBUG TRAIN Batch 18/7700 loss 6.640426 loss_att 10.685358 loss_ctc 8.351207 loss_rnnt 5.525491 hw_loss 0.145959 lr 0.00039805 rank 0
2023-02-22 11:22:56,593 DEBUG TRAIN Batch 18/7700 loss 12.492175 loss_att 13.775613 loss_ctc 15.312559 loss_rnnt 11.702380 hw_loss 0.294480 lr 0.00039797 rank 2
2023-02-22 11:22:56,594 DEBUG TRAIN Batch 18/7700 loss 5.281634 loss_att 8.455040 loss_ctc 6.276733 loss_rnnt 4.362746 hw_loss 0.284113 lr 0.00039794 rank 6
2023-02-22 11:22:56,594 DEBUG TRAIN Batch 18/7700 loss 2.323447 loss_att 4.126379 loss_ctc 1.190780 loss_rnnt 1.941947 hw_loss 0.322380 lr 0.00039795 rank 7
2023-02-22 11:22:56,595 DEBUG TRAIN Batch 18/7700 loss 7.170506 loss_att 6.965694 loss_ctc 7.661975 loss_rnnt 6.915332 hw_loss 0.432387 lr 0.00039801 rank 4
2023-02-22 11:22:56,595 DEBUG TRAIN Batch 18/7700 loss 7.415710 loss_att 10.545158 loss_ctc 7.746238 loss_rnnt 6.601035 hw_loss 0.271342 lr 0.00039800 rank 5
2023-02-22 11:22:56,595 DEBUG TRAIN Batch 18/7700 loss 8.490317 loss_att 10.754109 loss_ctc 11.649570 loss_rnnt 7.541904 hw_loss 0.139539 lr 0.00039797 rank 3
2023-02-22 11:24:11,738 DEBUG TRAIN Batch 18/7800 loss 12.532704 loss_att 17.849752 loss_ctc 18.316547 loss_rnnt 10.497694 hw_loss 0.375789 lr 0.00039785 rank 2
2023-02-22 11:24:11,740 DEBUG TRAIN Batch 18/7800 loss 10.784148 loss_att 10.248087 loss_ctc 15.453291 loss_rnnt 10.113117 hw_loss 0.291919 lr 0.00039785 rank 3
2023-02-22 11:24:11,742 DEBUG TRAIN Batch 18/7800 loss 8.718414 loss_att 10.856030 loss_ctc 12.431533 loss_rnnt 7.711820 hw_loss 0.157477 lr 0.00039786 rank 1
2023-02-22 11:24:11,742 DEBUG TRAIN Batch 18/7800 loss 12.147934 loss_att 11.502613 loss_ctc 21.701065 loss_rnnt 10.896197 hw_loss 0.200717 lr 0.00039787 rank 5
2023-02-22 11:24:11,744 DEBUG TRAIN Batch 18/7800 loss 7.883628 loss_att 11.905830 loss_ctc 8.210430 loss_rnnt 6.914027 hw_loss 0.227976 lr 0.00039783 rank 7
2023-02-22 11:24:11,745 DEBUG TRAIN Batch 18/7800 loss 20.004459 loss_att 21.417130 loss_ctc 25.635824 loss_rnnt 18.861973 hw_loss 0.204567 lr 0.00039782 rank 6
2023-02-22 11:24:11,745 DEBUG TRAIN Batch 18/7800 loss 13.399712 loss_att 17.282064 loss_ctc 21.775017 loss_rnnt 11.382895 hw_loss 0.231823 lr 0.00039793 rank 0
2023-02-22 11:24:11,748 DEBUG TRAIN Batch 18/7800 loss 4.814907 loss_att 9.672338 loss_ctc 8.290608 loss_rnnt 3.248823 hw_loss 0.245946 lr 0.00039789 rank 4
2023-02-22 11:25:24,843 DEBUG TRAIN Batch 18/7900 loss 6.505110 loss_att 10.531706 loss_ctc 10.120482 loss_rnnt 5.141389 hw_loss 0.143162 lr 0.00039772 rank 2
2023-02-22 11:25:24,843 DEBUG TRAIN Batch 18/7900 loss 8.399406 loss_att 9.105441 loss_ctc 9.988691 loss_rnnt 7.900545 hw_loss 0.273280 lr 0.00039770 rank 7
2023-02-22 11:25:24,847 DEBUG TRAIN Batch 18/7900 loss 10.506368 loss_att 12.979130 loss_ctc 13.428049 loss_rnnt 9.422065 hw_loss 0.375361 lr 0.00039772 rank 3
2023-02-22 11:25:24,850 DEBUG TRAIN Batch 18/7900 loss 18.570330 loss_att 21.805122 loss_ctc 22.940903 loss_rnnt 17.212978 hw_loss 0.239342 lr 0.00039774 rank 1
2023-02-22 11:25:24,851 DEBUG TRAIN Batch 18/7900 loss 16.315939 loss_att 18.770695 loss_ctc 21.753880 loss_rnnt 14.946213 hw_loss 0.288216 lr 0.00039774 rank 5
2023-02-22 11:25:24,850 DEBUG TRAIN Batch 18/7900 loss 8.307795 loss_att 11.140733 loss_ctc 11.591389 loss_rnnt 7.182433 hw_loss 0.226804 lr 0.00039769 rank 6
2023-02-22 11:25:24,851 DEBUG TRAIN Batch 18/7900 loss 3.146383 loss_att 6.857759 loss_ctc 4.199448 loss_rnnt 2.128565 hw_loss 0.253376 lr 0.00039776 rank 4
2023-02-22 11:25:24,899 DEBUG TRAIN Batch 18/7900 loss 17.663939 loss_att 19.514410 loss_ctc 24.087864 loss_rnnt 16.265390 hw_loss 0.322364 lr 0.00039780 rank 0
2023-02-22 11:26:36,879 DEBUG TRAIN Batch 18/8000 loss 10.005067 loss_att 12.949007 loss_ctc 14.544109 loss_rnnt 8.739245 hw_loss 0.134678 lr 0.00039760 rank 2
2023-02-22 11:26:36,882 DEBUG TRAIN Batch 18/8000 loss 6.567184 loss_att 8.472214 loss_ctc 7.604124 loss_rnnt 5.936747 hw_loss 0.208450 lr 0.00039768 rank 0
2023-02-22 11:26:36,884 DEBUG TRAIN Batch 18/8000 loss 12.435337 loss_att 15.875425 loss_ctc 19.178265 loss_rnnt 10.762020 hw_loss 0.161706 lr 0.00039759 rank 3
2023-02-22 11:26:36,885 DEBUG TRAIN Batch 18/8000 loss 9.933229 loss_att 11.396626 loss_ctc 12.899984 loss_rnnt 9.032415 hw_loss 0.398563 lr 0.00039756 rank 6
2023-02-22 11:26:36,886 DEBUG TRAIN Batch 18/8000 loss 16.044878 loss_att 18.661509 loss_ctc 20.477074 loss_rnnt 14.745670 hw_loss 0.346729 lr 0.00039764 rank 4
2023-02-22 11:26:36,889 DEBUG TRAIN Batch 18/8000 loss 12.798306 loss_att 16.363930 loss_ctc 19.255289 loss_rnnt 11.069363 hw_loss 0.290412 lr 0.00039758 rank 7
2023-02-22 11:26:36,892 DEBUG TRAIN Batch 18/8000 loss 21.306877 loss_att 23.859444 loss_ctc 30.526041 loss_rnnt 19.454107 hw_loss 0.211942 lr 0.00039761 rank 1
2023-02-22 11:26:36,896 DEBUG TRAIN Batch 18/8000 loss 7.572744 loss_att 11.457520 loss_ctc 16.410788 loss_rnnt 5.519457 hw_loss 0.183610 lr 0.00039762 rank 5
2023-02-22 11:27:49,703 DEBUG TRAIN Batch 18/8100 loss 6.964118 loss_att 9.472639 loss_ctc 7.835737 loss_rnnt 6.249835 hw_loss 0.180678 lr 0.00039747 rank 2
2023-02-22 11:27:49,718 DEBUG TRAIN Batch 18/8100 loss 7.834297 loss_att 8.283897 loss_ctc 8.449886 loss_rnnt 7.464498 hw_loss 0.370875 lr 0.00039751 rank 4
2023-02-22 11:27:49,718 DEBUG TRAIN Batch 18/8100 loss 8.947007 loss_att 10.272033 loss_ctc 13.113443 loss_rnnt 7.915781 hw_loss 0.395055 lr 0.00039747 rank 3
2023-02-22 11:27:49,719 DEBUG TRAIN Batch 18/8100 loss 14.561857 loss_att 19.661249 loss_ctc 19.712822 loss_rnnt 12.671875 hw_loss 0.343703 lr 0.00039749 rank 5
2023-02-22 11:27:49,722 DEBUG TRAIN Batch 18/8100 loss 9.675560 loss_att 14.574250 loss_ctc 14.787054 loss_rnnt 7.900583 hw_loss 0.213199 lr 0.00039755 rank 0
2023-02-22 11:27:49,723 DEBUG TRAIN Batch 18/8100 loss 7.415628 loss_att 11.242754 loss_ctc 9.815227 loss_rnnt 6.232065 hw_loss 0.184109 lr 0.00039744 rank 6
2023-02-22 11:27:49,724 DEBUG TRAIN Batch 18/8100 loss 9.199027 loss_att 15.004879 loss_ctc 11.885878 loss_rnnt 7.590742 hw_loss 0.166628 lr 0.00039748 rank 1
2023-02-22 11:27:49,750 DEBUG TRAIN Batch 18/8100 loss 10.748902 loss_att 12.314422 loss_ctc 15.730280 loss_rnnt 9.572094 hw_loss 0.374103 lr 0.00039745 rank 7
2023-02-22 11:29:03,111 DEBUG TRAIN Batch 18/8200 loss 15.471573 loss_att 19.081539 loss_ctc 33.506908 loss_rnnt 12.142764 hw_loss 0.378944 lr 0.00039733 rank 7
2023-02-22 11:29:03,112 DEBUG TRAIN Batch 18/8200 loss 4.785228 loss_att 6.199176 loss_ctc 5.779454 loss_rnnt 4.200666 hw_loss 0.317266 lr 0.00039731 rank 6
2023-02-22 11:29:03,114 DEBUG TRAIN Batch 18/8200 loss 12.958901 loss_att 14.430298 loss_ctc 17.910614 loss_rnnt 11.845412 hw_loss 0.298091 lr 0.00039735 rank 2
2023-02-22 11:29:03,115 DEBUG TRAIN Batch 18/8200 loss 4.606863 loss_att 6.433762 loss_ctc 6.182298 loss_rnnt 3.889286 hw_loss 0.266512 lr 0.00039734 rank 3
2023-02-22 11:29:03,117 DEBUG TRAIN Batch 18/8200 loss 10.524453 loss_att 13.619665 loss_ctc 12.361843 loss_rnnt 9.516693 hw_loss 0.269500 lr 0.00039736 rank 1
2023-02-22 11:29:03,121 DEBUG TRAIN Batch 18/8200 loss 12.582920 loss_att 12.964291 loss_ctc 17.212234 loss_rnnt 11.771454 hw_loss 0.221155 lr 0.00039742 rank 0
2023-02-22 11:29:03,127 DEBUG TRAIN Batch 18/8200 loss 20.007580 loss_att 21.953352 loss_ctc 30.959751 loss_rnnt 18.032227 hw_loss 0.236080 lr 0.00039737 rank 5
2023-02-22 11:29:03,164 DEBUG TRAIN Batch 18/8200 loss 8.311712 loss_att 12.020867 loss_ctc 12.614222 loss_rnnt 6.852161 hw_loss 0.270099 lr 0.00039739 rank 4
2023-02-22 11:30:15,419 DEBUG TRAIN Batch 18/8300 loss 17.653555 loss_att 23.161671 loss_ctc 25.703545 loss_rnnt 15.357226 hw_loss 0.227574 lr 0.00039726 rank 4
2023-02-22 11:30:15,432 DEBUG TRAIN Batch 18/8300 loss 8.768511 loss_att 13.087059 loss_ctc 13.653837 loss_rnnt 7.190340 hw_loss 0.118285 lr 0.00039719 rank 6
2023-02-22 11:30:15,433 DEBUG TRAIN Batch 18/8300 loss 12.448435 loss_att 13.139254 loss_ctc 17.531940 loss_rnnt 11.441178 hw_loss 0.358672 lr 0.00039723 rank 1
2023-02-22 11:30:15,435 DEBUG TRAIN Batch 18/8300 loss 11.879592 loss_att 13.447632 loss_ctc 12.928206 loss_rnnt 11.327098 hw_loss 0.185757 lr 0.00039730 rank 0
2023-02-22 11:30:15,436 DEBUG TRAIN Batch 18/8300 loss 21.484535 loss_att 24.108837 loss_ctc 31.283764 loss_rnnt 19.563797 hw_loss 0.167466 lr 0.00039722 rank 3
2023-02-22 11:30:15,437 DEBUG TRAIN Batch 18/8300 loss 12.079195 loss_att 14.380591 loss_ctc 15.314207 loss_rnnt 10.914786 hw_loss 0.511490 lr 0.00039722 rank 2
2023-02-22 11:30:15,442 DEBUG TRAIN Batch 18/8300 loss 5.152759 loss_att 8.002913 loss_ctc 8.917882 loss_rnnt 4.016125 hw_loss 0.121100 lr 0.00039720 rank 7
2023-02-22 11:30:15,447 DEBUG TRAIN Batch 18/8300 loss 5.438235 loss_att 5.857822 loss_ctc 6.735128 loss_rnnt 4.965456 hw_loss 0.404891 lr 0.00039724 rank 5
2023-02-22 11:31:03,846 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 4
2023-02-22 11:31:03,847 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 5
2023-02-22 11:31:03,848 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 3
2023-02-22 11:31:03,854 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 2
2023-02-22 11:31:03,857 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 0
2023-02-22 11:31:03,859 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 7
2023-02-22 11:31:03,862 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 1
2023-02-22 11:31:03,865 DEBUG CV Batch 18/0 loss 1.933966 loss_att 1.850140 loss_ctc 2.553427 loss_rnnt 1.395250 hw_loss 0.886662 history loss 1.862337 rank 6
2023-02-22 11:31:15,226 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 7
2023-02-22 11:31:15,255 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 0
2023-02-22 11:31:15,280 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 4
2023-02-22 11:31:15,318 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 1
2023-02-22 11:31:15,455 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 5
2023-02-22 11:31:15,457 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 3
2023-02-22 11:31:15,522 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 6
2023-02-22 11:31:15,576 DEBUG CV Batch 18/100 loss 7.382646 loss_att 7.936282 loss_ctc 10.611766 loss_rnnt 6.745810 hw_loss 0.179175 history loss 3.711460 rank 2
2023-02-22 11:31:28,669 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 7
2023-02-22 11:31:28,721 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 1
2023-02-22 11:31:28,800 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 4
2023-02-22 11:31:28,960 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 5
2023-02-22 11:31:29,102 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 3
2023-02-22 11:31:29,170 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 0
2023-02-22 11:31:29,238 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 6
2023-02-22 11:31:29,322 DEBUG CV Batch 18/200 loss 8.932683 loss_att 20.012613 loss_ctc 11.006721 loss_rnnt 6.345167 hw_loss 0.178108 history loss 4.292665 rank 2
2023-02-22 11:31:41,030 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 7
2023-02-22 11:31:41,098 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 4
2023-02-22 11:31:41,105 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 1
2023-02-22 11:31:41,498 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 0
2023-02-22 11:31:41,660 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 3
2023-02-22 11:31:41,752 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 2
2023-02-22 11:31:41,772 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 6
2023-02-22 11:31:41,873 DEBUG CV Batch 18/300 loss 6.323007 loss_att 6.789772 loss_ctc 9.588938 loss_rnnt 5.499734 hw_loss 0.552117 history loss 4.427010 rank 5
2023-02-22 11:31:53,048 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 7
2023-02-22 11:31:53,157 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 1
2023-02-22 11:31:53,235 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 4
2023-02-22 11:31:53,782 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 0
2023-02-22 11:31:53,943 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 5
2023-02-22 11:31:53,997 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 3
2023-02-22 11:31:54,171 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 6
2023-02-22 11:31:54,286 DEBUG CV Batch 18/400 loss 20.930197 loss_att 82.992104 loss_ctc 8.038435 loss_rnnt 10.109233 hw_loss 0.239034 history loss 5.347974 rank 2
2023-02-22 11:32:03,991 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 7
2023-02-22 11:32:03,992 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 1
2023-02-22 11:32:04,223 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 4
2023-02-22 11:32:04,933 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 0
2023-02-22 11:32:04,937 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 5
2023-02-22 11:32:04,949 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 3
2023-02-22 11:32:05,236 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 6
2023-02-22 11:32:05,245 DEBUG CV Batch 18/500 loss 5.963589 loss_att 5.990962 loss_ctc 7.323211 loss_rnnt 5.615933 hw_loss 0.301683 history loss 6.095171 rank 2
2023-02-22 11:32:16,161 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 1
2023-02-22 11:32:16,399 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 7
2023-02-22 11:32:16,489 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 4
2023-02-22 11:32:17,267 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 3
2023-02-22 11:32:17,312 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 0
2023-02-22 11:32:17,386 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 5
2023-02-22 11:32:17,780 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 6
2023-02-22 11:32:17,799 DEBUG CV Batch 18/600 loss 7.375925 loss_att 7.046997 loss_ctc 9.800820 loss_rnnt 6.776898 hw_loss 0.640298 history loss 7.104498 rank 2
2023-02-22 11:32:27,408 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 1
2023-02-22 11:32:27,878 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 7
2023-02-22 11:32:28,153 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 4
2023-02-22 11:32:28,901 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 5
2023-02-22 11:32:29,003 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 3
2023-02-22 11:32:29,012 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 0
2023-02-22 11:32:29,469 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 6
2023-02-22 11:32:29,528 DEBUG CV Batch 18/700 loss 18.137871 loss_att 42.401955 loss_ctc 17.744463 loss_rnnt 13.224961 hw_loss 0.211025 history loss 7.820479 rank 2
2023-02-22 11:32:38,899 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 1
2023-02-22 11:32:39,374 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 7
2023-02-22 11:32:39,875 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 4
2023-02-22 11:32:40,478 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 5
2023-02-22 11:32:40,536 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 3
2023-02-22 11:32:40,671 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 0
2023-02-22 11:32:40,950 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 2
2023-02-22 11:32:41,007 DEBUG CV Batch 18/800 loss 11.727971 loss_att 11.793448 loss_ctc 17.466436 loss_rnnt 10.810139 hw_loss 0.261764 history loss 7.266356 rank 6
2023-02-22 11:32:52,174 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 1
2023-02-22 11:32:52,861 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 7
2023-02-22 11:32:53,165 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 4
2023-02-22 11:32:53,825 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 5
2023-02-22 11:32:54,130 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 3
2023-02-22 11:32:54,481 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 0
2023-02-22 11:32:54,588 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 2
2023-02-22 11:32:54,752 DEBUG CV Batch 18/900 loss 10.636616 loss_att 16.951056 loss_ctc 19.668213 loss_rnnt 8.105926 hw_loss 0.119228 history loss 7.060532 rank 6
2023-02-22 11:33:04,668 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 1
2023-02-22 11:33:05,323 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 7
2023-02-22 11:33:05,569 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 4
2023-02-22 11:33:06,492 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 5
2023-02-22 11:33:06,556 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 3
2023-02-22 11:33:07,070 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 0
2023-02-22 11:33:07,231 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 2
2023-02-22 11:33:07,420 DEBUG CV Batch 18/1000 loss 3.436121 loss_att 3.995821 loss_ctc 3.743468 loss_rnnt 3.095238 hw_loss 0.352429 history loss 6.815447 rank 6
2023-02-22 11:33:16,542 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 1
2023-02-22 11:33:17,323 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 7
2023-02-22 11:33:17,489 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 4
2023-02-22 11:33:18,466 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 5
2023-02-22 11:33:18,906 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 3
2023-02-22 11:33:19,350 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 0
2023-02-22 11:33:19,576 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 2
2023-02-22 11:33:19,756 DEBUG CV Batch 18/1100 loss 6.999070 loss_att 6.379455 loss_ctc 9.568258 loss_rnnt 6.490676 hw_loss 0.543298 history loss 6.787265 rank 6
2023-02-22 11:33:27,441 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 1
2023-02-22 11:33:28,260 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 7
2023-02-22 11:33:28,451 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 4
2023-02-22 11:33:29,157 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 5
2023-02-22 11:33:29,984 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 3
2023-02-22 11:33:30,550 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 0
2023-02-22 11:33:30,762 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 2
2023-02-22 11:33:30,969 DEBUG CV Batch 18/1200 loss 6.935705 loss_att 7.640912 loss_ctc 8.799825 loss_rnnt 6.409297 hw_loss 0.256534 history loss 7.097105 rank 6
2023-02-22 11:33:39,672 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 1
2023-02-22 11:33:40,493 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 7
2023-02-22 11:33:40,807 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 4
2023-02-22 11:33:41,301 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 5
2023-02-22 11:33:42,388 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 3
2023-02-22 11:33:42,989 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 0
2023-02-22 11:33:43,266 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 2
2023-02-22 11:33:43,343 DEBUG CV Batch 18/1300 loss 5.962313 loss_att 6.028309 loss_ctc 8.659747 loss_rnnt 5.383495 hw_loss 0.386176 history loss 7.435017 rank 6
2023-02-22 11:33:50,901 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 1
2023-02-22 11:33:51,843 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 7
2023-02-22 11:33:52,090 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 4
2023-02-22 11:33:52,546 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 5
2023-02-22 11:33:54,053 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 3
2023-02-22 11:33:54,929 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 2
2023-02-22 11:33:54,986 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 0
2023-02-22 11:33:55,013 DEBUG CV Batch 18/1400 loss 6.504065 loss_att 19.120548 loss_ctc 4.946723 loss_rnnt 4.122830 hw_loss 0.122969 history loss 7.779958 rank 6
2023-02-22 11:34:02,706 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 1
2023-02-22 11:34:03,748 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 7
2023-02-22 11:34:04,131 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 4
2023-02-22 11:34:04,293 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 5
2023-02-22 11:34:05,860 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 3
2023-02-22 11:34:06,922 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 2
2023-02-22 11:34:06,975 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 0
2023-02-22 11:34:07,034 DEBUG CV Batch 18/1500 loss 6.801745 loss_att 8.024759 loss_ctc 6.349014 loss_rnnt 6.407699 hw_loss 0.393391 history loss 7.602541 rank 6
2023-02-22 11:34:15,771 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 1
2023-02-22 11:34:17,263 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 7
2023-02-22 11:34:17,346 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 4
2023-02-22 11:34:17,690 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 5
2023-02-22 11:34:19,204 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 3
2023-02-22 11:34:20,260 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 0
2023-02-22 11:34:20,469 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 6
2023-02-22 11:34:20,496 DEBUG CV Batch 18/1600 loss 7.837942 loss_att 12.287462 loss_ctc 10.886411 loss_rnnt 6.484144 hw_loss 0.107684 history loss 7.533275 rank 2
2023-02-22 11:34:28,301 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 1
2023-02-22 11:34:30,024 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 4
2023-02-22 11:34:30,027 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 7
2023-02-22 11:34:30,197 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 5
2023-02-22 11:34:31,640 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 3
2023-02-22 11:34:32,968 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 6
2023-02-22 11:34:32,985 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 0
2023-02-22 11:34:33,110 DEBUG CV Batch 18/1700 loss 7.198069 loss_att 8.361366 loss_ctc 12.603237 loss_rnnt 6.059098 hw_loss 0.348041 history loss 7.426833 rank 2
2023-02-22 11:34:37,371 INFO Epoch 18 CV info cv_loss 7.387055971002988
2023-02-22 11:34:37,372 INFO Epoch 19 TRAIN info lr 0.00039718957917730057
2023-02-22 11:34:37,377 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:34:39,155 INFO Epoch 18 CV info cv_loss 7.387055970203981
2023-02-22 11:34:39,156 INFO Epoch 19 TRAIN info lr 0.0003971256809370967
2023-02-22 11:34:39,159 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:34:39,228 INFO Epoch 18 CV info cv_loss 7.387055968702882
2023-02-22 11:34:39,229 INFO Epoch 19 TRAIN info lr 0.0003972246736822444
2023-02-22 11:34:39,234 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:34:39,480 INFO Epoch 18 CV info cv_loss 7.3870559678737235
2023-02-22 11:34:39,480 INFO Epoch 19 TRAIN info lr 0.00039719835193149385
2023-02-22 11:34:39,486 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:34:40,688 INFO Epoch 18 CV info cv_loss 7.387055972659152
2023-02-22 11:34:40,688 INFO Epoch 19 TRAIN info lr 0.00039716201144791077
2023-02-22 11:34:40,690 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:34:42,104 INFO Epoch 18 CV info cv_loss 7.387055970677786
2023-02-22 11:34:42,105 INFO Epoch 19 TRAIN info lr 0.0003971419657951875
2023-02-22 11:34:42,110 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:34:42,273 INFO Epoch 18 CV info cv_loss 7.38705597041504
2023-02-22 11:34:42,274 INFO Epoch 19 TRAIN info lr 0.00039717328846156904
2023-02-22 11:34:42,278 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:34:42,505 INFO Epoch 18 CV info cv_loss 7.387055969411436
2023-02-22 11:34:42,505 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/18.pt
2023-02-22 11:34:43,149 INFO Epoch 19 TRAIN info lr 0.00039724473186219557
2023-02-22 11:34:43,154 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 11:35:46,468 DEBUG TRAIN Batch 19/0 loss 13.114207 loss_att 12.872684 loss_ctc 16.615015 loss_rnnt 12.392365 hw_loss 0.568825 lr 0.00039712 rank 7
2023-02-22 11:35:46,470 DEBUG TRAIN Batch 19/0 loss 8.125103 loss_att 7.832169 loss_ctc 10.623846 loss_rnnt 7.602101 hw_loss 0.465792 lr 0.00039716 rank 3
2023-02-22 11:35:46,470 DEBUG TRAIN Batch 19/0 loss 8.026189 loss_att 7.555573 loss_ctc 10.391569 loss_rnnt 7.600652 hw_loss 0.383016 lr 0.00039719 rank 1
2023-02-22 11:35:46,476 DEBUG TRAIN Batch 19/0 loss 7.713223 loss_att 7.372746 loss_ctc 10.179162 loss_rnnt 7.111034 hw_loss 0.640298 lr 0.00039722 rank 4
2023-02-22 11:35:46,477 DEBUG TRAIN Batch 19/0 loss 9.011606 loss_att 7.976962 loss_ctc 10.658631 loss_rnnt 8.666292 hw_loss 0.623699 lr 0.00039724 rank 0
2023-02-22 11:35:46,478 DEBUG TRAIN Batch 19/0 loss 9.308636 loss_att 9.095947 loss_ctc 10.704191 loss_rnnt 8.859018 hw_loss 0.573902 lr 0.00039720 rank 5
2023-02-22 11:35:46,479 DEBUG TRAIN Batch 19/0 loss 11.863207 loss_att 11.395376 loss_ctc 15.335917 loss_rnnt 11.272649 hw_loss 0.414554 lr 0.00039714 rank 6
2023-02-22 11:35:46,537 DEBUG TRAIN Batch 19/0 loss 10.472632 loss_att 9.556001 loss_ctc 13.830019 loss_rnnt 9.933380 hw_loss 0.515488 lr 0.00039717 rank 2
2023-02-22 11:36:57,798 DEBUG TRAIN Batch 19/100 loss 8.006109 loss_att 10.371578 loss_ctc 9.300210 loss_rnnt 7.248611 hw_loss 0.209732 lr 0.00039704 rank 3
2023-02-22 11:36:57,799 DEBUG TRAIN Batch 19/100 loss 5.025528 loss_att 9.413280 loss_ctc 7.926281 loss_rnnt 3.608179 hw_loss 0.286935 lr 0.00039706 rank 1
2023-02-22 11:36:57,802 DEBUG TRAIN Batch 19/100 loss 11.709888 loss_att 14.036749 loss_ctc 15.087746 loss_rnnt 10.676111 hw_loss 0.221293 lr 0.00039705 rank 2
2023-02-22 11:36:57,803 DEBUG TRAIN Batch 19/100 loss 6.981207 loss_att 8.468410 loss_ctc 8.656224 loss_rnnt 6.332506 hw_loss 0.239859 lr 0.00039712 rank 0
2023-02-22 11:36:57,803 DEBUG TRAIN Batch 19/100 loss 8.950633 loss_att 14.512716 loss_ctc 10.837241 loss_rnnt 7.390324 hw_loss 0.368148 lr 0.00039700 rank 7
2023-02-22 11:36:57,805 DEBUG TRAIN Batch 19/100 loss 3.429760 loss_att 8.216954 loss_ctc 7.562425 loss_rnnt 1.762924 hw_loss 0.296952 lr 0.00039707 rank 5
2023-02-22 11:36:57,807 DEBUG TRAIN Batch 19/100 loss 7.816988 loss_att 11.179320 loss_ctc 9.069427 loss_rnnt 6.884233 hw_loss 0.174930 lr 0.00039702 rank 6
2023-02-22 11:36:57,857 DEBUG TRAIN Batch 19/100 loss 6.730873 loss_att 7.897555 loss_ctc 11.010361 loss_rnnt 5.804880 hw_loss 0.228860 lr 0.00039710 rank 4
2023-02-22 11:38:10,484 DEBUG TRAIN Batch 19/200 loss 10.848195 loss_att 11.351339 loss_ctc 13.226810 loss_rnnt 10.272155 hw_loss 0.296746 lr 0.00039692 rank 2
2023-02-22 11:38:10,487 DEBUG TRAIN Batch 19/200 loss 5.393641 loss_att 10.193853 loss_ctc 9.715404 loss_rnnt 3.725147 hw_loss 0.247906 lr 0.00039691 rank 3
2023-02-22 11:38:10,486 DEBUG TRAIN Batch 19/200 loss 7.635092 loss_att 12.451013 loss_ctc 9.202566 loss_rnnt 6.400844 hw_loss 0.116377 lr 0.00039689 rank 6
2023-02-22 11:38:10,491 DEBUG TRAIN Batch 19/200 loss 11.656293 loss_att 16.132957 loss_ctc 18.406631 loss_rnnt 9.708822 hw_loss 0.285173 lr 0.00039687 rank 7
2023-02-22 11:38:10,491 DEBUG TRAIN Batch 19/200 loss 6.007696 loss_att 8.150703 loss_ctc 13.392452 loss_rnnt 4.499030 hw_loss 0.178931 lr 0.00039699 rank 0
2023-02-22 11:38:10,492 DEBUG TRAIN Batch 19/200 loss 6.766940 loss_att 8.749586 loss_ctc 7.204177 loss_rnnt 6.248325 hw_loss 0.119603 lr 0.00039694 rank 1
2023-02-22 11:38:10,493 DEBUG TRAIN Batch 19/200 loss 8.218072 loss_att 11.124567 loss_ctc 9.461419 loss_rnnt 7.375391 hw_loss 0.179256 lr 0.00039697 rank 4
2023-02-22 11:38:10,537 DEBUG TRAIN Batch 19/200 loss 16.366520 loss_att 17.928425 loss_ctc 19.478548 loss_rnnt 15.530215 hw_loss 0.204351 lr 0.00039695 rank 5
2023-02-22 11:39:23,726 DEBUG TRAIN Batch 19/300 loss 14.629869 loss_att 16.178036 loss_ctc 19.778387 loss_rnnt 13.468283 hw_loss 0.310285 lr 0.00039687 rank 0
2023-02-22 11:39:23,731 DEBUG TRAIN Batch 19/300 loss 6.891180 loss_att 10.036495 loss_ctc 9.902122 loss_rnnt 5.727065 hw_loss 0.250488 lr 0.00039681 rank 1
2023-02-22 11:39:23,731 DEBUG TRAIN Batch 19/300 loss 11.407961 loss_att 13.994183 loss_ctc 16.200645 loss_rnnt 10.184223 hw_loss 0.126503 lr 0.00039685 rank 4
2023-02-22 11:39:23,739 DEBUG TRAIN Batch 19/300 loss 13.457619 loss_att 17.460846 loss_ctc 26.409029 loss_rnnt 10.729367 hw_loss 0.376406 lr 0.00039680 rank 2
2023-02-22 11:39:23,741 DEBUG TRAIN Batch 19/300 loss 12.129988 loss_att 16.081299 loss_ctc 16.858231 loss_rnnt 10.570624 hw_loss 0.260002 lr 0.00039675 rank 7
2023-02-22 11:39:23,742 DEBUG TRAIN Batch 19/300 loss 9.933344 loss_att 13.537578 loss_ctc 9.616928 loss_rnnt 9.087173 hw_loss 0.314086 lr 0.00039679 rank 3
2023-02-22 11:39:23,746 DEBUG TRAIN Batch 19/300 loss 8.023411 loss_att 12.016858 loss_ctc 10.094847 loss_rnnt 6.805262 hw_loss 0.268627 lr 0.00039677 rank 6
2023-02-22 11:39:23,747 DEBUG TRAIN Batch 19/300 loss 6.699758 loss_att 8.201906 loss_ctc 10.184972 loss_rnnt 5.767868 hw_loss 0.312684 lr 0.00039682 rank 5
2023-02-22 11:40:36,695 DEBUG TRAIN Batch 19/400 loss 3.935643 loss_att 6.787272 loss_ctc 7.441183 loss_rnnt 2.748559 hw_loss 0.280038 lr 0.00039667 rank 2
2023-02-22 11:40:36,701 DEBUG TRAIN Batch 19/400 loss 9.720222 loss_att 10.956239 loss_ctc 13.079593 loss_rnnt 8.917833 hw_loss 0.201132 lr 0.00039670 rank 5
2023-02-22 11:40:36,701 DEBUG TRAIN Batch 19/400 loss 4.867468 loss_att 7.694599 loss_ctc 8.227954 loss_rnnt 3.726399 hw_loss 0.239207 lr 0.00039669 rank 1
2023-02-22 11:40:36,704 DEBUG TRAIN Batch 19/400 loss 11.668560 loss_att 13.955973 loss_ctc 18.306217 loss_rnnt 10.253533 hw_loss 0.135981 lr 0.00039666 rank 3
2023-02-22 11:40:36,703 DEBUG TRAIN Batch 19/400 loss 2.838034 loss_att 4.824800 loss_ctc 3.032413 loss_rnnt 2.306772 hw_loss 0.202485 lr 0.00039674 rank 0
2023-02-22 11:40:36,704 DEBUG TRAIN Batch 19/400 loss 14.036471 loss_att 18.104158 loss_ctc 21.015987 loss_rnnt 12.137552 hw_loss 0.290210 lr 0.00039662 rank 7
2023-02-22 11:40:36,705 DEBUG TRAIN Batch 19/400 loss 14.405974 loss_att 15.700967 loss_ctc 17.940437 loss_rnnt 13.541321 hw_loss 0.251986 lr 0.00039672 rank 4
2023-02-22 11:40:36,706 DEBUG TRAIN Batch 19/400 loss 7.135847 loss_att 9.656694 loss_ctc 9.179850 loss_rnnt 6.273752 hw_loss 0.160109 lr 0.00039664 rank 6
2023-02-22 11:41:48,718 DEBUG TRAIN Batch 19/500 loss 18.241501 loss_att 18.667473 loss_ctc 21.048248 loss_rnnt 17.630512 hw_loss 0.284174 lr 0.00039660 rank 4
2023-02-22 11:41:48,725 DEBUG TRAIN Batch 19/500 loss 5.909484 loss_att 8.365646 loss_ctc 5.748380 loss_rnnt 5.240458 hw_loss 0.373637 lr 0.00039655 rank 2
2023-02-22 11:41:48,726 DEBUG TRAIN Batch 19/500 loss 3.728687 loss_att 7.286785 loss_ctc 4.766112 loss_rnnt 2.677763 hw_loss 0.376840 lr 0.00039656 rank 1
2023-02-22 11:41:48,729 DEBUG TRAIN Batch 19/500 loss 13.394016 loss_att 16.471615 loss_ctc 18.121119 loss_rnnt 11.944452 hw_loss 0.382057 lr 0.00039654 rank 3
2023-02-22 11:41:48,732 DEBUG TRAIN Batch 19/500 loss 12.860903 loss_att 14.354013 loss_ctc 18.760275 loss_rnnt 11.608216 hw_loss 0.314029 lr 0.00039652 rank 6
2023-02-22 11:41:48,733 DEBUG TRAIN Batch 19/500 loss 8.762809 loss_att 11.909672 loss_ctc 14.075723 loss_rnnt 7.275527 hw_loss 0.280351 lr 0.00039650 rank 7
2023-02-22 11:41:48,736 DEBUG TRAIN Batch 19/500 loss 9.596840 loss_att 11.698093 loss_ctc 13.005554 loss_rnnt 8.574739 hw_loss 0.276291 lr 0.00039657 rank 5
2023-02-22 11:41:48,779 DEBUG TRAIN Batch 19/500 loss 3.698127 loss_att 5.361648 loss_ctc 4.751796 loss_rnnt 3.000259 hw_loss 0.421263 lr 0.00039662 rank 0
2023-02-22 11:43:01,385 DEBUG TRAIN Batch 19/600 loss 9.352519 loss_att 11.126106 loss_ctc 10.233237 loss_rnnt 8.690060 hw_loss 0.356837 lr 0.00039644 rank 1
2023-02-22 11:43:01,387 DEBUG TRAIN Batch 19/600 loss 6.212856 loss_att 6.987559 loss_ctc 8.761817 loss_rnnt 5.614238 hw_loss 0.194655 lr 0.00039641 rank 3
2023-02-22 11:43:01,388 DEBUG TRAIN Batch 19/600 loss 8.529618 loss_att 9.707708 loss_ctc 10.632595 loss_rnnt 7.757604 hw_loss 0.479998 lr 0.00039642 rank 2
2023-02-22 11:43:01,389 DEBUG TRAIN Batch 19/600 loss 14.515542 loss_att 21.134928 loss_ctc 22.632309 loss_rnnt 12.011419 hw_loss 0.183768 lr 0.00039645 rank 5
2023-02-22 11:43:01,391 DEBUG TRAIN Batch 19/600 loss 11.973154 loss_att 13.320986 loss_ctc 16.470417 loss_rnnt 10.952290 hw_loss 0.284369 lr 0.00039639 rank 6
2023-02-22 11:43:01,392 DEBUG TRAIN Batch 19/600 loss 6.103679 loss_att 9.612288 loss_ctc 7.316446 loss_rnnt 5.128307 hw_loss 0.209902 lr 0.00039637 rank 7
2023-02-22 11:43:01,394 DEBUG TRAIN Batch 19/600 loss 11.160193 loss_att 13.038132 loss_ctc 18.038042 loss_rnnt 9.739145 hw_loss 0.240777 lr 0.00039647 rank 4
2023-02-22 11:43:01,441 DEBUG TRAIN Batch 19/600 loss 17.329559 loss_att 19.005276 loss_ctc 25.027386 loss_rnnt 15.784798 hw_loss 0.343578 lr 0.00039649 rank 0
2023-02-22 11:44:16,004 DEBUG TRAIN Batch 19/700 loss 6.487608 loss_att 7.948199 loss_ctc 9.026402 loss_rnnt 5.664842 hw_loss 0.360265 lr 0.00039630 rank 2
2023-02-22 11:44:16,008 DEBUG TRAIN Batch 19/700 loss 11.574863 loss_att 18.798344 loss_ctc 17.314598 loss_rnnt 9.194040 hw_loss 0.320303 lr 0.00039625 rank 7
2023-02-22 11:44:16,008 DEBUG TRAIN Batch 19/700 loss 14.532424 loss_att 16.556942 loss_ctc 19.736456 loss_rnnt 13.305922 hw_loss 0.239491 lr 0.00039631 rank 1
2023-02-22 11:44:16,013 DEBUG TRAIN Batch 19/700 loss 9.499633 loss_att 15.018768 loss_ctc 15.068110 loss_rnnt 7.590328 hw_loss 0.118152 lr 0.00039632 rank 5
2023-02-22 11:44:16,019 DEBUG TRAIN Batch 19/700 loss 4.702818 loss_att 11.020292 loss_ctc 3.586185 loss_rnnt 3.420859 hw_loss 0.313779 lr 0.00039637 rank 0
2023-02-22 11:44:16,031 DEBUG TRAIN Batch 19/700 loss 7.181957 loss_att 10.240093 loss_ctc 10.851381 loss_rnnt 5.973953 hw_loss 0.200849 lr 0.00039627 rank 6
2023-02-22 11:44:16,040 DEBUG TRAIN Batch 19/700 loss 5.212686 loss_att 10.544070 loss_ctc 7.517686 loss_rnnt 3.740751 hw_loss 0.184357 lr 0.00039629 rank 3
2023-02-22 11:44:16,072 DEBUG TRAIN Batch 19/700 loss 14.931431 loss_att 16.877663 loss_ctc 18.537962 loss_rnnt 13.904165 hw_loss 0.294655 lr 0.00039635 rank 4
2023-02-22 11:45:28,087 DEBUG TRAIN Batch 19/800 loss 13.665529 loss_att 15.555654 loss_ctc 17.335682 loss_rnnt 12.655037 hw_loss 0.268337 lr 0.00039617 rank 2
2023-02-22 11:45:28,087 DEBUG TRAIN Batch 19/800 loss 6.537569 loss_att 9.387149 loss_ctc 7.800891 loss_rnnt 5.603799 hw_loss 0.366394 lr 0.00039616 rank 3
2023-02-22 11:45:28,089 DEBUG TRAIN Batch 19/800 loss 7.303004 loss_att 12.015530 loss_ctc 10.182325 loss_rnnt 5.768362 hw_loss 0.390426 lr 0.00039614 rank 6
2023-02-22 11:45:28,092 DEBUG TRAIN Batch 19/800 loss 17.217360 loss_att 17.940607 loss_ctc 17.948406 loss_rnnt 16.908939 hw_loss 0.124307 lr 0.00039613 rank 7
2023-02-22 11:45:28,094 DEBUG TRAIN Batch 19/800 loss 6.414305 loss_att 9.181009 loss_ctc 8.508281 loss_rnnt 5.439060 hw_loss 0.267576 lr 0.00039620 rank 5
2023-02-22 11:45:28,095 DEBUG TRAIN Batch 19/800 loss 8.487253 loss_att 12.456717 loss_ctc 12.975492 loss_rnnt 6.891426 hw_loss 0.381567 lr 0.00039619 rank 1
2023-02-22 11:45:28,098 DEBUG TRAIN Batch 19/800 loss 13.485662 loss_att 15.671152 loss_ctc 22.785564 loss_rnnt 11.592134 hw_loss 0.405828 lr 0.00039624 rank 0
2023-02-22 11:45:28,142 DEBUG TRAIN Batch 19/800 loss 10.324518 loss_att 11.819302 loss_ctc 13.075361 loss_rnnt 9.539836 hw_loss 0.223026 lr 0.00039622 rank 4
2023-02-22 11:46:40,142 DEBUG TRAIN Batch 19/900 loss 11.915857 loss_att 14.965021 loss_ctc 14.879108 loss_rnnt 10.808661 hw_loss 0.191747 lr 0.00039604 rank 3
2023-02-22 11:46:40,146 DEBUG TRAIN Batch 19/900 loss 6.325978 loss_att 11.462095 loss_ctc 11.877790 loss_rnnt 4.468254 hw_loss 0.169237 lr 0.00039607 rank 1
2023-02-22 11:46:40,148 DEBUG TRAIN Batch 19/900 loss 5.630151 loss_att 8.823048 loss_ctc 7.620934 loss_rnnt 4.603311 hw_loss 0.230294 lr 0.00039607 rank 5
2023-02-22 11:46:40,149 DEBUG TRAIN Batch 19/900 loss 8.389893 loss_att 12.155650 loss_ctc 11.163452 loss_rnnt 7.106027 hw_loss 0.301699 lr 0.00039602 rank 6
2023-02-22 11:46:40,150 DEBUG TRAIN Batch 19/900 loss 8.993590 loss_att 16.677134 loss_ctc 14.435869 loss_rnnt 6.572090 hw_loss 0.298414 lr 0.00039600 rank 7
2023-02-22 11:46:40,151 DEBUG TRAIN Batch 19/900 loss 7.455277 loss_att 11.151691 loss_ctc 12.640765 loss_rnnt 5.829932 hw_loss 0.364994 lr 0.00039605 rank 2
2023-02-22 11:46:40,151 DEBUG TRAIN Batch 19/900 loss 4.430649 loss_att 9.125704 loss_ctc 5.472467 loss_rnnt 3.167116 hw_loss 0.348026 lr 0.00039610 rank 4
2023-02-22 11:46:40,153 DEBUG TRAIN Batch 19/900 loss 14.322703 loss_att 16.910635 loss_ctc 18.712337 loss_rnnt 13.097693 hw_loss 0.229010 lr 0.00039612 rank 0
2023-02-22 11:47:52,839 DEBUG TRAIN Batch 19/1000 loss 11.050679 loss_att 13.117013 loss_ctc 13.540697 loss_rnnt 10.093599 hw_loss 0.397147 lr 0.00039589 rank 6
2023-02-22 11:47:52,844 DEBUG TRAIN Batch 19/1000 loss 14.826729 loss_att 16.117554 loss_ctc 16.674049 loss_rnnt 14.223783 hw_loss 0.184634 lr 0.00039594 rank 1
2023-02-22 11:47:52,855 DEBUG TRAIN Batch 19/1000 loss 20.091146 loss_att 22.668890 loss_ctc 28.711895 loss_rnnt 18.328516 hw_loss 0.183090 lr 0.00039591 rank 3
2023-02-22 11:47:52,859 DEBUG TRAIN Batch 19/1000 loss 8.000375 loss_att 10.636925 loss_ctc 10.943228 loss_rnnt 6.952442 hw_loss 0.240454 lr 0.00039600 rank 0
2023-02-22 11:47:52,859 DEBUG TRAIN Batch 19/1000 loss 7.316483 loss_att 9.712152 loss_ctc 8.012306 loss_rnnt 6.586043 hw_loss 0.297244 lr 0.00039595 rank 5
2023-02-22 11:47:52,859 DEBUG TRAIN Batch 19/1000 loss 9.543130 loss_att 11.745800 loss_ctc 15.027125 loss_rnnt 8.267121 hw_loss 0.195515 lr 0.00039592 rank 2
2023-02-22 11:47:52,863 DEBUG TRAIN Batch 19/1000 loss 5.996571 loss_att 8.948416 loss_ctc 9.588018 loss_rnnt 4.803047 hw_loss 0.233054 lr 0.00039588 rank 7
2023-02-22 11:47:52,904 DEBUG TRAIN Batch 19/1000 loss 15.828204 loss_att 18.717087 loss_ctc 21.164997 loss_rnnt 14.365881 hw_loss 0.324328 lr 0.00039598 rank 4
2023-02-22 11:49:07,895 DEBUG TRAIN Batch 19/1100 loss 14.536711 loss_att 17.482544 loss_ctc 17.450315 loss_rnnt 13.454295 hw_loss 0.196442 lr 0.00039580 rank 2
2023-02-22 11:49:07,896 DEBUG TRAIN Batch 19/1100 loss 14.164201 loss_att 15.471016 loss_ctc 16.902676 loss_rnnt 13.378531 hw_loss 0.298460 lr 0.00039579 rank 3
2023-02-22 11:49:07,897 DEBUG TRAIN Batch 19/1100 loss 12.409349 loss_att 17.176121 loss_ctc 19.080513 loss_rnnt 10.454773 hw_loss 0.209500 lr 0.00039577 rank 6
2023-02-22 11:49:07,899 DEBUG TRAIN Batch 19/1100 loss 9.658080 loss_att 12.371787 loss_ctc 11.928065 loss_rnnt 8.674580 hw_loss 0.258928 lr 0.00039585 rank 4
2023-02-22 11:49:07,899 DEBUG TRAIN Batch 19/1100 loss 5.415808 loss_att 7.876542 loss_ctc 4.575645 loss_rnnt 4.928314 hw_loss 0.201317 lr 0.00039583 rank 5
2023-02-22 11:49:07,900 DEBUG TRAIN Batch 19/1100 loss 14.761406 loss_att 16.450819 loss_ctc 16.152266 loss_rnnt 14.135002 hw_loss 0.193261 lr 0.00039587 rank 0
2023-02-22 11:49:07,903 DEBUG TRAIN Batch 19/1100 loss 9.109731 loss_att 13.407556 loss_ctc 11.139849 loss_rnnt 7.852847 hw_loss 0.237443 lr 0.00039582 rank 1
2023-02-22 11:49:07,945 DEBUG TRAIN Batch 19/1100 loss 8.262846 loss_att 10.088558 loss_ctc 9.626789 loss_rnnt 7.565791 hw_loss 0.281352 lr 0.00039575 rank 7
2023-02-22 11:50:20,965 DEBUG TRAIN Batch 19/1200 loss 5.967146 loss_att 7.734425 loss_ctc 8.504111 loss_rnnt 5.084671 hw_loss 0.357670 lr 0.00039565 rank 6
2023-02-22 11:50:20,967 DEBUG TRAIN Batch 19/1200 loss 8.253283 loss_att 9.784613 loss_ctc 10.040439 loss_rnnt 7.613172 hw_loss 0.179169 lr 0.00039563 rank 7
2023-02-22 11:50:20,967 DEBUG TRAIN Batch 19/1200 loss 6.533252 loss_att 8.468707 loss_ctc 8.048652 loss_rnnt 5.787240 hw_loss 0.294127 lr 0.00039568 rank 2
2023-02-22 11:50:20,969 DEBUG TRAIN Batch 19/1200 loss 10.752814 loss_att 12.071440 loss_ctc 15.601472 loss_rnnt 9.618940 hw_loss 0.419367 lr 0.00039567 rank 3
2023-02-22 11:50:20,971 DEBUG TRAIN Batch 19/1200 loss 7.983741 loss_att 7.477592 loss_ctc 10.177043 loss_rnnt 7.555494 hw_loss 0.444444 lr 0.00039570 rank 5
2023-02-22 11:50:20,973 DEBUG TRAIN Batch 19/1200 loss 7.103622 loss_att 9.567125 loss_ctc 8.468020 loss_rnnt 6.286541 hw_loss 0.267115 lr 0.00039573 rank 4
2023-02-22 11:50:21,004 DEBUG TRAIN Batch 19/1200 loss 6.942302 loss_att 8.495486 loss_ctc 7.678216 loss_rnnt 6.421569 hw_loss 0.209951 lr 0.00039575 rank 0
2023-02-22 11:50:21,038 DEBUG TRAIN Batch 19/1200 loss 23.275820 loss_att 27.029034 loss_ctc 33.859810 loss_rnnt 20.989088 hw_loss 0.234169 lr 0.00039569 rank 1
2023-02-22 11:51:33,873 DEBUG TRAIN Batch 19/1300 loss 14.874086 loss_att 18.843819 loss_ctc 20.404228 loss_rnnt 13.153739 hw_loss 0.354467 lr 0.00039555 rank 2
2023-02-22 11:51:33,880 DEBUG TRAIN Batch 19/1300 loss 8.077791 loss_att 13.187548 loss_ctc 13.139941 loss_rnnt 6.274264 hw_loss 0.199915 lr 0.00039551 rank 7
2023-02-22 11:51:33,880 DEBUG TRAIN Batch 19/1300 loss 1.859070 loss_att 4.658035 loss_ctc 3.051235 loss_rnnt 1.059487 hw_loss 0.151566 lr 0.00039562 rank 0
2023-02-22 11:51:33,881 DEBUG TRAIN Batch 19/1300 loss 9.723025 loss_att 14.761208 loss_ctc 17.853603 loss_rnnt 7.570009 hw_loss 0.114944 lr 0.00039554 rank 3
2023-02-22 11:51:33,882 DEBUG TRAIN Batch 19/1300 loss 3.903494 loss_att 6.941540 loss_ctc 5.586786 loss_rnnt 2.954802 hw_loss 0.218707 lr 0.00039552 rank 6
2023-02-22 11:51:33,884 DEBUG TRAIN Batch 19/1300 loss 4.455594 loss_att 4.445524 loss_ctc 5.832756 loss_rnnt 3.936268 hw_loss 0.633222 lr 0.00039560 rank 4
2023-02-22 11:51:33,886 DEBUG TRAIN Batch 19/1300 loss 13.337255 loss_att 16.519556 loss_ctc 19.652710 loss_rnnt 11.720996 hw_loss 0.258259 lr 0.00039558 rank 5
2023-02-22 11:51:33,885 DEBUG TRAIN Batch 19/1300 loss 8.540976 loss_att 9.998405 loss_ctc 10.565306 loss_rnnt 7.785948 hw_loss 0.363058 lr 0.00039557 rank 1
2023-02-22 11:52:48,375 DEBUG TRAIN Batch 19/1400 loss 6.507057 loss_att 9.434509 loss_ctc 9.175535 loss_rnnt 5.507776 hw_loss 0.108739 lr 0.00039538 rank 7
2023-02-22 11:52:48,378 DEBUG TRAIN Batch 19/1400 loss 17.805727 loss_att 23.943369 loss_ctc 23.909023 loss_rnnt 15.598014 hw_loss 0.312025 lr 0.00039545 rank 1
2023-02-22 11:52:48,387 DEBUG TRAIN Batch 19/1400 loss 1.419048 loss_att 4.734071 loss_ctc 2.076094 loss_rnnt 0.558727 hw_loss 0.205706 lr 0.00039543 rank 2
2023-02-22 11:52:48,392 DEBUG TRAIN Batch 19/1400 loss 12.087501 loss_att 13.750694 loss_ctc 15.314985 loss_rnnt 11.128669 hw_loss 0.367241 lr 0.00039548 rank 4
2023-02-22 11:52:48,391 DEBUG TRAIN Batch 19/1400 loss 5.067929 loss_att 8.745763 loss_ctc 7.119754 loss_rnnt 3.963902 hw_loss 0.177907 lr 0.00039550 rank 0
2023-02-22 11:52:48,391 DEBUG TRAIN Batch 19/1400 loss 7.683650 loss_att 12.331924 loss_ctc 13.359511 loss_rnnt 5.866417 hw_loss 0.245245 lr 0.00039545 rank 5
2023-02-22 11:52:48,392 DEBUG TRAIN Batch 19/1400 loss 5.323987 loss_att 8.069645 loss_ctc 8.212411 loss_rnnt 4.247012 hw_loss 0.267599 lr 0.00039542 rank 3
2023-02-22 11:52:48,392 DEBUG TRAIN Batch 19/1400 loss 16.759827 loss_att 20.455366 loss_ctc 24.526937 loss_rnnt 14.898143 hw_loss 0.163051 lr 0.00039540 rank 6
2023-02-22 11:54:01,593 DEBUG TRAIN Batch 19/1500 loss 6.207831 loss_att 10.266722 loss_ctc 9.905087 loss_rnnt 4.708992 hw_loss 0.363927 lr 0.00039531 rank 2
2023-02-22 11:54:01,599 DEBUG TRAIN Batch 19/1500 loss 11.198682 loss_att 13.534813 loss_ctc 16.969856 loss_rnnt 9.852368 hw_loss 0.205496 lr 0.00039532 rank 1
2023-02-22 11:54:01,605 DEBUG TRAIN Batch 19/1500 loss 5.908634 loss_att 10.678149 loss_ctc 8.890776 loss_rnnt 4.439292 hw_loss 0.220910 lr 0.00039526 rank 7
2023-02-22 11:54:01,606 DEBUG TRAIN Batch 19/1500 loss 8.648620 loss_att 13.049447 loss_ctc 10.857473 loss_rnnt 7.320760 hw_loss 0.287213 lr 0.00039527 rank 6
2023-02-22 11:54:01,610 DEBUG TRAIN Batch 19/1500 loss 7.569319 loss_att 10.661785 loss_ctc 11.933438 loss_rnnt 6.211615 hw_loss 0.294991 lr 0.00039529 rank 3
2023-02-22 11:54:01,612 DEBUG TRAIN Batch 19/1500 loss 4.634682 loss_att 7.715901 loss_ctc 8.335406 loss_rnnt 3.322837 hw_loss 0.379070 lr 0.00039536 rank 4
2023-02-22 11:54:01,613 DEBUG TRAIN Batch 19/1500 loss 12.191391 loss_att 15.313307 loss_ctc 14.672609 loss_rnnt 11.083053 hw_loss 0.287112 lr 0.00039538 rank 0
2023-02-22 11:54:01,614 DEBUG TRAIN Batch 19/1500 loss 7.974654 loss_att 12.696734 loss_ctc 13.136995 loss_rnnt 6.145132 hw_loss 0.368988 lr 0.00039533 rank 5
2023-02-22 11:55:12,999 DEBUG TRAIN Batch 19/1600 loss 6.312961 loss_att 8.735284 loss_ctc 8.013151 loss_rnnt 5.475912 hw_loss 0.236046 lr 0.00039514 rank 7
2023-02-22 11:55:12,998 DEBUG TRAIN Batch 19/1600 loss 10.423565 loss_att 10.997085 loss_ctc 11.902850 loss_rnnt 9.992710 hw_loss 0.222961 lr 0.00039518 rank 2
2023-02-22 11:55:13,000 DEBUG TRAIN Batch 19/1600 loss 18.538429 loss_att 17.915049 loss_ctc 22.507786 loss_rnnt 18.066509 hw_loss 0.126274 lr 0.00039517 rank 3
2023-02-22 11:55:13,001 DEBUG TRAIN Batch 19/1600 loss 17.274298 loss_att 22.800968 loss_ctc 28.840893 loss_rnnt 14.499789 hw_loss 0.238052 lr 0.00039515 rank 6
2023-02-22 11:55:13,002 DEBUG TRAIN Batch 19/1600 loss 2.138637 loss_att 6.008437 loss_ctc 3.311758 loss_rnnt 1.049161 hw_loss 0.298311 lr 0.00039520 rank 1
2023-02-22 11:55:13,004 DEBUG TRAIN Batch 19/1600 loss 9.319741 loss_att 13.433939 loss_ctc 11.975248 loss_rnnt 7.974592 hw_loss 0.315454 lr 0.00039521 rank 5
2023-02-22 11:55:13,005 DEBUG TRAIN Batch 19/1600 loss 15.335062 loss_att 17.177538 loss_ctc 26.029522 loss_rnnt 13.465748 hw_loss 0.140421 lr 0.00039523 rank 4
2023-02-22 11:55:13,006 DEBUG TRAIN Batch 19/1600 loss 9.049707 loss_att 13.945296 loss_ctc 16.935593 loss_rnnt 6.881669 hw_loss 0.257754 lr 0.00039525 rank 0
2023-02-22 11:56:26,196 DEBUG TRAIN Batch 19/1700 loss 13.779187 loss_att 16.280495 loss_ctc 18.502098 loss_rnnt 12.487211 hw_loss 0.303738 lr 0.00039501 rank 7
2023-02-22 11:56:26,205 DEBUG TRAIN Batch 19/1700 loss 9.783545 loss_att 12.177940 loss_ctc 17.171295 loss_rnnt 8.213081 hw_loss 0.199782 lr 0.00039506 rank 2
2023-02-22 11:56:26,206 DEBUG TRAIN Batch 19/1700 loss 8.763759 loss_att 11.903552 loss_ctc 14.459988 loss_rnnt 7.283790 hw_loss 0.173465 lr 0.00039507 rank 1
2023-02-22 11:56:26,209 DEBUG TRAIN Batch 19/1700 loss 16.624437 loss_att 19.953634 loss_ctc 22.825178 loss_rnnt 14.985307 hw_loss 0.274736 lr 0.00039503 rank 6
2023-02-22 11:56:26,209 DEBUG TRAIN Batch 19/1700 loss 10.937576 loss_att 13.879622 loss_ctc 14.094931 loss_rnnt 9.831216 hw_loss 0.181819 lr 0.00039511 rank 4
2023-02-22 11:56:26,210 DEBUG TRAIN Batch 19/1700 loss 8.851877 loss_att 11.924891 loss_ctc 15.592411 loss_rnnt 7.212472 hw_loss 0.236370 lr 0.00039505 rank 3
2023-02-22 11:56:26,210 DEBUG TRAIN Batch 19/1700 loss 7.512352 loss_att 9.705965 loss_ctc 9.885097 loss_rnnt 6.559270 hw_loss 0.371237 lr 0.00039508 rank 5
2023-02-22 11:56:26,216 DEBUG TRAIN Batch 19/1700 loss 9.485308 loss_att 12.384783 loss_ctc 15.198046 loss_rnnt 8.009009 hw_loss 0.252570 lr 0.00039513 rank 0
2023-02-22 11:57:41,416 DEBUG TRAIN Batch 19/1800 loss 4.199657 loss_att 6.348477 loss_ctc 4.814296 loss_rnnt 3.451710 hw_loss 0.442932 lr 0.00039489 rank 7
2023-02-22 11:57:41,424 DEBUG TRAIN Batch 19/1800 loss 14.532510 loss_att 16.014513 loss_ctc 13.934451 loss_rnnt 14.181563 hw_loss 0.251790 lr 0.00039494 rank 2
2023-02-22 11:57:41,431 DEBUG TRAIN Batch 19/1800 loss 8.878183 loss_att 10.649615 loss_ctc 11.392822 loss_rnnt 7.968886 hw_loss 0.411984 lr 0.00039499 rank 4
2023-02-22 11:57:41,431 DEBUG TRAIN Batch 19/1800 loss 14.116877 loss_att 17.754314 loss_ctc 19.877541 loss_rnnt 12.524357 hw_loss 0.181771 lr 0.00039501 rank 0
2023-02-22 11:57:41,433 DEBUG TRAIN Batch 19/1800 loss 15.222610 loss_att 18.283920 loss_ctc 19.588995 loss_rnnt 13.885852 hw_loss 0.266834 lr 0.00039495 rank 1
2023-02-22 11:57:41,435 DEBUG TRAIN Batch 19/1800 loss 12.594919 loss_att 14.416443 loss_ctc 21.222185 loss_rnnt 10.866716 hw_loss 0.400492 lr 0.00039492 rank 3
2023-02-22 11:57:41,437 DEBUG TRAIN Batch 19/1800 loss 6.617264 loss_att 9.442760 loss_ctc 9.646503 loss_rnnt 5.540495 hw_loss 0.202070 lr 0.00039490 rank 6
2023-02-22 11:57:41,487 DEBUG TRAIN Batch 19/1800 loss 7.300986 loss_att 8.996454 loss_ctc 11.407494 loss_rnnt 6.219718 hw_loss 0.364948 lr 0.00039496 rank 5
2023-02-22 11:58:53,761 DEBUG TRAIN Batch 19/1900 loss 5.394781 loss_att 6.211520 loss_ctc 6.886999 loss_rnnt 4.699898 hw_loss 0.623575 lr 0.00039481 rank 2
2023-02-22 11:58:53,762 DEBUG TRAIN Batch 19/1900 loss 12.974124 loss_att 14.371349 loss_ctc 18.462509 loss_rnnt 11.755102 hw_loss 0.389611 lr 0.00039486 rank 4
2023-02-22 11:58:53,764 DEBUG TRAIN Batch 19/1900 loss 6.733040 loss_att 8.647701 loss_ctc 10.394677 loss_rnnt 5.745661 hw_loss 0.217927 lr 0.00039483 rank 1
2023-02-22 11:58:53,765 DEBUG TRAIN Batch 19/1900 loss 14.113605 loss_att 15.882145 loss_ctc 15.770012 loss_rnnt 13.363730 hw_loss 0.328713 lr 0.00039480 rank 3
2023-02-22 11:58:53,767 DEBUG TRAIN Batch 19/1900 loss 7.615722 loss_att 8.085453 loss_ctc 10.467052 loss_rnnt 6.937158 hw_loss 0.383326 lr 0.00039477 rank 7
2023-02-22 11:58:53,767 DEBUG TRAIN Batch 19/1900 loss 10.281095 loss_att 11.836792 loss_ctc 14.555873 loss_rnnt 9.268717 hw_loss 0.246126 lr 0.00039478 rank 6
2023-02-22 11:58:53,772 DEBUG TRAIN Batch 19/1900 loss 5.360970 loss_att 6.246224 loss_ctc 7.499065 loss_rnnt 4.708683 hw_loss 0.356544 lr 0.00039488 rank 0
2023-02-22 11:58:53,772 DEBUG TRAIN Batch 19/1900 loss 15.660041 loss_att 19.392048 loss_ctc 20.711452 loss_rnnt 14.094504 hw_loss 0.273024 lr 0.00039484 rank 5
2023-02-22 12:00:06,992 DEBUG TRAIN Batch 19/2000 loss 11.648888 loss_att 14.283657 loss_ctc 19.236088 loss_rnnt 10.026220 hw_loss 0.157663 lr 0.00039468 rank 3
2023-02-22 12:00:07,009 DEBUG TRAIN Batch 19/2000 loss 5.123528 loss_att 9.456535 loss_ctc 8.196960 loss_rnnt 3.723659 hw_loss 0.231519 lr 0.00039474 rank 4
2023-02-22 12:00:07,010 DEBUG TRAIN Batch 19/2000 loss 7.984900 loss_att 10.393388 loss_ctc 9.603184 loss_rnnt 7.119125 hw_loss 0.315573 lr 0.00039466 rank 6
2023-02-22 12:00:07,010 DEBUG TRAIN Batch 19/2000 loss 8.825935 loss_att 9.383647 loss_ctc 10.647282 loss_rnnt 8.399084 hw_loss 0.135867 lr 0.00039469 rank 2
2023-02-22 12:00:07,013 DEBUG TRAIN Batch 19/2000 loss 17.120668 loss_att 21.856226 loss_ctc 20.422913 loss_rnnt 15.611903 hw_loss 0.227539 lr 0.00039464 rank 7
2023-02-22 12:00:07,014 DEBUG TRAIN Batch 19/2000 loss 17.786587 loss_att 25.684429 loss_ctc 22.878357 loss_rnnt 15.452375 hw_loss 0.142010 lr 0.00039476 rank 0
2023-02-22 12:00:07,018 DEBUG TRAIN Batch 19/2000 loss 1.482938 loss_att 4.040143 loss_ctc 3.759264 loss_rnnt 0.542728 hw_loss 0.234861 lr 0.00039471 rank 1
2023-02-22 12:00:07,020 DEBUG TRAIN Batch 19/2000 loss 12.392970 loss_att 15.024014 loss_ctc 14.293379 loss_rnnt 11.397943 hw_loss 0.403931 lr 0.00039471 rank 5
2023-02-22 12:01:21,089 DEBUG TRAIN Batch 19/2100 loss 4.997408 loss_att 6.606932 loss_ctc 5.992217 loss_rnnt 4.370760 hw_loss 0.322691 lr 0.00039464 rank 0
2023-02-22 12:01:21,098 DEBUG TRAIN Batch 19/2100 loss 4.032727 loss_att 6.170185 loss_ctc 4.668719 loss_rnnt 3.394724 hw_loss 0.235712 lr 0.00039462 rank 4
2023-02-22 12:01:21,098 DEBUG TRAIN Batch 19/2100 loss 5.901973 loss_att 10.377544 loss_ctc 9.175215 loss_rnnt 4.457075 hw_loss 0.212536 lr 0.00039456 rank 3
2023-02-22 12:01:21,101 DEBUG TRAIN Batch 19/2100 loss 14.707760 loss_att 19.856529 loss_ctc 19.297340 loss_rnnt 13.007370 hw_loss 0.110046 lr 0.00039457 rank 2
2023-02-22 12:01:21,101 DEBUG TRAIN Batch 19/2100 loss 13.375065 loss_att 18.303669 loss_ctc 23.890760 loss_rnnt 10.872821 hw_loss 0.214558 lr 0.00039452 rank 7
2023-02-22 12:01:21,102 DEBUG TRAIN Batch 19/2100 loss 9.896909 loss_att 13.303499 loss_ctc 12.590584 loss_rnnt 8.689354 hw_loss 0.313275 lr 0.00039454 rank 6
2023-02-22 12:01:21,104 DEBUG TRAIN Batch 19/2100 loss 5.109179 loss_att 9.468363 loss_ctc 5.688661 loss_rnnt 4.000213 hw_loss 0.299748 lr 0.00039459 rank 5
2023-02-22 12:01:21,108 DEBUG TRAIN Batch 19/2100 loss 11.924719 loss_att 15.282548 loss_ctc 15.694639 loss_rnnt 10.613260 hw_loss 0.257319 lr 0.00039458 rank 1
2023-02-22 12:02:34,719 DEBUG TRAIN Batch 19/2200 loss 6.267470 loss_att 12.138280 loss_ctc 10.220044 loss_rnnt 4.434786 hw_loss 0.246583 lr 0.00039444 rank 2
2023-02-22 12:02:34,720 DEBUG TRAIN Batch 19/2200 loss 6.863210 loss_att 12.309807 loss_ctc 10.832687 loss_rnnt 5.016003 hw_loss 0.428669 lr 0.00039440 rank 7
2023-02-22 12:02:34,720 DEBUG TRAIN Batch 19/2200 loss 5.468320 loss_att 8.757827 loss_ctc 8.201223 loss_rnnt 4.273588 hw_loss 0.323334 lr 0.00039451 rank 0
2023-02-22 12:02:34,724 DEBUG TRAIN Batch 19/2200 loss 9.439052 loss_att 13.594137 loss_ctc 11.276535 loss_rnnt 8.240686 hw_loss 0.229407 lr 0.00039449 rank 4
2023-02-22 12:02:34,724 DEBUG TRAIN Batch 19/2200 loss 13.593638 loss_att 18.600189 loss_ctc 21.668451 loss_rnnt 11.401852 hw_loss 0.213440 lr 0.00039441 rank 6
2023-02-22 12:02:34,724 DEBUG TRAIN Batch 19/2200 loss 19.222387 loss_att 22.311272 loss_ctc 24.260340 loss_rnnt 17.826612 hw_loss 0.199258 lr 0.00039447 rank 5
2023-02-22 12:02:34,725 DEBUG TRAIN Batch 19/2200 loss 5.380921 loss_att 8.030983 loss_ctc 7.492303 loss_rnnt 4.498702 hw_loss 0.132542 lr 0.00039443 rank 3
2023-02-22 12:02:34,776 DEBUG TRAIN Batch 19/2200 loss 6.200553 loss_att 8.699289 loss_ctc 9.244074 loss_rnnt 5.165709 hw_loss 0.242426 lr 0.00039446 rank 1
2023-02-22 12:03:47,032 DEBUG TRAIN Batch 19/2300 loss 3.074597 loss_att 7.822904 loss_ctc 4.363139 loss_rnnt 1.826772 hw_loss 0.236922 lr 0.00039429 rank 6
2023-02-22 12:03:47,032 DEBUG TRAIN Batch 19/2300 loss 16.497869 loss_att 20.077229 loss_ctc 22.676725 loss_rnnt 14.787357 hw_loss 0.320233 lr 0.00039437 rank 4
2023-02-22 12:03:47,033 DEBUG TRAIN Batch 19/2300 loss 11.126665 loss_att 15.134438 loss_ctc 16.522198 loss_rnnt 9.428131 hw_loss 0.332954 lr 0.00039434 rank 1
2023-02-22 12:03:47,035 DEBUG TRAIN Batch 19/2300 loss 9.570322 loss_att 12.685657 loss_ctc 14.561611 loss_rnnt 8.176278 hw_loss 0.197758 lr 0.00039432 rank 2
2023-02-22 12:03:47,036 DEBUG TRAIN Batch 19/2300 loss 6.821551 loss_att 8.224814 loss_ctc 6.978838 loss_rnnt 6.314242 hw_loss 0.385660 lr 0.00039427 rank 7
2023-02-22 12:03:47,037 DEBUG TRAIN Batch 19/2300 loss 6.958988 loss_att 9.606876 loss_ctc 9.543733 loss_rnnt 5.927948 hw_loss 0.294054 lr 0.00039435 rank 5
2023-02-22 12:03:47,040 DEBUG TRAIN Batch 19/2300 loss 11.590148 loss_att 15.551479 loss_ctc 18.551483 loss_rnnt 9.729881 hw_loss 0.262166 lr 0.00039431 rank 3
2023-02-22 12:03:47,097 DEBUG TRAIN Batch 19/2300 loss 9.011220 loss_att 10.382331 loss_ctc 13.462646 loss_rnnt 8.044615 hw_loss 0.185363 lr 0.00039439 rank 0
2023-02-22 12:05:00,270 DEBUG TRAIN Batch 19/2400 loss 6.986784 loss_att 9.560820 loss_ctc 10.586865 loss_rnnt 5.804721 hw_loss 0.351084 lr 0.00039425 rank 4
2023-02-22 12:05:00,271 DEBUG TRAIN Batch 19/2400 loss 7.497807 loss_att 9.328753 loss_ctc 12.066047 loss_rnnt 6.401609 hw_loss 0.226705 lr 0.00039415 rank 7
2023-02-22 12:05:00,280 DEBUG TRAIN Batch 19/2400 loss 7.045304 loss_att 9.863587 loss_ctc 7.725663 loss_rnnt 6.260388 hw_loss 0.244770 lr 0.00039420 rank 2
2023-02-22 12:05:00,282 DEBUG TRAIN Batch 19/2400 loss 4.769583 loss_att 7.078139 loss_ctc 5.871845 loss_rnnt 3.926286 hw_loss 0.439907 lr 0.00039419 rank 3
2023-02-22 12:05:00,284 DEBUG TRAIN Batch 19/2400 loss 20.857147 loss_att 22.126770 loss_ctc 28.783926 loss_rnnt 19.411985 hw_loss 0.251877 lr 0.00039417 rank 6
2023-02-22 12:05:00,284 DEBUG TRAIN Batch 19/2400 loss 12.890668 loss_att 13.158789 loss_ctc 17.976896 loss_rnnt 12.053401 hw_loss 0.197773 lr 0.00039427 rank 0
2023-02-22 12:05:00,286 DEBUG TRAIN Batch 19/2400 loss 3.108425 loss_att 5.665731 loss_ctc 6.887277 loss_rnnt 1.862227 hw_loss 0.432920 lr 0.00039421 rank 1
2023-02-22 12:05:00,289 DEBUG TRAIN Batch 19/2400 loss 10.961536 loss_att 12.564835 loss_ctc 14.743988 loss_rnnt 10.023076 hw_loss 0.212762 lr 0.00039422 rank 5
2023-02-22 12:06:16,201 DEBUG TRAIN Batch 19/2500 loss 12.378586 loss_att 16.004047 loss_ctc 17.698757 loss_rnnt 10.875744 hw_loss 0.128239 lr 0.00039405 rank 6
2023-02-22 12:06:16,212 DEBUG TRAIN Batch 19/2500 loss 6.219879 loss_att 10.445878 loss_ctc 9.949595 loss_rnnt 4.817920 hw_loss 0.111494 lr 0.00039406 rank 3
2023-02-22 12:06:16,216 DEBUG TRAIN Batch 19/2500 loss 12.468323 loss_att 13.938770 loss_ctc 15.584371 loss_rnnt 11.674642 hw_loss 0.157722 lr 0.00039408 rank 2
2023-02-22 12:06:16,217 DEBUG TRAIN Batch 19/2500 loss 9.565277 loss_att 10.832676 loss_ctc 13.336373 loss_rnnt 8.590718 hw_loss 0.409249 lr 0.00039403 rank 7
2023-02-22 12:06:16,219 DEBUG TRAIN Batch 19/2500 loss 5.274699 loss_att 7.297077 loss_ctc 7.202075 loss_rnnt 4.419076 hw_loss 0.364055 lr 0.00039415 rank 0
2023-02-22 12:06:16,222 DEBUG TRAIN Batch 19/2500 loss 9.781636 loss_att 13.475405 loss_ctc 14.886322 loss_rnnt 8.267146 hw_loss 0.178335 lr 0.00039413 rank 4
2023-02-22 12:06:16,222 DEBUG TRAIN Batch 19/2500 loss 5.104263 loss_att 6.045133 loss_ctc 9.338435 loss_rnnt 4.124623 hw_loss 0.425456 lr 0.00039410 rank 5
2023-02-22 12:06:16,222 DEBUG TRAIN Batch 19/2500 loss 7.646522 loss_att 9.904997 loss_ctc 10.675660 loss_rnnt 6.661434 hw_loss 0.242827 lr 0.00039409 rank 1
2023-02-22 12:07:28,775 DEBUG TRAIN Batch 19/2600 loss 9.216521 loss_att 12.295996 loss_ctc 13.505171 loss_rnnt 7.820328 hw_loss 0.390896 lr 0.00039395 rank 2
2023-02-22 12:07:28,775 DEBUG TRAIN Batch 19/2600 loss 3.260508 loss_att 7.510077 loss_ctc 5.036434 loss_rnnt 2.022104 hw_loss 0.284437 lr 0.00039394 rank 3
2023-02-22 12:07:28,780 DEBUG TRAIN Batch 19/2600 loss 7.378978 loss_att 11.106454 loss_ctc 11.033816 loss_rnnt 5.903165 hw_loss 0.455635 lr 0.00039400 rank 4
2023-02-22 12:07:28,780 DEBUG TRAIN Batch 19/2600 loss 7.946436 loss_att 9.359591 loss_ctc 8.358572 loss_rnnt 7.448230 hw_loss 0.301169 lr 0.00039398 rank 5
2023-02-22 12:07:28,781 DEBUG TRAIN Batch 19/2600 loss 6.207313 loss_att 7.464290 loss_ctc 8.693803 loss_rnnt 5.401779 hw_loss 0.417386 lr 0.00039397 rank 1
2023-02-22 12:07:28,782 DEBUG TRAIN Batch 19/2600 loss 7.606405 loss_att 6.946015 loss_ctc 8.343882 loss_rnnt 7.283390 hw_loss 0.668931 lr 0.00039402 rank 0
2023-02-22 12:07:28,786 DEBUG TRAIN Batch 19/2600 loss 9.220317 loss_att 11.423946 loss_ctc 15.091743 loss_rnnt 7.812169 hw_loss 0.346057 lr 0.00039392 rank 6
2023-02-22 12:07:28,831 DEBUG TRAIN Batch 19/2600 loss 8.330198 loss_att 10.117848 loss_ctc 10.205489 loss_rnnt 7.556347 hw_loss 0.311780 lr 0.00039391 rank 7
2023-02-22 12:08:41,348 DEBUG TRAIN Batch 19/2700 loss 4.989658 loss_att 8.179132 loss_ctc 6.311198 loss_rnnt 4.066106 hw_loss 0.205224 lr 0.00039382 rank 3
2023-02-22 12:08:41,352 DEBUG TRAIN Batch 19/2700 loss 3.041369 loss_att 5.648144 loss_ctc 5.732348 loss_rnnt 2.039556 hw_loss 0.228113 lr 0.00039383 rank 2
2023-02-22 12:08:41,354 DEBUG TRAIN Batch 19/2700 loss 10.912543 loss_att 14.463280 loss_ctc 18.514769 loss_rnnt 9.044040 hw_loss 0.271364 lr 0.00039380 rank 6
2023-02-22 12:08:41,354 DEBUG TRAIN Batch 19/2700 loss 1.806721 loss_att 4.319912 loss_ctc 2.868029 loss_rnnt 1.038488 hw_loss 0.232663 lr 0.00039385 rank 1
2023-02-22 12:08:41,354 DEBUG TRAIN Batch 19/2700 loss 12.624004 loss_att 16.903133 loss_ctc 18.435085 loss_rnnt 10.762897 hw_loss 0.432133 lr 0.00039386 rank 5
2023-02-22 12:08:41,360 DEBUG TRAIN Batch 19/2700 loss 3.538501 loss_att 6.964229 loss_ctc 6.359607 loss_rnnt 2.347987 hw_loss 0.242290 lr 0.00039379 rank 7
2023-02-22 12:08:41,360 DEBUG TRAIN Batch 19/2700 loss 4.128307 loss_att 6.097287 loss_ctc 6.274506 loss_rnnt 3.368279 hw_loss 0.150136 lr 0.00039390 rank 0
2023-02-22 12:08:41,396 DEBUG TRAIN Batch 19/2700 loss 8.166142 loss_att 11.899889 loss_ctc 13.287898 loss_rnnt 6.664905 hw_loss 0.134226 lr 0.00039388 rank 4
2023-02-22 12:09:55,168 DEBUG TRAIN Batch 19/2800 loss 7.817877 loss_att 13.568405 loss_ctc 13.175024 loss_rnnt 5.836634 hw_loss 0.219096 lr 0.00039371 rank 2
2023-02-22 12:09:55,167 DEBUG TRAIN Batch 19/2800 loss 4.320783 loss_att 6.769619 loss_ctc 4.912251 loss_rnnt 3.615874 hw_loss 0.255524 lr 0.00039366 rank 7
2023-02-22 12:09:55,167 DEBUG TRAIN Batch 19/2800 loss 11.843229 loss_att 14.572803 loss_ctc 20.771080 loss_rnnt 9.992764 hw_loss 0.214070 lr 0.00039378 rank 0
2023-02-22 12:09:55,173 DEBUG TRAIN Batch 19/2800 loss 20.808613 loss_att 21.687349 loss_ctc 26.801716 loss_rnnt 19.658714 hw_loss 0.328254 lr 0.00039368 rank 6
2023-02-22 12:09:55,175 DEBUG TRAIN Batch 19/2800 loss 15.355501 loss_att 17.601349 loss_ctc 21.159077 loss_rnnt 14.004417 hw_loss 0.240194 lr 0.00039370 rank 3
2023-02-22 12:09:55,183 DEBUG TRAIN Batch 19/2800 loss 9.934626 loss_att 11.573422 loss_ctc 12.218937 loss_rnnt 9.114085 hw_loss 0.352889 lr 0.00039376 rank 4
2023-02-22 12:09:55,191 DEBUG TRAIN Batch 19/2800 loss 8.034188 loss_att 11.601772 loss_ctc 16.908909 loss_rnnt 6.046869 hw_loss 0.169700 lr 0.00039373 rank 5
2023-02-22 12:09:55,235 DEBUG TRAIN Batch 19/2800 loss 12.150816 loss_att 14.544003 loss_ctc 17.714771 loss_rnnt 10.758877 hw_loss 0.321453 lr 0.00039373 rank 1
2023-02-22 12:11:08,431 DEBUG TRAIN Batch 19/2900 loss 10.399702 loss_att 12.405792 loss_ctc 15.779139 loss_rnnt 9.154543 hw_loss 0.237531 lr 0.00039359 rank 2
2023-02-22 12:11:08,433 DEBUG TRAIN Batch 19/2900 loss 7.964223 loss_att 10.454364 loss_ctc 9.476897 loss_rnnt 7.113557 hw_loss 0.283027 lr 0.00039364 rank 4
2023-02-22 12:11:08,436 DEBUG TRAIN Batch 19/2900 loss 5.627448 loss_att 8.657318 loss_ctc 6.590376 loss_rnnt 4.772091 hw_loss 0.226860 lr 0.00039358 rank 3
2023-02-22 12:11:08,436 DEBUG TRAIN Batch 19/2900 loss 11.367812 loss_att 13.595074 loss_ctc 16.024769 loss_rnnt 10.120104 hw_loss 0.339991 lr 0.00039361 rank 5
2023-02-22 12:11:08,436 DEBUG TRAIN Batch 19/2900 loss 4.816478 loss_att 7.334638 loss_ctc 8.590752 loss_rnnt 3.732713 hw_loss 0.144182 lr 0.00039360 rank 1
2023-02-22 12:11:08,437 DEBUG TRAIN Batch 19/2900 loss 14.048310 loss_att 16.143702 loss_ctc 23.537745 loss_rnnt 12.263601 hw_loss 0.188199 lr 0.00039356 rank 6
2023-02-22 12:11:08,441 DEBUG TRAIN Batch 19/2900 loss 10.591242 loss_att 13.879960 loss_ctc 15.119564 loss_rnnt 9.171473 hw_loss 0.296718 lr 0.00039366 rank 0
2023-02-22 12:11:08,445 DEBUG TRAIN Batch 19/2900 loss 13.372375 loss_att 16.925045 loss_ctc 18.070147 loss_rnnt 11.929362 hw_loss 0.198953 lr 0.00039354 rank 7
2023-02-22 12:12:21,752 DEBUG TRAIN Batch 19/3000 loss 5.480447 loss_att 7.160481 loss_ctc 6.195367 loss_rnnt 4.855050 hw_loss 0.363876 lr 0.00039347 rank 2
2023-02-22 12:12:21,753 DEBUG TRAIN Batch 19/3000 loss 9.557597 loss_att 12.030285 loss_ctc 16.856199 loss_rnnt 7.961686 hw_loss 0.240425 lr 0.00039352 rank 4
2023-02-22 12:12:21,753 DEBUG TRAIN Batch 19/3000 loss 7.893489 loss_att 12.125006 loss_ctc 13.635092 loss_rnnt 6.121417 hw_loss 0.300417 lr 0.00039343 rank 6
2023-02-22 12:12:21,753 DEBUG TRAIN Batch 19/3000 loss 8.627400 loss_att 10.297515 loss_ctc 11.451269 loss_rnnt 7.695480 hw_loss 0.415089 lr 0.00039345 rank 3
2023-02-22 12:12:21,755 DEBUG TRAIN Batch 19/3000 loss 5.606263 loss_att 9.222736 loss_ctc 7.843433 loss_rnnt 4.392243 hw_loss 0.360817 lr 0.00039348 rank 1
2023-02-22 12:12:21,757 DEBUG TRAIN Batch 19/3000 loss 13.321892 loss_att 15.931744 loss_ctc 19.618490 loss_rnnt 11.822561 hw_loss 0.258401 lr 0.00039353 rank 0
2023-02-22 12:12:21,760 DEBUG TRAIN Batch 19/3000 loss 5.474391 loss_att 9.148837 loss_ctc 8.755412 loss_rnnt 4.146930 hw_loss 0.290816 lr 0.00039349 rank 5
2023-02-22 12:12:21,812 DEBUG TRAIN Batch 19/3000 loss 12.045772 loss_att 16.268913 loss_ctc 15.495874 loss_rnnt 10.535296 hw_loss 0.385937 lr 0.00039342 rank 7
2023-02-22 12:13:34,663 DEBUG TRAIN Batch 19/3100 loss 6.847183 loss_att 8.157722 loss_ctc 7.879416 loss_rnnt 6.300795 hw_loss 0.274967 lr 0.00039339 rank 4
2023-02-22 12:13:34,669 DEBUG TRAIN Batch 19/3100 loss 7.389552 loss_att 9.560146 loss_ctc 10.105576 loss_rnnt 6.408582 hw_loss 0.346339 lr 0.00039331 rank 6
2023-02-22 12:13:34,673 DEBUG TRAIN Batch 19/3100 loss 12.974704 loss_att 15.225433 loss_ctc 17.755157 loss_rnnt 11.739574 hw_loss 0.276730 lr 0.00039336 rank 1
2023-02-22 12:13:34,674 DEBUG TRAIN Batch 19/3100 loss 17.388432 loss_att 21.230951 loss_ctc 28.499435 loss_rnnt 15.003648 hw_loss 0.252771 lr 0.00039334 rank 2
2023-02-22 12:13:34,674 DEBUG TRAIN Batch 19/3100 loss 18.345188 loss_att 19.638285 loss_ctc 26.247787 loss_rnnt 16.909098 hw_loss 0.232105 lr 0.00039330 rank 7
2023-02-22 12:13:34,676 DEBUG TRAIN Batch 19/3100 loss 5.487603 loss_att 7.475941 loss_ctc 8.959114 loss_rnnt 4.544434 hw_loss 0.154939 lr 0.00039333 rank 3
2023-02-22 12:13:34,682 DEBUG TRAIN Batch 19/3100 loss 10.755010 loss_att 13.294004 loss_ctc 20.842203 loss_rnnt 8.650130 hw_loss 0.472730 lr 0.00039341 rank 0
2023-02-22 12:13:34,682 DEBUG TRAIN Batch 19/3100 loss 8.410336 loss_att 9.360844 loss_ctc 8.459430 loss_rnnt 8.093977 hw_loss 0.224456 lr 0.00039337 rank 5
2023-02-22 12:14:49,779 DEBUG TRAIN Batch 19/3200 loss 4.080936 loss_att 7.198169 loss_ctc 5.661141 loss_rnnt 3.015686 hw_loss 0.433331 lr 0.00039321 rank 3
2023-02-22 12:14:49,782 DEBUG TRAIN Batch 19/3200 loss 5.944631 loss_att 7.276960 loss_ctc 7.869894 loss_rnnt 5.174620 hw_loss 0.462833 lr 0.00039322 rank 2
2023-02-22 12:14:49,785 DEBUG TRAIN Batch 19/3200 loss 13.510138 loss_att 15.280886 loss_ctc 14.639496 loss_rnnt 12.775774 hw_loss 0.430560 lr 0.00039324 rank 1
2023-02-22 12:14:49,787 DEBUG TRAIN Batch 19/3200 loss 10.303920 loss_att 12.591393 loss_ctc 23.018295 loss_rnnt 8.052918 hw_loss 0.184232 lr 0.00039319 rank 6
2023-02-22 12:14:49,786 DEBUG TRAIN Batch 19/3200 loss 3.758929 loss_att 7.460171 loss_ctc 4.148121 loss_rnnt 2.879444 hw_loss 0.163771 lr 0.00039318 rank 7
2023-02-22 12:14:49,788 DEBUG TRAIN Batch 19/3200 loss 9.249365 loss_att 10.147375 loss_ctc 10.285038 loss_rnnt 8.803835 hw_loss 0.239696 lr 0.00039325 rank 5
2023-02-22 12:14:49,789 DEBUG TRAIN Batch 19/3200 loss 14.113933 loss_att 13.501837 loss_ctc 16.595621 loss_rnnt 13.578638 hw_loss 0.612791 lr 0.00039327 rank 4
2023-02-22 12:14:49,830 DEBUG TRAIN Batch 19/3200 loss 8.881427 loss_att 11.238255 loss_ctc 10.374344 loss_rnnt 8.086020 hw_loss 0.234347 lr 0.00039329 rank 0
2023-02-22 12:16:02,826 DEBUG TRAIN Batch 19/3300 loss 13.410792 loss_att 16.209381 loss_ctc 21.086235 loss_rnnt 11.725245 hw_loss 0.192070 lr 0.00039310 rank 2
2023-02-22 12:16:02,826 DEBUG TRAIN Batch 19/3300 loss 5.769320 loss_att 7.911202 loss_ctc 5.550239 loss_rnnt 5.227437 hw_loss 0.267597 lr 0.00039309 rank 3
2023-02-22 12:16:02,828 DEBUG TRAIN Batch 19/3300 loss 9.281643 loss_att 10.328966 loss_ctc 12.241386 loss_rnnt 8.444895 hw_loss 0.436221 lr 0.00039305 rank 7
2023-02-22 12:16:02,830 DEBUG TRAIN Batch 19/3300 loss 11.931555 loss_att 12.694585 loss_ctc 18.030022 loss_rnnt 10.758578 hw_loss 0.388576 lr 0.00039315 rank 4
2023-02-22 12:16:02,831 DEBUG TRAIN Batch 19/3300 loss 12.879043 loss_att 16.238064 loss_ctc 18.422894 loss_rnnt 11.239449 hw_loss 0.428644 lr 0.00039312 rank 5
2023-02-22 12:16:02,832 DEBUG TRAIN Batch 19/3300 loss 8.887627 loss_att 8.594133 loss_ctc 11.003615 loss_rnnt 8.343429 hw_loss 0.601436 lr 0.00039312 rank 1
2023-02-22 12:16:02,835 DEBUG TRAIN Batch 19/3300 loss 11.973851 loss_att 16.396133 loss_ctc 16.349405 loss_rnnt 10.338030 hw_loss 0.314919 lr 0.00039307 rank 6
2023-02-22 12:16:02,836 DEBUG TRAIN Batch 19/3300 loss 14.964160 loss_att 16.478781 loss_ctc 17.083355 loss_rnnt 14.296667 hw_loss 0.153768 lr 0.00039317 rank 0
2023-02-22 12:17:14,966 DEBUG TRAIN Batch 19/3400 loss 5.628762 loss_att 8.566384 loss_ctc 6.132225 loss_rnnt 4.873366 hw_loss 0.188893 lr 0.00039298 rank 2
2023-02-22 12:17:14,969 DEBUG TRAIN Batch 19/3400 loss 16.571253 loss_att 21.671667 loss_ctc 22.020512 loss_rnnt 14.689467 hw_loss 0.253375 lr 0.00039295 rank 6
2023-02-22 12:17:14,972 DEBUG TRAIN Batch 19/3400 loss 5.356898 loss_att 7.541667 loss_ctc 10.090456 loss_rnnt 4.183245 hw_loss 0.197923 lr 0.00039297 rank 3
2023-02-22 12:17:14,972 DEBUG TRAIN Batch 19/3400 loss 9.404860 loss_att 11.437372 loss_ctc 9.364187 loss_rnnt 8.876220 hw_loss 0.239178 lr 0.00039299 rank 1
2023-02-22 12:17:14,974 DEBUG TRAIN Batch 19/3400 loss 20.299603 loss_att 20.191402 loss_ctc 34.921062 loss_rnnt 18.304932 hw_loss 0.125219 lr 0.00039303 rank 4
2023-02-22 12:17:14,974 DEBUG TRAIN Batch 19/3400 loss 7.441097 loss_att 12.268300 loss_ctc 12.948784 loss_rnnt 5.657398 hw_loss 0.157312 lr 0.00039305 rank 0
2023-02-22 12:17:14,977 DEBUG TRAIN Batch 19/3400 loss 12.354694 loss_att 16.066576 loss_ctc 13.142521 loss_rnnt 11.381727 hw_loss 0.235401 lr 0.00039293 rank 7
2023-02-22 12:17:15,027 DEBUG TRAIN Batch 19/3400 loss 7.003479 loss_att 11.219213 loss_ctc 7.794819 loss_rnnt 5.924053 hw_loss 0.245186 lr 0.00039300 rank 5
2023-02-22 12:18:28,197 DEBUG TRAIN Batch 19/3500 loss 20.144184 loss_att 23.558601 loss_ctc 31.933519 loss_rnnt 17.747658 hw_loss 0.265747 lr 0.00039281 rank 7
2023-02-22 12:18:28,207 DEBUG TRAIN Batch 19/3500 loss 9.341556 loss_att 11.001287 loss_ctc 10.882675 loss_rnnt 8.758972 hw_loss 0.084665 lr 0.00039285 rank 3
2023-02-22 12:18:28,208 DEBUG TRAIN Batch 19/3500 loss 6.361339 loss_att 10.283410 loss_ctc 10.756629 loss_rnnt 4.799170 hw_loss 0.359468 lr 0.00039287 rank 1
2023-02-22 12:18:28,210 DEBUG TRAIN Batch 19/3500 loss 8.243766 loss_att 12.497951 loss_ctc 10.971060 loss_rnnt 6.906952 hw_loss 0.229384 lr 0.00039286 rank 2
2023-02-22 12:18:28,214 DEBUG TRAIN Batch 19/3500 loss 6.802051 loss_att 9.817185 loss_ctc 7.721040 loss_rnnt 5.941530 hw_loss 0.253053 lr 0.00039293 rank 0
2023-02-22 12:18:28,214 DEBUG TRAIN Batch 19/3500 loss 2.162193 loss_att 5.064861 loss_ctc 3.585202 loss_rnnt 1.162589 hw_loss 0.430005 lr 0.00039288 rank 5
2023-02-22 12:18:28,215 DEBUG TRAIN Batch 19/3500 loss 16.841547 loss_att 18.915857 loss_ctc 21.746389 loss_rnnt 15.690929 hw_loss 0.153334 lr 0.00039283 rank 6
2023-02-22 12:18:28,231 DEBUG TRAIN Batch 19/3500 loss 9.651525 loss_att 13.072454 loss_ctc 11.455525 loss_rnnt 8.523560 hw_loss 0.381089 lr 0.00039291 rank 4
2023-02-22 12:19:42,094 DEBUG TRAIN Batch 19/3600 loss 4.973520 loss_att 8.256346 loss_ctc 6.584318 loss_rnnt 3.982750 hw_loss 0.223934 lr 0.00039279 rank 4
2023-02-22 12:19:42,097 DEBUG TRAIN Batch 19/3600 loss 3.840102 loss_att 6.732279 loss_ctc 5.773702 loss_rnnt 2.883563 hw_loss 0.225544 lr 0.00039274 rank 2
2023-02-22 12:19:42,099 DEBUG TRAIN Batch 19/3600 loss 7.844682 loss_att 9.153950 loss_ctc 7.571708 loss_rnnt 7.513628 hw_loss 0.197993 lr 0.00039269 rank 7
2023-02-22 12:19:42,099 DEBUG TRAIN Batch 19/3600 loss 10.810665 loss_att 14.148867 loss_ctc 14.055110 loss_rnnt 9.608905 hw_loss 0.190363 lr 0.00039273 rank 3
2023-02-22 12:19:42,101 DEBUG TRAIN Batch 19/3600 loss 9.585083 loss_att 10.604343 loss_ctc 13.945845 loss_rnnt 8.644648 hw_loss 0.290901 lr 0.00039271 rank 6
2023-02-22 12:19:42,101 DEBUG TRAIN Batch 19/3600 loss 4.130642 loss_att 7.102055 loss_ctc 4.248412 loss_rnnt 3.317254 hw_loss 0.381381 lr 0.00039275 rank 1
2023-02-22 12:19:42,103 DEBUG TRAIN Batch 19/3600 loss 16.447384 loss_att 16.631435 loss_ctc 22.371012 loss_rnnt 15.517300 hw_loss 0.193980 lr 0.00039281 rank 0
2023-02-22 12:19:42,104 DEBUG TRAIN Batch 19/3600 loss 11.031475 loss_att 13.885468 loss_ctc 15.105381 loss_rnnt 9.812004 hw_loss 0.197785 lr 0.00039276 rank 5
2023-02-22 12:20:54,011 DEBUG TRAIN Batch 19/3700 loss 5.117042 loss_att 8.765440 loss_ctc 9.143777 loss_rnnt 3.697046 hw_loss 0.287659 lr 0.00039268 rank 0
2023-02-22 12:20:54,013 DEBUG TRAIN Batch 19/3700 loss 6.077537 loss_att 8.395133 loss_ctc 7.729326 loss_rnnt 5.225440 hw_loss 0.315636 lr 0.00039263 rank 1
2023-02-22 12:20:54,014 DEBUG TRAIN Batch 19/3700 loss 11.588532 loss_att 12.900919 loss_ctc 14.565545 loss_rnnt 10.709273 hw_loss 0.412213 lr 0.00039262 rank 2
2023-02-22 12:20:54,016 DEBUG TRAIN Batch 19/3700 loss 9.916379 loss_att 11.810875 loss_ctc 14.357080 loss_rnnt 8.750340 hw_loss 0.365709 lr 0.00039260 rank 3
2023-02-22 12:20:54,017 DEBUG TRAIN Batch 19/3700 loss 6.741076 loss_att 9.793713 loss_ctc 11.759300 loss_rnnt 5.262622 hw_loss 0.372804 lr 0.00039259 rank 6
2023-02-22 12:20:54,020 DEBUG TRAIN Batch 19/3700 loss 7.026168 loss_att 10.202023 loss_ctc 10.648528 loss_rnnt 5.719894 hw_loss 0.352729 lr 0.00039257 rank 7
2023-02-22 12:20:54,022 DEBUG TRAIN Batch 19/3700 loss 14.563010 loss_att 15.989206 loss_ctc 23.826637 loss_rnnt 12.885651 hw_loss 0.294317 lr 0.00039267 rank 4
2023-02-22 12:20:54,022 DEBUG TRAIN Batch 19/3700 loss 8.397426 loss_att 10.157430 loss_ctc 9.095950 loss_rnnt 7.763204 hw_loss 0.354533 lr 0.00039264 rank 5
2023-02-22 12:22:06,421 DEBUG TRAIN Batch 19/3800 loss 7.700456 loss_att 8.741142 loss_ctc 12.104109 loss_rnnt 6.743570 hw_loss 0.302990 lr 0.00039249 rank 2
2023-02-22 12:22:06,424 DEBUG TRAIN Batch 19/3800 loss 4.306143 loss_att 8.667627 loss_ctc 5.629817 loss_rnnt 3.166293 hw_loss 0.170744 lr 0.00039246 rank 6
2023-02-22 12:22:06,428 DEBUG TRAIN Batch 19/3800 loss 3.149466 loss_att 8.352016 loss_ctc 5.883635 loss_rnnt 1.683838 hw_loss 0.113553 lr 0.00039248 rank 3
2023-02-22 12:22:06,428 DEBUG TRAIN Batch 19/3800 loss 14.103768 loss_att 13.696516 loss_ctc 17.703527 loss_rnnt 13.417260 hw_loss 0.539983 lr 0.00039245 rank 7
2023-02-22 12:22:06,431 DEBUG TRAIN Batch 19/3800 loss 11.700362 loss_att 12.128871 loss_ctc 15.136912 loss_rnnt 11.039603 hw_loss 0.219094 lr 0.00039254 rank 4
2023-02-22 12:22:06,432 DEBUG TRAIN Batch 19/3800 loss 7.829198 loss_att 8.965268 loss_ctc 10.433431 loss_rnnt 7.079805 hw_loss 0.328029 lr 0.00039256 rank 0
2023-02-22 12:22:06,433 DEBUG TRAIN Batch 19/3800 loss 10.350801 loss_att 11.959440 loss_ctc 11.485824 loss_rnnt 9.756136 hw_loss 0.228001 lr 0.00039252 rank 5
2023-02-22 12:22:06,440 DEBUG TRAIN Batch 19/3800 loss 10.763073 loss_att 13.414218 loss_ctc 11.614243 loss_rnnt 9.963412 hw_loss 0.292392 lr 0.00039251 rank 1
2023-02-22 12:23:21,878 DEBUG TRAIN Batch 19/3900 loss 9.299408 loss_att 11.946556 loss_ctc 12.166553 loss_rnnt 8.320554 hw_loss 0.125884 lr 0.00039237 rank 2
2023-02-22 12:23:21,881 DEBUG TRAIN Batch 19/3900 loss 6.847785 loss_att 7.751803 loss_ctc 7.776376 loss_rnnt 6.484749 hw_loss 0.109540 lr 0.00039236 rank 3
2023-02-22 12:23:21,882 DEBUG TRAIN Batch 19/3900 loss 7.509778 loss_att 11.994378 loss_ctc 10.788460 loss_rnnt 6.055574 hw_loss 0.225236 lr 0.00039242 rank 4
2023-02-22 12:23:21,882 DEBUG TRAIN Batch 19/3900 loss 5.625386 loss_att 9.101609 loss_ctc 8.651497 loss_rnnt 4.394229 hw_loss 0.248307 lr 0.00039233 rank 7
2023-02-22 12:23:21,883 DEBUG TRAIN Batch 19/3900 loss 9.775692 loss_att 13.507454 loss_ctc 12.726110 loss_rnnt 8.498713 hw_loss 0.257319 lr 0.00039240 rank 5
2023-02-22 12:23:21,884 DEBUG TRAIN Batch 19/3900 loss 10.099897 loss_att 15.026310 loss_ctc 12.690245 loss_rnnt 8.595575 hw_loss 0.325612 lr 0.00039244 rank 0
2023-02-22 12:23:21,885 DEBUG TRAIN Batch 19/3900 loss 6.609746 loss_att 12.057617 loss_ctc 9.505201 loss_rnnt 5.033566 hw_loss 0.188522 lr 0.00039234 rank 6
2023-02-22 12:23:21,911 DEBUG TRAIN Batch 19/3900 loss 7.400149 loss_att 8.199434 loss_ctc 10.898286 loss_rnnt 6.483796 hw_loss 0.543894 lr 0.00039239 rank 1
2023-02-22 12:24:35,139 DEBUG TRAIN Batch 19/4000 loss 12.121114 loss_att 13.938574 loss_ctc 18.212379 loss_rnnt 10.730141 hw_loss 0.403711 lr 0.00039221 rank 7
2023-02-22 12:24:35,139 DEBUG TRAIN Batch 19/4000 loss 11.331513 loss_att 12.971072 loss_ctc 15.373096 loss_rnnt 10.337836 hw_loss 0.237914 lr 0.00039225 rank 2
2023-02-22 12:24:35,139 DEBUG TRAIN Batch 19/4000 loss 5.631420 loss_att 9.445590 loss_ctc 8.571142 loss_rnnt 4.311946 hw_loss 0.308769 lr 0.00039224 rank 3
2023-02-22 12:24:35,139 DEBUG TRAIN Batch 19/4000 loss 2.871139 loss_att 7.276757 loss_ctc 4.655365 loss_rnnt 1.527050 hw_loss 0.422005 lr 0.00039222 rank 6
2023-02-22 12:24:35,144 DEBUG TRAIN Batch 19/4000 loss 11.877876 loss_att 14.490517 loss_ctc 21.084105 loss_rnnt 10.061205 hw_loss 0.124962 lr 0.00039230 rank 4
2023-02-22 12:24:35,145 DEBUG TRAIN Batch 19/4000 loss 22.258734 loss_att 27.927292 loss_ctc 27.106468 loss_rnnt 20.316574 hw_loss 0.303902 lr 0.00039232 rank 0
2023-02-22 12:24:35,150 DEBUG TRAIN Batch 19/4000 loss 14.688354 loss_att 18.401913 loss_ctc 20.565443 loss_rnnt 13.034212 hw_loss 0.239658 lr 0.00039228 rank 5
2023-02-22 12:24:35,193 DEBUG TRAIN Batch 19/4000 loss 8.536800 loss_att 11.025230 loss_ctc 12.900584 loss_rnnt 7.316446 hw_loss 0.264059 lr 0.00039227 rank 1
2023-02-22 12:25:47,757 DEBUG TRAIN Batch 19/4100 loss 12.242457 loss_att 14.108169 loss_ctc 21.821083 loss_rnnt 10.403313 hw_loss 0.354100 lr 0.00039213 rank 2
2023-02-22 12:25:47,759 DEBUG TRAIN Batch 19/4100 loss 6.034343 loss_att 9.383091 loss_ctc 10.735712 loss_rnnt 4.644456 hw_loss 0.174916 lr 0.00039209 rank 7
2023-02-22 12:25:47,760 DEBUG TRAIN Batch 19/4100 loss 15.289169 loss_att 17.613569 loss_ctc 19.387165 loss_rnnt 14.195174 hw_loss 0.155092 lr 0.00039212 rank 3
2023-02-22 12:25:47,762 DEBUG TRAIN Batch 19/4100 loss 4.600138 loss_att 7.277565 loss_ctc 10.352519 loss_rnnt 3.225334 hw_loss 0.135627 lr 0.00039210 rank 6
2023-02-22 12:25:47,763 DEBUG TRAIN Batch 19/4100 loss 11.082170 loss_att 13.453201 loss_ctc 14.303451 loss_rnnt 10.019748 hw_loss 0.297584 lr 0.00039216 rank 5
2023-02-22 12:25:47,766 DEBUG TRAIN Batch 19/4100 loss 11.252184 loss_att 15.909025 loss_ctc 14.174720 loss_rnnt 9.862550 hw_loss 0.128612 lr 0.00039220 rank 0
2023-02-22 12:25:47,767 DEBUG TRAIN Batch 19/4100 loss 4.579102 loss_att 6.988099 loss_ctc 4.163656 loss_rnnt 4.031632 hw_loss 0.226993 lr 0.00039215 rank 1
2023-02-22 12:25:47,818 DEBUG TRAIN Batch 19/4100 loss 8.987035 loss_att 10.479954 loss_ctc 8.990664 loss_rnnt 8.538963 hw_loss 0.279381 lr 0.00039218 rank 4
2023-02-22 12:27:00,898 DEBUG TRAIN Batch 19/4200 loss 9.611342 loss_att 11.511580 loss_ctc 15.970809 loss_rnnt 8.268908 hw_loss 0.214609 lr 0.00039203 rank 1
2023-02-22 12:27:00,906 DEBUG TRAIN Batch 19/4200 loss 9.263821 loss_att 13.405735 loss_ctc 15.818727 loss_rnnt 7.411733 hw_loss 0.280719 lr 0.00039204 rank 5
2023-02-22 12:27:00,911 DEBUG TRAIN Batch 19/4200 loss 2.634613 loss_att 5.243183 loss_ctc 3.624386 loss_rnnt 1.847260 hw_loss 0.250631 lr 0.00039200 rank 3
2023-02-22 12:27:00,913 DEBUG TRAIN Batch 19/4200 loss 9.571921 loss_att 11.404414 loss_ctc 14.093909 loss_rnnt 8.494566 hw_loss 0.202360 lr 0.00039201 rank 2
2023-02-22 12:27:00,917 DEBUG TRAIN Batch 19/4200 loss 4.223371 loss_att 5.582543 loss_ctc 5.652371 loss_rnnt 3.609842 hw_loss 0.283425 lr 0.00039208 rank 0
2023-02-22 12:27:00,916 DEBUG TRAIN Batch 19/4200 loss 8.621974 loss_att 12.048872 loss_ctc 14.577524 loss_rnnt 6.996040 hw_loss 0.274651 lr 0.00039198 rank 6
2023-02-22 12:27:00,939 DEBUG TRAIN Batch 19/4200 loss 9.864191 loss_att 14.125809 loss_ctc 14.705686 loss_rnnt 8.243362 hw_loss 0.230571 lr 0.00039197 rank 7
2023-02-22 12:27:00,960 DEBUG TRAIN Batch 19/4200 loss 7.716838 loss_att 12.629173 loss_ctc 12.905563 loss_rnnt 5.952000 hw_loss 0.169764 lr 0.00039206 rank 4
2023-02-22 12:28:15,791 DEBUG TRAIN Batch 19/4300 loss 10.337618 loss_att 14.811882 loss_ctc 14.937162 loss_rnnt 8.719881 hw_loss 0.205522 lr 0.00039189 rank 2
2023-02-22 12:28:15,794 DEBUG TRAIN Batch 19/4300 loss 13.137013 loss_att 15.178224 loss_ctc 18.970615 loss_rnnt 11.690440 hw_loss 0.488472 lr 0.00039188 rank 3
2023-02-22 12:28:15,796 DEBUG TRAIN Batch 19/4300 loss 7.543399 loss_att 9.613396 loss_ctc 13.472743 loss_rnnt 6.201300 hw_loss 0.257851 lr 0.00039191 rank 1
2023-02-22 12:28:15,799 DEBUG TRAIN Batch 19/4300 loss 11.640797 loss_att 14.561207 loss_ctc 16.258007 loss_rnnt 10.137051 hw_loss 0.570065 lr 0.00039186 rank 6
2023-02-22 12:28:15,800 DEBUG TRAIN Batch 19/4300 loss 12.050104 loss_att 14.928182 loss_ctc 17.798054 loss_rnnt 10.577665 hw_loss 0.244555 lr 0.00039194 rank 4
2023-02-22 12:28:15,802 DEBUG TRAIN Batch 19/4300 loss 7.046257 loss_att 8.875416 loss_ctc 9.427694 loss_rnnt 6.194501 hw_loss 0.315748 lr 0.00039185 rank 7
2023-02-22 12:28:15,803 DEBUG TRAIN Batch 19/4300 loss 13.382689 loss_att 16.964636 loss_ctc 22.028791 loss_rnnt 11.429746 hw_loss 0.157016 lr 0.00039192 rank 5
2023-02-22 12:28:15,806 DEBUG TRAIN Batch 19/4300 loss 4.712014 loss_att 6.620005 loss_ctc 8.516693 loss_rnnt 3.583162 hw_loss 0.449931 lr 0.00039196 rank 0
2023-02-22 12:29:28,590 DEBUG TRAIN Batch 19/4400 loss 6.145377 loss_att 9.071885 loss_ctc 5.376911 loss_rnnt 5.503661 hw_loss 0.297895 lr 0.00039176 rank 3
2023-02-22 12:29:28,599 DEBUG TRAIN Batch 19/4400 loss 4.202125 loss_att 7.567634 loss_ctc 7.698968 loss_rnnt 3.000652 hw_loss 0.116485 lr 0.00039177 rank 2
2023-02-22 12:29:28,599 DEBUG TRAIN Batch 19/4400 loss 7.185524 loss_att 8.731990 loss_ctc 10.224683 loss_rnnt 6.295895 hw_loss 0.328340 lr 0.00039179 rank 5
2023-02-22 12:29:28,600 DEBUG TRAIN Batch 19/4400 loss 9.165483 loss_att 13.753540 loss_ctc 14.359776 loss_rnnt 7.312358 hw_loss 0.455517 lr 0.00039182 rank 4
2023-02-22 12:29:28,603 DEBUG TRAIN Batch 19/4400 loss 3.897385 loss_att 6.567226 loss_ctc 5.530930 loss_rnnt 2.887842 hw_loss 0.483317 lr 0.00039184 rank 0
2023-02-22 12:29:28,604 DEBUG TRAIN Batch 19/4400 loss 12.301840 loss_att 19.029268 loss_ctc 17.588051 loss_rnnt 10.153867 hw_loss 0.183110 lr 0.00039174 rank 6
2023-02-22 12:29:28,605 DEBUG TRAIN Batch 19/4400 loss 8.193527 loss_att 10.404498 loss_ctc 11.856886 loss_rnnt 7.037024 hw_loss 0.423488 lr 0.00039173 rank 7
2023-02-22 12:29:28,609 DEBUG TRAIN Batch 19/4400 loss 10.247547 loss_att 12.254402 loss_ctc 13.888771 loss_rnnt 9.216910 hw_loss 0.269569 lr 0.00039179 rank 1
2023-02-22 12:30:41,075 DEBUG TRAIN Batch 19/4500 loss 3.371327 loss_att 3.428887 loss_ctc 4.804467 loss_rnnt 3.009504 hw_loss 0.298547 lr 0.00039165 rank 2
2023-02-22 12:30:41,094 DEBUG TRAIN Batch 19/4500 loss 4.530511 loss_att 8.375256 loss_ctc 7.778354 loss_rnnt 3.207704 hw_loss 0.226524 lr 0.00039172 rank 0
2023-02-22 12:30:41,094 DEBUG TRAIN Batch 19/4500 loss 5.310457 loss_att 9.330091 loss_ctc 7.542048 loss_rnnt 4.132916 hw_loss 0.142628 lr 0.00039162 rank 6
2023-02-22 12:30:41,095 DEBUG TRAIN Batch 19/4500 loss 9.182104 loss_att 11.391435 loss_ctc 10.695407 loss_rnnt 8.377809 hw_loss 0.301229 lr 0.00039167 rank 5
2023-02-22 12:30:41,096 DEBUG TRAIN Batch 19/4500 loss 9.009559 loss_att 10.558561 loss_ctc 11.919688 loss_rnnt 8.135447 hw_loss 0.330551 lr 0.00039160 rank 7
2023-02-22 12:30:41,096 DEBUG TRAIN Batch 19/4500 loss 6.783336 loss_att 8.315523 loss_ctc 9.586568 loss_rnnt 5.878209 hw_loss 0.421734 lr 0.00039167 rank 1
2023-02-22 12:30:41,100 DEBUG TRAIN Batch 19/4500 loss 7.910246 loss_att 9.481651 loss_ctc 10.394722 loss_rnnt 7.082714 hw_loss 0.341226 lr 0.00039170 rank 4
2023-02-22 12:30:41,104 DEBUG TRAIN Batch 19/4500 loss 12.239278 loss_att 16.466686 loss_ctc 16.406574 loss_rnnt 10.693514 hw_loss 0.271202 lr 0.00039164 rank 3
2023-02-22 12:31:55,825 DEBUG TRAIN Batch 19/4600 loss 7.155713 loss_att 10.405935 loss_ctc 9.600357 loss_rnnt 6.014232 hw_loss 0.310283 lr 0.00039153 rank 2
2023-02-22 12:31:55,826 DEBUG TRAIN Batch 19/4600 loss 9.390016 loss_att 11.069969 loss_ctc 7.521858 loss_rnnt 9.127451 hw_loss 0.329367 lr 0.00039160 rank 0
2023-02-22 12:31:55,827 DEBUG TRAIN Batch 19/4600 loss 6.208407 loss_att 9.617994 loss_ctc 11.136581 loss_rnnt 4.715931 hw_loss 0.287755 lr 0.00039148 rank 7
2023-02-22 12:31:55,831 DEBUG TRAIN Batch 19/4600 loss 7.954830 loss_att 10.423757 loss_ctc 10.900401 loss_rnnt 6.934658 hw_loss 0.250582 lr 0.00039158 rank 4
2023-02-22 12:31:55,833 DEBUG TRAIN Batch 19/4600 loss 20.592009 loss_att 22.595222 loss_ctc 35.876244 loss_rnnt 18.046795 hw_loss 0.200008 lr 0.00039152 rank 3
2023-02-22 12:31:55,834 DEBUG TRAIN Batch 19/4600 loss 10.353168 loss_att 11.510818 loss_ctc 12.024105 loss_rnnt 9.741669 hw_loss 0.294709 lr 0.00039155 rank 5
2023-02-22 12:31:55,837 DEBUG TRAIN Batch 19/4600 loss 11.908628 loss_att 13.695818 loss_ctc 14.966014 loss_rnnt 11.060198 hw_loss 0.156263 lr 0.00039150 rank 6
2023-02-22 12:31:55,860 DEBUG TRAIN Batch 19/4600 loss 6.126894 loss_att 8.258135 loss_ctc 6.149526 loss_rnnt 5.525672 hw_loss 0.322417 lr 0.00039155 rank 1
2023-02-22 12:33:08,344 DEBUG TRAIN Batch 19/4700 loss 3.936549 loss_att 8.092278 loss_ctc 7.690180 loss_rnnt 2.434330 hw_loss 0.319854 lr 0.00039148 rank 0
2023-02-22 12:33:08,344 DEBUG TRAIN Batch 19/4700 loss 15.872184 loss_att 19.670206 loss_ctc 19.531187 loss_rnnt 14.467592 hw_loss 0.294600 lr 0.00039146 rank 4
2023-02-22 12:33:08,345 DEBUG TRAIN Batch 19/4700 loss 11.598693 loss_att 14.498337 loss_ctc 21.040680 loss_rnnt 9.706566 hw_loss 0.099876 lr 0.00039138 rank 6
2023-02-22 12:33:08,346 DEBUG TRAIN Batch 19/4700 loss 10.915739 loss_att 15.024578 loss_ctc 16.816744 loss_rnnt 9.151646 hw_loss 0.291609 lr 0.00039141 rank 2
2023-02-22 12:33:08,347 DEBUG TRAIN Batch 19/4700 loss 2.766742 loss_att 6.907801 loss_ctc 5.141134 loss_rnnt 1.478153 hw_loss 0.269610 lr 0.00039140 rank 3
2023-02-22 12:33:08,348 DEBUG TRAIN Batch 19/4700 loss 10.025198 loss_att 12.916245 loss_ctc 13.355299 loss_rnnt 8.827187 hw_loss 0.329604 lr 0.00039137 rank 7
2023-02-22 12:33:08,349 DEBUG TRAIN Batch 19/4700 loss 8.229522 loss_att 9.530951 loss_ctc 12.056189 loss_rnnt 7.367422 hw_loss 0.171734 lr 0.00039143 rank 1
2023-02-22 12:33:08,351 DEBUG TRAIN Batch 19/4700 loss 5.115317 loss_att 8.043852 loss_ctc 9.345454 loss_rnnt 3.806899 hw_loss 0.297550 lr 0.00039143 rank 5
2023-02-22 12:34:19,749 DEBUG TRAIN Batch 19/4800 loss 15.714032 loss_att 16.383348 loss_ctc 23.954302 loss_rnnt 14.335750 hw_loss 0.273218 lr 0.00039129 rank 2
2023-02-22 12:34:19,753 DEBUG TRAIN Batch 19/4800 loss 9.354991 loss_att 9.643520 loss_ctc 10.504443 loss_rnnt 8.986675 hw_loss 0.295029 lr 0.00039136 rank 0
2023-02-22 12:34:19,754 DEBUG TRAIN Batch 19/4800 loss 16.117012 loss_att 17.252428 loss_ctc 21.155321 loss_rnnt 15.095881 hw_loss 0.229262 lr 0.00039128 rank 3
2023-02-22 12:34:19,755 DEBUG TRAIN Batch 19/4800 loss 12.086746 loss_att 12.815957 loss_ctc 15.985102 loss_rnnt 11.256168 hw_loss 0.309292 lr 0.00039126 rank 6
2023-02-22 12:34:19,756 DEBUG TRAIN Batch 19/4800 loss 10.323279 loss_att 14.240465 loss_ctc 14.767029 loss_rnnt 8.892220 hw_loss 0.103358 lr 0.00039134 rank 4
2023-02-22 12:34:19,757 DEBUG TRAIN Batch 19/4800 loss 8.704036 loss_att 12.445153 loss_ctc 13.204315 loss_rnnt 7.202793 hw_loss 0.286841 lr 0.00039131 rank 1
2023-02-22 12:34:19,759 DEBUG TRAIN Batch 19/4800 loss 12.843629 loss_att 15.120026 loss_ctc 17.144642 loss_rnnt 11.663652 hw_loss 0.283554 lr 0.00039131 rank 5
2023-02-22 12:34:19,760 DEBUG TRAIN Batch 19/4800 loss 11.256949 loss_att 13.120882 loss_ctc 14.975077 loss_rnnt 10.284894 hw_loss 0.194096 lr 0.00039125 rank 7
2023-02-22 12:35:33,224 DEBUG TRAIN Batch 19/4900 loss 14.836035 loss_att 16.378700 loss_ctc 20.193171 loss_rnnt 13.647274 hw_loss 0.311144 lr 0.00039113 rank 7
2023-02-22 12:35:33,235 DEBUG TRAIN Batch 19/4900 loss 9.011787 loss_att 13.077807 loss_ctc 12.838744 loss_rnnt 7.501711 hw_loss 0.349895 lr 0.00039119 rank 5
2023-02-22 12:35:33,237 DEBUG TRAIN Batch 19/4900 loss 8.501773 loss_att 12.339670 loss_ctc 10.505986 loss_rnnt 7.338978 hw_loss 0.239976 lr 0.00039122 rank 4
2023-02-22 12:35:33,238 DEBUG TRAIN Batch 19/4900 loss 16.928402 loss_att 18.734209 loss_ctc 24.430500 loss_rnnt 15.415600 hw_loss 0.283800 lr 0.00039117 rank 2
2023-02-22 12:35:33,240 DEBUG TRAIN Batch 19/4900 loss 11.717707 loss_att 13.538971 loss_ctc 18.536079 loss_rnnt 10.297084 hw_loss 0.276102 lr 0.00039116 rank 3
2023-02-22 12:35:33,243 DEBUG TRAIN Batch 19/4900 loss 3.987146 loss_att 6.542696 loss_ctc 8.668636 loss_rnnt 2.682719 hw_loss 0.317097 lr 0.00039114 rank 6
2023-02-22 12:35:33,259 DEBUG TRAIN Batch 19/4900 loss 6.411677 loss_att 11.221792 loss_ctc 8.611078 loss_rnnt 5.065852 hw_loss 0.169779 lr 0.00039119 rank 1
2023-02-22 12:35:33,260 DEBUG TRAIN Batch 19/4900 loss 5.719263 loss_att 9.553167 loss_ctc 10.129869 loss_rnnt 4.205834 hw_loss 0.297311 lr 0.00039124 rank 0
2023-02-22 12:36:48,130 DEBUG TRAIN Batch 19/5000 loss 12.840665 loss_att 15.145618 loss_ctc 15.116343 loss_rnnt 11.950260 hw_loss 0.236232 lr 0.00039105 rank 2
2023-02-22 12:36:48,134 DEBUG TRAIN Batch 19/5000 loss 14.980741 loss_att 17.486153 loss_ctc 19.510153 loss_rnnt 13.696300 hw_loss 0.336444 lr 0.00039101 rank 7
2023-02-22 12:36:48,133 DEBUG TRAIN Batch 19/5000 loss 10.277134 loss_att 10.326919 loss_ctc 15.103912 loss_rnnt 9.494625 hw_loss 0.241840 lr 0.00039108 rank 5
2023-02-22 12:36:48,134 DEBUG TRAIN Batch 19/5000 loss 7.635058 loss_att 8.193816 loss_ctc 9.872912 loss_rnnt 7.045488 hw_loss 0.336445 lr 0.00039104 rank 3
2023-02-22 12:36:48,137 DEBUG TRAIN Batch 19/5000 loss 12.245814 loss_att 14.354054 loss_ctc 16.679867 loss_rnnt 11.121553 hw_loss 0.208883 lr 0.00039107 rank 1
2023-02-22 12:36:48,140 DEBUG TRAIN Batch 19/5000 loss 27.161980 loss_att 28.936905 loss_ctc 30.081047 loss_rnnt 26.308899 hw_loss 0.204162 lr 0.00039110 rank 4
2023-02-22 12:36:48,140 DEBUG TRAIN Batch 19/5000 loss 14.828627 loss_att 14.140882 loss_ctc 20.446236 loss_rnnt 14.106804 hw_loss 0.206918 lr 0.00039112 rank 0
2023-02-22 12:36:48,140 DEBUG TRAIN Batch 19/5000 loss 8.382600 loss_att 8.885412 loss_ctc 11.650677 loss_rnnt 7.655593 hw_loss 0.357564 lr 0.00039102 rank 6
2023-02-22 12:38:01,147 DEBUG TRAIN Batch 19/5100 loss 8.252774 loss_att 10.606805 loss_ctc 11.032252 loss_rnnt 7.306145 hw_loss 0.197299 lr 0.00039092 rank 3
2023-02-22 12:38:01,149 DEBUG TRAIN Batch 19/5100 loss 8.627206 loss_att 10.629006 loss_ctc 12.778762 loss_rnnt 7.501795 hw_loss 0.321580 lr 0.00039098 rank 4
2023-02-22 12:38:01,151 DEBUG TRAIN Batch 19/5100 loss 13.282532 loss_att 17.993818 loss_ctc 23.100914 loss_rnnt 10.897510 hw_loss 0.250591 lr 0.00039090 rank 6
2023-02-22 12:38:01,151 DEBUG TRAIN Batch 19/5100 loss 9.137708 loss_att 9.278696 loss_ctc 11.514090 loss_rnnt 8.608371 hw_loss 0.345540 lr 0.00039093 rank 2
2023-02-22 12:38:01,154 DEBUG TRAIN Batch 19/5100 loss 5.921303 loss_att 6.506940 loss_ctc 6.445760 loss_rnnt 5.521606 hw_loss 0.398704 lr 0.00039095 rank 1
2023-02-22 12:38:01,154 DEBUG TRAIN Batch 19/5100 loss 6.319838 loss_att 7.642999 loss_ctc 8.975571 loss_rnnt 5.509084 hw_loss 0.360045 lr 0.00039100 rank 0
2023-02-22 12:38:01,156 DEBUG TRAIN Batch 19/5100 loss 11.182155 loss_att 10.386664 loss_ctc 12.555687 loss_rnnt 10.892418 hw_loss 0.498182 lr 0.00039096 rank 5
2023-02-22 12:38:01,207 DEBUG TRAIN Batch 19/5100 loss 10.012704 loss_att 13.010573 loss_ctc 13.062865 loss_rnnt 8.921871 hw_loss 0.158570 lr 0.00039089 rank 7
2023-02-22 12:39:13,693 DEBUG TRAIN Batch 19/5200 loss 5.075694 loss_att 8.519732 loss_ctc 7.399576 loss_rnnt 4.001746 hw_loss 0.141168 lr 0.00039080 rank 3
2023-02-22 12:39:13,697 DEBUG TRAIN Batch 19/5200 loss 7.186465 loss_att 11.046833 loss_ctc 12.124656 loss_rnnt 5.647724 hw_loss 0.202955 lr 0.00039078 rank 6
2023-02-22 12:39:13,698 DEBUG TRAIN Batch 19/5200 loss 12.182029 loss_att 15.711684 loss_ctc 19.463921 loss_rnnt 10.243435 hw_loss 0.490770 lr 0.00039081 rank 2
2023-02-22 12:39:13,699 DEBUG TRAIN Batch 19/5200 loss 8.942524 loss_att 11.111597 loss_ctc 11.011809 loss_rnnt 8.149325 hw_loss 0.156525 lr 0.00039088 rank 0
2023-02-22 12:39:13,699 DEBUG TRAIN Batch 19/5200 loss 20.311714 loss_att 22.875452 loss_ctc 29.274052 loss_rnnt 18.452320 hw_loss 0.284378 lr 0.00039083 rank 1
2023-02-22 12:39:13,703 DEBUG TRAIN Batch 19/5200 loss 8.873962 loss_att 9.760946 loss_ctc 11.850430 loss_rnnt 8.084395 hw_loss 0.403702 lr 0.00039086 rank 4
2023-02-22 12:39:13,705 DEBUG TRAIN Batch 19/5200 loss 7.362885 loss_att 9.535461 loss_ctc 11.827375 loss_rnnt 6.222278 hw_loss 0.207800 lr 0.00039084 rank 5
2023-02-22 12:39:13,705 DEBUG TRAIN Batch 19/5200 loss 20.558176 loss_att 23.784264 loss_ctc 30.203215 loss_rnnt 18.569416 hw_loss 0.107881 lr 0.00039077 rank 7
2023-02-22 12:40:28,030 DEBUG TRAIN Batch 19/5300 loss 8.232611 loss_att 11.721219 loss_ctc 6.726797 loss_rnnt 7.568584 hw_loss 0.313275 lr 0.00039074 rank 4
2023-02-22 12:40:28,036 DEBUG TRAIN Batch 19/5300 loss 8.309366 loss_att 11.046024 loss_ctc 10.309418 loss_rnnt 7.364539 hw_loss 0.245289 lr 0.00039065 rank 7
2023-02-22 12:40:28,046 DEBUG TRAIN Batch 19/5300 loss 9.675467 loss_att 10.512572 loss_ctc 9.712473 loss_rnnt 9.276531 hw_loss 0.424841 lr 0.00039069 rank 2
2023-02-22 12:40:28,049 DEBUG TRAIN Batch 19/5300 loss 13.980596 loss_att 17.452963 loss_ctc 17.685486 loss_rnnt 12.635577 hw_loss 0.293549 lr 0.00039068 rank 3
2023-02-22 12:40:28,050 DEBUG TRAIN Batch 19/5300 loss 9.301590 loss_att 10.665683 loss_ctc 11.424055 loss_rnnt 8.689407 hw_loss 0.105692 lr 0.00039072 rank 5
2023-02-22 12:40:28,050 DEBUG TRAIN Batch 19/5300 loss 14.197473 loss_att 17.044371 loss_ctc 17.698566 loss_rnnt 12.969894 hw_loss 0.358848 lr 0.00039066 rank 6
2023-02-22 12:40:28,050 DEBUG TRAIN Batch 19/5300 loss 11.023602 loss_att 15.114403 loss_ctc 18.329100 loss_rnnt 9.079825 hw_loss 0.284156 lr 0.00039071 rank 1
2023-02-22 12:40:28,075 DEBUG TRAIN Batch 19/5300 loss 11.941442 loss_att 15.570848 loss_ctc 19.460041 loss_rnnt 10.069603 hw_loss 0.269022 lr 0.00039076 rank 0
2023-02-22 12:41:40,717 DEBUG TRAIN Batch 19/5400 loss 11.260807 loss_att 13.696805 loss_ctc 16.280388 loss_rnnt 9.910339 hw_loss 0.363734 lr 0.00039060 rank 5
2023-02-22 12:41:40,724 DEBUG TRAIN Batch 19/5400 loss 4.629578 loss_att 7.893085 loss_ctc 7.502441 loss_rnnt 3.545315 hw_loss 0.090961 lr 0.00039057 rank 2
2023-02-22 12:41:40,725 DEBUG TRAIN Batch 19/5400 loss 17.570011 loss_att 20.292894 loss_ctc 27.644497 loss_rnnt 15.589240 hw_loss 0.174241 lr 0.00039053 rank 7
2023-02-22 12:41:40,729 DEBUG TRAIN Batch 19/5400 loss 7.767078 loss_att 10.163963 loss_ctc 11.245164 loss_rnnt 6.711315 hw_loss 0.211202 lr 0.00039064 rank 0
2023-02-22 12:41:40,729 DEBUG TRAIN Batch 19/5400 loss 9.049391 loss_att 12.343115 loss_ctc 8.603641 loss_rnnt 8.326547 hw_loss 0.231623 lr 0.00039062 rank 4
2023-02-22 12:41:40,731 DEBUG TRAIN Batch 19/5400 loss 4.392986 loss_att 6.788424 loss_ctc 5.651657 loss_rnnt 3.646374 hw_loss 0.186939 lr 0.00039056 rank 3
2023-02-22 12:41:40,732 DEBUG TRAIN Batch 19/5400 loss 10.176640 loss_att 12.840121 loss_ctc 12.970939 loss_rnnt 9.161265 hw_loss 0.206446 lr 0.00039059 rank 1
2023-02-22 12:41:40,735 DEBUG TRAIN Batch 19/5400 loss 3.341532 loss_att 7.376173 loss_ctc 4.626005 loss_rnnt 2.270761 hw_loss 0.173586 lr 0.00039054 rank 6
2023-02-22 12:42:53,064 DEBUG TRAIN Batch 19/5500 loss 12.777104 loss_att 14.492156 loss_ctc 13.974381 loss_rnnt 12.082959 hw_loss 0.359059 lr 0.00039042 rank 6
2023-02-22 12:42:53,065 DEBUG TRAIN Batch 19/5500 loss 7.783707 loss_att 9.835087 loss_ctc 12.512228 loss_rnnt 6.609651 hw_loss 0.249958 lr 0.00039048 rank 5
2023-02-22 12:42:53,064 DEBUG TRAIN Batch 19/5500 loss 10.971869 loss_att 12.420156 loss_ctc 12.508307 loss_rnnt 10.406738 hw_loss 0.132404 lr 0.00039041 rank 7
2023-02-22 12:42:53,065 DEBUG TRAIN Batch 19/5500 loss 11.440818 loss_att 13.099640 loss_ctc 13.287249 loss_rnnt 10.708161 hw_loss 0.290064 lr 0.00039044 rank 3
2023-02-22 12:42:53,066 DEBUG TRAIN Batch 19/5500 loss 14.078010 loss_att 16.210909 loss_ctc 20.264156 loss_rnnt 12.708322 hw_loss 0.221789 lr 0.00039045 rank 2
2023-02-22 12:42:53,066 DEBUG TRAIN Batch 19/5500 loss 8.771369 loss_att 12.822880 loss_ctc 15.521786 loss_rnnt 6.885919 hw_loss 0.328298 lr 0.00039047 rank 1
2023-02-22 12:42:53,073 DEBUG TRAIN Batch 19/5500 loss 15.608855 loss_att 15.841835 loss_ctc 20.089455 loss_rnnt 14.831471 hw_loss 0.250078 lr 0.00039052 rank 0
2023-02-22 12:42:53,072 DEBUG TRAIN Batch 19/5500 loss 13.842204 loss_att 17.864731 loss_ctc 21.095985 loss_rnnt 11.948820 hw_loss 0.228204 lr 0.00039050 rank 4
2023-02-22 12:44:06,193 DEBUG TRAIN Batch 19/5600 loss 9.335011 loss_att 11.019628 loss_ctc 11.533949 loss_rnnt 8.567801 hw_loss 0.257053 lr 0.00039034 rank 2
2023-02-22 12:44:06,200 DEBUG TRAIN Batch 19/5600 loss 9.166912 loss_att 12.260927 loss_ctc 14.902817 loss_rnnt 7.624153 hw_loss 0.298440 lr 0.00039032 rank 3
2023-02-22 12:44:06,203 DEBUG TRAIN Batch 19/5600 loss 7.949625 loss_att 8.951945 loss_ctc 11.747954 loss_rnnt 7.182686 hw_loss 0.112559 lr 0.00039029 rank 7
2023-02-22 12:44:06,204 DEBUG TRAIN Batch 19/5600 loss 5.125618 loss_att 8.618179 loss_ctc 9.280572 loss_rnnt 3.738069 hw_loss 0.253205 lr 0.00039035 rank 1
2023-02-22 12:44:06,204 DEBUG TRAIN Batch 19/5600 loss 7.643482 loss_att 13.663065 loss_ctc 9.715439 loss_rnnt 6.001528 hw_loss 0.303330 lr 0.00039038 rank 4
2023-02-22 12:44:06,207 DEBUG TRAIN Batch 19/5600 loss 12.714063 loss_att 13.237082 loss_ctc 13.862219 loss_rnnt 12.294810 hw_loss 0.302927 lr 0.00039031 rank 6
2023-02-22 12:44:06,208 DEBUG TRAIN Batch 19/5600 loss 15.992414 loss_att 17.175243 loss_ctc 21.178228 loss_rnnt 14.912821 hw_loss 0.284222 lr 0.00039036 rank 5
2023-02-22 12:44:06,211 DEBUG TRAIN Batch 19/5600 loss 10.235617 loss_att 12.928039 loss_ctc 17.559196 loss_rnnt 8.628397 hw_loss 0.172982 lr 0.00039040 rank 0
2023-02-22 12:45:22,217 DEBUG TRAIN Batch 19/5700 loss 8.374494 loss_att 12.298000 loss_ctc 10.818703 loss_rnnt 7.215968 hw_loss 0.089871 lr 0.00039021 rank 3
2023-02-22 12:45:22,220 DEBUG TRAIN Batch 19/5700 loss 12.403837 loss_att 14.569503 loss_ctc 17.121933 loss_rnnt 11.217885 hw_loss 0.232009 lr 0.00039022 rank 2
2023-02-22 12:45:22,221 DEBUG TRAIN Batch 19/5700 loss 9.545335 loss_att 15.463217 loss_ctc 13.105576 loss_rnnt 7.671733 hw_loss 0.403737 lr 0.00039019 rank 6
2023-02-22 12:45:22,222 DEBUG TRAIN Batch 19/5700 loss 16.973169 loss_att 19.558994 loss_ctc 24.704550 loss_rnnt 15.354679 hw_loss 0.132137 lr 0.00039017 rank 7
2023-02-22 12:45:22,224 DEBUG TRAIN Batch 19/5700 loss 6.961317 loss_att 7.680835 loss_ctc 12.049926 loss_rnnt 6.014399 hw_loss 0.233498 lr 0.00039023 rank 1
2023-02-22 12:45:22,226 DEBUG TRAIN Batch 19/5700 loss 7.763040 loss_att 10.747499 loss_ctc 14.092405 loss_rnnt 6.192462 hw_loss 0.243320 lr 0.00039027 rank 4
2023-02-22 12:45:22,227 DEBUG TRAIN Batch 19/5700 loss 10.867507 loss_att 12.755272 loss_ctc 12.748985 loss_rnnt 9.988173 hw_loss 0.470469 lr 0.00039024 rank 5
2023-02-22 12:45:22,229 DEBUG TRAIN Batch 19/5700 loss 12.931190 loss_att 13.413088 loss_ctc 20.141567 loss_rnnt 11.746803 hw_loss 0.237421 lr 0.00039028 rank 0
2023-02-22 12:46:34,665 DEBUG TRAIN Batch 19/5800 loss 6.394694 loss_att 8.489508 loss_ctc 7.644355 loss_rnnt 5.666664 hw_loss 0.267086 lr 0.00039009 rank 3
2023-02-22 12:46:34,665 DEBUG TRAIN Batch 19/5800 loss 5.754967 loss_att 11.171806 loss_ctc 9.274891 loss_rnnt 4.042787 hw_loss 0.299041 lr 0.00039010 rank 2
2023-02-22 12:46:34,670 DEBUG TRAIN Batch 19/5800 loss 20.037474 loss_att 23.176283 loss_ctc 33.127602 loss_rnnt 17.558502 hw_loss 0.198488 lr 0.00039017 rank 0
2023-02-22 12:46:34,671 DEBUG TRAIN Batch 19/5800 loss 5.427756 loss_att 7.833893 loss_ctc 7.838945 loss_rnnt 4.480925 hw_loss 0.270211 lr 0.00039005 rank 7
2023-02-22 12:46:34,674 DEBUG TRAIN Batch 19/5800 loss 12.796668 loss_att 19.633186 loss_ctc 19.332500 loss_rnnt 10.442238 hw_loss 0.216904 lr 0.00039011 rank 1
2023-02-22 12:46:34,674 DEBUG TRAIN Batch 19/5800 loss 11.172162 loss_att 13.590039 loss_ctc 15.478423 loss_rnnt 9.930428 hw_loss 0.344985 lr 0.00039015 rank 4
2023-02-22 12:46:34,676 DEBUG TRAIN Batch 19/5800 loss 12.926044 loss_att 18.457016 loss_ctc 20.667921 loss_rnnt 10.541752 hw_loss 0.460961 lr 0.00039007 rank 6
2023-02-22 12:46:34,677 DEBUG TRAIN Batch 19/5800 loss 9.848923 loss_att 12.138973 loss_ctc 15.074860 loss_rnnt 8.623022 hw_loss 0.133309 lr 0.00039012 rank 5
2023-02-22 12:47:47,659 DEBUG TRAIN Batch 19/5900 loss 15.969978 loss_att 19.339085 loss_ctc 22.647919 loss_rnnt 14.320155 hw_loss 0.160521 lr 0.00038998 rank 2
2023-02-22 12:47:47,666 DEBUG TRAIN Batch 19/5900 loss 15.427704 loss_att 18.835274 loss_ctc 22.419346 loss_rnnt 13.686354 hw_loss 0.239281 lr 0.00038993 rank 7
2023-02-22 12:47:47,666 DEBUG TRAIN Batch 19/5900 loss 11.120213 loss_att 13.400762 loss_ctc 13.872923 loss_rnnt 10.187466 hw_loss 0.205517 lr 0.00039003 rank 4
2023-02-22 12:47:47,669 DEBUG TRAIN Batch 19/5900 loss 4.503706 loss_att 9.125220 loss_ctc 6.704548 loss_rnnt 3.182054 hw_loss 0.194819 lr 0.00038997 rank 3
2023-02-22 12:47:47,669 DEBUG TRAIN Batch 19/5900 loss 9.952732 loss_att 13.065094 loss_ctc 15.011312 loss_rnnt 8.563341 hw_loss 0.173326 lr 0.00038999 rank 1
2023-02-22 12:47:47,669 DEBUG TRAIN Batch 19/5900 loss 7.531442 loss_att 11.631752 loss_ctc 9.661063 loss_rnnt 6.260316 hw_loss 0.313338 lr 0.00039005 rank 0
2023-02-22 12:47:47,670 DEBUG TRAIN Batch 19/5900 loss 7.536658 loss_att 11.138782 loss_ctc 13.310516 loss_rnnt 5.880235 hw_loss 0.311532 lr 0.00038995 rank 6
2023-02-22 12:47:47,673 DEBUG TRAIN Batch 19/5900 loss 5.190852 loss_att 8.879598 loss_ctc 7.336176 loss_rnnt 4.070487 hw_loss 0.181073 lr 0.00039000 rank 5
2023-02-22 12:49:01,460 DEBUG TRAIN Batch 19/6000 loss 1.524751 loss_att 3.401371 loss_ctc 1.581829 loss_rnnt 1.008985 hw_loss 0.249058 lr 0.00038991 rank 4
2023-02-22 12:49:01,462 DEBUG TRAIN Batch 19/6000 loss 6.188915 loss_att 9.664843 loss_ctc 6.345393 loss_rnnt 5.373557 hw_loss 0.186205 lr 0.00038982 rank 7
2023-02-22 12:49:01,462 DEBUG TRAIN Batch 19/6000 loss 8.886289 loss_att 12.850983 loss_ctc 12.336711 loss_rnnt 7.491214 hw_loss 0.266399 lr 0.00038983 rank 6
2023-02-22 12:49:01,463 DEBUG TRAIN Batch 19/6000 loss 7.062771 loss_att 8.915863 loss_ctc 8.038447 loss_rnnt 6.391866 hw_loss 0.319118 lr 0.00038986 rank 2
2023-02-22 12:49:01,467 DEBUG TRAIN Batch 19/6000 loss 20.604052 loss_att 22.690092 loss_ctc 30.696510 loss_rnnt 18.759907 hw_loss 0.152392 lr 0.00038988 rank 5
2023-02-22 12:49:01,468 DEBUG TRAIN Batch 19/6000 loss 7.234516 loss_att 8.733955 loss_ctc 9.740005 loss_rnnt 6.536895 hw_loss 0.119378 lr 0.00038993 rank 0
2023-02-22 12:49:01,469 DEBUG TRAIN Batch 19/6000 loss 7.881688 loss_att 9.785300 loss_ctc 11.024615 loss_rnnt 6.958998 hw_loss 0.230457 lr 0.00038988 rank 1
2023-02-22 12:49:01,472 DEBUG TRAIN Batch 19/6000 loss 14.260626 loss_att 17.059353 loss_ctc 19.317669 loss_rnnt 12.936174 hw_loss 0.169563 lr 0.00038985 rank 3
2023-02-22 12:50:15,585 DEBUG TRAIN Batch 19/6100 loss 10.255345 loss_att 10.891434 loss_ctc 15.238534 loss_rnnt 9.383430 hw_loss 0.150511 lr 0.00038974 rank 2
2023-02-22 12:50:15,587 DEBUG TRAIN Batch 19/6100 loss 11.211913 loss_att 11.809824 loss_ctc 12.894983 loss_rnnt 10.733214 hw_loss 0.252575 lr 0.00038979 rank 4
2023-02-22 12:50:15,590 DEBUG TRAIN Batch 19/6100 loss 18.970913 loss_att 21.758583 loss_ctc 28.879662 loss_rnnt 16.941072 hw_loss 0.283384 lr 0.00038981 rank 0
2023-02-22 12:50:15,591 DEBUG TRAIN Batch 19/6100 loss 8.752547 loss_att 10.513599 loss_ctc 11.765757 loss_rnnt 7.843769 hw_loss 0.290263 lr 0.00038971 rank 6
2023-02-22 12:50:15,592 DEBUG TRAIN Batch 19/6100 loss 11.347232 loss_att 13.649719 loss_ctc 17.203522 loss_rnnt 9.982467 hw_loss 0.231430 lr 0.00038973 rank 3
2023-02-22 12:50:15,594 DEBUG TRAIN Batch 19/6100 loss 6.002365 loss_att 8.637676 loss_ctc 10.992895 loss_rnnt 4.615815 hw_loss 0.363906 lr 0.00038976 rank 1
2023-02-22 12:50:15,594 DEBUG TRAIN Batch 19/6100 loss 7.066400 loss_att 8.817705 loss_ctc 11.044380 loss_rnnt 6.041794 hw_loss 0.269902 lr 0.00038977 rank 5
2023-02-22 12:50:15,595 DEBUG TRAIN Batch 19/6100 loss 16.272522 loss_att 17.232529 loss_ctc 23.166382 loss_rnnt 14.955196 hw_loss 0.386517 lr 0.00038970 rank 7
2023-02-22 12:51:28,327 DEBUG TRAIN Batch 19/6200 loss 7.739583 loss_att 10.776918 loss_ctc 11.926496 loss_rnnt 6.352220 hw_loss 0.415576 lr 0.00038961 rank 3
2023-02-22 12:51:28,330 DEBUG TRAIN Batch 19/6200 loss 6.379202 loss_att 9.493203 loss_ctc 8.618857 loss_rnnt 5.346267 hw_loss 0.209088 lr 0.00038959 rank 6
2023-02-22 12:51:28,336 DEBUG TRAIN Batch 19/6200 loss 16.118238 loss_att 20.427095 loss_ctc 20.265587 loss_rnnt 14.533099 hw_loss 0.319478 lr 0.00038962 rank 2
2023-02-22 12:51:28,339 DEBUG TRAIN Batch 19/6200 loss 11.103858 loss_att 13.708754 loss_ctc 16.248535 loss_rnnt 9.740282 hw_loss 0.293701 lr 0.00038969 rank 0
2023-02-22 12:51:28,338 DEBUG TRAIN Batch 19/6200 loss 10.608512 loss_att 12.918863 loss_ctc 15.039022 loss_rnnt 9.386879 hw_loss 0.316551 lr 0.00038967 rank 4
2023-02-22 12:51:28,339 DEBUG TRAIN Batch 19/6200 loss 17.483133 loss_att 17.763332 loss_ctc 21.996529 loss_rnnt 16.680906 hw_loss 0.270751 lr 0.00038965 rank 5
2023-02-22 12:51:28,339 DEBUG TRAIN Batch 19/6200 loss 12.463212 loss_att 13.799909 loss_ctc 15.784616 loss_rnnt 11.690073 hw_loss 0.118022 lr 0.00038958 rank 7
2023-02-22 12:51:28,387 DEBUG TRAIN Batch 19/6200 loss 10.990938 loss_att 11.788653 loss_ctc 13.130672 loss_rnnt 10.433123 hw_loss 0.211827 lr 0.00038964 rank 1
2023-02-22 12:52:41,426 DEBUG TRAIN Batch 19/6300 loss 8.427486 loss_att 9.667289 loss_ctc 13.253284 loss_rnnt 7.301689 hw_loss 0.439493 lr 0.00038950 rank 3
2023-02-22 12:52:41,431 DEBUG TRAIN Batch 19/6300 loss 17.704943 loss_att 19.413765 loss_ctc 25.690992 loss_rnnt 16.128693 hw_loss 0.318143 lr 0.00038951 rank 2
2023-02-22 12:52:41,432 DEBUG TRAIN Batch 19/6300 loss 12.879314 loss_att 12.854101 loss_ctc 15.350346 loss_rnnt 12.293035 hw_loss 0.490973 lr 0.00038948 rank 6
2023-02-22 12:52:41,434 DEBUG TRAIN Batch 19/6300 loss 10.506878 loss_att 16.488533 loss_ctc 16.368591 loss_rnnt 8.420656 hw_loss 0.203115 lr 0.00038957 rank 0
2023-02-22 12:52:41,436 DEBUG TRAIN Batch 19/6300 loss 8.022706 loss_att 8.906424 loss_ctc 14.261706 loss_rnnt 6.889823 hw_loss 0.233010 lr 0.00038953 rank 5
2023-02-22 12:52:41,438 DEBUG TRAIN Batch 19/6300 loss 13.999209 loss_att 19.362675 loss_ctc 19.708578 loss_rnnt 11.988935 hw_loss 0.330623 lr 0.00038952 rank 1
2023-02-22 12:52:41,440 DEBUG TRAIN Batch 19/6300 loss 11.397918 loss_att 10.961440 loss_ctc 13.262792 loss_rnnt 11.012217 hw_loss 0.420650 lr 0.00038946 rank 7
2023-02-22 12:52:41,440 DEBUG TRAIN Batch 19/6300 loss 15.441560 loss_att 18.506479 loss_ctc 25.269131 loss_rnnt 13.365215 hw_loss 0.286906 lr 0.00038955 rank 4
2023-02-22 12:53:57,024 DEBUG TRAIN Batch 19/6400 loss 12.102895 loss_att 17.005129 loss_ctc 18.013279 loss_rnnt 10.162788 hw_loss 0.321766 lr 0.00038938 rank 3
2023-02-22 12:53:57,026 DEBUG TRAIN Batch 19/6400 loss 14.710654 loss_att 19.640303 loss_ctc 16.618431 loss_rnnt 13.331060 hw_loss 0.261177 lr 0.00038940 rank 1
2023-02-22 12:53:57,027 DEBUG TRAIN Batch 19/6400 loss 18.169863 loss_att 20.032982 loss_ctc 22.000130 loss_rnnt 17.163769 hw_loss 0.230188 lr 0.00038939 rank 2
2023-02-22 12:53:57,028 DEBUG TRAIN Batch 19/6400 loss 5.496007 loss_att 7.517071 loss_ctc 7.594728 loss_rnnt 4.628662 hw_loss 0.343694 lr 0.00038944 rank 4
2023-02-22 12:53:57,030 DEBUG TRAIN Batch 19/6400 loss 5.384178 loss_att 9.696705 loss_ctc 7.449392 loss_rnnt 4.104739 hw_loss 0.265446 lr 0.00038936 rank 6
2023-02-22 12:53:57,033 DEBUG TRAIN Batch 19/6400 loss 5.608142 loss_att 7.319642 loss_ctc 6.483306 loss_rnnt 4.910008 hw_loss 0.448397 lr 0.00038945 rank 0
2023-02-22 12:53:57,034 DEBUG TRAIN Batch 19/6400 loss 15.108589 loss_att 15.604788 loss_ctc 15.772357 loss_rnnt 14.707938 hw_loss 0.399206 lr 0.00038941 rank 5
2023-02-22 12:53:57,081 DEBUG TRAIN Batch 19/6400 loss 10.791739 loss_att 16.820192 loss_ctc 14.918633 loss_rnnt 8.902176 hw_loss 0.250537 lr 0.00038934 rank 7
2023-02-22 12:55:10,748 DEBUG TRAIN Batch 19/6500 loss 12.799393 loss_att 12.791653 loss_ctc 18.956215 loss_rnnt 11.854197 hw_loss 0.235938 lr 0.00038924 rank 6
2023-02-22 12:55:10,749 DEBUG TRAIN Batch 19/6500 loss 20.128496 loss_att 28.231640 loss_ctc 30.553108 loss_rnnt 16.920578 hw_loss 0.370009 lr 0.00038922 rank 7
2023-02-22 12:55:10,755 DEBUG TRAIN Batch 19/6500 loss 15.477942 loss_att 14.584290 loss_ctc 19.434135 loss_rnnt 14.832182 hw_loss 0.556869 lr 0.00038932 rank 4
2023-02-22 12:55:10,755 DEBUG TRAIN Batch 19/6500 loss 5.961169 loss_att 9.142733 loss_ctc 9.019608 loss_rnnt 4.784834 hw_loss 0.247932 lr 0.00038926 rank 3
2023-02-22 12:55:10,756 DEBUG TRAIN Batch 19/6500 loss 8.739884 loss_att 11.784349 loss_ctc 13.779788 loss_rnnt 7.312037 hw_loss 0.275561 lr 0.00038934 rank 0
2023-02-22 12:55:10,759 DEBUG TRAIN Batch 19/6500 loss 7.875840 loss_att 15.551704 loss_ctc 11.772902 loss_rnnt 5.715766 hw_loss 0.197425 lr 0.00038928 rank 1
2023-02-22 12:55:10,801 DEBUG TRAIN Batch 19/6500 loss 10.427614 loss_att 17.630308 loss_ctc 13.667429 loss_rnnt 8.452814 hw_loss 0.191786 lr 0.00038929 rank 5
2023-02-22 12:55:11,100 DEBUG TRAIN Batch 19/6500 loss 10.892601 loss_att 14.020254 loss_ctc 15.550921 loss_rnnt 9.499351 hw_loss 0.274897 lr 0.00038927 rank 2
2023-02-22 12:56:22,852 DEBUG TRAIN Batch 19/6600 loss 10.208383 loss_att 11.872969 loss_ctc 12.290870 loss_rnnt 9.376564 hw_loss 0.414817 lr 0.00038917 rank 1
2023-02-22 12:56:22,854 DEBUG TRAIN Batch 19/6600 loss 12.312799 loss_att 13.595076 loss_ctc 15.139233 loss_rnnt 11.551982 hw_loss 0.239069 lr 0.00038915 rank 2
2023-02-22 12:56:22,854 DEBUG TRAIN Batch 19/6600 loss 18.275808 loss_att 19.317024 loss_ctc 23.067667 loss_rnnt 17.213049 hw_loss 0.404254 lr 0.00038912 rank 6
2023-02-22 12:56:22,855 DEBUG TRAIN Batch 19/6600 loss 11.892126 loss_att 16.943317 loss_ctc 18.692696 loss_rnnt 9.758704 hw_loss 0.405826 lr 0.00038922 rank 0
2023-02-22 12:56:22,855 DEBUG TRAIN Batch 19/6600 loss 6.848289 loss_att 11.181938 loss_ctc 14.430367 loss_rnnt 4.876981 hw_loss 0.175564 lr 0.00038920 rank 4
2023-02-22 12:56:22,857 DEBUG TRAIN Batch 19/6600 loss 14.120989 loss_att 17.756824 loss_ctc 18.987778 loss_rnnt 12.599403 hw_loss 0.272836 lr 0.00038914 rank 3
2023-02-22 12:56:22,864 DEBUG TRAIN Batch 19/6600 loss 14.063741 loss_att 17.096155 loss_ctc 19.416294 loss_rnnt 12.553604 hw_loss 0.356212 lr 0.00038918 rank 5
2023-02-22 12:56:22,870 DEBUG TRAIN Batch 19/6600 loss 6.016163 loss_att 10.557653 loss_ctc 9.835690 loss_rnnt 4.437990 hw_loss 0.301134 lr 0.00038911 rank 7
2023-02-22 12:57:36,049 DEBUG TRAIN Batch 19/6700 loss 4.145824 loss_att 6.084160 loss_ctc 4.655566 loss_rnnt 3.520094 hw_loss 0.318932 lr 0.00038902 rank 3
2023-02-22 12:57:36,051 DEBUG TRAIN Batch 19/6700 loss 9.736700 loss_att 10.708263 loss_ctc 12.075869 loss_rnnt 9.136345 hw_loss 0.176538 lr 0.00038899 rank 7
2023-02-22 12:57:36,052 DEBUG TRAIN Batch 19/6700 loss 1.981580 loss_att 3.644809 loss_ctc 3.431235 loss_rnnt 1.366063 hw_loss 0.167970 lr 0.00038908 rank 4
2023-02-22 12:57:36,052 DEBUG TRAIN Batch 19/6700 loss 11.060005 loss_att 14.989632 loss_ctc 16.641777 loss_rnnt 9.450312 hw_loss 0.149124 lr 0.00038906 rank 5
2023-02-22 12:57:36,053 DEBUG TRAIN Batch 19/6700 loss 10.000338 loss_att 11.566965 loss_ctc 15.309622 loss_rnnt 8.766682 hw_loss 0.398301 lr 0.00038903 rank 2
2023-02-22 12:57:36,056 DEBUG TRAIN Batch 19/6700 loss 13.670926 loss_att 16.500267 loss_ctc 21.826530 loss_rnnt 11.894428 hw_loss 0.231028 lr 0.00038910 rank 0
2023-02-22 12:57:36,058 DEBUG TRAIN Batch 19/6700 loss 11.094394 loss_att 13.001413 loss_ctc 12.769037 loss_rnnt 10.205186 hw_loss 0.533469 lr 0.00038900 rank 6
2023-02-22 12:57:36,081 DEBUG TRAIN Batch 19/6700 loss 5.327654 loss_att 7.367536 loss_ctc 9.955084 loss_rnnt 4.158506 hw_loss 0.270339 lr 0.00038905 rank 1
2023-02-22 12:58:50,849 DEBUG TRAIN Batch 19/6800 loss 8.390888 loss_att 11.130131 loss_ctc 12.874212 loss_rnnt 7.059582 hw_loss 0.348153 lr 0.00038896 rank 4
2023-02-22 12:58:50,859 DEBUG TRAIN Batch 19/6800 loss 5.096968 loss_att 6.718356 loss_ctc 5.836050 loss_rnnt 4.487237 hw_loss 0.350455 lr 0.00038891 rank 3
2023-02-22 12:58:50,860 DEBUG TRAIN Batch 19/6800 loss 7.651160 loss_att 12.114501 loss_ctc 16.316311 loss_rnnt 5.476442 hw_loss 0.237555 lr 0.00038892 rank 2
2023-02-22 12:58:50,863 DEBUG TRAIN Batch 19/6800 loss 8.222623 loss_att 10.828502 loss_ctc 13.353739 loss_rnnt 6.884518 hw_loss 0.248962 lr 0.00038898 rank 0
2023-02-22 12:58:50,864 DEBUG TRAIN Batch 19/6800 loss 15.036141 loss_att 16.670380 loss_ctc 20.579281 loss_rnnt 13.810041 hw_loss 0.300315 lr 0.00038894 rank 5
2023-02-22 12:58:50,864 DEBUG TRAIN Batch 19/6800 loss 18.627748 loss_att 21.443174 loss_ctc 32.943233 loss_rnnt 15.984606 hw_loss 0.321238 lr 0.00038887 rank 7
2023-02-22 12:58:50,865 DEBUG TRAIN Batch 19/6800 loss 4.419182 loss_att 5.617473 loss_ctc 4.965790 loss_rnnt 3.955489 hw_loss 0.283414 lr 0.00038889 rank 6
2023-02-22 12:58:50,868 DEBUG TRAIN Batch 19/6800 loss 12.596194 loss_att 15.539215 loss_ctc 12.430892 loss_rnnt 11.909473 hw_loss 0.225296 lr 0.00038893 rank 1
2023-02-22 13:00:03,859 DEBUG TRAIN Batch 19/6900 loss 4.296380 loss_att 6.318914 loss_ctc 7.660852 loss_rnnt 3.265877 hw_loss 0.332623 lr 0.00038875 rank 7
2023-02-22 13:00:03,859 DEBUG TRAIN Batch 19/6900 loss 7.681238 loss_att 8.433196 loss_ctc 10.034652 loss_rnnt 6.991384 hw_loss 0.423138 lr 0.00038880 rank 2
2023-02-22 13:00:03,861 DEBUG TRAIN Batch 19/6900 loss 10.945786 loss_att 12.988865 loss_ctc 14.887492 loss_rnnt 9.752811 hw_loss 0.485247 lr 0.00038879 rank 3
2023-02-22 13:00:03,868 DEBUG TRAIN Batch 19/6900 loss 11.488323 loss_att 12.178366 loss_ctc 16.825569 loss_rnnt 10.496894 hw_loss 0.265853 lr 0.00038881 rank 1
2023-02-22 13:00:03,868 DEBUG TRAIN Batch 19/6900 loss 8.811428 loss_att 11.214571 loss_ctc 10.266329 loss_rnnt 7.983830 hw_loss 0.286842 lr 0.00038882 rank 5
2023-02-22 13:00:03,869 DEBUG TRAIN Batch 19/6900 loss 11.122072 loss_att 11.424914 loss_ctc 12.435522 loss_rnnt 10.719513 hw_loss 0.312869 lr 0.00038877 rank 6
2023-02-22 13:00:03,871 DEBUG TRAIN Batch 19/6900 loss 15.931943 loss_att 19.010414 loss_ctc 16.889231 loss_rnnt 15.060625 hw_loss 0.239970 lr 0.00038887 rank 0
2023-02-22 13:00:03,875 DEBUG TRAIN Batch 19/6900 loss 20.849388 loss_att 21.871040 loss_ctc 24.446581 loss_rnnt 20.052202 hw_loss 0.212301 lr 0.00038885 rank 4
2023-02-22 13:01:16,924 DEBUG TRAIN Batch 19/7000 loss 10.628642 loss_att 14.528250 loss_ctc 12.659327 loss_rnnt 9.473789 hw_loss 0.195324 lr 0.00038867 rank 3
2023-02-22 13:01:16,929 DEBUG TRAIN Batch 19/7000 loss 13.723373 loss_att 17.979942 loss_ctc 27.308279 loss_rnnt 10.864828 hw_loss 0.367331 lr 0.00038865 rank 6
2023-02-22 13:01:16,930 DEBUG TRAIN Batch 19/7000 loss 8.591743 loss_att 12.373300 loss_ctc 14.397768 loss_rnnt 6.891491 hw_loss 0.318383 lr 0.00038864 rank 7
2023-02-22 13:01:16,931 DEBUG TRAIN Batch 19/7000 loss 12.668810 loss_att 11.981144 loss_ctc 18.099165 loss_rnnt 11.920593 hw_loss 0.303192 lr 0.00038868 rank 2
2023-02-22 13:01:16,933 DEBUG TRAIN Batch 19/7000 loss 8.567581 loss_att 10.631881 loss_ctc 13.236374 loss_rnnt 7.336149 hw_loss 0.367624 lr 0.00038873 rank 4
2023-02-22 13:01:16,934 DEBUG TRAIN Batch 19/7000 loss 11.561964 loss_att 12.043896 loss_ctc 15.870776 loss_rnnt 10.775309 hw_loss 0.217050 lr 0.00038870 rank 1
2023-02-22 13:01:16,938 DEBUG TRAIN Batch 19/7000 loss 12.718525 loss_att 15.334088 loss_ctc 18.449543 loss_rnnt 11.243427 hw_loss 0.352215 lr 0.00038870 rank 5
2023-02-22 13:01:16,939 DEBUG TRAIN Batch 19/7000 loss 14.905355 loss_att 17.244473 loss_ctc 20.735785 loss_rnnt 13.374475 hw_loss 0.535621 lr 0.00038875 rank 0
2023-02-22 13:02:31,726 DEBUG TRAIN Batch 19/7100 loss 9.217989 loss_att 11.773882 loss_ctc 12.967964 loss_rnnt 8.089493 hw_loss 0.219976 lr 0.00038859 rank 5
2023-02-22 13:02:31,727 DEBUG TRAIN Batch 19/7100 loss 9.101456 loss_att 10.141549 loss_ctc 15.094719 loss_rnnt 7.944064 hw_loss 0.281758 lr 0.00038861 rank 4
2023-02-22 13:02:31,733 DEBUG TRAIN Batch 19/7100 loss 8.643441 loss_att 10.748626 loss_ctc 7.130733 loss_rnnt 8.317907 hw_loss 0.199109 lr 0.00038852 rank 7
2023-02-22 13:02:31,735 DEBUG TRAIN Batch 19/7100 loss 9.607458 loss_att 13.647013 loss_ctc 12.628389 loss_rnnt 8.306587 hw_loss 0.169069 lr 0.00038853 rank 6
2023-02-22 13:02:31,736 DEBUG TRAIN Batch 19/7100 loss 12.076565 loss_att 15.600589 loss_ctc 16.105526 loss_rnnt 10.636409 hw_loss 0.371542 lr 0.00038856 rank 2
2023-02-22 13:02:31,737 DEBUG TRAIN Batch 19/7100 loss 13.218178 loss_att 15.426168 loss_ctc 13.794752 loss_rnnt 12.611864 hw_loss 0.164694 lr 0.00038863 rank 0
2023-02-22 13:02:31,737 DEBUG TRAIN Batch 19/7100 loss 5.192101 loss_att 9.301420 loss_ctc 7.707518 loss_rnnt 3.871809 hw_loss 0.305698 lr 0.00038858 rank 1
2023-02-22 13:02:31,739 DEBUG TRAIN Batch 19/7100 loss 16.307592 loss_att 18.657333 loss_ctc 17.270941 loss_rnnt 15.518245 hw_loss 0.358040 lr 0.00038855 rank 3
2023-02-22 13:03:45,000 DEBUG TRAIN Batch 19/7200 loss 15.878600 loss_att 17.369612 loss_ctc 20.560295 loss_rnnt 14.796641 hw_loss 0.299119 lr 0.00038844 rank 3
2023-02-22 13:03:45,001 DEBUG TRAIN Batch 19/7200 loss 9.764302 loss_att 13.486975 loss_ctc 15.160442 loss_rnnt 8.151137 hw_loss 0.279648 lr 0.00038845 rank 2
2023-02-22 13:03:45,005 DEBUG TRAIN Batch 19/7200 loss 23.093262 loss_att 32.153725 loss_ctc 37.546989 loss_rnnt 19.281286 hw_loss 0.136349 lr 0.00038842 rank 6
2023-02-22 13:03:45,008 DEBUG TRAIN Batch 19/7200 loss 6.308362 loss_att 11.020608 loss_ctc 10.804977 loss_rnnt 4.608991 hw_loss 0.295075 lr 0.00038847 rank 5
2023-02-22 13:03:45,007 DEBUG TRAIN Batch 19/7200 loss 5.331923 loss_att 9.884146 loss_ctc 9.059914 loss_rnnt 3.789790 hw_loss 0.252419 lr 0.00038851 rank 0
2023-02-22 13:03:45,015 DEBUG TRAIN Batch 19/7200 loss 8.072169 loss_att 13.240328 loss_ctc 13.470927 loss_rnnt 6.166972 hw_loss 0.284496 lr 0.00038846 rank 1
2023-02-22 13:03:45,016 DEBUG TRAIN Batch 19/7200 loss 13.965533 loss_att 15.159441 loss_ctc 20.003201 loss_rnnt 12.757770 hw_loss 0.307425 lr 0.00038849 rank 4
2023-02-22 13:03:45,062 DEBUG TRAIN Batch 19/7200 loss 8.338202 loss_att 11.557238 loss_ctc 16.889647 loss_rnnt 6.512378 hw_loss 0.078423 lr 0.00038840 rank 7
2023-02-22 13:04:57,382 DEBUG TRAIN Batch 19/7300 loss 6.800886 loss_att 9.206579 loss_ctc 10.411856 loss_rnnt 5.640942 hw_loss 0.370019 lr 0.00038840 rank 0
2023-02-22 13:04:57,396 DEBUG TRAIN Batch 19/7300 loss 6.546052 loss_att 9.962251 loss_ctc 9.172338 loss_rnnt 5.381928 hw_loss 0.245084 lr 0.00038833 rank 2
2023-02-22 13:04:57,398 DEBUG TRAIN Batch 19/7300 loss 19.335449 loss_att 14.134912 loss_ctc 26.153168 loss_rnnt 19.385857 hw_loss 0.151256 lr 0.00038834 rank 1
2023-02-22 13:04:57,399 DEBUG TRAIN Batch 19/7300 loss 13.050640 loss_att 15.824928 loss_ctc 19.719128 loss_rnnt 11.449519 hw_loss 0.294624 lr 0.00038830 rank 6
2023-02-22 13:04:57,400 DEBUG TRAIN Batch 19/7300 loss 11.691159 loss_att 13.943566 loss_ctc 19.907263 loss_rnnt 10.047541 hw_loss 0.183107 lr 0.00038838 rank 4
2023-02-22 13:04:57,403 DEBUG TRAIN Batch 19/7300 loss 9.269600 loss_att 15.731289 loss_ctc 15.319469 loss_rnnt 6.999616 hw_loss 0.320618 lr 0.00038832 rank 3
2023-02-22 13:04:57,403 DEBUG TRAIN Batch 19/7300 loss 8.944733 loss_att 11.010564 loss_ctc 11.206222 loss_rnnt 8.099982 hw_loss 0.243849 lr 0.00038828 rank 7
2023-02-22 13:04:57,405 DEBUG TRAIN Batch 19/7300 loss 17.921879 loss_att 19.200300 loss_ctc 22.974581 loss_rnnt 16.886341 hw_loss 0.199049 lr 0.00038835 rank 5
2023-02-22 13:06:10,676 DEBUG TRAIN Batch 19/7400 loss 8.153435 loss_att 10.432343 loss_ctc 11.902838 loss_rnnt 7.070031 hw_loss 0.239439 lr 0.00038828 rank 0
2023-02-22 13:06:10,677 DEBUG TRAIN Batch 19/7400 loss 9.955915 loss_att 11.535482 loss_ctc 11.375889 loss_rnnt 9.301712 hw_loss 0.279300 lr 0.00038820 rank 3
2023-02-22 13:06:10,679 DEBUG TRAIN Batch 19/7400 loss 11.071332 loss_att 13.230566 loss_ctc 11.500475 loss_rnnt 10.457016 hw_loss 0.234844 lr 0.00038826 rank 4
2023-02-22 13:06:10,685 DEBUG TRAIN Batch 19/7400 loss 9.551493 loss_att 13.092562 loss_ctc 14.916863 loss_rnnt 8.025286 hw_loss 0.192394 lr 0.00038823 rank 1
2023-02-22 13:06:10,688 DEBUG TRAIN Batch 19/7400 loss 5.582935 loss_att 8.040609 loss_ctc 9.811304 loss_rnnt 4.290553 hw_loss 0.444497 lr 0.00038817 rank 7
2023-02-22 13:06:10,693 DEBUG TRAIN Batch 19/7400 loss 10.019109 loss_att 11.294816 loss_ctc 14.027964 loss_rnnt 9.072596 hw_loss 0.294109 lr 0.00038824 rank 5
2023-02-22 13:06:10,712 DEBUG TRAIN Batch 19/7400 loss 4.390100 loss_att 6.295608 loss_ctc 5.610169 loss_rnnt 3.780784 hw_loss 0.122883 lr 0.00038821 rank 2
2023-02-22 13:06:10,716 DEBUG TRAIN Batch 19/7400 loss 6.462753 loss_att 9.104483 loss_ctc 9.929228 loss_rnnt 5.303563 hw_loss 0.316213 lr 0.00038818 rank 6
2023-02-22 13:07:25,579 DEBUG TRAIN Batch 19/7500 loss 16.299784 loss_att 15.810917 loss_ctc 20.348820 loss_rnnt 15.617025 hw_loss 0.451239 lr 0.00038810 rank 2
2023-02-22 13:07:25,583 DEBUG TRAIN Batch 19/7500 loss 13.324750 loss_att 15.015181 loss_ctc 20.808304 loss_rnnt 11.847235 hw_loss 0.265542 lr 0.00038814 rank 4
2023-02-22 13:07:25,584 DEBUG TRAIN Batch 19/7500 loss 7.806068 loss_att 9.431479 loss_ctc 11.295795 loss_rnnt 6.841882 hw_loss 0.325889 lr 0.00038808 rank 3
2023-02-22 13:07:25,585 DEBUG TRAIN Batch 19/7500 loss 11.159243 loss_att 14.247693 loss_ctc 12.909547 loss_rnnt 10.121792 hw_loss 0.349475 lr 0.00038811 rank 1
2023-02-22 13:07:25,586 DEBUG TRAIN Batch 19/7500 loss 11.575835 loss_att 13.085875 loss_ctc 14.519018 loss_rnnt 10.694332 hw_loss 0.350760 lr 0.00038816 rank 0
2023-02-22 13:07:25,591 DEBUG TRAIN Batch 19/7500 loss 10.213157 loss_att 12.604889 loss_ctc 14.853300 loss_rnnt 9.032091 hw_loss 0.157562 lr 0.00038807 rank 6
2023-02-22 13:07:25,593 DEBUG TRAIN Batch 19/7500 loss 6.962663 loss_att 8.891095 loss_ctc 8.518736 loss_rnnt 6.260180 hw_loss 0.204976 lr 0.00038812 rank 5
2023-02-22 13:07:25,594 DEBUG TRAIN Batch 19/7500 loss 11.070622 loss_att 12.985246 loss_ctc 14.983685 loss_rnnt 9.970522 hw_loss 0.366438 lr 0.00038805 rank 7
2023-02-22 13:08:38,821 DEBUG TRAIN Batch 19/7600 loss 14.030410 loss_att 19.856281 loss_ctc 20.238026 loss_rnnt 11.970737 hw_loss 0.125283 lr 0.00038793 rank 7
2023-02-22 13:08:38,825 DEBUG TRAIN Batch 19/7600 loss 13.062599 loss_att 15.557167 loss_ctc 18.878256 loss_rnnt 11.628254 hw_loss 0.300019 lr 0.00038800 rank 5
2023-02-22 13:08:38,824 DEBUG TRAIN Batch 19/7600 loss 8.866617 loss_att 12.760868 loss_ctc 16.579615 loss_rnnt 6.952413 hw_loss 0.200538 lr 0.00038797 rank 3
2023-02-22 13:08:38,824 DEBUG TRAIN Batch 19/7600 loss 9.111667 loss_att 11.615083 loss_ctc 13.186897 loss_rnnt 7.964562 hw_loss 0.193231 lr 0.00038798 rank 2
2023-02-22 13:08:38,826 DEBUG TRAIN Batch 19/7600 loss 10.971018 loss_att 11.645162 loss_ctc 13.086802 loss_rnnt 10.391507 hw_loss 0.304831 lr 0.00038804 rank 0
2023-02-22 13:08:38,828 DEBUG TRAIN Batch 19/7600 loss 11.592376 loss_att 12.789985 loss_ctc 15.293383 loss_rnnt 10.729013 hw_loss 0.244448 lr 0.00038795 rank 6
2023-02-22 13:08:38,828 DEBUG TRAIN Batch 19/7600 loss 13.860839 loss_att 16.716431 loss_ctc 19.552267 loss_rnnt 12.412159 hw_loss 0.222571 lr 0.00038803 rank 4
2023-02-22 13:08:38,830 DEBUG TRAIN Batch 19/7600 loss 11.648715 loss_att 13.950821 loss_ctc 17.105946 loss_rnnt 10.277736 hw_loss 0.342991 lr 0.00038799 rank 1
2023-02-22 13:09:51,178 DEBUG TRAIN Batch 19/7700 loss 10.872016 loss_att 12.475683 loss_ctc 13.147253 loss_rnnt 10.164902 hw_loss 0.155655 lr 0.00038786 rank 2
2023-02-22 13:09:51,181 DEBUG TRAIN Batch 19/7700 loss 9.082709 loss_att 13.528519 loss_ctc 14.189354 loss_rnnt 7.395561 hw_loss 0.219562 lr 0.00038783 rank 6
2023-02-22 13:09:51,182 DEBUG TRAIN Batch 19/7700 loss 8.677709 loss_att 9.929747 loss_ctc 9.412590 loss_rnnt 8.252668 hw_loss 0.143716 lr 0.00038785 rank 3
2023-02-22 13:09:51,187 DEBUG TRAIN Batch 19/7700 loss 6.784832 loss_att 7.086911 loss_ctc 11.415709 loss_rnnt 5.980270 hw_loss 0.237554 lr 0.00038782 rank 7
2023-02-22 13:09:51,188 DEBUG TRAIN Batch 19/7700 loss 11.936472 loss_att 11.172691 loss_ctc 16.077568 loss_rnnt 11.292364 hw_loss 0.458845 lr 0.00038793 rank 0
2023-02-22 13:09:51,188 DEBUG TRAIN Batch 19/7700 loss 14.397875 loss_att 14.000068 loss_ctc 22.116932 loss_rnnt 13.115118 hw_loss 0.624586 lr 0.00038788 rank 1
2023-02-22 13:09:51,193 DEBUG TRAIN Batch 19/7700 loss 13.234608 loss_att 16.866598 loss_ctc 20.068905 loss_rnnt 11.452324 hw_loss 0.271211 lr 0.00038788 rank 5
2023-02-22 13:09:51,236 DEBUG TRAIN Batch 19/7700 loss 5.647778 loss_att 7.842376 loss_ctc 6.720019 loss_rnnt 4.911562 hw_loss 0.289369 lr 0.00038791 rank 4
2023-02-22 13:11:05,430 DEBUG TRAIN Batch 19/7800 loss 10.184458 loss_att 15.783303 loss_ctc 13.892689 loss_rnnt 8.354120 hw_loss 0.405259 lr 0.00038774 rank 2
2023-02-22 13:11:05,435 DEBUG TRAIN Batch 19/7800 loss 4.914353 loss_att 8.964669 loss_ctc 5.696926 loss_rnnt 3.836226 hw_loss 0.306976 lr 0.00038770 rank 7
2023-02-22 13:11:05,437 DEBUG TRAIN Batch 19/7800 loss 3.710464 loss_att 6.389918 loss_ctc 2.829809 loss_rnnt 3.170995 hw_loss 0.226873 lr 0.00038781 rank 0
2023-02-22 13:11:05,437 DEBUG TRAIN Batch 19/7800 loss 20.224558 loss_att 27.943686 loss_ctc 29.147337 loss_rnnt 17.379156 hw_loss 0.209759 lr 0.00038772 rank 6
2023-02-22 13:11:05,440 DEBUG TRAIN Batch 19/7800 loss 15.081697 loss_att 18.192596 loss_ctc 20.561361 loss_rnnt 13.599653 hw_loss 0.242329 lr 0.00038776 rank 1
2023-02-22 13:11:05,440 DEBUG TRAIN Batch 19/7800 loss 4.638044 loss_att 7.042281 loss_ctc 6.512554 loss_rnnt 3.749626 hw_loss 0.295569 lr 0.00038773 rank 3
2023-02-22 13:11:05,473 DEBUG TRAIN Batch 19/7800 loss 9.254723 loss_att 11.943420 loss_ctc 14.868080 loss_rnnt 7.885847 hw_loss 0.155038 lr 0.00038779 rank 4
2023-02-22 13:11:05,490 DEBUG TRAIN Batch 19/7800 loss 14.220661 loss_att 17.639969 loss_ctc 22.567932 loss_rnnt 12.245125 hw_loss 0.335073 lr 0.00038777 rank 5
2023-02-22 13:12:18,526 DEBUG TRAIN Batch 19/7900 loss 15.920559 loss_att 19.295300 loss_ctc 22.319355 loss_rnnt 14.147700 hw_loss 0.458885 lr 0.00038762 rank 3
2023-02-22 13:12:18,539 DEBUG TRAIN Batch 19/7900 loss 3.944592 loss_att 6.584280 loss_ctc 6.492168 loss_rnnt 2.868378 hw_loss 0.391124 lr 0.00038760 rank 6
2023-02-22 13:12:18,540 DEBUG TRAIN Batch 19/7900 loss 12.154834 loss_att 13.283591 loss_ctc 15.276707 loss_rnnt 11.344923 hw_loss 0.314832 lr 0.00038763 rank 2
2023-02-22 13:12:18,541 DEBUG TRAIN Batch 19/7900 loss 4.919037 loss_att 10.467731 loss_ctc 8.311562 loss_rnnt 3.186236 hw_loss 0.320110 lr 0.00038768 rank 4
2023-02-22 13:12:18,545 DEBUG TRAIN Batch 19/7900 loss 14.683342 loss_att 16.059525 loss_ctc 16.408047 loss_rnnt 14.059790 hw_loss 0.221917 lr 0.00038769 rank 0
2023-02-22 13:12:18,547 DEBUG TRAIN Batch 19/7900 loss 2.650038 loss_att 5.164581 loss_ctc 3.780965 loss_rnnt 1.787522 hw_loss 0.391534 lr 0.00038764 rank 1
2023-02-22 13:12:18,548 DEBUG TRAIN Batch 19/7900 loss 10.531363 loss_att 14.489146 loss_ctc 13.420704 loss_rnnt 9.182329 hw_loss 0.322935 lr 0.00038765 rank 5
2023-02-22 13:12:18,597 DEBUG TRAIN Batch 19/7900 loss 6.176890 loss_att 8.743679 loss_ctc 9.235094 loss_rnnt 5.142505 hw_loss 0.212375 lr 0.00038758 rank 7
2023-02-22 13:13:31,404 DEBUG TRAIN Batch 19/8000 loss 15.744953 loss_att 19.150066 loss_ctc 20.086788 loss_rnnt 14.398851 hw_loss 0.161564 lr 0.00038751 rank 2
2023-02-22 13:13:31,412 DEBUG TRAIN Batch 19/8000 loss 18.664797 loss_att 23.998590 loss_ctc 27.160976 loss_rnnt 16.367256 hw_loss 0.183675 lr 0.00038753 rank 1
2023-02-22 13:13:31,412 DEBUG TRAIN Batch 19/8000 loss 12.479228 loss_att 15.722298 loss_ctc 16.789244 loss_rnnt 11.115993 hw_loss 0.262409 lr 0.00038750 rank 3
2023-02-22 13:13:31,414 DEBUG TRAIN Batch 19/8000 loss 16.796280 loss_att 17.483496 loss_ctc 23.216225 loss_rnnt 15.653499 hw_loss 0.280024 lr 0.00038748 rank 6
2023-02-22 13:13:31,415 DEBUG TRAIN Batch 19/8000 loss 18.542223 loss_att 24.052290 loss_ctc 24.031815 loss_rnnt 16.560404 hw_loss 0.277239 lr 0.00038756 rank 4
2023-02-22 13:13:31,416 DEBUG TRAIN Batch 19/8000 loss 7.457519 loss_att 9.925998 loss_ctc 11.601532 loss_rnnt 6.341323 hw_loss 0.131183 lr 0.00038758 rank 0
2023-02-22 13:13:31,418 DEBUG TRAIN Batch 19/8000 loss 12.668130 loss_att 12.937528 loss_ctc 16.814150 loss_rnnt 11.854389 hw_loss 0.388236 lr 0.00038747 rank 7
2023-02-22 13:13:31,419 DEBUG TRAIN Batch 19/8000 loss 16.956024 loss_att 19.270733 loss_ctc 25.694740 loss_rnnt 15.174910 hw_loss 0.286893 lr 0.00038754 rank 5
2023-02-22 13:14:43,804 DEBUG TRAIN Batch 19/8100 loss 11.863481 loss_att 13.827568 loss_ctc 16.298382 loss_rnnt 10.761839 hw_loss 0.220321 lr 0.00038742 rank 5
2023-02-22 13:14:43,807 DEBUG TRAIN Batch 19/8100 loss 4.721594 loss_att 6.570112 loss_ctc 8.390838 loss_rnnt 3.698716 hw_loss 0.307392 lr 0.00038741 rank 1
2023-02-22 13:14:43,813 DEBUG TRAIN Batch 19/8100 loss 5.734787 loss_att 8.357106 loss_ctc 9.421011 loss_rnnt 4.565718 hw_loss 0.287080 lr 0.00038740 rank 2
2023-02-22 13:14:43,817 DEBUG TRAIN Batch 19/8100 loss 2.871684 loss_att 6.478886 loss_ctc 3.948263 loss_rnnt 1.906732 hw_loss 0.187439 lr 0.00038746 rank 0
2023-02-22 13:14:43,817 DEBUG TRAIN Batch 19/8100 loss 5.414059 loss_att 7.681172 loss_ctc 7.393321 loss_rnnt 4.519658 hw_loss 0.332018 lr 0.00038739 rank 3
2023-02-22 13:14:43,821 DEBUG TRAIN Batch 19/8100 loss 13.465288 loss_att 15.738903 loss_ctc 24.660629 loss_rnnt 11.367688 hw_loss 0.281557 lr 0.00038744 rank 4
2023-02-22 13:14:43,822 DEBUG TRAIN Batch 19/8100 loss 8.486572 loss_att 11.969619 loss_ctc 14.198112 loss_rnnt 6.852072 hw_loss 0.330661 lr 0.00038737 rank 6
2023-02-22 13:14:43,823 DEBUG TRAIN Batch 19/8100 loss 6.812658 loss_att 8.396619 loss_ctc 8.222921 loss_rnnt 6.199190 hw_loss 0.203701 lr 0.00038735 rank 7
2023-02-22 13:15:56,819 DEBUG TRAIN Batch 19/8200 loss 8.894021 loss_att 10.391122 loss_ctc 11.259043 loss_rnnt 8.166967 hw_loss 0.210556 lr 0.00038728 rank 2
2023-02-22 13:15:56,822 DEBUG TRAIN Batch 19/8200 loss 9.780900 loss_att 12.980719 loss_ctc 13.801717 loss_rnnt 8.503289 hw_loss 0.190381 lr 0.00038729 rank 1
2023-02-22 13:15:56,823 DEBUG TRAIN Batch 19/8200 loss 6.695336 loss_att 12.315327 loss_ctc 11.917583 loss_rnnt 4.783854 hw_loss 0.170970 lr 0.00038725 rank 6
2023-02-22 13:15:56,825 DEBUG TRAIN Batch 19/8200 loss 9.194488 loss_att 12.206560 loss_ctc 17.459499 loss_rnnt 7.345950 hw_loss 0.270229 lr 0.00038727 rank 3
2023-02-22 13:15:56,827 DEBUG TRAIN Batch 19/8200 loss 13.076282 loss_att 14.443659 loss_ctc 15.801870 loss_rnnt 12.310030 hw_loss 0.242557 lr 0.00038735 rank 0
2023-02-22 13:15:56,830 DEBUG TRAIN Batch 19/8200 loss 14.282815 loss_att 17.099442 loss_ctc 22.344337 loss_rnnt 12.459069 hw_loss 0.347905 lr 0.00038733 rank 4
2023-02-22 13:15:56,838 DEBUG TRAIN Batch 19/8200 loss 5.292397 loss_att 7.884870 loss_ctc 7.633835 loss_rnnt 4.306516 hw_loss 0.290990 lr 0.00038730 rank 5
2023-02-22 13:15:56,873 DEBUG TRAIN Batch 19/8200 loss 8.403572 loss_att 8.844004 loss_ctc 9.644221 loss_rnnt 8.001353 hw_loss 0.278835 lr 0.00038724 rank 7
2023-02-22 13:17:08,711 DEBUG TRAIN Batch 19/8300 loss 9.673634 loss_att 12.391590 loss_ctc 12.409340 loss_rnnt 8.635828 hw_loss 0.242724 lr 0.00038712 rank 7
2023-02-22 13:17:08,721 DEBUG TRAIN Batch 19/8300 loss 13.414764 loss_att 13.650724 loss_ctc 17.926563 loss_rnnt 12.612377 hw_loss 0.288042 lr 0.00038716 rank 2
2023-02-22 13:17:08,725 DEBUG TRAIN Batch 19/8300 loss 9.612932 loss_att 13.294572 loss_ctc 14.987127 loss_rnnt 8.096016 hw_loss 0.120055 lr 0.00038715 rank 3
2023-02-22 13:17:08,727 DEBUG TRAIN Batch 19/8300 loss 9.796348 loss_att 10.434946 loss_ctc 14.608032 loss_rnnt 8.857500 hw_loss 0.317943 lr 0.00038723 rank 0
2023-02-22 13:17:08,727 DEBUG TRAIN Batch 19/8300 loss 4.646724 loss_att 10.638126 loss_ctc 4.869206 loss_rnnt 3.301607 hw_loss 0.219698 lr 0.00038713 rank 6
2023-02-22 13:17:08,728 DEBUG TRAIN Batch 19/8300 loss 5.848180 loss_att 7.334244 loss_ctc 6.233807 loss_rnnt 5.336284 hw_loss 0.306125 lr 0.00038718 rank 1
2023-02-22 13:17:08,729 DEBUG TRAIN Batch 19/8300 loss 5.423525 loss_att 9.007259 loss_ctc 6.905214 loss_rnnt 4.427606 hw_loss 0.153026 lr 0.00038721 rank 4
2023-02-22 13:17:08,749 DEBUG TRAIN Batch 19/8300 loss 16.324055 loss_att 19.110355 loss_ctc 23.154713 loss_rnnt 14.732685 hw_loss 0.231292 lr 0.00038719 rank 5
2023-02-22 13:17:58,113 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 1
2023-02-22 13:17:58,114 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 7
2023-02-22 13:17:58,114 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 2
2023-02-22 13:17:58,115 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 3
2023-02-22 13:17:58,121 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 4
2023-02-22 13:17:58,121 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 6
2023-02-22 13:17:58,123 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 5
2023-02-22 13:17:58,133 DEBUG CV Batch 19/0 loss 1.915462 loss_att 2.109336 loss_ctc 2.681896 loss_rnnt 1.324572 hw_loss 0.843609 history loss 1.844519 rank 0
2023-02-22 13:18:09,491 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 4
2023-02-22 13:18:09,551 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 5
2023-02-22 13:18:09,575 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 1
2023-02-22 13:18:09,581 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 0
2023-02-22 13:18:09,585 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 3
2023-02-22 13:18:09,612 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 2
2023-02-22 13:18:09,676 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 6
2023-02-22 13:18:09,830 DEBUG CV Batch 19/100 loss 7.204809 loss_att 8.402215 loss_ctc 10.795767 loss_rnnt 6.285743 hw_loss 0.376483 history loss 3.596562 rank 7
2023-02-22 13:18:22,846 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 4
2023-02-22 13:18:22,997 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 1
2023-02-22 13:18:23,105 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 0
2023-02-22 13:18:23,182 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 2
2023-02-22 13:18:23,217 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 3
2023-02-22 13:18:23,250 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 7
2023-02-22 13:18:23,287 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 6
2023-02-22 13:18:23,675 DEBUG CV Batch 19/200 loss 5.663291 loss_att 15.332646 loss_ctc 4.396633 loss_rnnt 3.850924 hw_loss 0.088844 history loss 4.204855 rank 5
2023-02-22 13:18:35,101 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 1
2023-02-22 13:18:35,108 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 4
2023-02-22 13:18:35,589 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 2
2023-02-22 13:18:35,678 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 3
2023-02-22 13:18:35,701 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 7
2023-02-22 13:18:35,755 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 6
2023-02-22 13:18:36,077 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 0
2023-02-22 13:18:36,231 DEBUG CV Batch 19/300 loss 3.969564 loss_att 4.598401 loss_ctc 6.652365 loss_rnnt 3.286255 hw_loss 0.374691 history loss 4.383583 rank 5
2023-02-22 13:18:47,317 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 1
2023-02-22 13:18:47,459 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 4
2023-02-22 13:18:47,824 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 2
2023-02-22 13:18:47,891 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 7
2023-02-22 13:18:47,972 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 3
2023-02-22 13:18:48,328 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 6
2023-02-22 13:18:48,449 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 0
2023-02-22 13:18:48,628 DEBUG CV Batch 19/400 loss 16.432699 loss_att 74.678032 loss_ctc 7.304457 loss_rnnt 5.911005 hw_loss 0.168232 history loss 5.323848 rank 5
2023-02-22 13:18:57,921 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 1
2023-02-22 13:18:58,233 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 4
2023-02-22 13:18:58,782 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 7
2023-02-22 13:18:58,864 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 3
2023-02-22 13:18:58,887 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 2
2023-02-22 13:18:59,283 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 6
2023-02-22 13:18:59,473 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 5
2023-02-22 13:18:59,877 DEBUG CV Batch 19/500 loss 5.263410 loss_att 5.586200 loss_ctc 7.008541 loss_rnnt 4.829365 hw_loss 0.256504 history loss 6.118829 rank 0
2023-02-22 13:19:10,045 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 1
2023-02-22 13:19:10,548 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 4
2023-02-22 13:19:11,158 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 3
2023-02-22 13:19:11,182 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 2
2023-02-22 13:19:11,189 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 7
2023-02-22 13:19:11,601 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 6
2023-02-22 13:19:11,772 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 5
2023-02-22 13:19:12,425 DEBUG CV Batch 19/600 loss 8.364021 loss_att 8.514747 loss_ctc 10.233224 loss_rnnt 7.695524 hw_loss 0.729608 history loss 7.129725 rank 0
2023-02-22 13:19:21,342 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 1
2023-02-22 13:19:22,178 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 4
2023-02-22 13:19:22,773 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 3
2023-02-22 13:19:22,802 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 2
2023-02-22 13:19:22,807 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 7
2023-02-22 13:19:23,209 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 6
2023-02-22 13:19:23,267 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 5
2023-02-22 13:19:24,548 DEBUG CV Batch 19/700 loss 16.697557 loss_att 47.618252 loss_ctc 19.055561 loss_rnnt 10.057622 hw_loss 0.265115 history loss 7.827361 rank 0
2023-02-22 13:19:32,784 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 1
2023-02-22 13:19:33,563 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 4
2023-02-22 13:19:34,314 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 3
2023-02-22 13:19:34,346 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 7
2023-02-22 13:19:34,437 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 2
2023-02-22 13:19:34,737 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 5
2023-02-22 13:19:34,782 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 6
2023-02-22 13:19:36,400 DEBUG CV Batch 19/800 loss 10.829231 loss_att 11.782661 loss_ctc 16.676765 loss_rnnt 9.702571 hw_loss 0.293068 history loss 7.263914 rank 0
2023-02-22 13:19:46,554 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 1
2023-02-22 13:19:46,869 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 4
2023-02-22 13:19:47,730 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 3
2023-02-22 13:19:47,877 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 7
2023-02-22 13:19:47,917 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 2
2023-02-22 13:19:48,212 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 5
2023-02-22 13:19:48,278 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 6
2023-02-22 13:19:50,132 DEBUG CV Batch 19/900 loss 12.486667 loss_att 17.157307 loss_ctc 22.904585 loss_rnnt 10.085097 hw_loss 0.146973 history loss 7.053075 rank 0
2023-02-22 13:19:58,826 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 1
2023-02-22 13:19:59,262 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 4
2023-02-22 13:19:59,981 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 3
2023-02-22 13:20:00,191 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 2
2023-02-22 13:20:00,299 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 7
2023-02-22 13:20:00,658 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 6
2023-02-22 13:20:01,050 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 5
2023-02-22 13:20:02,901 DEBUG CV Batch 19/1000 loss 4.500199 loss_att 5.398796 loss_ctc 5.024298 loss_rnnt 4.040077 hw_loss 0.394730 history loss 6.814797 rank 0
2023-02-22 13:20:10,636 DEBUG CV Batch 19/1100 loss 6.623429 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 1
2023-02-22 13:20:11,150 DEBUG CV Batch 19/1100 loss 6.623429 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 4
2023-02-22 13:20:12,154 DEBUG CV Batch 19/1100 loss 6.623430 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 3
2023-02-22 13:20:12,362 DEBUG CV Batch 19/1100 loss 6.623429 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 2
2023-02-22 13:20:12,568 DEBUG CV Batch 19/1100 loss 6.623430 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 7
2023-02-22 13:20:12,857 DEBUG CV Batch 19/1100 loss 6.623430 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 6
2023-02-22 13:20:13,576 DEBUG CV Batch 19/1100 loss 6.623429 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 5
2023-02-22 13:20:15,320 DEBUG CV Batch 19/1100 loss 6.623429 loss_att 5.840974 loss_ctc 8.317847 loss_rnnt 6.172474 hw_loss 0.715358 history loss 6.775536 rank 0
2023-02-22 13:20:21,309 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 1
2023-02-22 13:20:21,937 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 4
2023-02-22 13:20:23,149 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 3
2023-02-22 13:20:23,364 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 2
2023-02-22 13:20:23,456 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 7
2023-02-22 13:20:23,814 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 6
2023-02-22 13:20:24,493 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 5
2023-02-22 13:20:26,553 DEBUG CV Batch 19/1200 loss 7.063570 loss_att 7.338428 loss_ctc 9.312050 loss_rnnt 6.474718 hw_loss 0.438906 history loss 7.117587 rank 0
2023-02-22 13:20:33,274 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 1
2023-02-22 13:20:34,126 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 4
2023-02-22 13:20:35,422 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 3
2023-02-22 13:20:35,578 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 2
2023-02-22 13:20:35,715 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 7
2023-02-22 13:20:36,123 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 6
2023-02-22 13:20:36,927 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 5
2023-02-22 13:20:39,098 DEBUG CV Batch 19/1300 loss 5.285875 loss_att 5.201501 loss_ctc 7.629845 loss_rnnt 4.736947 hw_loss 0.474887 history loss 7.455739 rank 0
2023-02-22 13:20:44,477 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 1
2023-02-22 13:20:45,343 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 4
2023-02-22 13:20:46,871 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 3
2023-02-22 13:20:47,049 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 2
2023-02-22 13:20:47,114 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 7
2023-02-22 13:20:47,688 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 6
2023-02-22 13:20:48,333 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 5
2023-02-22 13:20:51,238 DEBUG CV Batch 19/1400 loss 4.529709 loss_att 18.002176 loss_ctc 3.081768 loss_rnnt 1.802974 hw_loss 0.422439 history loss 7.795736 rank 0
2023-02-22 13:20:55,974 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 1
2023-02-22 13:20:57,012 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 4
2023-02-22 13:20:58,650 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 3
2023-02-22 13:20:58,892 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 2
2023-02-22 13:20:58,989 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 7
2023-02-22 13:20:59,394 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 6
2023-02-22 13:21:00,103 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 5
2023-02-22 13:21:03,410 DEBUG CV Batch 19/1500 loss 6.183921 loss_att 7.086483 loss_ctc 5.860915 loss_rnnt 5.918863 hw_loss 0.239275 history loss 7.608715 rank 0
2023-02-22 13:21:08,963 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 1
2023-02-22 13:21:10,352 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 4
2023-02-22 13:21:11,944 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 3
2023-02-22 13:21:12,177 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 2
2023-02-22 13:21:12,317 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 7
2023-02-22 13:21:12,807 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 6
2023-02-22 13:21:13,470 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 5
2023-02-22 13:21:17,043 DEBUG CV Batch 19/1600 loss 10.702709 loss_att 18.641005 loss_ctc 10.361607 loss_rnnt 9.018408 hw_loss 0.266479 history loss 7.533150 rank 0
2023-02-22 13:21:21,532 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 1
2023-02-22 13:21:22,869 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 4
2023-02-22 13:21:24,456 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 3
2023-02-22 13:21:24,743 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 2
2023-02-22 13:21:24,791 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 7
2023-02-22 13:21:25,409 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 6
2023-02-22 13:21:25,848 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 5
2023-02-22 13:21:29,697 DEBUG CV Batch 19/1700 loss 9.842117 loss_att 9.605306 loss_ctc 15.452475 loss_rnnt 8.921138 hw_loss 0.413052 history loss 7.429070 rank 0
2023-02-22 13:21:30,863 INFO Epoch 19 CV info cv_loss 7.3938966322636945
2023-02-22 13:21:30,863 INFO Epoch 20 TRAIN info lr 0.0003871423476796645
2023-02-22 13:21:30,868 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:21:31,892 INFO Epoch 19 CV info cv_loss 7.393896630239256
2023-02-22 13:21:31,893 INFO Epoch 20 TRAIN info lr 0.0003871922584723622
2023-02-22 13:21:31,895 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:21:33,648 INFO Epoch 19 CV info cv_loss 7.393896630187568
2023-02-22 13:21:33,649 INFO Epoch 20 TRAIN info lr 0.00038708897610084024
2023-02-22 13:21:33,654 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:21:33,904 INFO Epoch 19 CV info cv_loss 7.393896634313977
2023-02-22 13:21:33,904 INFO Epoch 20 TRAIN info lr 0.0003871226208288659
2023-02-22 13:21:33,906 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:21:33,945 INFO Epoch 19 CV info cv_loss 7.393896633788485
2023-02-22 13:21:33,945 INFO Epoch 20 TRAIN info lr 0.0003870657779504856
2023-02-22 13:21:33,947 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:21:34,466 INFO Epoch 19 CV info cv_loss 7.393896632713809
2023-02-22 13:21:34,467 INFO Epoch 20 TRAIN info lr 0.00038706345836483604
2023-02-22 13:21:34,469 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:21:34,912 INFO Epoch 19 CV info cv_loss 7.3938966326341236
2023-02-22 13:21:34,913 INFO Epoch 20 TRAIN info lr 0.00038715743495349255
2023-02-22 13:21:34,914 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:21:39,070 INFO Epoch 19 CV info cv_loss 7.393896633883245
2023-02-22 13:21:39,070 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/19.pt
2023-02-22 13:21:39,793 INFO Epoch 20 TRAIN info lr 0.0003871922584723622
2023-02-22 13:21:39,796 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 13:22:38,973 DEBUG TRAIN Batch 20/0 loss 11.180080 loss_att 9.622993 loss_ctc 13.153593 loss_rnnt 10.992692 hw_loss 0.441881 lr 0.00038709 rank 3
2023-02-22 13:22:38,973 DEBUG TRAIN Batch 20/0 loss 10.361319 loss_att 9.218723 loss_ctc 13.287676 loss_rnnt 10.024419 hw_loss 0.328569 lr 0.00038714 rank 1
2023-02-22 13:22:38,974 DEBUG TRAIN Batch 20/0 loss 6.478209 loss_att 6.572921 loss_ctc 7.752133 loss_rnnt 6.087438 hw_loss 0.378699 lr 0.00038706 rank 7
2023-02-22 13:22:38,974 DEBUG TRAIN Batch 20/0 loss 10.863164 loss_att 10.085334 loss_ctc 13.618325 loss_rnnt 10.454352 hw_loss 0.369418 lr 0.00038706 rank 6
2023-02-22 13:22:38,976 DEBUG TRAIN Batch 20/0 loss 14.141864 loss_att 13.156171 loss_ctc 15.753847 loss_rnnt 13.856547 hw_loss 0.501606 lr 0.00038712 rank 2
2023-02-22 13:22:38,977 DEBUG TRAIN Batch 20/0 loss 9.698840 loss_att 8.976227 loss_ctc 11.757708 loss_rnnt 9.261088 hw_loss 0.577048 lr 0.00038719 rank 4
2023-02-22 13:22:38,978 DEBUG TRAIN Batch 20/0 loss 7.247276 loss_att 6.934098 loss_ctc 9.327781 loss_rnnt 6.782088 hw_loss 0.469543 lr 0.00038716 rank 5
2023-02-22 13:22:39,026 DEBUG TRAIN Batch 20/0 loss 7.778109 loss_att 7.607688 loss_ctc 9.801284 loss_rnnt 7.307484 hw_loss 0.440534 lr 0.00038719 rank 0
2023-02-22 13:23:50,749 DEBUG TRAIN Batch 20/100 loss 2.031428 loss_att 5.959507 loss_ctc 2.898040 loss_rnnt 1.050209 hw_loss 0.150105 lr 0.00038701 rank 2
2023-02-22 13:23:50,752 DEBUG TRAIN Batch 20/100 loss 9.089444 loss_att 11.068946 loss_ctc 9.979994 loss_rnnt 8.382178 hw_loss 0.361174 lr 0.00038708 rank 0
2023-02-22 13:23:50,754 DEBUG TRAIN Batch 20/100 loss 5.603259 loss_att 8.751513 loss_ctc 4.885887 loss_rnnt 4.862049 hw_loss 0.388515 lr 0.00038695 rank 6
2023-02-22 13:23:50,754 DEBUG TRAIN Batch 20/100 loss 10.742677 loss_att 17.651579 loss_ctc 21.023445 loss_rnnt 7.901671 hw_loss 0.165856 lr 0.00038697 rank 3
2023-02-22 13:23:50,755 DEBUG TRAIN Batch 20/100 loss 12.121536 loss_att 14.376188 loss_ctc 16.974964 loss_rnnt 10.930016 hw_loss 0.175250 lr 0.00038704 rank 5
2023-02-22 13:23:50,757 DEBUG TRAIN Batch 20/100 loss 4.648579 loss_att 7.355374 loss_ctc 8.469226 loss_rnnt 3.434648 hw_loss 0.305911 lr 0.00038703 rank 1
2023-02-22 13:23:50,760 DEBUG TRAIN Batch 20/100 loss 14.360247 loss_att 16.844490 loss_ctc 18.735159 loss_rnnt 13.119978 hw_loss 0.300185 lr 0.00038695 rank 7
2023-02-22 13:23:50,762 DEBUG TRAIN Batch 20/100 loss 4.902282 loss_att 8.572718 loss_ctc 8.618636 loss_rnnt 3.509533 hw_loss 0.305901 lr 0.00038708 rank 4
2023-02-22 13:25:02,733 DEBUG TRAIN Batch 20/200 loss 8.407660 loss_att 11.308176 loss_ctc 14.462745 loss_rnnt 6.821069 hw_loss 0.373395 lr 0.00038691 rank 1
2023-02-22 13:25:02,735 DEBUG TRAIN Batch 20/200 loss 4.063551 loss_att 5.933047 loss_ctc 3.473439 loss_rnnt 3.579495 hw_loss 0.354072 lr 0.00038689 rank 2
2023-02-22 13:25:02,737 DEBUG TRAIN Batch 20/200 loss 3.154211 loss_att 7.890595 loss_ctc 4.674502 loss_rnnt 1.929783 hw_loss 0.139585 lr 0.00038686 rank 3
2023-02-22 13:25:02,737 DEBUG TRAIN Batch 20/200 loss 13.642920 loss_att 17.154907 loss_ctc 15.066412 loss_rnnt 12.605124 hw_loss 0.273002 lr 0.00038683 rank 6
2023-02-22 13:25:02,740 DEBUG TRAIN Batch 20/200 loss 3.517166 loss_att 5.686576 loss_ctc 3.873417 loss_rnnt 2.850509 hw_loss 0.347390 lr 0.00038696 rank 0
2023-02-22 13:25:02,740 DEBUG TRAIN Batch 20/200 loss 2.843134 loss_att 5.693249 loss_ctc 4.733243 loss_rnnt 1.911049 hw_loss 0.206338 lr 0.00038683 rank 7
2023-02-22 13:25:02,742 DEBUG TRAIN Batch 20/200 loss 11.441700 loss_att 14.603595 loss_ctc 17.029881 loss_rnnt 9.960540 hw_loss 0.194420 lr 0.00038692 rank 5
2023-02-22 13:25:02,788 DEBUG TRAIN Batch 20/200 loss 13.707129 loss_att 18.290274 loss_ctc 19.137379 loss_rnnt 11.937363 hw_loss 0.242066 lr 0.00038696 rank 4
2023-02-22 13:26:15,628 DEBUG TRAIN Batch 20/300 loss 13.344367 loss_att 16.621994 loss_ctc 17.504314 loss_rnnt 11.982919 hw_loss 0.283619 lr 0.00038677 rank 2
2023-02-22 13:26:15,629 DEBUG TRAIN Batch 20/300 loss 5.436230 loss_att 8.699838 loss_ctc 9.427541 loss_rnnt 4.046715 hw_loss 0.383660 lr 0.00038684 rank 0
2023-02-22 13:26:15,632 DEBUG TRAIN Batch 20/300 loss 7.684548 loss_att 11.360596 loss_ctc 8.508194 loss_rnnt 6.796126 hw_loss 0.081361 lr 0.00038672 rank 7
2023-02-22 13:26:15,636 DEBUG TRAIN Batch 20/300 loss 5.533971 loss_att 8.443202 loss_ctc 8.523560 loss_rnnt 4.420460 hw_loss 0.249472 lr 0.00038671 rank 6
2023-02-22 13:26:15,647 DEBUG TRAIN Batch 20/300 loss 9.348923 loss_att 11.620716 loss_ctc 11.588569 loss_rnnt 8.495718 hw_loss 0.187923 lr 0.00038679 rank 1
2023-02-22 13:26:15,655 DEBUG TRAIN Batch 20/300 loss 11.980091 loss_att 14.193104 loss_ctc 14.245464 loss_rnnt 11.082338 hw_loss 0.287063 lr 0.00038674 rank 3
2023-02-22 13:26:15,658 DEBUG TRAIN Batch 20/300 loss 11.518117 loss_att 14.052048 loss_ctc 14.712039 loss_rnnt 10.448002 hw_loss 0.257761 lr 0.00038681 rank 5
2023-02-22 13:26:15,663 DEBUG TRAIN Batch 20/300 loss 9.870358 loss_att 11.999165 loss_ctc 13.595634 loss_rnnt 8.893950 hw_loss 0.101142 lr 0.00038684 rank 4
2023-02-22 13:27:29,648 DEBUG TRAIN Batch 20/400 loss 13.420896 loss_att 14.694745 loss_ctc 11.833421 loss_rnnt 13.259946 hw_loss 0.220955 lr 0.00038668 rank 1
2023-02-22 13:27:29,659 DEBUG TRAIN Batch 20/400 loss 12.198133 loss_att 13.047503 loss_ctc 15.580495 loss_rnnt 11.422158 hw_loss 0.290848 lr 0.00038666 rank 2
2023-02-22 13:27:29,661 DEBUG TRAIN Batch 20/400 loss 9.940474 loss_att 14.374102 loss_ctc 13.385508 loss_rnnt 8.469625 hw_loss 0.233970 lr 0.00038673 rank 4
2023-02-22 13:27:29,663 DEBUG TRAIN Batch 20/400 loss 12.598246 loss_att 15.793147 loss_ctc 16.019819 loss_rnnt 11.354216 hw_loss 0.279076 lr 0.00038662 rank 3
2023-02-22 13:27:29,666 DEBUG TRAIN Batch 20/400 loss 13.227277 loss_att 17.025452 loss_ctc 17.011425 loss_rnnt 11.892823 hw_loss 0.131747 lr 0.00038673 rank 0
2023-02-22 13:27:29,667 DEBUG TRAIN Batch 20/400 loss 6.424187 loss_att 9.149389 loss_ctc 11.237806 loss_rnnt 5.007736 hw_loss 0.430490 lr 0.00038660 rank 6
2023-02-22 13:27:29,668 DEBUG TRAIN Batch 20/400 loss 9.360373 loss_att 13.182154 loss_ctc 14.045712 loss_rnnt 7.818152 hw_loss 0.287161 lr 0.00038660 rank 7
2023-02-22 13:27:29,671 DEBUG TRAIN Batch 20/400 loss 11.117252 loss_att 13.686550 loss_ctc 13.852444 loss_rnnt 10.050875 hw_loss 0.352173 lr 0.00038669 rank 5
2023-02-22 13:28:42,238 DEBUG TRAIN Batch 20/500 loss 6.533966 loss_att 10.116543 loss_ctc 13.959200 loss_rnnt 4.684489 hw_loss 0.267996 lr 0.00038654 rank 2
2023-02-22 13:28:42,238 DEBUG TRAIN Batch 20/500 loss 12.158036 loss_att 15.037999 loss_ctc 19.954159 loss_rnnt 10.402689 hw_loss 0.262257 lr 0.00038651 rank 3
2023-02-22 13:28:42,248 DEBUG TRAIN Batch 20/500 loss 11.929095 loss_att 14.221514 loss_ctc 17.476208 loss_rnnt 10.545956 hw_loss 0.346953 lr 0.00038649 rank 7
2023-02-22 13:28:42,248 DEBUG TRAIN Batch 20/500 loss 10.989775 loss_att 13.723571 loss_ctc 10.753795 loss_rnnt 10.306128 hw_loss 0.315659 lr 0.00038648 rank 6
2023-02-22 13:28:42,249 DEBUG TRAIN Batch 20/500 loss 7.936874 loss_att 9.309107 loss_ctc 11.691516 loss_rnnt 7.054105 hw_loss 0.201944 lr 0.00038661 rank 4
2023-02-22 13:28:42,253 DEBUG TRAIN Batch 20/500 loss 14.429291 loss_att 16.511850 loss_ctc 19.555204 loss_rnnt 13.219923 hw_loss 0.205126 lr 0.00038656 rank 1
2023-02-22 13:28:42,256 DEBUG TRAIN Batch 20/500 loss 8.006399 loss_att 11.228970 loss_ctc 10.016748 loss_rnnt 6.923459 hw_loss 0.319462 lr 0.00038658 rank 5
2023-02-22 13:28:42,303 DEBUG TRAIN Batch 20/500 loss 10.535841 loss_att 13.714361 loss_ctc 15.006028 loss_rnnt 9.086119 hw_loss 0.408735 lr 0.00038661 rank 0
2023-02-22 13:29:55,679 DEBUG TRAIN Batch 20/600 loss 12.987706 loss_att 13.299282 loss_ctc 17.231133 loss_rnnt 12.147143 hw_loss 0.398358 lr 0.00038637 rank 7
2023-02-22 13:29:55,679 DEBUG TRAIN Batch 20/600 loss 5.106454 loss_att 6.688868 loss_ctc 6.196158 loss_rnnt 4.508872 hw_loss 0.254635 lr 0.00038639 rank 3
2023-02-22 13:29:55,681 DEBUG TRAIN Batch 20/600 loss 11.674848 loss_att 12.827208 loss_ctc 15.795020 loss_rnnt 10.719225 hw_loss 0.329613 lr 0.00038650 rank 0
2023-02-22 13:29:55,682 DEBUG TRAIN Batch 20/600 loss 7.514109 loss_att 9.500371 loss_ctc 10.640309 loss_rnnt 6.458820 hw_loss 0.452269 lr 0.00038637 rank 6
2023-02-22 13:29:55,683 DEBUG TRAIN Batch 20/600 loss 8.481587 loss_att 11.943433 loss_ctc 10.754505 loss_rnnt 7.342491 hw_loss 0.269385 lr 0.00038650 rank 4
2023-02-22 13:29:55,683 DEBUG TRAIN Batch 20/600 loss 6.654974 loss_att 8.584087 loss_ctc 9.991705 loss_rnnt 5.678025 hw_loss 0.274178 lr 0.00038643 rank 2
2023-02-22 13:29:55,686 DEBUG TRAIN Batch 20/600 loss 10.104116 loss_att 10.442053 loss_ctc 14.388843 loss_rnnt 9.324210 hw_loss 0.264418 lr 0.00038646 rank 5
2023-02-22 13:29:55,690 DEBUG TRAIN Batch 20/600 loss 7.670946 loss_att 8.306703 loss_ctc 9.348472 loss_rnnt 7.130703 hw_loss 0.355164 lr 0.00038645 rank 1
2023-02-22 13:31:09,856 DEBUG TRAIN Batch 20/700 loss 6.137306 loss_att 10.160504 loss_ctc 15.568839 loss_rnnt 3.998482 hw_loss 0.143714 lr 0.00038631 rank 2
2023-02-22 13:31:09,858 DEBUG TRAIN Batch 20/700 loss 5.089808 loss_att 8.069468 loss_ctc 8.979099 loss_rnnt 3.835261 hw_loss 0.262580 lr 0.00038628 rank 3
2023-02-22 13:31:09,858 DEBUG TRAIN Batch 20/700 loss 1.917932 loss_att 5.898473 loss_ctc 3.022959 loss_rnnt 0.920645 hw_loss 0.100955 lr 0.00038626 rank 7
2023-02-22 13:31:09,860 DEBUG TRAIN Batch 20/700 loss 8.950209 loss_att 11.861216 loss_ctc 13.413009 loss_rnnt 7.667836 hw_loss 0.197119 lr 0.00038625 rank 6
2023-02-22 13:31:09,863 DEBUG TRAIN Batch 20/700 loss 8.797130 loss_att 13.033636 loss_ctc 12.180255 loss_rnnt 7.348895 hw_loss 0.280970 lr 0.00038638 rank 4
2023-02-22 13:31:09,882 DEBUG TRAIN Batch 20/700 loss 5.822943 loss_att 9.236893 loss_ctc 8.617672 loss_rnnt 4.613981 hw_loss 0.287889 lr 0.00038633 rank 1
2023-02-22 13:31:09,892 DEBUG TRAIN Batch 20/700 loss 9.109002 loss_att 12.357475 loss_ctc 9.826865 loss_rnnt 8.311010 hw_loss 0.098591 lr 0.00038638 rank 0
2023-02-22 13:31:09,911 DEBUG TRAIN Batch 20/700 loss 2.610023 loss_att 6.559258 loss_ctc 4.399809 loss_rnnt 1.464841 hw_loss 0.218805 lr 0.00038635 rank 5
2023-02-22 13:32:22,245 DEBUG TRAIN Batch 20/800 loss 11.695013 loss_att 12.599569 loss_ctc 18.550018 loss_rnnt 10.499849 hw_loss 0.187971 lr 0.00038616 rank 3
2023-02-22 13:32:22,246 DEBUG TRAIN Batch 20/800 loss 11.762137 loss_att 15.119503 loss_ctc 19.197908 loss_rnnt 9.964678 hw_loss 0.252283 lr 0.00038622 rank 1
2023-02-22 13:32:22,247 DEBUG TRAIN Batch 20/800 loss 10.505861 loss_att 11.472058 loss_ctc 14.444041 loss_rnnt 9.652992 hw_loss 0.252259 lr 0.00038620 rank 2
2023-02-22 13:32:22,248 DEBUG TRAIN Batch 20/800 loss 7.612230 loss_att 10.796311 loss_ctc 13.668066 loss_rnnt 6.109871 hw_loss 0.108933 lr 0.00038627 rank 4
2023-02-22 13:32:22,249 DEBUG TRAIN Batch 20/800 loss 16.254015 loss_att 23.294548 loss_ctc 26.233618 loss_rnnt 13.325686 hw_loss 0.355515 lr 0.00038614 rank 6
2023-02-22 13:32:22,249 DEBUG TRAIN Batch 20/800 loss 5.694065 loss_att 7.377933 loss_ctc 6.239479 loss_rnnt 5.164412 hw_loss 0.225295 lr 0.00038623 rank 5
2023-02-22 13:32:22,252 DEBUG TRAIN Batch 20/800 loss 11.946553 loss_att 15.461708 loss_ctc 15.260693 loss_rnnt 10.728839 hw_loss 0.136498 lr 0.00038614 rank 7
2023-02-22 13:32:22,300 DEBUG TRAIN Batch 20/800 loss 2.181433 loss_att 4.422380 loss_ctc 2.856996 loss_rnnt 1.517548 hw_loss 0.235537 lr 0.00038627 rank 0
2023-02-22 13:33:34,031 DEBUG TRAIN Batch 20/900 loss 10.696619 loss_att 12.435583 loss_ctc 13.959076 loss_rnnt 9.767286 hw_loss 0.274772 lr 0.00038615 rank 4
2023-02-22 13:33:34,043 DEBUG TRAIN Batch 20/900 loss 11.644968 loss_att 13.142904 loss_ctc 12.729246 loss_rnnt 11.084230 hw_loss 0.218586 lr 0.00038605 rank 3
2023-02-22 13:33:34,044 DEBUG TRAIN Batch 20/900 loss 7.971591 loss_att 10.533949 loss_ctc 9.844818 loss_rnnt 7.022601 hw_loss 0.350167 lr 0.00038602 rank 6
2023-02-22 13:33:34,046 DEBUG TRAIN Batch 20/900 loss 10.079437 loss_att 13.752296 loss_ctc 10.979052 loss_rnnt 8.972385 hw_loss 0.473496 lr 0.00038612 rank 5
2023-02-22 13:33:34,046 DEBUG TRAIN Batch 20/900 loss 10.720900 loss_att 13.546673 loss_ctc 13.598809 loss_rnnt 9.620621 hw_loss 0.283880 lr 0.00038608 rank 2
2023-02-22 13:33:34,057 DEBUG TRAIN Batch 20/900 loss 5.414490 loss_att 10.030511 loss_ctc 8.113297 loss_rnnt 3.964897 hw_loss 0.312279 lr 0.00038610 rank 1
2023-02-22 13:33:34,071 DEBUG TRAIN Batch 20/900 loss 13.753554 loss_att 17.523336 loss_ctc 18.527050 loss_rnnt 12.226871 hw_loss 0.255492 lr 0.00038603 rank 7
2023-02-22 13:33:34,107 DEBUG TRAIN Batch 20/900 loss 10.684525 loss_att 13.888769 loss_ctc 17.658253 loss_rnnt 8.909237 hw_loss 0.383641 lr 0.00038615 rank 0
2023-02-22 13:34:46,994 DEBUG TRAIN Batch 20/1000 loss 7.563130 loss_att 8.591286 loss_ctc 9.457653 loss_rnnt 6.958653 hw_loss 0.274204 lr 0.00038591 rank 6
2023-02-22 13:34:46,994 DEBUG TRAIN Batch 20/1000 loss 5.991820 loss_att 8.561233 loss_ctc 8.936388 loss_rnnt 4.952344 hw_loss 0.249346 lr 0.00038599 rank 1
2023-02-22 13:34:46,994 DEBUG TRAIN Batch 20/1000 loss 10.632953 loss_att 14.946852 loss_ctc 13.104812 loss_rnnt 9.274306 hw_loss 0.311788 lr 0.00038600 rank 5
2023-02-22 13:34:46,998 DEBUG TRAIN Batch 20/1000 loss 8.376487 loss_att 14.082225 loss_ctc 10.498075 loss_rnnt 6.877819 hw_loss 0.139953 lr 0.00038593 rank 3
2023-02-22 13:34:47,001 DEBUG TRAIN Batch 20/1000 loss 5.925470 loss_att 9.306851 loss_ctc 6.074871 loss_rnnt 5.062266 hw_loss 0.313139 lr 0.00038597 rank 2
2023-02-22 13:34:47,002 DEBUG TRAIN Batch 20/1000 loss 12.433031 loss_att 15.202435 loss_ctc 19.028130 loss_rnnt 10.905886 hw_loss 0.176095 lr 0.00038604 rank 0
2023-02-22 13:34:47,017 DEBUG TRAIN Batch 20/1000 loss 8.050358 loss_att 10.805960 loss_ctc 13.582353 loss_rnnt 6.564790 hw_loss 0.369089 lr 0.00038604 rank 4
2023-02-22 13:34:47,025 DEBUG TRAIN Batch 20/1000 loss 18.662603 loss_att 17.390778 loss_ctc 24.887171 loss_rnnt 17.997705 hw_loss 0.167476 lr 0.00038591 rank 7
2023-02-22 13:36:01,302 DEBUG TRAIN Batch 20/1100 loss 10.711656 loss_att 13.327778 loss_ctc 14.783048 loss_rnnt 9.487556 hw_loss 0.296293 lr 0.00038582 rank 3
2023-02-22 13:36:01,305 DEBUG TRAIN Batch 20/1100 loss 15.379910 loss_att 15.419474 loss_ctc 17.006880 loss_rnnt 14.971191 hw_loss 0.344768 lr 0.00038585 rank 2
2023-02-22 13:36:01,306 DEBUG TRAIN Batch 20/1100 loss 12.907972 loss_att 14.861134 loss_ctc 18.559801 loss_rnnt 11.614506 hw_loss 0.279858 lr 0.00038592 rank 0
2023-02-22 13:36:01,306 DEBUG TRAIN Batch 20/1100 loss 8.704991 loss_att 12.002548 loss_ctc 13.555494 loss_rnnt 7.315246 hw_loss 0.156563 lr 0.00038579 rank 6
2023-02-22 13:36:01,312 DEBUG TRAIN Batch 20/1100 loss 9.045023 loss_att 11.687920 loss_ctc 12.504521 loss_rnnt 7.979130 hw_loss 0.142589 lr 0.00038589 rank 5
2023-02-22 13:36:01,313 DEBUG TRAIN Batch 20/1100 loss 20.182055 loss_att 24.497566 loss_ctc 30.199480 loss_rnnt 17.832218 hw_loss 0.283270 lr 0.00038580 rank 7
2023-02-22 13:36:01,313 DEBUG TRAIN Batch 20/1100 loss 5.293985 loss_att 7.637699 loss_ctc 6.876037 loss_rnnt 4.497453 hw_loss 0.219092 lr 0.00038587 rank 1
2023-02-22 13:36:01,363 DEBUG TRAIN Batch 20/1100 loss 6.923657 loss_att 10.525227 loss_ctc 12.767122 loss_rnnt 5.277931 hw_loss 0.274282 lr 0.00038592 rank 4
2023-02-22 13:37:13,942 DEBUG TRAIN Batch 20/1200 loss 10.582404 loss_att 10.603215 loss_ctc 11.763618 loss_rnnt 10.173731 hw_loss 0.463155 lr 0.00038570 rank 3
2023-02-22 13:37:13,942 DEBUG TRAIN Batch 20/1200 loss 7.660689 loss_att 9.274592 loss_ctc 9.448829 loss_rnnt 6.965696 hw_loss 0.250862 lr 0.00038574 rank 2
2023-02-22 13:37:13,943 DEBUG TRAIN Batch 20/1200 loss 13.282668 loss_att 12.884186 loss_ctc 14.467551 loss_rnnt 13.100424 hw_loss 0.194918 lr 0.00038577 rank 5
2023-02-22 13:37:13,944 DEBUG TRAIN Batch 20/1200 loss 8.162992 loss_att 11.938250 loss_ctc 12.495720 loss_rnnt 6.630824 hw_loss 0.373911 lr 0.00038568 rank 6
2023-02-22 13:37:13,945 DEBUG TRAIN Batch 20/1200 loss 10.464592 loss_att 11.725367 loss_ctc 13.564722 loss_rnnt 9.594296 hw_loss 0.383983 lr 0.00038568 rank 7
2023-02-22 13:37:13,947 DEBUG TRAIN Batch 20/1200 loss 7.995995 loss_att 10.151207 loss_ctc 13.153862 loss_rnnt 6.745518 hw_loss 0.246973 lr 0.00038581 rank 0
2023-02-22 13:37:13,947 DEBUG TRAIN Batch 20/1200 loss 6.011411 loss_att 7.337097 loss_ctc 6.848423 loss_rnnt 5.427329 hw_loss 0.388769 lr 0.00038576 rank 1
2023-02-22 13:37:13,990 DEBUG TRAIN Batch 20/1200 loss 8.916067 loss_att 8.801912 loss_ctc 12.772867 loss_rnnt 8.191859 hw_loss 0.436499 lr 0.00038581 rank 4
2023-02-22 13:38:26,505 DEBUG TRAIN Batch 20/1300 loss 9.692493 loss_att 12.479011 loss_ctc 11.690677 loss_rnnt 8.717125 hw_loss 0.284326 lr 0.00038557 rank 7
2023-02-22 13:38:26,505 DEBUG TRAIN Batch 20/1300 loss 6.841735 loss_att 6.443937 loss_ctc 8.945325 loss_rnnt 6.335616 hw_loss 0.572251 lr 0.00038559 rank 3
2023-02-22 13:38:26,508 DEBUG TRAIN Batch 20/1300 loss 3.135423 loss_att 6.265574 loss_ctc 6.905719 loss_rnnt 1.853003 hw_loss 0.288157 lr 0.00038569 rank 4
2023-02-22 13:38:26,509 DEBUG TRAIN Batch 20/1300 loss 15.558610 loss_att 15.673069 loss_ctc 19.961874 loss_rnnt 14.792598 hw_loss 0.292535 lr 0.00038569 rank 0
2023-02-22 13:38:26,508 DEBUG TRAIN Batch 20/1300 loss 9.275798 loss_att 12.903126 loss_ctc 19.523294 loss_rnnt 7.026520 hw_loss 0.295274 lr 0.00038562 rank 2
2023-02-22 13:38:26,512 DEBUG TRAIN Batch 20/1300 loss 11.489647 loss_att 14.775082 loss_ctc 14.015459 loss_rnnt 10.370082 hw_loss 0.235696 lr 0.00038566 rank 5
2023-02-22 13:38:26,513 DEBUG TRAIN Batch 20/1300 loss 9.690352 loss_att 9.901165 loss_ctc 14.620159 loss_rnnt 8.743471 hw_loss 0.463895 lr 0.00038556 rank 6
2023-02-22 13:38:26,516 DEBUG TRAIN Batch 20/1300 loss 12.745420 loss_att 17.066597 loss_ctc 17.459869 loss_rnnt 11.049536 hw_loss 0.380731 lr 0.00038564 rank 1
2023-02-22 13:39:41,096 DEBUG TRAIN Batch 20/1400 loss 11.463010 loss_att 13.407090 loss_ctc 15.024689 loss_rnnt 10.460587 hw_loss 0.260093 lr 0.00038551 rank 2
2023-02-22 13:39:41,103 DEBUG TRAIN Batch 20/1400 loss 1.846510 loss_att 5.445714 loss_ctc 2.597166 loss_rnnt 0.969492 hw_loss 0.107044 lr 0.00038545 rank 6
2023-02-22 13:39:41,107 DEBUG TRAIN Batch 20/1400 loss 19.010946 loss_att 23.446999 loss_ctc 20.102037 loss_rnnt 17.860628 hw_loss 0.220553 lr 0.00038558 rank 4
2023-02-22 13:39:41,107 DEBUG TRAIN Batch 20/1400 loss 11.903786 loss_att 14.797180 loss_ctc 15.432705 loss_rnnt 10.709942 hw_loss 0.271206 lr 0.00038547 rank 3
2023-02-22 13:39:41,107 DEBUG TRAIN Batch 20/1400 loss 20.526333 loss_att 23.541691 loss_ctc 26.742851 loss_rnnt 19.002075 hw_loss 0.173091 lr 0.00038545 rank 7
2023-02-22 13:39:41,107 DEBUG TRAIN Batch 20/1400 loss 6.389225 loss_att 11.715172 loss_ctc 9.232615 loss_rnnt 4.848763 hw_loss 0.180291 lr 0.00038554 rank 5
2023-02-22 13:39:41,114 DEBUG TRAIN Batch 20/1400 loss 8.320609 loss_att 9.135725 loss_ctc 11.591455 loss_rnnt 7.568361 hw_loss 0.287087 lr 0.00038553 rank 1
2023-02-22 13:39:41,114 DEBUG TRAIN Batch 20/1400 loss 7.338962 loss_att 10.707586 loss_ctc 9.942810 loss_rnnt 6.133613 hw_loss 0.345833 lr 0.00038558 rank 0
2023-02-22 13:40:53,894 DEBUG TRAIN Batch 20/1500 loss 15.668915 loss_att 21.345814 loss_ctc 27.595226 loss_rnnt 12.669847 hw_loss 0.512837 lr 0.00038536 rank 3
2023-02-22 13:40:53,897 DEBUG TRAIN Batch 20/1500 loss 17.382538 loss_att 18.676146 loss_ctc 26.431356 loss_rnnt 15.800975 hw_loss 0.218123 lr 0.00038539 rank 2
2023-02-22 13:40:53,897 DEBUG TRAIN Batch 20/1500 loss 5.174262 loss_att 6.707273 loss_ctc 5.376932 loss_rnnt 4.712616 hw_loss 0.240039 lr 0.00038533 rank 6
2023-02-22 13:40:53,898 DEBUG TRAIN Batch 20/1500 loss 6.847140 loss_att 10.682121 loss_ctc 11.824682 loss_rnnt 5.215446 hw_loss 0.376922 lr 0.00038546 rank 0
2023-02-22 13:40:53,899 DEBUG TRAIN Batch 20/1500 loss 13.441491 loss_att 16.167164 loss_ctc 18.677814 loss_rnnt 12.076508 hw_loss 0.228136 lr 0.00038546 rank 4
2023-02-22 13:40:53,901 DEBUG TRAIN Batch 20/1500 loss 13.488632 loss_att 15.823924 loss_ctc 15.372210 loss_rnnt 12.701992 hw_loss 0.128321 lr 0.00038534 rank 7
2023-02-22 13:40:53,900 DEBUG TRAIN Batch 20/1500 loss 6.502890 loss_att 9.163541 loss_ctc 7.652854 loss_rnnt 5.732078 hw_loss 0.160036 lr 0.00038541 rank 1
2023-02-22 13:40:53,906 DEBUG TRAIN Batch 20/1500 loss 6.977142 loss_att 11.131008 loss_ctc 8.399915 loss_rnnt 5.810590 hw_loss 0.273893 lr 0.00038543 rank 5
2023-02-22 13:42:05,111 DEBUG TRAIN Batch 20/1600 loss 11.176658 loss_att 10.386827 loss_ctc 12.631876 loss_rnnt 10.951144 hw_loss 0.355220 lr 0.00038522 rank 6
2023-02-22 13:42:05,130 DEBUG TRAIN Batch 20/1600 loss 22.848906 loss_att 26.287167 loss_ctc 35.341320 loss_rnnt 20.356007 hw_loss 0.261738 lr 0.00038525 rank 3
2023-02-22 13:42:05,133 DEBUG TRAIN Batch 20/1600 loss 11.450547 loss_att 13.798727 loss_ctc 12.054013 loss_rnnt 10.724819 hw_loss 0.329306 lr 0.00038530 rank 1
2023-02-22 13:42:05,136 DEBUG TRAIN Batch 20/1600 loss 4.438840 loss_att 7.342241 loss_ctc 7.561073 loss_rnnt 3.294260 hw_loss 0.276755 lr 0.00038528 rank 2
2023-02-22 13:42:05,140 DEBUG TRAIN Batch 20/1600 loss 5.903072 loss_att 7.537425 loss_ctc 6.652205 loss_rnnt 5.386761 hw_loss 0.167918 lr 0.00038522 rank 7
2023-02-22 13:42:05,140 DEBUG TRAIN Batch 20/1600 loss 8.198888 loss_att 10.836143 loss_ctc 11.834914 loss_rnnt 7.065365 hw_loss 0.227377 lr 0.00038535 rank 0
2023-02-22 13:42:05,168 DEBUG TRAIN Batch 20/1600 loss 12.537559 loss_att 15.009306 loss_ctc 12.632195 loss_rnnt 11.884316 hw_loss 0.274262 lr 0.00038531 rank 5
2023-02-22 13:42:05,177 DEBUG TRAIN Batch 20/1600 loss 6.728605 loss_att 8.971266 loss_ctc 10.766394 loss_rnnt 5.556965 hw_loss 0.346381 lr 0.00038535 rank 4
2023-02-22 13:43:18,375 DEBUG TRAIN Batch 20/1700 loss 8.698019 loss_att 11.699142 loss_ctc 15.075860 loss_rnnt 7.112017 hw_loss 0.253874 lr 0.00038518 rank 1
2023-02-22 13:43:18,392 DEBUG TRAIN Batch 20/1700 loss 8.990835 loss_att 12.863920 loss_ctc 12.762487 loss_rnnt 7.637426 hw_loss 0.142323 lr 0.00038513 rank 3
2023-02-22 13:43:18,394 DEBUG TRAIN Batch 20/1700 loss 11.419963 loss_att 13.146173 loss_ctc 18.469316 loss_rnnt 10.028683 hw_loss 0.198984 lr 0.00038516 rank 2
2023-02-22 13:43:18,398 DEBUG TRAIN Batch 20/1700 loss 14.895211 loss_att 17.784195 loss_ctc 20.524502 loss_rnnt 13.381210 hw_loss 0.348060 lr 0.00038523 rank 0
2023-02-22 13:43:18,398 DEBUG TRAIN Batch 20/1700 loss 8.211827 loss_att 13.837453 loss_ctc 10.442829 loss_rnnt 6.685659 hw_loss 0.194203 lr 0.00038511 rank 6
2023-02-22 13:43:18,398 DEBUG TRAIN Batch 20/1700 loss 11.196907 loss_att 16.096273 loss_ctc 17.547165 loss_rnnt 9.277332 hw_loss 0.174374 lr 0.00038520 rank 5
2023-02-22 13:43:18,401 DEBUG TRAIN Batch 20/1700 loss 6.767383 loss_att 9.333985 loss_ctc 11.570358 loss_rnnt 5.462092 hw_loss 0.284201 lr 0.00038511 rank 7
2023-02-22 13:43:18,436 DEBUG TRAIN Batch 20/1700 loss 19.581343 loss_att 20.969139 loss_ctc 24.588335 loss_rnnt 18.558258 hw_loss 0.146113 lr 0.00038523 rank 4
2023-02-22 13:44:33,410 DEBUG TRAIN Batch 20/1800 loss 9.223647 loss_att 10.721446 loss_ctc 12.306087 loss_rnnt 8.383718 hw_loss 0.242581 lr 0.00038505 rank 2
2023-02-22 13:44:33,419 DEBUG TRAIN Batch 20/1800 loss 6.499691 loss_att 7.349841 loss_ctc 7.064656 loss_rnnt 6.077413 hw_loss 0.331725 lr 0.00038512 rank 4
2023-02-22 13:44:33,418 DEBUG TRAIN Batch 20/1800 loss 12.510907 loss_att 16.189751 loss_ctc 16.526762 loss_rnnt 11.130141 hw_loss 0.205405 lr 0.00038499 rank 6
2023-02-22 13:44:33,419 DEBUG TRAIN Batch 20/1800 loss 3.495275 loss_att 7.520712 loss_ctc 7.888909 loss_rnnt 1.970634 hw_loss 0.250756 lr 0.00038502 rank 3
2023-02-22 13:44:33,421 DEBUG TRAIN Batch 20/1800 loss 18.666672 loss_att 19.323980 loss_ctc 24.462677 loss_rnnt 17.543074 hw_loss 0.411252 lr 0.00038512 rank 0
2023-02-22 13:44:33,423 DEBUG TRAIN Batch 20/1800 loss 6.312096 loss_att 8.509247 loss_ctc 9.521880 loss_rnnt 5.340372 hw_loss 0.195606 lr 0.00038507 rank 1
2023-02-22 13:44:33,422 DEBUG TRAIN Batch 20/1800 loss 3.849514 loss_att 5.683159 loss_ctc 7.024528 loss_rnnt 2.756625 hw_loss 0.567796 lr 0.00038508 rank 5
2023-02-22 13:44:33,463 DEBUG TRAIN Batch 20/1800 loss 12.965690 loss_att 16.377316 loss_ctc 16.954714 loss_rnnt 11.575506 hw_loss 0.329979 lr 0.00038499 rank 7
2023-02-22 13:45:46,090 DEBUG TRAIN Batch 20/1900 loss 9.859733 loss_att 11.363535 loss_ctc 11.807034 loss_rnnt 9.103019 hw_loss 0.368087 lr 0.00038490 rank 3
2023-02-22 13:45:46,093 DEBUG TRAIN Batch 20/1900 loss 8.319511 loss_att 9.882079 loss_ctc 10.311631 loss_rnnt 7.657207 hw_loss 0.157829 lr 0.00038500 rank 4
2023-02-22 13:45:46,094 DEBUG TRAIN Batch 20/1900 loss 14.397574 loss_att 14.859564 loss_ctc 20.328403 loss_rnnt 13.301046 hw_loss 0.400036 lr 0.00038494 rank 2
2023-02-22 13:45:46,098 DEBUG TRAIN Batch 20/1900 loss 4.237355 loss_att 8.759336 loss_ctc 6.497568 loss_rnnt 2.904129 hw_loss 0.239004 lr 0.00038500 rank 0
2023-02-22 13:45:46,099 DEBUG TRAIN Batch 20/1900 loss 4.213619 loss_att 6.283810 loss_ctc 5.765347 loss_rnnt 3.378733 hw_loss 0.401157 lr 0.00038488 rank 6
2023-02-22 13:45:46,102 DEBUG TRAIN Batch 20/1900 loss 7.900209 loss_att 8.428329 loss_ctc 9.552695 loss_rnnt 7.482676 hw_loss 0.171708 lr 0.00038488 rank 7
2023-02-22 13:45:46,121 DEBUG TRAIN Batch 20/1900 loss 7.872057 loss_att 10.430527 loss_ctc 10.317717 loss_rnnt 6.907363 hw_loss 0.237963 lr 0.00038497 rank 5
2023-02-22 13:45:46,142 DEBUG TRAIN Batch 20/1900 loss 8.502121 loss_att 13.363721 loss_ctc 11.439363 loss_rnnt 6.994034 hw_loss 0.270251 lr 0.00038495 rank 1
2023-02-22 13:47:00,053 DEBUG TRAIN Batch 20/2000 loss 7.387614 loss_att 10.855309 loss_ctc 7.272962 loss_rnnt 6.649272 hw_loss 0.112669 lr 0.00038482 rank 2
2023-02-22 13:47:00,056 DEBUG TRAIN Batch 20/2000 loss 13.694701 loss_att 18.286381 loss_ctc 16.657064 loss_rnnt 12.294655 hw_loss 0.162615 lr 0.00038477 rank 7
2023-02-22 13:47:00,058 DEBUG TRAIN Batch 20/2000 loss 8.149499 loss_att 11.837799 loss_ctc 11.315874 loss_rnnt 6.801845 hw_loss 0.352144 lr 0.00038484 rank 1
2023-02-22 13:47:00,058 DEBUG TRAIN Batch 20/2000 loss 5.867348 loss_att 10.224608 loss_ctc 9.707253 loss_rnnt 4.401599 hw_loss 0.154330 lr 0.00038479 rank 3
2023-02-22 13:47:00,063 DEBUG TRAIN Batch 20/2000 loss 5.115088 loss_att 7.139183 loss_ctc 6.640915 loss_rnnt 4.355413 hw_loss 0.283896 lr 0.00038476 rank 6
2023-02-22 13:47:00,063 DEBUG TRAIN Batch 20/2000 loss 10.422709 loss_att 15.246186 loss_ctc 15.708279 loss_rnnt 8.536217 hw_loss 0.406975 lr 0.00038486 rank 5
2023-02-22 13:47:00,064 DEBUG TRAIN Batch 20/2000 loss 7.584345 loss_att 10.111497 loss_ctc 10.177534 loss_rnnt 6.496961 hw_loss 0.442865 lr 0.00038489 rank 0
2023-02-22 13:47:00,064 DEBUG TRAIN Batch 20/2000 loss 11.318285 loss_att 13.423004 loss_ctc 14.826912 loss_rnnt 10.270838 hw_loss 0.297536 lr 0.00038489 rank 4
2023-02-22 13:48:14,321 DEBUG TRAIN Batch 20/2100 loss 7.378749 loss_att 10.922574 loss_ctc 10.442929 loss_rnnt 6.140268 hw_loss 0.227172 lr 0.00038467 rank 3
2023-02-22 13:48:14,322 DEBUG TRAIN Batch 20/2100 loss 7.028692 loss_att 11.494473 loss_ctc 9.327509 loss_rnnt 5.650266 hw_loss 0.335179 lr 0.00038473 rank 1
2023-02-22 13:48:14,323 DEBUG TRAIN Batch 20/2100 loss 4.108823 loss_att 8.607557 loss_ctc 10.223056 loss_rnnt 2.107061 hw_loss 0.537720 lr 0.00038478 rank 4
2023-02-22 13:48:14,324 DEBUG TRAIN Batch 20/2100 loss 2.698612 loss_att 7.345929 loss_ctc 5.485935 loss_rnnt 1.298631 hw_loss 0.185391 lr 0.00038465 rank 6
2023-02-22 13:48:14,324 DEBUG TRAIN Batch 20/2100 loss 5.901935 loss_att 8.582380 loss_ctc 8.751025 loss_rnnt 4.793963 hw_loss 0.360008 lr 0.00038474 rank 5
2023-02-22 13:48:14,324 DEBUG TRAIN Batch 20/2100 loss 10.307113 loss_att 12.311516 loss_ctc 15.438994 loss_rnnt 9.086171 hw_loss 0.254642 lr 0.00038471 rank 2
2023-02-22 13:48:14,348 DEBUG TRAIN Batch 20/2100 loss 4.728543 loss_att 8.681274 loss_ctc 7.530716 loss_rnnt 3.458117 hw_loss 0.199231 lr 0.00038478 rank 0
2023-02-22 13:48:14,371 DEBUG TRAIN Batch 20/2100 loss 9.796464 loss_att 13.807033 loss_ctc 18.205544 loss_rnnt 7.749963 hw_loss 0.230955 lr 0.00038465 rank 7
2023-02-22 13:49:27,724 DEBUG TRAIN Batch 20/2200 loss 2.650409 loss_att 5.131319 loss_ctc 3.563293 loss_rnnt 1.931827 hw_loss 0.188780 lr 0.00038454 rank 7
2023-02-22 13:49:27,725 DEBUG TRAIN Batch 20/2200 loss 9.820620 loss_att 11.859403 loss_ctc 12.647778 loss_rnnt 8.893492 hw_loss 0.267031 lr 0.00038466 rank 4
2023-02-22 13:49:27,726 DEBUG TRAIN Batch 20/2200 loss 6.668510 loss_att 10.360294 loss_ctc 6.848104 loss_rnnt 5.827838 hw_loss 0.146944 lr 0.00038456 rank 3
2023-02-22 13:49:27,727 DEBUG TRAIN Batch 20/2200 loss 6.522979 loss_att 9.411130 loss_ctc 8.500054 loss_rnnt 5.482268 hw_loss 0.374007 lr 0.00038463 rank 5
2023-02-22 13:49:27,727 DEBUG TRAIN Batch 20/2200 loss 13.030551 loss_att 13.968003 loss_ctc 16.925608 loss_rnnt 12.159683 hw_loss 0.307566 lr 0.00038454 rank 6
2023-02-22 13:49:27,728 DEBUG TRAIN Batch 20/2200 loss 7.164602 loss_att 10.739561 loss_ctc 9.911322 loss_rnnt 5.960972 hw_loss 0.229516 lr 0.00038459 rank 2
2023-02-22 13:49:27,729 DEBUG TRAIN Batch 20/2200 loss 11.274742 loss_att 13.607298 loss_ctc 18.376738 loss_rnnt 9.684037 hw_loss 0.332363 lr 0.00038461 rank 1
2023-02-22 13:49:27,733 DEBUG TRAIN Batch 20/2200 loss 10.818808 loss_att 14.533341 loss_ctc 14.776109 loss_rnnt 9.301658 hw_loss 0.462382 lr 0.00038466 rank 0
2023-02-22 13:50:40,363 DEBUG TRAIN Batch 20/2300 loss 6.577523 loss_att 8.629656 loss_ctc 6.855826 loss_rnnt 5.993672 hw_loss 0.255593 lr 0.00038455 rank 0
2023-02-22 13:50:40,373 DEBUG TRAIN Batch 20/2300 loss 9.401635 loss_att 10.686196 loss_ctc 12.219549 loss_rnnt 8.668307 hw_loss 0.188802 lr 0.00038445 rank 3
2023-02-22 13:50:40,376 DEBUG TRAIN Batch 20/2300 loss 13.908604 loss_att 16.123377 loss_ctc 18.818916 loss_rnnt 12.665195 hw_loss 0.273272 lr 0.00038455 rank 4
2023-02-22 13:50:40,379 DEBUG TRAIN Batch 20/2300 loss 11.777053 loss_att 16.037563 loss_ctc 17.921028 loss_rnnt 10.003266 hw_loss 0.192163 lr 0.00038448 rank 2
2023-02-22 13:50:40,380 DEBUG TRAIN Batch 20/2300 loss 16.586615 loss_att 18.518436 loss_ctc 21.492922 loss_rnnt 15.427514 hw_loss 0.222300 lr 0.00038451 rank 5
2023-02-22 13:50:40,382 DEBUG TRAIN Batch 20/2300 loss 8.500669 loss_att 11.385218 loss_ctc 11.703581 loss_rnnt 7.438948 hw_loss 0.108293 lr 0.00038442 rank 7
2023-02-22 13:50:40,383 DEBUG TRAIN Batch 20/2300 loss 5.846258 loss_att 8.875918 loss_ctc 6.921755 loss_rnnt 4.915175 hw_loss 0.340784 lr 0.00038442 rank 6
2023-02-22 13:50:40,428 DEBUG TRAIN Batch 20/2300 loss 5.538986 loss_att 9.286508 loss_ctc 8.472676 loss_rnnt 4.238190 hw_loss 0.300251 lr 0.00038450 rank 1
2023-02-22 13:51:53,143 DEBUG TRAIN Batch 20/2400 loss 6.739914 loss_att 9.132296 loss_ctc 7.663477 loss_rnnt 6.034641 hw_loss 0.194352 lr 0.00038443 rank 0
2023-02-22 13:51:53,143 DEBUG TRAIN Batch 20/2400 loss 14.484199 loss_att 19.908112 loss_ctc 19.027254 loss_rnnt 12.617723 hw_loss 0.329909 lr 0.00038437 rank 2
2023-02-22 13:51:53,143 DEBUG TRAIN Batch 20/2400 loss 18.124176 loss_att 17.518740 loss_ctc 26.024189 loss_rnnt 16.970201 hw_loss 0.415737 lr 0.00038439 rank 1
2023-02-22 13:51:53,146 DEBUG TRAIN Batch 20/2400 loss 7.916232 loss_att 9.715549 loss_ctc 12.547528 loss_rnnt 6.796283 hw_loss 0.267336 lr 0.00038443 rank 4
2023-02-22 13:51:53,146 DEBUG TRAIN Batch 20/2400 loss 5.687069 loss_att 6.872869 loss_ctc 8.758505 loss_rnnt 4.981082 hw_loss 0.111193 lr 0.00038431 rank 6
2023-02-22 13:51:53,147 DEBUG TRAIN Batch 20/2400 loss 9.740119 loss_att 12.846335 loss_ctc 18.226759 loss_rnnt 7.865406 hw_loss 0.228595 lr 0.00038433 rank 3
2023-02-22 13:51:53,148 DEBUG TRAIN Batch 20/2400 loss 7.604957 loss_att 10.355503 loss_ctc 10.543288 loss_rnnt 6.427827 hw_loss 0.441080 lr 0.00038440 rank 5
2023-02-22 13:51:53,190 DEBUG TRAIN Batch 20/2400 loss 11.668423 loss_att 12.922275 loss_ctc 22.836634 loss_rnnt 9.797403 hw_loss 0.245915 lr 0.00038431 rank 7
2023-02-22 13:53:08,566 DEBUG TRAIN Batch 20/2500 loss 5.269797 loss_att 7.672445 loss_ctc 6.942081 loss_rnnt 4.411037 hw_loss 0.291111 lr 0.00038425 rank 2
2023-02-22 13:53:08,567 DEBUG TRAIN Batch 20/2500 loss 9.942539 loss_att 15.494802 loss_ctc 12.086815 loss_rnnt 8.377968 hw_loss 0.315403 lr 0.00038432 rank 4
2023-02-22 13:53:08,569 DEBUG TRAIN Batch 20/2500 loss 14.521661 loss_att 13.428740 loss_ctc 20.579185 loss_rnnt 13.729980 hw_loss 0.379864 lr 0.00038432 rank 0
2023-02-22 13:53:08,568 DEBUG TRAIN Batch 20/2500 loss 13.014214 loss_att 14.791629 loss_ctc 17.901560 loss_rnnt 11.819361 hw_loss 0.351980 lr 0.00038422 rank 3
2023-02-22 13:53:08,569 DEBUG TRAIN Batch 20/2500 loss 8.423468 loss_att 9.303196 loss_ctc 12.237454 loss_rnnt 7.437951 hw_loss 0.564450 lr 0.00038429 rank 5
2023-02-22 13:53:08,572 DEBUG TRAIN Batch 20/2500 loss 6.063643 loss_att 7.434005 loss_ctc 8.776793 loss_rnnt 5.229095 hw_loss 0.372602 lr 0.00038427 rank 1
2023-02-22 13:53:08,573 DEBUG TRAIN Batch 20/2500 loss 6.671824 loss_att 7.765677 loss_ctc 10.628084 loss_rnnt 5.707546 hw_loss 0.408762 lr 0.00038420 rank 6
2023-02-22 13:53:08,575 DEBUG TRAIN Batch 20/2500 loss 7.136222 loss_att 9.393097 loss_ctc 8.840495 loss_rnnt 6.254820 hw_loss 0.380232 lr 0.00038420 rank 7
2023-02-22 13:54:20,796 DEBUG TRAIN Batch 20/2600 loss 6.410824 loss_att 10.455671 loss_ctc 5.607021 loss_rnnt 5.560839 hw_loss 0.277855 lr 0.00038421 rank 4
2023-02-22 13:54:20,797 DEBUG TRAIN Batch 20/2600 loss 7.332136 loss_att 9.888790 loss_ctc 8.818695 loss_rnnt 6.416697 hw_loss 0.386063 lr 0.00038414 rank 2
2023-02-22 13:54:20,800 DEBUG TRAIN Batch 20/2600 loss 4.782578 loss_att 11.655377 loss_ctc 6.579570 loss_rnnt 3.063770 hw_loss 0.196218 lr 0.00038408 rank 7
2023-02-22 13:54:20,802 DEBUG TRAIN Batch 20/2600 loss 5.227196 loss_att 7.560266 loss_ctc 7.343847 loss_rnnt 4.301708 hw_loss 0.331226 lr 0.00038421 rank 0
2023-02-22 13:54:20,802 DEBUG TRAIN Batch 20/2600 loss 4.441250 loss_att 8.157124 loss_ctc 9.858982 loss_rnnt 2.834766 hw_loss 0.264273 lr 0.00038408 rank 6
2023-02-22 13:54:20,802 DEBUG TRAIN Batch 20/2600 loss 8.586788 loss_att 13.894533 loss_ctc 12.554843 loss_rnnt 6.744637 hw_loss 0.471615 lr 0.00038416 rank 1
2023-02-22 13:54:20,804 DEBUG TRAIN Batch 20/2600 loss 10.324142 loss_att 13.444836 loss_ctc 13.926957 loss_rnnt 9.068829 hw_loss 0.282747 lr 0.00038411 rank 3
2023-02-22 13:54:20,851 DEBUG TRAIN Batch 20/2600 loss 10.731669 loss_att 12.706447 loss_ctc 15.859004 loss_rnnt 9.607060 hw_loss 0.086267 lr 0.00038417 rank 5
2023-02-22 13:55:32,991 DEBUG TRAIN Batch 20/2700 loss 7.914081 loss_att 11.008209 loss_ctc 11.487445 loss_rnnt 6.710798 hw_loss 0.202516 lr 0.00038403 rank 2
2023-02-22 13:55:32,994 DEBUG TRAIN Batch 20/2700 loss 5.924161 loss_att 10.682024 loss_ctc 8.227799 loss_rnnt 4.491631 hw_loss 0.325885 lr 0.00038399 rank 3
2023-02-22 13:55:32,997 DEBUG TRAIN Batch 20/2700 loss 14.776084 loss_att 15.867987 loss_ctc 25.008442 loss_rnnt 13.033566 hw_loss 0.299670 lr 0.00038409 rank 4
2023-02-22 13:55:32,999 DEBUG TRAIN Batch 20/2700 loss 8.600569 loss_att 12.088667 loss_ctc 11.246131 loss_rnnt 7.466865 hw_loss 0.156269 lr 0.00038406 rank 5
2023-02-22 13:55:32,999 DEBUG TRAIN Batch 20/2700 loss 7.975771 loss_att 11.151777 loss_ctc 10.875446 loss_rnnt 6.860821 hw_loss 0.174611 lr 0.00038397 rank 7
2023-02-22 13:55:33,001 DEBUG TRAIN Batch 20/2700 loss 3.806978 loss_att 7.087788 loss_ctc 5.698619 loss_rnnt 2.767926 hw_loss 0.245008 lr 0.00038397 rank 6
2023-02-22 13:55:33,046 DEBUG TRAIN Batch 20/2700 loss 9.756676 loss_att 11.215979 loss_ctc 10.533585 loss_rnnt 9.188807 hw_loss 0.323288 lr 0.00038409 rank 0
2023-02-22 13:55:33,081 DEBUG TRAIN Batch 20/2700 loss 13.134584 loss_att 14.960777 loss_ctc 21.536171 loss_rnnt 11.499614 hw_loss 0.280352 lr 0.00038405 rank 1
2023-02-22 13:56:46,860 DEBUG TRAIN Batch 20/2800 loss 10.561891 loss_att 13.152431 loss_ctc 13.266273 loss_rnnt 9.434378 hw_loss 0.466538 lr 0.00038395 rank 5
2023-02-22 13:56:46,864 DEBUG TRAIN Batch 20/2800 loss 9.433994 loss_att 11.800531 loss_ctc 13.254954 loss_rnnt 8.303062 hw_loss 0.277806 lr 0.00038386 rank 7
2023-02-22 13:56:46,877 DEBUG TRAIN Batch 20/2800 loss 12.406629 loss_att 16.790356 loss_ctc 22.226416 loss_rnnt 10.118312 hw_loss 0.191749 lr 0.00038388 rank 3
2023-02-22 13:56:46,876 DEBUG TRAIN Batch 20/2800 loss 7.551558 loss_att 11.741616 loss_ctc 8.868221 loss_rnnt 6.414039 hw_loss 0.232412 lr 0.00038391 rank 2
2023-02-22 13:56:46,877 DEBUG TRAIN Batch 20/2800 loss 8.248038 loss_att 10.774668 loss_ctc 12.599491 loss_rnnt 7.023521 hw_loss 0.260620 lr 0.00038398 rank 4
2023-02-22 13:56:46,878 DEBUG TRAIN Batch 20/2800 loss 14.989308 loss_att 21.104565 loss_ctc 31.544104 loss_rnnt 11.426516 hw_loss 0.248316 lr 0.00038386 rank 6
2023-02-22 13:56:46,881 DEBUG TRAIN Batch 20/2800 loss 7.664369 loss_att 10.147923 loss_ctc 9.285404 loss_rnnt 6.902344 hw_loss 0.092207 lr 0.00038398 rank 0
2023-02-22 13:56:46,885 DEBUG TRAIN Batch 20/2800 loss 5.202082 loss_att 7.898081 loss_ctc 9.471234 loss_rnnt 3.988984 hw_loss 0.196271 lr 0.00038393 rank 1
2023-02-22 13:58:00,720 DEBUG TRAIN Batch 20/2900 loss 4.052917 loss_att 7.016314 loss_ctc 5.988146 loss_rnnt 3.105561 hw_loss 0.181208 lr 0.00038382 rank 1
2023-02-22 13:58:00,731 DEBUG TRAIN Batch 20/2900 loss 17.258636 loss_att 17.551004 loss_ctc 19.408463 loss_rnnt 16.827818 hw_loss 0.160690 lr 0.00038383 rank 5
2023-02-22 13:58:00,731 DEBUG TRAIN Batch 20/2900 loss 8.530205 loss_att 11.018140 loss_ctc 10.240788 loss_rnnt 7.675482 hw_loss 0.241984 lr 0.00038387 rank 4
2023-02-22 13:58:00,730 DEBUG TRAIN Batch 20/2900 loss 2.447243 loss_att 5.701678 loss_ctc 7.341595 loss_rnnt 0.941850 hw_loss 0.378611 lr 0.00038377 rank 3
2023-02-22 13:58:00,731 DEBUG TRAIN Batch 20/2900 loss 4.832317 loss_att 8.258015 loss_ctc 6.444865 loss_rnnt 3.719365 hw_loss 0.399011 lr 0.00038374 rank 7
2023-02-22 13:58:00,731 DEBUG TRAIN Batch 20/2900 loss 7.129306 loss_att 10.192955 loss_ctc 9.810244 loss_rnnt 6.048876 hw_loss 0.206702 lr 0.00038374 rank 6
2023-02-22 13:58:00,731 DEBUG TRAIN Batch 20/2900 loss 12.848989 loss_att 19.446455 loss_ctc 22.886623 loss_rnnt 10.088196 hw_loss 0.193032 lr 0.00038380 rank 2
2023-02-22 13:58:00,736 DEBUG TRAIN Batch 20/2900 loss 20.193371 loss_att 20.734756 loss_ctc 29.678635 loss_rnnt 18.661022 hw_loss 0.298817 lr 0.00038387 rank 0
2023-02-22 13:59:13,356 DEBUG TRAIN Batch 20/3000 loss 17.051716 loss_att 20.780092 loss_ctc 23.782974 loss_rnnt 15.287615 hw_loss 0.226730 lr 0.00038369 rank 2
2023-02-22 13:59:13,357 DEBUG TRAIN Batch 20/3000 loss 11.417054 loss_att 14.386852 loss_ctc 17.410715 loss_rnnt 9.756706 hw_loss 0.501063 lr 0.00038371 rank 1
2023-02-22 13:59:13,360 DEBUG TRAIN Batch 20/3000 loss 9.829965 loss_att 15.049208 loss_ctc 15.176880 loss_rnnt 7.961192 hw_loss 0.210004 lr 0.00038363 rank 6
2023-02-22 13:59:13,362 DEBUG TRAIN Batch 20/3000 loss 8.102284 loss_att 9.861176 loss_ctc 9.683815 loss_rnnt 7.292274 hw_loss 0.463802 lr 0.00038375 rank 4
2023-02-22 13:59:13,363 DEBUG TRAIN Batch 20/3000 loss 8.572161 loss_att 11.903493 loss_ctc 15.816132 loss_rnnt 6.756938 hw_loss 0.343300 lr 0.00038363 rank 7
2023-02-22 13:59:13,365 DEBUG TRAIN Batch 20/3000 loss 10.943922 loss_att 11.486198 loss_ctc 13.542776 loss_rnnt 10.361366 hw_loss 0.239224 lr 0.00038365 rank 3
2023-02-22 13:59:13,368 DEBUG TRAIN Batch 20/3000 loss 9.102883 loss_att 12.114239 loss_ctc 12.632883 loss_rnnt 7.817898 hw_loss 0.397590 lr 0.00038375 rank 0
2023-02-22 13:59:13,372 DEBUG TRAIN Batch 20/3000 loss 15.994359 loss_att 19.781620 loss_ctc 23.478630 loss_rnnt 14.082394 hw_loss 0.293644 lr 0.00038372 rank 5
2023-02-22 14:00:26,090 DEBUG TRAIN Batch 20/3100 loss 16.807016 loss_att 20.148909 loss_ctc 26.401663 loss_rnnt 14.731494 hw_loss 0.239734 lr 0.00038352 rank 7
2023-02-22 14:00:26,092 DEBUG TRAIN Batch 20/3100 loss 6.560061 loss_att 7.924905 loss_ctc 9.895758 loss_rnnt 5.740407 hw_loss 0.191110 lr 0.00038361 rank 5
2023-02-22 14:00:26,093 DEBUG TRAIN Batch 20/3100 loss 4.425722 loss_att 6.320152 loss_ctc 6.175336 loss_rnnt 3.631776 hw_loss 0.340833 lr 0.00038359 rank 1
2023-02-22 14:00:26,094 DEBUG TRAIN Batch 20/3100 loss 7.544299 loss_att 12.834738 loss_ctc 8.884950 loss_rnnt 6.151269 hw_loss 0.292853 lr 0.00038364 rank 4
2023-02-22 14:00:26,094 DEBUG TRAIN Batch 20/3100 loss 12.494229 loss_att 12.538816 loss_ctc 18.714485 loss_rnnt 11.510348 hw_loss 0.272994 lr 0.00038357 rank 2
2023-02-22 14:00:26,095 DEBUG TRAIN Batch 20/3100 loss 9.345385 loss_att 11.076987 loss_ctc 14.823058 loss_rnnt 8.015409 hw_loss 0.474934 lr 0.00038364 rank 0
2023-02-22 14:00:26,096 DEBUG TRAIN Batch 20/3100 loss 6.879015 loss_att 10.849987 loss_ctc 9.430932 loss_rnnt 5.633055 hw_loss 0.209081 lr 0.00038354 rank 3
2023-02-22 14:00:26,099 DEBUG TRAIN Batch 20/3100 loss 6.189152 loss_att 9.089418 loss_ctc 8.578382 loss_rnnt 5.116136 hw_loss 0.326999 lr 0.00038352 rank 6
2023-02-22 14:01:40,798 DEBUG TRAIN Batch 20/3200 loss 11.735974 loss_att 14.363522 loss_ctc 16.435375 loss_rnnt 10.301088 hw_loss 0.530228 lr 0.00038353 rank 4
2023-02-22 14:01:40,809 DEBUG TRAIN Batch 20/3200 loss 12.965471 loss_att 16.385412 loss_ctc 19.113823 loss_rnnt 11.366511 hw_loss 0.178486 lr 0.00038346 rank 2
2023-02-22 14:01:40,810 DEBUG TRAIN Batch 20/3200 loss 9.526390 loss_att 10.907350 loss_ctc 12.465538 loss_rnnt 8.698354 hw_loss 0.299921 lr 0.00038343 rank 3
2023-02-22 14:01:40,811 DEBUG TRAIN Batch 20/3200 loss 7.953016 loss_att 8.603472 loss_ctc 11.733329 loss_rnnt 7.080460 hw_loss 0.447044 lr 0.00038341 rank 7
2023-02-22 14:01:40,810 DEBUG TRAIN Batch 20/3200 loss 4.586619 loss_att 8.894407 loss_ctc 6.140069 loss_rnnt 3.407584 hw_loss 0.206908 lr 0.00038340 rank 6
2023-02-22 14:01:40,814 DEBUG TRAIN Batch 20/3200 loss 7.552237 loss_att 9.889705 loss_ctc 7.625936 loss_rnnt 7.025741 hw_loss 0.092206 lr 0.00038349 rank 5
2023-02-22 14:01:40,860 DEBUG TRAIN Batch 20/3200 loss 16.122225 loss_att 17.636549 loss_ctc 21.200914 loss_rnnt 15.049559 hw_loss 0.173705 lr 0.00038353 rank 0
2023-02-22 14:01:40,861 DEBUG TRAIN Batch 20/3200 loss 5.953884 loss_att 9.416236 loss_ctc 9.384738 loss_rnnt 4.669308 hw_loss 0.252485 lr 0.00038348 rank 1
2023-02-22 14:02:53,460 DEBUG TRAIN Batch 20/3300 loss 5.373680 loss_att 9.597424 loss_ctc 9.970336 loss_rnnt 3.792358 hw_loss 0.231911 lr 0.00038335 rank 2
2023-02-22 14:02:53,463 DEBUG TRAIN Batch 20/3300 loss 8.888503 loss_att 11.041813 loss_ctc 15.737486 loss_rnnt 7.302299 hw_loss 0.454394 lr 0.00038342 rank 4
2023-02-22 14:02:53,465 DEBUG TRAIN Batch 20/3300 loss 10.872336 loss_att 15.669064 loss_ctc 18.235540 loss_rnnt 8.790352 hw_loss 0.264147 lr 0.00038338 rank 5
2023-02-22 14:02:53,464 DEBUG TRAIN Batch 20/3300 loss 7.090796 loss_att 9.273731 loss_ctc 9.213987 loss_rnnt 6.299743 hw_loss 0.133827 lr 0.00038329 rank 6
2023-02-22 14:02:53,465 DEBUG TRAIN Batch 20/3300 loss 3.745139 loss_att 6.153539 loss_ctc 3.794127 loss_rnnt 3.167084 hw_loss 0.168455 lr 0.00038329 rank 7
2023-02-22 14:02:53,466 DEBUG TRAIN Batch 20/3300 loss 5.814213 loss_att 5.982093 loss_ctc 7.939923 loss_rnnt 5.183500 hw_loss 0.588205 lr 0.00038332 rank 3
2023-02-22 14:02:53,471 DEBUG TRAIN Batch 20/3300 loss 1.617228 loss_att 3.568648 loss_ctc 2.166044 loss_rnnt 1.069376 hw_loss 0.158236 lr 0.00038342 rank 0
2023-02-22 14:02:53,478 DEBUG TRAIN Batch 20/3300 loss 4.157366 loss_att 6.249774 loss_ctc 7.141202 loss_rnnt 3.237589 hw_loss 0.193969 lr 0.00038337 rank 1
2023-02-22 14:04:05,816 DEBUG TRAIN Batch 20/3400 loss 2.142137 loss_att 4.563320 loss_ctc 3.383239 loss_rnnt 1.384160 hw_loss 0.202989 lr 0.00038324 rank 2
2023-02-22 14:04:05,822 DEBUG TRAIN Batch 20/3400 loss 14.922858 loss_att 19.350031 loss_ctc 25.897711 loss_rnnt 12.489611 hw_loss 0.158434 lr 0.00038320 rank 3
2023-02-22 14:04:05,824 DEBUG TRAIN Batch 20/3400 loss 8.535386 loss_att 9.638739 loss_ctc 12.709295 loss_rnnt 7.614112 hw_loss 0.270155 lr 0.00038318 rank 6
2023-02-22 14:04:05,825 DEBUG TRAIN Batch 20/3400 loss 6.575979 loss_att 11.929664 loss_ctc 7.052933 loss_rnnt 5.392543 hw_loss 0.092074 lr 0.00038318 rank 7
2023-02-22 14:04:05,827 DEBUG TRAIN Batch 20/3400 loss 7.397067 loss_att 11.572119 loss_ctc 13.151406 loss_rnnt 5.689688 hw_loss 0.197107 lr 0.00038330 rank 4
2023-02-22 14:04:05,831 DEBUG TRAIN Batch 20/3400 loss 19.276861 loss_att 21.532719 loss_ctc 32.165611 loss_rnnt 16.972122 hw_loss 0.253254 lr 0.00038325 rank 1
2023-02-22 14:04:05,834 DEBUG TRAIN Batch 20/3400 loss 11.996207 loss_att 13.078801 loss_ctc 20.056370 loss_rnnt 10.530027 hw_loss 0.328073 lr 0.00038327 rank 5
2023-02-22 14:04:05,877 DEBUG TRAIN Batch 20/3400 loss 3.736163 loss_att 6.103752 loss_ctc 5.129842 loss_rnnt 2.856895 hw_loss 0.412361 lr 0.00038330 rank 0
2023-02-22 14:05:19,245 DEBUG TRAIN Batch 20/3500 loss 10.234993 loss_att 12.908596 loss_ctc 11.839729 loss_rnnt 9.363048 hw_loss 0.231112 lr 0.00038319 rank 4
2023-02-22 14:05:19,254 DEBUG TRAIN Batch 20/3500 loss 13.564005 loss_att 17.403372 loss_ctc 16.863935 loss_rnnt 12.209867 hw_loss 0.274263 lr 0.00038319 rank 0
2023-02-22 14:05:19,266 DEBUG TRAIN Batch 20/3500 loss 7.509331 loss_att 11.684034 loss_ctc 12.329638 loss_rnnt 5.872085 hw_loss 0.299244 lr 0.00038307 rank 7
2023-02-22 14:05:19,266 DEBUG TRAIN Batch 20/3500 loss 10.746223 loss_att 15.973614 loss_ctc 13.376341 loss_rnnt 9.199100 hw_loss 0.283059 lr 0.00038309 rank 3
2023-02-22 14:05:19,267 DEBUG TRAIN Batch 20/3500 loss 7.548506 loss_att 12.070829 loss_ctc 11.283266 loss_rnnt 6.047668 hw_loss 0.184513 lr 0.00038312 rank 2
2023-02-22 14:05:19,269 DEBUG TRAIN Batch 20/3500 loss 11.935987 loss_att 13.301502 loss_ctc 16.324909 loss_rnnt 10.984305 hw_loss 0.175103 lr 0.00038316 rank 5
2023-02-22 14:05:19,268 DEBUG TRAIN Batch 20/3500 loss 7.388716 loss_att 8.809526 loss_ctc 10.034998 loss_rnnt 6.592973 hw_loss 0.297642 lr 0.00038307 rank 6
2023-02-22 14:05:19,270 DEBUG TRAIN Batch 20/3500 loss 8.709766 loss_att 12.925247 loss_ctc 11.605198 loss_rnnt 7.336705 hw_loss 0.269825 lr 0.00038314 rank 1
2023-02-22 14:06:33,326 DEBUG TRAIN Batch 20/3600 loss 6.684415 loss_att 9.647929 loss_ctc 10.490634 loss_rnnt 5.338514 hw_loss 0.460693 lr 0.00038298 rank 3
2023-02-22 14:06:33,332 DEBUG TRAIN Batch 20/3600 loss 5.605532 loss_att 8.212900 loss_ctc 10.489424 loss_rnnt 4.203677 hw_loss 0.429741 lr 0.00038308 rank 4
2023-02-22 14:06:33,333 DEBUG TRAIN Batch 20/3600 loss 4.901977 loss_att 7.641981 loss_ctc 6.577212 loss_rnnt 3.934466 hw_loss 0.367770 lr 0.00038296 rank 7
2023-02-22 14:06:33,334 DEBUG TRAIN Batch 20/3600 loss 6.668445 loss_att 8.796159 loss_ctc 7.818800 loss_rnnt 5.934656 hw_loss 0.290372 lr 0.00038295 rank 6
2023-02-22 14:06:33,336 DEBUG TRAIN Batch 20/3600 loss 2.776711 loss_att 6.585753 loss_ctc 4.419412 loss_rnnt 1.697454 hw_loss 0.184539 lr 0.00038304 rank 5
2023-02-22 14:06:33,335 DEBUG TRAIN Batch 20/3600 loss 11.210653 loss_att 11.355801 loss_ctc 11.338362 loss_rnnt 11.048006 hw_loss 0.218606 lr 0.00038301 rank 2
2023-02-22 14:06:33,338 DEBUG TRAIN Batch 20/3600 loss 4.920821 loss_att 7.950491 loss_ctc 8.053654 loss_rnnt 3.726026 hw_loss 0.320907 lr 0.00038303 rank 1
2023-02-22 14:06:33,387 DEBUG TRAIN Batch 20/3600 loss 9.292200 loss_att 12.881633 loss_ctc 11.766849 loss_rnnt 8.070797 hw_loss 0.325433 lr 0.00038308 rank 0
2023-02-22 14:07:46,012 DEBUG TRAIN Batch 20/3700 loss 10.144166 loss_att 13.424152 loss_ctc 13.595455 loss_rnnt 8.954882 hw_loss 0.137091 lr 0.00038284 rank 6
2023-02-22 14:07:46,012 DEBUG TRAIN Batch 20/3700 loss 9.089777 loss_att 9.198196 loss_ctc 9.650428 loss_rnnt 8.818766 hw_loss 0.327327 lr 0.00038287 rank 3
2023-02-22 14:07:46,013 DEBUG TRAIN Batch 20/3700 loss 11.431456 loss_att 12.898738 loss_ctc 15.278617 loss_rnnt 10.464924 hw_loss 0.300227 lr 0.00038290 rank 2
2023-02-22 14:07:46,015 DEBUG TRAIN Batch 20/3700 loss 13.501817 loss_att 13.849690 loss_ctc 20.485123 loss_rnnt 12.390862 hw_loss 0.206759 lr 0.00038292 rank 1
2023-02-22 14:07:46,017 DEBUG TRAIN Batch 20/3700 loss 18.977560 loss_att 21.630983 loss_ctc 22.947842 loss_rnnt 17.751076 hw_loss 0.312051 lr 0.00038284 rank 7
2023-02-22 14:07:46,017 DEBUG TRAIN Batch 20/3700 loss 10.552900 loss_att 11.922243 loss_ctc 17.981728 loss_rnnt 9.168060 hw_loss 0.225863 lr 0.00038297 rank 4
2023-02-22 14:07:46,053 DEBUG TRAIN Batch 20/3700 loss 15.807259 loss_att 14.232530 loss_ctc 18.159519 loss_rnnt 15.694359 hw_loss 0.214142 lr 0.00038293 rank 5
2023-02-22 14:07:46,058 DEBUG TRAIN Batch 20/3700 loss 13.467229 loss_att 14.629792 loss_ctc 18.711494 loss_rnnt 12.392339 hw_loss 0.268390 lr 0.00038297 rank 0
2023-02-22 14:08:58,053 DEBUG TRAIN Batch 20/3800 loss 6.917078 loss_att 10.091883 loss_ctc 10.121962 loss_rnnt 5.775735 hw_loss 0.148247 lr 0.00038275 rank 3
2023-02-22 14:08:58,056 DEBUG TRAIN Batch 20/3800 loss 9.960081 loss_att 9.490970 loss_ctc 14.526961 loss_rnnt 9.205448 hw_loss 0.449134 lr 0.00038279 rank 2
2023-02-22 14:08:58,057 DEBUG TRAIN Batch 20/3800 loss 6.324235 loss_att 10.226985 loss_ctc 9.357635 loss_rnnt 5.095426 hw_loss 0.082137 lr 0.00038285 rank 0
2023-02-22 14:08:58,057 DEBUG TRAIN Batch 20/3800 loss 8.285357 loss_att 11.580170 loss_ctc 12.032710 loss_rnnt 6.948586 hw_loss 0.334056 lr 0.00038281 rank 1
2023-02-22 14:08:58,059 DEBUG TRAIN Batch 20/3800 loss 9.512832 loss_att 12.388642 loss_ctc 14.608498 loss_rnnt 8.048334 hw_loss 0.393587 lr 0.00038273 rank 6
2023-02-22 14:08:58,060 DEBUG TRAIN Batch 20/3800 loss 8.270250 loss_att 9.200148 loss_ctc 10.457272 loss_rnnt 7.719437 hw_loss 0.137307 lr 0.00038285 rank 4
2023-02-22 14:08:58,061 DEBUG TRAIN Batch 20/3800 loss 6.850704 loss_att 10.155319 loss_ctc 8.929214 loss_rnnt 5.771112 hw_loss 0.265376 lr 0.00038273 rank 7
2023-02-22 14:08:58,062 DEBUG TRAIN Batch 20/3800 loss 6.191196 loss_att 11.389181 loss_ctc 12.557539 loss_rnnt 4.214971 hw_loss 0.164591 lr 0.00038282 rank 5
2023-02-22 14:10:12,466 DEBUG TRAIN Batch 20/3900 loss 2.340137 loss_att 4.527837 loss_ctc 2.274597 loss_rnnt 1.746454 hw_loss 0.309152 lr 0.00038274 rank 4
2023-02-22 14:10:12,471 DEBUG TRAIN Batch 20/3900 loss 8.321815 loss_att 10.950177 loss_ctc 10.752096 loss_rnnt 7.350626 hw_loss 0.227773 lr 0.00038269 rank 1
2023-02-22 14:10:12,476 DEBUG TRAIN Batch 20/3900 loss 4.976159 loss_att 7.793223 loss_ctc 9.330315 loss_rnnt 3.647375 hw_loss 0.346532 lr 0.00038267 rank 2
2023-02-22 14:10:12,477 DEBUG TRAIN Batch 20/3900 loss 18.194519 loss_att 21.966553 loss_ctc 24.987106 loss_rnnt 16.452072 hw_loss 0.154431 lr 0.00038262 rank 6
2023-02-22 14:10:12,477 DEBUG TRAIN Batch 20/3900 loss 2.753922 loss_att 4.560861 loss_ctc 5.808794 loss_rnnt 1.812204 hw_loss 0.324401 lr 0.00038264 rank 3
2023-02-22 14:10:12,480 DEBUG TRAIN Batch 20/3900 loss 14.871667 loss_att 17.521021 loss_ctc 18.997898 loss_rnnt 13.711994 hw_loss 0.149320 lr 0.00038274 rank 0
2023-02-22 14:10:12,485 DEBUG TRAIN Batch 20/3900 loss 8.656947 loss_att 9.666503 loss_ctc 13.172134 loss_rnnt 7.581619 hw_loss 0.508860 lr 0.00038262 rank 7
2023-02-22 14:10:12,488 DEBUG TRAIN Batch 20/3900 loss 19.520983 loss_att 21.529682 loss_ctc 22.891516 loss_rnnt 18.599884 hw_loss 0.131166 lr 0.00038271 rank 5
2023-02-22 14:11:26,073 DEBUG TRAIN Batch 20/4000 loss 9.928413 loss_att 10.821723 loss_ctc 13.309641 loss_rnnt 9.136082 hw_loss 0.305325 lr 0.00038253 rank 3
2023-02-22 14:11:26,073 DEBUG TRAIN Batch 20/4000 loss 18.425411 loss_att 20.420700 loss_ctc 21.458698 loss_rnnt 17.536276 hw_loss 0.160574 lr 0.00038250 rank 6
2023-02-22 14:11:26,075 DEBUG TRAIN Batch 20/4000 loss 15.483591 loss_att 19.912872 loss_ctc 26.577805 loss_rnnt 12.960127 hw_loss 0.296962 lr 0.00038263 rank 0
2023-02-22 14:11:26,075 DEBUG TRAIN Batch 20/4000 loss 2.262587 loss_att 5.570013 loss_ctc 2.640317 loss_rnnt 1.399691 hw_loss 0.283212 lr 0.00038260 rank 5
2023-02-22 14:11:26,076 DEBUG TRAIN Batch 20/4000 loss 8.309272 loss_att 9.474903 loss_ctc 14.207279 loss_rnnt 7.108203 hw_loss 0.340392 lr 0.00038256 rank 2
2023-02-22 14:11:26,076 DEBUG TRAIN Batch 20/4000 loss 6.387422 loss_att 8.581387 loss_ctc 8.871608 loss_rnnt 5.435938 hw_loss 0.340249 lr 0.00038263 rank 4
2023-02-22 14:11:26,085 DEBUG TRAIN Batch 20/4000 loss 14.474852 loss_att 16.805994 loss_ctc 15.288119 loss_rnnt 13.753535 hw_loss 0.274974 lr 0.00038258 rank 1
2023-02-22 14:11:26,125 DEBUG TRAIN Batch 20/4000 loss 12.882236 loss_att 13.151252 loss_ctc 17.115353 loss_rnnt 12.184757 hw_loss 0.148614 lr 0.00038251 rank 7
2023-02-22 14:12:37,942 DEBUG TRAIN Batch 20/4100 loss 14.602011 loss_att 15.358049 loss_ctc 18.309189 loss_rnnt 13.685532 hw_loss 0.508089 lr 0.00038245 rank 2
2023-02-22 14:12:37,943 DEBUG TRAIN Batch 20/4100 loss 4.847418 loss_att 9.292408 loss_ctc 13.644688 loss_rnnt 2.707659 hw_loss 0.145859 lr 0.00038242 rank 3
2023-02-22 14:12:37,944 DEBUG TRAIN Batch 20/4100 loss 9.785210 loss_att 14.046797 loss_ctc 11.537063 loss_rnnt 8.533394 hw_loss 0.311096 lr 0.00038239 rank 6
2023-02-22 14:12:37,946 DEBUG TRAIN Batch 20/4100 loss 5.946782 loss_att 9.815473 loss_ctc 8.889184 loss_rnnt 4.629457 hw_loss 0.283626 lr 0.00038248 rank 5
2023-02-22 14:12:37,947 DEBUG TRAIN Batch 20/4100 loss 12.459553 loss_att 14.707414 loss_ctc 15.648187 loss_rnnt 11.419945 hw_loss 0.309161 lr 0.00038252 rank 4
2023-02-22 14:12:37,952 DEBUG TRAIN Batch 20/4100 loss 11.962596 loss_att 15.058311 loss_ctc 20.812376 loss_rnnt 10.018836 hw_loss 0.271212 lr 0.00038252 rank 0
2023-02-22 14:12:37,955 DEBUG TRAIN Batch 20/4100 loss 12.506205 loss_att 15.868607 loss_ctc 19.448151 loss_rnnt 10.699968 hw_loss 0.390306 lr 0.00038240 rank 7
2023-02-22 14:12:37,999 DEBUG TRAIN Batch 20/4100 loss 11.673965 loss_att 14.779768 loss_ctc 14.609390 loss_rnnt 10.577722 hw_loss 0.156922 lr 0.00038247 rank 1
2023-02-22 14:13:51,044 DEBUG TRAIN Batch 20/4200 loss 11.847830 loss_att 13.355300 loss_ctc 18.679626 loss_rnnt 10.515891 hw_loss 0.224135 lr 0.00038237 rank 5
2023-02-22 14:13:51,052 DEBUG TRAIN Batch 20/4200 loss 10.189553 loss_att 14.354309 loss_ctc 14.105793 loss_rnnt 8.664514 hw_loss 0.318606 lr 0.00038234 rank 2
2023-02-22 14:13:51,056 DEBUG TRAIN Batch 20/4200 loss 11.599009 loss_att 17.413078 loss_ctc 15.840847 loss_rnnt 9.655822 hw_loss 0.402741 lr 0.00038231 rank 3
2023-02-22 14:13:51,055 DEBUG TRAIN Batch 20/4200 loss 20.781176 loss_att 25.071928 loss_ctc 26.681011 loss_rnnt 18.953308 hw_loss 0.343260 lr 0.00038228 rank 7
2023-02-22 14:13:51,056 DEBUG TRAIN Batch 20/4200 loss 10.629322 loss_att 10.954788 loss_ctc 16.476608 loss_rnnt 9.683852 hw_loss 0.188886 lr 0.00038236 rank 1
2023-02-22 14:13:51,058 DEBUG TRAIN Batch 20/4200 loss 11.864178 loss_att 13.750370 loss_ctc 20.947025 loss_rnnt 10.065212 hw_loss 0.395025 lr 0.00038241 rank 4
2023-02-22 14:13:51,060 DEBUG TRAIN Batch 20/4200 loss 11.987134 loss_att 14.914581 loss_ctc 14.648614 loss_rnnt 10.974260 hw_loss 0.135976 lr 0.00038228 rank 6
2023-02-22 14:13:51,083 DEBUG TRAIN Batch 20/4200 loss 7.815459 loss_att 10.946312 loss_ctc 12.095709 loss_rnnt 6.478926 hw_loss 0.261869 lr 0.00038241 rank 0
2023-02-22 14:15:05,500 DEBUG TRAIN Batch 20/4300 loss 3.699857 loss_att 7.297276 loss_ctc 6.934226 loss_rnnt 2.359323 hw_loss 0.355877 lr 0.00038217 rank 6
2023-02-22 14:15:05,503 DEBUG TRAIN Batch 20/4300 loss 9.538147 loss_att 11.778945 loss_ctc 14.979586 loss_rnnt 8.249269 hw_loss 0.215988 lr 0.00038223 rank 2
2023-02-22 14:15:05,504 DEBUG TRAIN Batch 20/4300 loss 15.733788 loss_att 18.289486 loss_ctc 18.787903 loss_rnnt 14.657429 hw_loss 0.296258 lr 0.00038219 rank 3
2023-02-22 14:15:05,504 DEBUG TRAIN Batch 20/4300 loss 10.822360 loss_att 15.652795 loss_ctc 12.534128 loss_rnnt 9.459452 hw_loss 0.316098 lr 0.00038217 rank 7
2023-02-22 14:15:05,510 DEBUG TRAIN Batch 20/4300 loss 11.811518 loss_att 13.792456 loss_ctc 16.743170 loss_rnnt 10.602913 hw_loss 0.290368 lr 0.00038229 rank 0
2023-02-22 14:15:05,512 DEBUG TRAIN Batch 20/4300 loss 7.094053 loss_att 9.565928 loss_ctc 7.842164 loss_rnnt 6.375467 hw_loss 0.233366 lr 0.00038226 rank 5
2023-02-22 14:15:05,513 DEBUG TRAIN Batch 20/4300 loss 14.171601 loss_att 14.198926 loss_ctc 17.609159 loss_rnnt 13.515776 hw_loss 0.360038 lr 0.00038225 rank 1
2023-02-22 14:15:05,560 DEBUG TRAIN Batch 20/4300 loss 6.595585 loss_att 8.924234 loss_ctc 11.529707 loss_rnnt 5.322126 hw_loss 0.280959 lr 0.00038229 rank 4
2023-02-22 14:16:17,618 DEBUG TRAIN Batch 20/4400 loss 11.564535 loss_att 15.980068 loss_ctc 12.022380 loss_rnnt 10.396427 hw_loss 0.419917 lr 0.00038215 rank 5
2023-02-22 14:16:17,625 DEBUG TRAIN Batch 20/4400 loss 5.351860 loss_att 8.280232 loss_ctc 7.605978 loss_rnnt 4.387657 hw_loss 0.146210 lr 0.00038206 rank 6
2023-02-22 14:16:17,626 DEBUG TRAIN Batch 20/4400 loss 21.207134 loss_att 25.038729 loss_ctc 31.934483 loss_rnnt 18.866241 hw_loss 0.270485 lr 0.00038208 rank 3
2023-02-22 14:16:17,629 DEBUG TRAIN Batch 20/4400 loss 7.666063 loss_att 9.759657 loss_ctc 11.146125 loss_rnnt 6.645800 hw_loss 0.257881 lr 0.00038206 rank 7
2023-02-22 14:16:17,629 DEBUG TRAIN Batch 20/4400 loss 11.276878 loss_att 10.521702 loss_ctc 15.908466 loss_rnnt 10.596593 hw_loss 0.400827 lr 0.00038218 rank 0
2023-02-22 14:16:17,630 DEBUG TRAIN Batch 20/4400 loss 8.091410 loss_att 9.997475 loss_ctc 11.056594 loss_rnnt 7.225165 hw_loss 0.168137 lr 0.00038213 rank 1
2023-02-22 14:16:17,633 DEBUG TRAIN Batch 20/4400 loss 5.611586 loss_att 9.409195 loss_ctc 7.832996 loss_rnnt 4.385286 hw_loss 0.319857 lr 0.00038218 rank 4
2023-02-22 14:16:17,635 DEBUG TRAIN Batch 20/4400 loss 22.835829 loss_att 23.688604 loss_ctc 29.192793 loss_rnnt 21.525188 hw_loss 0.548420 lr 0.00038211 rank 2
2023-02-22 14:17:30,608 DEBUG TRAIN Batch 20/4500 loss 7.021964 loss_att 7.748294 loss_ctc 10.847431 loss_rnnt 6.195589 hw_loss 0.320713 lr 0.00038195 rank 6
2023-02-22 14:17:30,613 DEBUG TRAIN Batch 20/4500 loss 2.761093 loss_att 5.510868 loss_ctc 5.663815 loss_rnnt 1.725524 hw_loss 0.184845 lr 0.00038204 rank 5
2023-02-22 14:17:30,614 DEBUG TRAIN Batch 20/4500 loss 16.728693 loss_att 19.982939 loss_ctc 23.581860 loss_rnnt 14.969684 hw_loss 0.364509 lr 0.00038202 rank 1
2023-02-22 14:17:30,615 DEBUG TRAIN Batch 20/4500 loss 9.691929 loss_att 11.135745 loss_ctc 12.451612 loss_rnnt 8.805304 hw_loss 0.431071 lr 0.00038207 rank 0
2023-02-22 14:17:30,621 DEBUG TRAIN Batch 20/4500 loss 12.272571 loss_att 13.150016 loss_ctc 15.999400 loss_rnnt 11.434079 hw_loss 0.311420 lr 0.00038195 rank 7
2023-02-22 14:17:30,635 DEBUG TRAIN Batch 20/4500 loss 5.784106 loss_att 7.372309 loss_ctc 6.526105 loss_rnnt 5.215372 hw_loss 0.285303 lr 0.00038197 rank 3
2023-02-22 14:17:30,651 DEBUG TRAIN Batch 20/4500 loss 10.442868 loss_att 15.791946 loss_ctc 16.441858 loss_rnnt 8.434717 hw_loss 0.259632 lr 0.00038200 rank 2
2023-02-22 14:17:30,666 DEBUG TRAIN Batch 20/4500 loss 8.682960 loss_att 10.216756 loss_ctc 11.716024 loss_rnnt 7.738839 hw_loss 0.436784 lr 0.00038207 rank 4
2023-02-22 14:18:44,878 DEBUG TRAIN Batch 20/4600 loss 7.102591 loss_att 8.982000 loss_ctc 10.389007 loss_rnnt 6.157706 hw_loss 0.245276 lr 0.00038189 rank 2
2023-02-22 14:18:44,886 DEBUG TRAIN Batch 20/4600 loss 8.053198 loss_att 11.589275 loss_ctc 11.198725 loss_rnnt 6.741167 hw_loss 0.347646 lr 0.00038191 rank 1
2023-02-22 14:18:44,887 DEBUG TRAIN Batch 20/4600 loss 4.751013 loss_att 9.415680 loss_ctc 7.448240 loss_rnnt 3.324146 hw_loss 0.251820 lr 0.00038196 rank 4
2023-02-22 14:18:44,887 DEBUG TRAIN Batch 20/4600 loss 9.399862 loss_att 11.579670 loss_ctc 15.648567 loss_rnnt 7.888929 hw_loss 0.453396 lr 0.00038186 rank 3
2023-02-22 14:18:44,890 DEBUG TRAIN Batch 20/4600 loss 8.888120 loss_att 11.352274 loss_ctc 13.479771 loss_rnnt 7.608007 hw_loss 0.328240 lr 0.00038193 rank 5
2023-02-22 14:18:44,893 DEBUG TRAIN Batch 20/4600 loss 10.066012 loss_att 14.163179 loss_ctc 16.844032 loss_rnnt 8.244807 hw_loss 0.183819 lr 0.00038196 rank 0
2023-02-22 14:18:44,902 DEBUG TRAIN Batch 20/4600 loss 3.641236 loss_att 4.990814 loss_ctc 3.968400 loss_rnnt 3.209646 hw_loss 0.221348 lr 0.00038184 rank 7
2023-02-22 14:18:44,908 DEBUG TRAIN Batch 20/4600 loss 4.674665 loss_att 7.606791 loss_ctc 7.393552 loss_rnnt 3.555890 hw_loss 0.318436 lr 0.00038184 rank 6
2023-02-22 14:19:58,393 DEBUG TRAIN Batch 20/4700 loss 3.647239 loss_att 5.743182 loss_ctc 4.748535 loss_rnnt 2.902380 hw_loss 0.335307 lr 0.00038172 rank 6
2023-02-22 14:19:58,397 DEBUG TRAIN Batch 20/4700 loss 5.519179 loss_att 9.285381 loss_ctc 8.817578 loss_rnnt 4.180457 hw_loss 0.273178 lr 0.00038178 rank 2
2023-02-22 14:19:58,398 DEBUG TRAIN Batch 20/4700 loss 7.351039 loss_att 8.635261 loss_ctc 11.799656 loss_rnnt 6.270604 hw_loss 0.432078 lr 0.00038175 rank 3
2023-02-22 14:19:58,398 DEBUG TRAIN Batch 20/4700 loss 15.823126 loss_att 15.533997 loss_ctc 24.158419 loss_rnnt 14.571096 hw_loss 0.372157 lr 0.00038180 rank 1
2023-02-22 14:19:58,400 DEBUG TRAIN Batch 20/4700 loss 7.756167 loss_att 12.735071 loss_ctc 17.330833 loss_rnnt 5.295151 hw_loss 0.353649 lr 0.00038181 rank 5
2023-02-22 14:19:58,401 DEBUG TRAIN Batch 20/4700 loss 15.638430 loss_att 19.727364 loss_ctc 19.290581 loss_rnnt 14.170340 hw_loss 0.306283 lr 0.00038185 rank 0
2023-02-22 14:19:58,402 DEBUG TRAIN Batch 20/4700 loss 8.648870 loss_att 13.054501 loss_ctc 11.645437 loss_rnnt 7.221786 hw_loss 0.274530 lr 0.00038185 rank 4
2023-02-22 14:19:58,405 DEBUG TRAIN Batch 20/4700 loss 5.422631 loss_att 9.245394 loss_ctc 6.989593 loss_rnnt 4.152580 hw_loss 0.556070 lr 0.00038173 rank 7
2023-02-22 14:21:10,641 DEBUG TRAIN Batch 20/4800 loss 10.947639 loss_att 12.948300 loss_ctc 14.518955 loss_rnnt 9.933907 hw_loss 0.257672 lr 0.00038167 rank 2
2023-02-22 14:21:10,643 DEBUG TRAIN Batch 20/4800 loss 4.827761 loss_att 8.629093 loss_ctc 5.613034 loss_rnnt 3.871840 hw_loss 0.170534 lr 0.00038164 rank 3
2023-02-22 14:21:10,643 DEBUG TRAIN Batch 20/4800 loss 13.742476 loss_att 19.293110 loss_ctc 24.839403 loss_rnnt 10.990460 hw_loss 0.304308 lr 0.00038174 rank 0
2023-02-22 14:21:10,644 DEBUG TRAIN Batch 20/4800 loss 8.060624 loss_att 13.246256 loss_ctc 13.489775 loss_rnnt 6.146450 hw_loss 0.287179 lr 0.00038161 rank 6
2023-02-22 14:21:10,645 DEBUG TRAIN Batch 20/4800 loss 7.087643 loss_att 10.418271 loss_ctc 8.908777 loss_rnnt 6.046640 hw_loss 0.247610 lr 0.00038169 rank 1
2023-02-22 14:21:10,646 DEBUG TRAIN Batch 20/4800 loss 14.808104 loss_att 15.567667 loss_ctc 22.529482 loss_rnnt 13.372010 hw_loss 0.477496 lr 0.00038170 rank 5
2023-02-22 14:21:10,649 DEBUG TRAIN Batch 20/4800 loss 7.496330 loss_att 12.450025 loss_ctc 14.186290 loss_rnnt 5.470972 hw_loss 0.267420 lr 0.00038161 rank 7
2023-02-22 14:21:10,649 DEBUG TRAIN Batch 20/4800 loss 9.010790 loss_att 11.627740 loss_ctc 11.711244 loss_rnnt 7.869450 hw_loss 0.483545 lr 0.00038174 rank 4
2023-02-22 14:22:23,333 DEBUG TRAIN Batch 20/4900 loss 12.667713 loss_att 15.694736 loss_ctc 15.518676 loss_rnnt 11.492685 hw_loss 0.355301 lr 0.00038158 rank 1
2023-02-22 14:22:23,337 DEBUG TRAIN Batch 20/4900 loss 12.028475 loss_att 12.056136 loss_ctc 14.919576 loss_rnnt 11.555554 hw_loss 0.153577 lr 0.00038156 rank 2
2023-02-22 14:22:23,339 DEBUG TRAIN Batch 20/4900 loss 9.613925 loss_att 13.312658 loss_ctc 16.495186 loss_rnnt 7.776684 hw_loss 0.337485 lr 0.00038162 rank 0
2023-02-22 14:22:23,339 DEBUG TRAIN Batch 20/4900 loss 14.226314 loss_att 19.584785 loss_ctc 23.251692 loss_rnnt 11.787995 hw_loss 0.306076 lr 0.00038159 rank 5
2023-02-22 14:22:23,339 DEBUG TRAIN Batch 20/4900 loss 14.406015 loss_att 16.313007 loss_ctc 19.663567 loss_rnnt 13.165363 hw_loss 0.296715 lr 0.00038153 rank 3
2023-02-22 14:22:23,345 DEBUG TRAIN Batch 20/4900 loss 11.904515 loss_att 14.005013 loss_ctc 16.678768 loss_rnnt 10.704819 hw_loss 0.268181 lr 0.00038150 rank 6
2023-02-22 14:22:23,347 DEBUG TRAIN Batch 20/4900 loss 8.145341 loss_att 10.379236 loss_ctc 11.003395 loss_rnnt 7.146780 hw_loss 0.320080 lr 0.00038162 rank 4
2023-02-22 14:22:23,382 DEBUG TRAIN Batch 20/4900 loss 8.485498 loss_att 11.538074 loss_ctc 13.922848 loss_rnnt 7.014539 hw_loss 0.253995 lr 0.00038150 rank 7
2023-02-22 14:23:38,301 DEBUG TRAIN Batch 20/5000 loss 10.803549 loss_att 12.587303 loss_ctc 14.318333 loss_rnnt 9.874306 hw_loss 0.194727 lr 0.00038141 rank 3
2023-02-22 14:23:38,302 DEBUG TRAIN Batch 20/5000 loss 8.931836 loss_att 11.606799 loss_ctc 12.309337 loss_rnnt 7.791242 hw_loss 0.291128 lr 0.00038145 rank 2
2023-02-22 14:23:38,303 DEBUG TRAIN Batch 20/5000 loss 9.311357 loss_att 9.336450 loss_ctc 12.315979 loss_rnnt 8.717142 hw_loss 0.353590 lr 0.00038148 rank 5
2023-02-22 14:23:38,305 DEBUG TRAIN Batch 20/5000 loss 12.493085 loss_att 12.761196 loss_ctc 17.527147 loss_rnnt 11.508355 hw_loss 0.487308 lr 0.00038151 rank 4
2023-02-22 14:23:38,308 DEBUG TRAIN Batch 20/5000 loss 9.397355 loss_att 12.300863 loss_ctc 15.450394 loss_rnnt 7.910455 hw_loss 0.185861 lr 0.00038139 rank 7
2023-02-22 14:23:38,311 DEBUG TRAIN Batch 20/5000 loss 6.253989 loss_att 7.933921 loss_ctc 10.187888 loss_rnnt 5.311191 hw_loss 0.154296 lr 0.00038139 rank 6
2023-02-22 14:23:38,318 DEBUG TRAIN Batch 20/5000 loss 12.817229 loss_att 12.057001 loss_ctc 16.000952 loss_rnnt 12.489578 hw_loss 0.103502 lr 0.00038151 rank 0
2023-02-22 14:23:38,347 DEBUG TRAIN Batch 20/5000 loss 13.326541 loss_att 19.317635 loss_ctc 21.441059 loss_rnnt 10.910975 hw_loss 0.253898 lr 0.00038147 rank 1
2023-02-22 14:24:50,868 DEBUG TRAIN Batch 20/5100 loss 6.394895 loss_att 9.155454 loss_ctc 10.979061 loss_rnnt 4.967219 hw_loss 0.495640 lr 0.00038130 rank 3
2023-02-22 14:24:50,870 DEBUG TRAIN Batch 20/5100 loss 6.850132 loss_att 10.033810 loss_ctc 9.458728 loss_rnnt 5.687776 hw_loss 0.333388 lr 0.00038140 rank 4
2023-02-22 14:24:50,873 DEBUG TRAIN Batch 20/5100 loss 7.702261 loss_att 13.429913 loss_ctc 9.569407 loss_rnnt 6.221696 hw_loss 0.161402 lr 0.00038140 rank 0
2023-02-22 14:24:50,873 DEBUG TRAIN Batch 20/5100 loss 8.875154 loss_att 12.849119 loss_ctc 14.284767 loss_rnnt 7.253802 hw_loss 0.197396 lr 0.00038134 rank 2
2023-02-22 14:24:50,877 DEBUG TRAIN Batch 20/5100 loss 10.727979 loss_att 15.144788 loss_ctc 15.451464 loss_rnnt 9.020175 hw_loss 0.364960 lr 0.00038128 rank 6
2023-02-22 14:24:50,878 DEBUG TRAIN Batch 20/5100 loss 10.987182 loss_att 11.800379 loss_ctc 12.303797 loss_rnnt 10.518073 hw_loss 0.245477 lr 0.00038137 rank 5
2023-02-22 14:24:50,883 DEBUG TRAIN Batch 20/5100 loss 11.620438 loss_att 14.318544 loss_ctc 19.686758 loss_rnnt 9.783027 hw_loss 0.416776 lr 0.00038128 rank 7
2023-02-22 14:24:50,928 DEBUG TRAIN Batch 20/5100 loss 7.689980 loss_att 8.373164 loss_ctc 8.686749 loss_rnnt 7.295592 hw_loss 0.234092 lr 0.00038136 rank 1
2023-02-22 14:26:03,526 DEBUG TRAIN Batch 20/5200 loss 7.429846 loss_att 10.779196 loss_ctc 8.332886 loss_rnnt 6.541168 hw_loss 0.184505 lr 0.00038123 rank 2
2023-02-22 14:26:03,547 DEBUG TRAIN Batch 20/5200 loss 5.975877 loss_att 9.435490 loss_ctc 7.988002 loss_rnnt 4.831670 hw_loss 0.345001 lr 0.00038117 rank 7
2023-02-22 14:26:03,553 DEBUG TRAIN Batch 20/5200 loss 7.644690 loss_att 9.993112 loss_ctc 9.064643 loss_rnnt 6.756923 hw_loss 0.428916 lr 0.00038129 rank 0
2023-02-22 14:26:03,552 DEBUG TRAIN Batch 20/5200 loss 5.329035 loss_att 6.468869 loss_ctc 7.824907 loss_rnnt 4.519608 hw_loss 0.466270 lr 0.00038119 rank 3
2023-02-22 14:26:03,552 DEBUG TRAIN Batch 20/5200 loss 8.241839 loss_att 10.805288 loss_ctc 10.762507 loss_rnnt 7.118480 hw_loss 0.514838 lr 0.00038117 rank 6
2023-02-22 14:26:03,553 DEBUG TRAIN Batch 20/5200 loss 19.298170 loss_att 18.850523 loss_ctc 20.913115 loss_rnnt 18.927456 hw_loss 0.459220 lr 0.00038129 rank 4
2023-02-22 14:26:03,559 DEBUG TRAIN Batch 20/5200 loss 7.045844 loss_att 8.978103 loss_ctc 8.813889 loss_rnnt 6.326147 hw_loss 0.182825 lr 0.00038126 rank 5
2023-02-22 14:26:03,599 DEBUG TRAIN Batch 20/5200 loss 7.955761 loss_att 10.940180 loss_ctc 9.746402 loss_rnnt 6.901174 hw_loss 0.410534 lr 0.00038124 rank 1
2023-02-22 14:27:17,379 DEBUG TRAIN Batch 20/5300 loss 4.990121 loss_att 7.465707 loss_ctc 5.264332 loss_rnnt 4.325777 hw_loss 0.248747 lr 0.00038118 rank 4
2023-02-22 14:27:17,390 DEBUG TRAIN Batch 20/5300 loss 8.881403 loss_att 11.237221 loss_ctc 14.305038 loss_rnnt 7.494254 hw_loss 0.361563 lr 0.00038106 rank 7
2023-02-22 14:27:17,389 DEBUG TRAIN Batch 20/5300 loss 4.225510 loss_att 9.687643 loss_ctc 4.830872 loss_rnnt 2.909936 hw_loss 0.267060 lr 0.00038106 rank 6
2023-02-22 14:27:17,390 DEBUG TRAIN Batch 20/5300 loss 6.776230 loss_att 10.509068 loss_ctc 9.985105 loss_rnnt 5.505457 hw_loss 0.180665 lr 0.00038113 rank 1
2023-02-22 14:27:17,390 DEBUG TRAIN Batch 20/5300 loss 16.869385 loss_att 18.364338 loss_ctc 18.953842 loss_rnnt 16.133276 hw_loss 0.298484 lr 0.00038111 rank 2
2023-02-22 14:27:17,394 DEBUG TRAIN Batch 20/5300 loss 5.987119 loss_att 13.987565 loss_ctc 12.712890 loss_rnnt 3.371711 hw_loss 0.222281 lr 0.00038108 rank 3
2023-02-22 14:27:17,395 DEBUG TRAIN Batch 20/5300 loss 6.294935 loss_att 9.234857 loss_ctc 9.514268 loss_rnnt 5.149241 hw_loss 0.240872 lr 0.00038118 rank 0
2023-02-22 14:27:17,395 DEBUG TRAIN Batch 20/5300 loss 8.160077 loss_att 11.865084 loss_ctc 10.436017 loss_rnnt 6.933778 hw_loss 0.340948 lr 0.00038115 rank 5
2023-02-22 14:28:30,870 DEBUG TRAIN Batch 20/5400 loss 6.111801 loss_att 10.591485 loss_ctc 8.371139 loss_rnnt 4.805699 hw_loss 0.204225 lr 0.00038100 rank 2
2023-02-22 14:28:30,873 DEBUG TRAIN Batch 20/5400 loss 10.094160 loss_att 14.861227 loss_ctc 15.454700 loss_rnnt 8.274577 hw_loss 0.283932 lr 0.00038095 rank 6
2023-02-22 14:28:30,874 DEBUG TRAIN Batch 20/5400 loss 3.274449 loss_att 8.334558 loss_ctc 6.404336 loss_rnnt 1.681356 hw_loss 0.307036 lr 0.00038095 rank 7
2023-02-22 14:28:30,877 DEBUG TRAIN Batch 20/5400 loss 8.998343 loss_att 10.634472 loss_ctc 14.280684 loss_rnnt 7.808583 hw_loss 0.296666 lr 0.00038097 rank 3
2023-02-22 14:28:30,877 DEBUG TRAIN Batch 20/5400 loss 20.940557 loss_att 21.240334 loss_ctc 26.541595 loss_rnnt 20.040295 hw_loss 0.175320 lr 0.00038104 rank 5
2023-02-22 14:28:30,877 DEBUG TRAIN Batch 20/5400 loss 6.609796 loss_att 8.567247 loss_ctc 6.673361 loss_rnnt 5.991952 hw_loss 0.408522 lr 0.00038102 rank 1
2023-02-22 14:28:30,878 DEBUG TRAIN Batch 20/5400 loss 7.681088 loss_att 9.379899 loss_ctc 11.010311 loss_rnnt 6.730515 hw_loss 0.312964 lr 0.00038107 rank 4
2023-02-22 14:28:30,884 DEBUG TRAIN Batch 20/5400 loss 3.336539 loss_att 7.432259 loss_ctc 7.638994 loss_rnnt 1.798439 hw_loss 0.272428 lr 0.00038107 rank 0
2023-02-22 14:29:43,296 DEBUG TRAIN Batch 20/5500 loss 7.812850 loss_att 9.039273 loss_ctc 9.787637 loss_rnnt 7.151270 hw_loss 0.286858 lr 0.00038084 rank 6
2023-02-22 14:29:43,297 DEBUG TRAIN Batch 20/5500 loss 9.531605 loss_att 12.163726 loss_ctc 13.488540 loss_rnnt 8.353372 hw_loss 0.232905 lr 0.00038086 rank 3
2023-02-22 14:29:43,298 DEBUG TRAIN Batch 20/5500 loss 4.089944 loss_att 6.019739 loss_ctc 5.556983 loss_rnnt 3.315841 hw_loss 0.361011 lr 0.00038091 rank 1
2023-02-22 14:29:43,299 DEBUG TRAIN Batch 20/5500 loss 7.043607 loss_att 8.371837 loss_ctc 9.973437 loss_rnnt 6.179323 hw_loss 0.389989 lr 0.00038089 rank 2
2023-02-22 14:29:43,301 DEBUG TRAIN Batch 20/5500 loss 11.914340 loss_att 16.315302 loss_ctc 18.253359 loss_rnnt 10.106975 hw_loss 0.153697 lr 0.00038096 rank 0
2023-02-22 14:29:43,301 DEBUG TRAIN Batch 20/5500 loss 7.130457 loss_att 8.595638 loss_ctc 8.652355 loss_rnnt 6.487932 hw_loss 0.274817 lr 0.00038096 rank 4
2023-02-22 14:29:43,304 DEBUG TRAIN Batch 20/5500 loss 8.553690 loss_att 12.269217 loss_ctc 12.879855 loss_rnnt 7.070069 hw_loss 0.306924 lr 0.00038084 rank 7
2023-02-22 14:29:43,306 DEBUG TRAIN Batch 20/5500 loss 9.679287 loss_att 12.634850 loss_ctc 14.151404 loss_rnnt 8.397326 hw_loss 0.177312 lr 0.00038093 rank 5
2023-02-22 14:30:55,578 DEBUG TRAIN Batch 20/5600 loss 4.777966 loss_att 6.725796 loss_ctc 4.559247 loss_rnnt 4.227035 hw_loss 0.357240 lr 0.00038080 rank 1
2023-02-22 14:30:55,579 DEBUG TRAIN Batch 20/5600 loss 14.618353 loss_att 17.912996 loss_ctc 18.703299 loss_rnnt 13.240565 hw_loss 0.326623 lr 0.00038078 rank 2
2023-02-22 14:30:55,580 DEBUG TRAIN Batch 20/5600 loss 10.917368 loss_att 13.348037 loss_ctc 11.544992 loss_rnnt 10.215659 hw_loss 0.247297 lr 0.00038073 rank 6
2023-02-22 14:30:55,581 DEBUG TRAIN Batch 20/5600 loss 5.623291 loss_att 7.701186 loss_ctc 6.894870 loss_rnnt 4.828971 hw_loss 0.392244 lr 0.00038085 rank 4
2023-02-22 14:30:55,583 DEBUG TRAIN Batch 20/5600 loss 3.201652 loss_att 5.770609 loss_ctc 4.744792 loss_rnnt 2.304065 hw_loss 0.333829 lr 0.00038073 rank 7
2023-02-22 14:30:55,583 DEBUG TRAIN Batch 20/5600 loss 10.847867 loss_att 13.448216 loss_ctc 16.724525 loss_rnnt 9.475891 hw_loss 0.128156 lr 0.00038075 rank 3
2023-02-22 14:30:55,584 DEBUG TRAIN Batch 20/5600 loss 7.049510 loss_att 10.075252 loss_ctc 11.539276 loss_rnnt 5.726086 hw_loss 0.224325 lr 0.00038085 rank 0
2023-02-22 14:30:55,586 DEBUG TRAIN Batch 20/5600 loss 6.692163 loss_att 8.952374 loss_ctc 9.060561 loss_rnnt 5.797758 hw_loss 0.237332 lr 0.00038082 rank 5
2023-02-22 14:32:11,307 DEBUG TRAIN Batch 20/5700 loss 8.870538 loss_att 11.652076 loss_ctc 12.264183 loss_rnnt 7.678137 hw_loss 0.344263 lr 0.00038067 rank 2
2023-02-22 14:32:11,308 DEBUG TRAIN Batch 20/5700 loss 5.122410 loss_att 8.160117 loss_ctc 8.131725 loss_rnnt 3.992775 hw_loss 0.226596 lr 0.00038062 rank 6
2023-02-22 14:32:11,310 DEBUG TRAIN Batch 20/5700 loss 9.317644 loss_att 9.093473 loss_ctc 11.461936 loss_rnnt 8.817342 hw_loss 0.486056 lr 0.00038074 rank 4
2023-02-22 14:32:11,312 DEBUG TRAIN Batch 20/5700 loss 5.343483 loss_att 8.861525 loss_ctc 8.226794 loss_rnnt 4.152750 hw_loss 0.192531 lr 0.00038069 rank 1
2023-02-22 14:32:11,315 DEBUG TRAIN Batch 20/5700 loss 6.213562 loss_att 8.831764 loss_ctc 7.583728 loss_rnnt 5.365160 hw_loss 0.266385 lr 0.00038062 rank 7
2023-02-22 14:32:11,316 DEBUG TRAIN Batch 20/5700 loss 8.901234 loss_att 10.268999 loss_ctc 11.447521 loss_rnnt 8.010734 hw_loss 0.520205 lr 0.00038064 rank 3
2023-02-22 14:32:11,316 DEBUG TRAIN Batch 20/5700 loss 10.566076 loss_att 14.607085 loss_ctc 14.422371 loss_rnnt 9.100616 hw_loss 0.268285 lr 0.00038071 rank 5
2023-02-22 14:32:11,396 DEBUG TRAIN Batch 20/5700 loss 7.089495 loss_att 10.160913 loss_ctc 12.281733 loss_rnnt 5.522175 hw_loss 0.488883 lr 0.00038074 rank 0
2023-02-22 14:33:24,268 DEBUG TRAIN Batch 20/5800 loss 20.856440 loss_att 22.570452 loss_ctc 27.721083 loss_rnnt 19.456663 hw_loss 0.265664 lr 0.00038056 rank 2
2023-02-22 14:33:24,273 DEBUG TRAIN Batch 20/5800 loss 5.559715 loss_att 5.327643 loss_ctc 8.345564 loss_rnnt 5.007531 hw_loss 0.425910 lr 0.00038063 rank 4
2023-02-22 14:33:24,273 DEBUG TRAIN Batch 20/5800 loss 10.613947 loss_att 10.019998 loss_ctc 12.612037 loss_rnnt 10.264375 hw_loss 0.378656 lr 0.00038051 rank 6
2023-02-22 14:33:24,277 DEBUG TRAIN Batch 20/5800 loss 19.249283 loss_att 23.597622 loss_ctc 30.634809 loss_rnnt 16.668373 hw_loss 0.362194 lr 0.00038053 rank 3
2023-02-22 14:33:24,278 DEBUG TRAIN Batch 20/5800 loss 3.193742 loss_att 6.606241 loss_ctc 3.642646 loss_rnnt 2.233889 hw_loss 0.407811 lr 0.00038058 rank 1
2023-02-22 14:33:24,279 DEBUG TRAIN Batch 20/5800 loss 9.023208 loss_att 12.412648 loss_ctc 12.682635 loss_rnnt 7.780869 hw_loss 0.143486 lr 0.00038051 rank 7
2023-02-22 14:33:24,281 DEBUG TRAIN Batch 20/5800 loss 2.476526 loss_att 4.869205 loss_ctc 4.781873 loss_rnnt 1.632596 hw_loss 0.108778 lr 0.00038060 rank 5
2023-02-22 14:33:24,325 DEBUG TRAIN Batch 20/5800 loss 4.247037 loss_att 7.928935 loss_ctc 8.070963 loss_rnnt 2.897797 hw_loss 0.193132 lr 0.00038063 rank 0
2023-02-22 14:34:37,622 DEBUG TRAIN Batch 20/5900 loss 4.750991 loss_att 8.671334 loss_ctc 5.601017 loss_rnnt 3.562972 hw_loss 0.544902 lr 0.00038045 rank 2
2023-02-22 14:34:37,628 DEBUG TRAIN Batch 20/5900 loss 8.617348 loss_att 13.546844 loss_ctc 11.957306 loss_rnnt 7.090318 hw_loss 0.179630 lr 0.00038040 rank 6
2023-02-22 14:34:37,629 DEBUG TRAIN Batch 20/5900 loss 6.258081 loss_att 8.320128 loss_ctc 11.212952 loss_rnnt 4.993385 hw_loss 0.359321 lr 0.00038049 rank 5
2023-02-22 14:34:37,629 DEBUG TRAIN Batch 20/5900 loss 6.273269 loss_att 8.319479 loss_ctc 6.483095 loss_rnnt 5.735513 hw_loss 0.188505 lr 0.00038040 rank 7
2023-02-22 14:34:37,629 DEBUG TRAIN Batch 20/5900 loss 6.345757 loss_att 8.462516 loss_ctc 8.850928 loss_rnnt 5.497535 hw_loss 0.170339 lr 0.00038052 rank 0
2023-02-22 14:34:37,634 DEBUG TRAIN Batch 20/5900 loss 10.301455 loss_att 12.263151 loss_ctc 13.645208 loss_rnnt 9.336939 hw_loss 0.236893 lr 0.00038047 rank 1
2023-02-22 14:34:37,634 DEBUG TRAIN Batch 20/5900 loss 10.082026 loss_att 14.088435 loss_ctc 13.229292 loss_rnnt 8.728851 hw_loss 0.247982 lr 0.00038052 rank 4
2023-02-22 14:34:37,635 DEBUG TRAIN Batch 20/5900 loss 5.268180 loss_att 9.806311 loss_ctc 5.732299 loss_rnnt 4.212890 hw_loss 0.160840 lr 0.00038042 rank 3
2023-02-22 14:35:51,198 DEBUG TRAIN Batch 20/6000 loss 5.613805 loss_att 7.232270 loss_ctc 9.454340 loss_rnnt 4.638741 hw_loss 0.261187 lr 0.00038041 rank 4
2023-02-22 14:35:51,198 DEBUG TRAIN Batch 20/6000 loss 10.373733 loss_att 12.615178 loss_ctc 13.835417 loss_rnnt 9.253082 hw_loss 0.395254 lr 0.00038029 rank 7
2023-02-22 14:35:51,202 DEBUG TRAIN Batch 20/6000 loss 8.513733 loss_att 12.201393 loss_ctc 12.309742 loss_rnnt 7.105131 hw_loss 0.309252 lr 0.00038037 rank 5
2023-02-22 14:35:51,214 DEBUG TRAIN Batch 20/6000 loss 11.313578 loss_att 14.080398 loss_ctc 14.834450 loss_rnnt 10.128456 hw_loss 0.304327 lr 0.00038034 rank 2
2023-02-22 14:35:51,215 DEBUG TRAIN Batch 20/6000 loss 5.319499 loss_att 8.223574 loss_ctc 8.978033 loss_rnnt 4.132698 hw_loss 0.221591 lr 0.00038029 rank 6
2023-02-22 14:35:51,215 DEBUG TRAIN Batch 20/6000 loss 7.239938 loss_att 12.218599 loss_ctc 17.334923 loss_rnnt 4.774838 hw_loss 0.231317 lr 0.00038031 rank 3
2023-02-22 14:35:51,217 DEBUG TRAIN Batch 20/6000 loss 13.859586 loss_att 15.740485 loss_ctc 18.219742 loss_rnnt 12.789886 hw_loss 0.210313 lr 0.00038036 rank 1
2023-02-22 14:35:51,233 DEBUG TRAIN Batch 20/6000 loss 6.237138 loss_att 6.416630 loss_ctc 7.986694 loss_rnnt 5.786552 hw_loss 0.340151 lr 0.00038041 rank 0
2023-02-22 14:37:05,547 DEBUG TRAIN Batch 20/6100 loss 6.357095 loss_att 8.738523 loss_ctc 8.619969 loss_rnnt 5.359969 hw_loss 0.410858 lr 0.00038018 rank 6
2023-02-22 14:37:05,551 DEBUG TRAIN Batch 20/6100 loss 5.222655 loss_att 8.412123 loss_ctc 7.121398 loss_rnnt 4.126288 hw_loss 0.384951 lr 0.00038023 rank 2
2023-02-22 14:37:05,553 DEBUG TRAIN Batch 20/6100 loss 11.073803 loss_att 14.306868 loss_ctc 18.280638 loss_rnnt 9.329041 hw_loss 0.257320 lr 0.00038030 rank 0
2023-02-22 14:37:05,557 DEBUG TRAIN Batch 20/6100 loss 7.411960 loss_att 9.911160 loss_ctc 11.374094 loss_rnnt 6.276184 hw_loss 0.201846 lr 0.00038025 rank 1
2023-02-22 14:37:05,559 DEBUG TRAIN Batch 20/6100 loss 13.824287 loss_att 16.965750 loss_ctc 15.913005 loss_rnnt 12.821301 hw_loss 0.180369 lr 0.00038030 rank 4
2023-02-22 14:37:05,561 DEBUG TRAIN Batch 20/6100 loss 11.750275 loss_att 13.427042 loss_ctc 15.740180 loss_rnnt 10.823604 hw_loss 0.111244 lr 0.00038020 rank 3
2023-02-22 14:37:05,561 DEBUG TRAIN Batch 20/6100 loss 12.841205 loss_att 14.156336 loss_ctc 18.208637 loss_rnnt 11.747377 hw_loss 0.215894 lr 0.00038018 rank 7
2023-02-22 14:37:05,563 DEBUG TRAIN Batch 20/6100 loss 18.857250 loss_att 19.327080 loss_ctc 26.615900 loss_rnnt 17.657925 hw_loss 0.132885 lr 0.00038026 rank 5
2023-02-22 14:38:17,785 DEBUG TRAIN Batch 20/6200 loss 2.811460 loss_att 5.199636 loss_ctc 4.758575 loss_rnnt 1.933015 hw_loss 0.264740 lr 0.00038012 rank 2
2023-02-22 14:38:17,786 DEBUG TRAIN Batch 20/6200 loss 5.978203 loss_att 9.075505 loss_ctc 9.133053 loss_rnnt 4.750311 hw_loss 0.352096 lr 0.00038019 rank 4
2023-02-22 14:38:17,787 DEBUG TRAIN Batch 20/6200 loss 10.342920 loss_att 10.244356 loss_ctc 12.156303 loss_rnnt 9.852528 hw_loss 0.503101 lr 0.00038014 rank 1
2023-02-22 14:38:17,787 DEBUG TRAIN Batch 20/6200 loss 9.222777 loss_att 9.996614 loss_ctc 13.639997 loss_rnnt 8.285329 hw_loss 0.363221 lr 0.00038007 rank 6
2023-02-22 14:38:17,791 DEBUG TRAIN Batch 20/6200 loss 6.212415 loss_att 8.132235 loss_ctc 9.083696 loss_rnnt 5.282684 hw_loss 0.305493 lr 0.00038019 rank 0
2023-02-22 14:38:17,792 DEBUG TRAIN Batch 20/6200 loss 6.363698 loss_att 10.417050 loss_ctc 10.129006 loss_rnnt 4.981220 hw_loss 0.130810 lr 0.00038009 rank 3
2023-02-22 14:38:17,792 DEBUG TRAIN Batch 20/6200 loss 10.682966 loss_att 13.833259 loss_ctc 15.628717 loss_rnnt 9.228802 hw_loss 0.308762 lr 0.00038007 rank 7
2023-02-22 14:38:17,838 DEBUG TRAIN Batch 20/6200 loss 13.535686 loss_att 15.146408 loss_ctc 21.969954 loss_rnnt 11.975093 hw_loss 0.213522 lr 0.00038016 rank 5
2023-02-22 14:39:31,186 DEBUG TRAIN Batch 20/6300 loss 8.045024 loss_att 9.766117 loss_ctc 12.231505 loss_rnnt 7.017042 hw_loss 0.235435 lr 0.00037998 rank 3
2023-02-22 14:39:31,195 DEBUG TRAIN Batch 20/6300 loss 9.473273 loss_att 9.858456 loss_ctc 12.938650 loss_rnnt 8.843829 hw_loss 0.169421 lr 0.00037996 rank 7
2023-02-22 14:39:31,199 DEBUG TRAIN Batch 20/6300 loss 2.797903 loss_att 7.659665 loss_ctc 4.729165 loss_rnnt 1.467298 hw_loss 0.188909 lr 0.00038008 rank 0
2023-02-22 14:39:31,199 DEBUG TRAIN Batch 20/6300 loss 9.574544 loss_att 13.732855 loss_ctc 12.746254 loss_rnnt 8.190191 hw_loss 0.243365 lr 0.00038003 rank 1
2023-02-22 14:39:31,201 DEBUG TRAIN Batch 20/6300 loss 17.436373 loss_att 16.835445 loss_ctc 21.744535 loss_rnnt 16.868319 hw_loss 0.213407 lr 0.00038005 rank 5
2023-02-22 14:39:31,201 DEBUG TRAIN Batch 20/6300 loss 18.700460 loss_att 22.432039 loss_ctc 38.626289 loss_rnnt 15.085415 hw_loss 0.397410 lr 0.00038001 rank 2
2023-02-22 14:39:31,203 DEBUG TRAIN Batch 20/6300 loss 7.149268 loss_att 8.111659 loss_ctc 9.497844 loss_rnnt 6.512635 hw_loss 0.245645 lr 0.00037996 rank 6
2023-02-22 14:39:31,204 DEBUG TRAIN Batch 20/6300 loss 11.322189 loss_att 11.314454 loss_ctc 15.424976 loss_rnnt 10.576950 hw_loss 0.374528 lr 0.00038008 rank 4
2023-02-22 14:40:46,324 DEBUG TRAIN Batch 20/6400 loss 7.306309 loss_att 8.401467 loss_ctc 8.728575 loss_rnnt 6.787992 hw_loss 0.205593 lr 0.00037997 rank 4
2023-02-22 14:40:46,335 DEBUG TRAIN Batch 20/6400 loss 8.203195 loss_att 9.488632 loss_ctc 11.517673 loss_rnnt 7.426280 hw_loss 0.146058 lr 0.00037990 rank 2
2023-02-22 14:40:46,346 DEBUG TRAIN Batch 20/6400 loss 14.793040 loss_att 22.253029 loss_ctc 24.492779 loss_rnnt 11.868403 hw_loss 0.261263 lr 0.00037985 rank 6
2023-02-22 14:40:46,346 DEBUG TRAIN Batch 20/6400 loss 12.800528 loss_att 14.200102 loss_ctc 14.055742 loss_rnnt 12.276148 hw_loss 0.144568 lr 0.00037987 rank 3
2023-02-22 14:40:46,350 DEBUG TRAIN Batch 20/6400 loss 11.545745 loss_att 18.327242 loss_ctc 22.742527 loss_rnnt 8.565845 hw_loss 0.245053 lr 0.00037997 rank 0
2023-02-22 14:40:46,349 DEBUG TRAIN Batch 20/6400 loss 7.757326 loss_att 10.701817 loss_ctc 13.200821 loss_rnnt 6.323830 hw_loss 0.222746 lr 0.00037992 rank 1
2023-02-22 14:40:46,350 DEBUG TRAIN Batch 20/6400 loss 5.874473 loss_att 9.435678 loss_ctc 11.447407 loss_rnnt 4.302581 hw_loss 0.218610 lr 0.00037994 rank 5
2023-02-22 14:40:46,351 DEBUG TRAIN Batch 20/6400 loss 7.298937 loss_att 7.616325 loss_ctc 9.755465 loss_rnnt 6.654733 hw_loss 0.474730 lr 0.00037985 rank 7
2023-02-22 14:41:58,367 DEBUG TRAIN Batch 20/6500 loss 1.494850 loss_att 4.399862 loss_ctc 1.657929 loss_rnnt 0.853066 hw_loss 0.073196 lr 0.00037974 rank 6
2023-02-22 14:41:58,386 DEBUG TRAIN Batch 20/6500 loss 8.309059 loss_att 10.591438 loss_ctc 13.071608 loss_rnnt 7.031525 hw_loss 0.348847 lr 0.00037979 rank 2
2023-02-22 14:41:58,386 DEBUG TRAIN Batch 20/6500 loss 7.347858 loss_att 10.626478 loss_ctc 9.246361 loss_rnnt 6.336214 hw_loss 0.192725 lr 0.00037986 rank 4
2023-02-22 14:41:58,386 DEBUG TRAIN Batch 20/6500 loss 14.998923 loss_att 19.909391 loss_ctc 22.164902 loss_rnnt 12.936216 hw_loss 0.234658 lr 0.00037981 rank 1
2023-02-22 14:41:58,387 DEBUG TRAIN Batch 20/6500 loss 8.184022 loss_att 10.283086 loss_ctc 8.551418 loss_rnnt 7.528904 hw_loss 0.349347 lr 0.00037983 rank 5
2023-02-22 14:41:58,388 DEBUG TRAIN Batch 20/6500 loss 8.569503 loss_att 8.476875 loss_ctc 10.910887 loss_rnnt 7.918249 hw_loss 0.670491 lr 0.00037976 rank 3
2023-02-22 14:41:58,389 DEBUG TRAIN Batch 20/6500 loss 9.184791 loss_att 13.149688 loss_ctc 12.083944 loss_rnnt 7.865989 hw_loss 0.261127 lr 0.00037974 rank 7
2023-02-22 14:41:58,396 DEBUG TRAIN Batch 20/6500 loss 9.054147 loss_att 10.695921 loss_ctc 14.472968 loss_rnnt 7.868456 hw_loss 0.252800 lr 0.00037986 rank 0
2023-02-22 14:43:10,618 DEBUG TRAIN Batch 20/6600 loss 3.784277 loss_att 8.272164 loss_ctc 4.904417 loss_rnnt 2.580166 hw_loss 0.294715 lr 0.00037975 rank 4
2023-02-22 14:43:10,621 DEBUG TRAIN Batch 20/6600 loss 7.910919 loss_att 11.697735 loss_ctc 11.769035 loss_rnnt 6.546472 hw_loss 0.173753 lr 0.00037963 rank 6
2023-02-22 14:43:10,623 DEBUG TRAIN Batch 20/6600 loss 5.411799 loss_att 8.098069 loss_ctc 9.316448 loss_rnnt 4.200734 hw_loss 0.287235 lr 0.00037968 rank 2
2023-02-22 14:43:10,626 DEBUG TRAIN Batch 20/6600 loss 15.682112 loss_att 16.509792 loss_ctc 19.829441 loss_rnnt 14.812568 hw_loss 0.283181 lr 0.00037970 rank 1
2023-02-22 14:43:10,627 DEBUG TRAIN Batch 20/6600 loss 8.804493 loss_att 13.087669 loss_ctc 9.996880 loss_rnnt 7.701301 hw_loss 0.164198 lr 0.00037965 rank 3
2023-02-22 14:43:10,633 DEBUG TRAIN Batch 20/6600 loss 6.293558 loss_att 9.021507 loss_ctc 9.303556 loss_rnnt 5.256973 hw_loss 0.168117 lr 0.00037975 rank 0
2023-02-22 14:43:10,636 DEBUG TRAIN Batch 20/6600 loss 8.498947 loss_att 9.987221 loss_ctc 9.471338 loss_rnnt 7.888307 hw_loss 0.343749 lr 0.00037972 rank 5
2023-02-22 14:43:10,678 DEBUG TRAIN Batch 20/6600 loss 3.841410 loss_att 6.252591 loss_ctc 7.087490 loss_rnnt 2.789599 hw_loss 0.256433 lr 0.00037963 rank 7
2023-02-22 14:44:23,574 DEBUG TRAIN Batch 20/6700 loss 6.879318 loss_att 8.819070 loss_ctc 9.143371 loss_rnnt 6.030326 hw_loss 0.298441 lr 0.00037957 rank 2
2023-02-22 14:44:23,580 DEBUG TRAIN Batch 20/6700 loss 16.070288 loss_att 17.691296 loss_ctc 24.054054 loss_rnnt 14.581799 hw_loss 0.187096 lr 0.00037959 rank 1
2023-02-22 14:44:23,588 DEBUG TRAIN Batch 20/6700 loss 8.555311 loss_att 10.378572 loss_ctc 9.716891 loss_rnnt 7.917776 hw_loss 0.221262 lr 0.00037952 rank 7
2023-02-22 14:44:23,591 DEBUG TRAIN Batch 20/6700 loss 23.369713 loss_att 26.348719 loss_ctc 32.226295 loss_rnnt 21.413364 hw_loss 0.336877 lr 0.00037961 rank 5
2023-02-22 14:44:23,607 DEBUG TRAIN Batch 20/6700 loss 3.134086 loss_att 5.735317 loss_ctc 3.506754 loss_rnnt 2.415754 hw_loss 0.278244 lr 0.00037964 rank 0
2023-02-22 14:44:23,610 DEBUG TRAIN Batch 20/6700 loss 13.057920 loss_att 19.580511 loss_ctc 15.742546 loss_rnnt 11.277099 hw_loss 0.221912 lr 0.00037954 rank 3
2023-02-22 14:44:23,613 DEBUG TRAIN Batch 20/6700 loss 6.673126 loss_att 8.145119 loss_ctc 10.749656 loss_rnnt 5.784945 hw_loss 0.094208 lr 0.00037964 rank 4
2023-02-22 14:44:23,618 DEBUG TRAIN Batch 20/6700 loss 6.611098 loss_att 8.993950 loss_ctc 9.281814 loss_rnnt 5.701481 hw_loss 0.144283 lr 0.00037952 rank 6
2023-02-22 14:45:38,693 DEBUG TRAIN Batch 20/6800 loss 8.027081 loss_att 11.347495 loss_ctc 12.308160 loss_rnnt 6.658006 hw_loss 0.251588 lr 0.00037943 rank 3
2023-02-22 14:45:38,704 DEBUG TRAIN Batch 20/6800 loss 4.307172 loss_att 6.043454 loss_ctc 6.622244 loss_rnnt 3.468354 hw_loss 0.342909 lr 0.00037946 rank 2
2023-02-22 14:45:38,707 DEBUG TRAIN Batch 20/6800 loss 4.943544 loss_att 7.016325 loss_ctc 6.575320 loss_rnnt 4.200104 hw_loss 0.208714 lr 0.00037941 rank 6
2023-02-22 14:45:38,711 DEBUG TRAIN Batch 20/6800 loss 11.148214 loss_att 13.358501 loss_ctc 14.011629 loss_rnnt 10.168018 hw_loss 0.293154 lr 0.00037953 rank 4
2023-02-22 14:45:38,711 DEBUG TRAIN Batch 20/6800 loss 12.934062 loss_att 13.451895 loss_ctc 18.447868 loss_rnnt 11.804169 hw_loss 0.545913 lr 0.00037948 rank 1
2023-02-22 14:45:38,711 DEBUG TRAIN Batch 20/6800 loss 17.511950 loss_att 16.350216 loss_ctc 22.339422 loss_rnnt 16.896677 hw_loss 0.382416 lr 0.00037953 rank 0
2023-02-22 14:45:38,716 DEBUG TRAIN Batch 20/6800 loss 6.449953 loss_att 8.852735 loss_ctc 9.063515 loss_rnnt 5.453118 hw_loss 0.314632 lr 0.00037950 rank 5
2023-02-22 14:45:38,754 DEBUG TRAIN Batch 20/6800 loss 6.517364 loss_att 9.399734 loss_ctc 10.146793 loss_rnnt 5.258633 hw_loss 0.371875 lr 0.00037941 rank 7
2023-02-22 14:46:51,515 DEBUG TRAIN Batch 20/6900 loss 13.067636 loss_att 14.501232 loss_ctc 17.369837 loss_rnnt 11.919271 hw_loss 0.540037 lr 0.00037936 rank 2
2023-02-22 14:46:51,515 DEBUG TRAIN Batch 20/6900 loss 10.091230 loss_att 11.830235 loss_ctc 14.156237 loss_rnnt 9.112496 hw_loss 0.166748 lr 0.00037930 rank 7
2023-02-22 14:46:51,520 DEBUG TRAIN Batch 20/6900 loss 7.676073 loss_att 9.132905 loss_ctc 11.713809 loss_rnnt 6.680596 hw_loss 0.310773 lr 0.00037930 rank 6
2023-02-22 14:46:51,520 DEBUG TRAIN Batch 20/6900 loss 5.367826 loss_att 8.849402 loss_ctc 11.078914 loss_rnnt 3.697129 hw_loss 0.399193 lr 0.00037932 rank 3
2023-02-22 14:46:51,520 DEBUG TRAIN Batch 20/6900 loss 4.820784 loss_att 6.511469 loss_ctc 11.914398 loss_rnnt 3.402256 hw_loss 0.252327 lr 0.00037937 rank 1
2023-02-22 14:46:51,523 DEBUG TRAIN Batch 20/6900 loss 6.532616 loss_att 7.520756 loss_ctc 10.394944 loss_rnnt 5.651799 hw_loss 0.315397 lr 0.00037942 rank 4
2023-02-22 14:46:51,523 DEBUG TRAIN Batch 20/6900 loss 10.674711 loss_att 11.069034 loss_ctc 14.290802 loss_rnnt 9.950014 hw_loss 0.306911 lr 0.00037942 rank 0
2023-02-22 14:46:51,525 DEBUG TRAIN Batch 20/6900 loss 14.714897 loss_att 14.175615 loss_ctc 17.301003 loss_rnnt 14.289449 hw_loss 0.353418 lr 0.00037939 rank 5
2023-02-22 14:48:03,333 DEBUG TRAIN Batch 20/7000 loss 7.244653 loss_att 10.997478 loss_ctc 13.500669 loss_rnnt 5.516014 hw_loss 0.269884 lr 0.00037925 rank 2
2023-02-22 14:48:03,334 DEBUG TRAIN Batch 20/7000 loss 16.600662 loss_att 16.070980 loss_ctc 19.693836 loss_rnnt 16.026987 hw_loss 0.500980 lr 0.00037919 rank 6
2023-02-22 14:48:03,338 DEBUG TRAIN Batch 20/7000 loss 7.134359 loss_att 7.692251 loss_ctc 11.072613 loss_rnnt 6.347723 hw_loss 0.281171 lr 0.00037919 rank 7
2023-02-22 14:48:03,339 DEBUG TRAIN Batch 20/7000 loss 7.902153 loss_att 10.159256 loss_ctc 8.689806 loss_rnnt 7.234492 hw_loss 0.208536 lr 0.00037921 rank 3
2023-02-22 14:48:03,340 DEBUG TRAIN Batch 20/7000 loss 11.913538 loss_att 13.525026 loss_ctc 16.186979 loss_rnnt 10.949957 hw_loss 0.134045 lr 0.00037926 rank 1
2023-02-22 14:48:03,341 DEBUG TRAIN Batch 20/7000 loss 5.489520 loss_att 7.643592 loss_ctc 6.422100 loss_rnnt 4.890526 hw_loss 0.082193 lr 0.00037931 rank 4
2023-02-22 14:48:03,342 DEBUG TRAIN Batch 20/7000 loss 6.630009 loss_att 9.223388 loss_ctc 10.777103 loss_rnnt 5.448498 hw_loss 0.206043 lr 0.00037931 rank 0
2023-02-22 14:48:03,342 DEBUG TRAIN Batch 20/7000 loss 7.639820 loss_att 10.894620 loss_ctc 11.442699 loss_rnnt 6.276739 hw_loss 0.384508 lr 0.00037928 rank 5
2023-02-22 14:49:18,128 DEBUG TRAIN Batch 20/7100 loss 9.982501 loss_att 12.561245 loss_ctc 14.128023 loss_rnnt 8.737618 hw_loss 0.330743 lr 0.00037916 rank 1
2023-02-22 14:49:18,129 DEBUG TRAIN Batch 20/7100 loss 19.155008 loss_att 20.948511 loss_ctc 25.239574 loss_rnnt 17.812523 hw_loss 0.323451 lr 0.00037917 rank 5
2023-02-22 14:49:18,129 DEBUG TRAIN Batch 20/7100 loss 13.894341 loss_att 13.390633 loss_ctc 16.827412 loss_rnnt 13.373253 hw_loss 0.432665 lr 0.00037911 rank 3
2023-02-22 14:49:18,131 DEBUG TRAIN Batch 20/7100 loss 5.747276 loss_att 11.581736 loss_ctc 12.159239 loss_rnnt 3.586133 hw_loss 0.261230 lr 0.00037920 rank 0
2023-02-22 14:49:18,131 DEBUG TRAIN Batch 20/7100 loss 12.021697 loss_att 12.049446 loss_ctc 15.839140 loss_rnnt 11.383403 hw_loss 0.232037 lr 0.00037908 rank 7
2023-02-22 14:49:18,138 DEBUG TRAIN Batch 20/7100 loss 5.791136 loss_att 9.098660 loss_ctc 9.432616 loss_rnnt 4.515686 hw_loss 0.240778 lr 0.00037908 rank 6
2023-02-22 14:49:18,154 DEBUG TRAIN Batch 20/7100 loss 8.854816 loss_att 12.311136 loss_ctc 10.931731 loss_rnnt 7.799789 hw_loss 0.162828 lr 0.00037914 rank 2
2023-02-22 14:49:18,155 DEBUG TRAIN Batch 20/7100 loss 11.277991 loss_att 14.172872 loss_ctc 15.258636 loss_rnnt 10.071043 hw_loss 0.182287 lr 0.00037920 rank 4
2023-02-22 14:50:30,504 DEBUG TRAIN Batch 20/7200 loss 7.530545 loss_att 12.528797 loss_ctc 11.594500 loss_rnnt 5.811583 hw_loss 0.332719 lr 0.00037903 rank 2
2023-02-22 14:50:30,507 DEBUG TRAIN Batch 20/7200 loss 21.104002 loss_att 23.979332 loss_ctc 27.686018 loss_rnnt 19.552031 hw_loss 0.186191 lr 0.00037900 rank 3
2023-02-22 14:50:30,509 DEBUG TRAIN Batch 20/7200 loss 8.847004 loss_att 11.908145 loss_ctc 10.374794 loss_rnnt 7.826559 hw_loss 0.383458 lr 0.00037905 rank 1
2023-02-22 14:50:30,509 DEBUG TRAIN Batch 20/7200 loss 11.825189 loss_att 15.000255 loss_ctc 15.793075 loss_rnnt 10.494244 hw_loss 0.312901 lr 0.00037909 rank 0
2023-02-22 14:50:30,510 DEBUG TRAIN Batch 20/7200 loss 14.195301 loss_att 18.017042 loss_ctc 15.120444 loss_rnnt 13.200605 hw_loss 0.200615 lr 0.00037909 rank 4
2023-02-22 14:50:30,513 DEBUG TRAIN Batch 20/7200 loss 6.093663 loss_att 8.509871 loss_ctc 7.019011 loss_rnnt 5.303850 hw_loss 0.343484 lr 0.00037897 rank 7
2023-02-22 14:50:30,514 DEBUG TRAIN Batch 20/7200 loss 6.505466 loss_att 9.692600 loss_ctc 11.427017 loss_rnnt 4.999373 hw_loss 0.398359 lr 0.00037897 rank 6
2023-02-22 14:50:30,517 DEBUG TRAIN Batch 20/7200 loss 8.468474 loss_att 12.982660 loss_ctc 14.984794 loss_rnnt 6.525116 hw_loss 0.321895 lr 0.00037906 rank 5
2023-02-22 14:51:43,422 DEBUG TRAIN Batch 20/7300 loss 4.909934 loss_att 7.227876 loss_ctc 6.942728 loss_rnnt 4.052267 hw_loss 0.230699 lr 0.00037898 rank 4
2023-02-22 14:51:43,423 DEBUG TRAIN Batch 20/7300 loss 5.364984 loss_att 7.684335 loss_ctc 10.058468 loss_rnnt 4.145638 hw_loss 0.243145 lr 0.00037889 rank 3
2023-02-22 14:51:43,424 DEBUG TRAIN Batch 20/7300 loss 13.650887 loss_att 17.695309 loss_ctc 20.959728 loss_rnnt 11.723211 hw_loss 0.270526 lr 0.00037898 rank 0
2023-02-22 14:51:43,425 DEBUG TRAIN Batch 20/7300 loss 6.052148 loss_att 8.615160 loss_ctc 8.458205 loss_rnnt 5.038016 hw_loss 0.338853 lr 0.00037887 rank 7
2023-02-22 14:51:43,430 DEBUG TRAIN Batch 20/7300 loss 8.951851 loss_att 13.402851 loss_ctc 12.368834 loss_rnnt 7.491236 hw_loss 0.215283 lr 0.00037892 rank 2
2023-02-22 14:51:43,432 DEBUG TRAIN Batch 20/7300 loss 4.654081 loss_att 9.614740 loss_ctc 9.751609 loss_rnnt 2.871464 hw_loss 0.207775 lr 0.00037895 rank 5
2023-02-22 14:51:43,433 DEBUG TRAIN Batch 20/7300 loss 11.618420 loss_att 10.980469 loss_ctc 17.661757 loss_rnnt 10.814548 hw_loss 0.235659 lr 0.00037886 rank 6
2023-02-22 14:51:43,437 DEBUG TRAIN Batch 20/7300 loss 8.517625 loss_att 12.606951 loss_ctc 12.953506 loss_rnnt 6.987457 hw_loss 0.226595 lr 0.00037894 rank 1
2023-02-22 14:52:56,773 DEBUG TRAIN Batch 20/7400 loss 7.101617 loss_att 11.582632 loss_ctc 14.638897 loss_rnnt 4.991538 hw_loss 0.391697 lr 0.00037876 rank 7
2023-02-22 14:52:56,779 DEBUG TRAIN Batch 20/7400 loss 8.707473 loss_att 9.475518 loss_ctc 12.652983 loss_rnnt 7.840270 hw_loss 0.351611 lr 0.00037881 rank 2
2023-02-22 14:52:56,781 DEBUG TRAIN Batch 20/7400 loss 5.238383 loss_att 7.114364 loss_ctc 12.517747 loss_rnnt 3.716140 hw_loss 0.330871 lr 0.00037888 rank 0
2023-02-22 14:52:56,784 DEBUG TRAIN Batch 20/7400 loss 6.974881 loss_att 10.005066 loss_ctc 11.010923 loss_rnnt 5.667585 hw_loss 0.305848 lr 0.00037888 rank 4
2023-02-22 14:52:56,786 DEBUG TRAIN Batch 20/7400 loss 16.707796 loss_att 15.692099 loss_ctc 20.646158 loss_rnnt 16.235563 hw_loss 0.281737 lr 0.00037883 rank 1
2023-02-22 14:52:56,791 DEBUG TRAIN Batch 20/7400 loss 7.396376 loss_att 10.839023 loss_ctc 13.652323 loss_rnnt 5.661810 hw_loss 0.397330 lr 0.00037884 rank 5
2023-02-22 14:52:56,806 DEBUG TRAIN Batch 20/7400 loss 5.972081 loss_att 7.979368 loss_ctc 7.248033 loss_rnnt 5.222683 hw_loss 0.333401 lr 0.00037876 rank 6
2023-02-22 14:52:56,811 DEBUG TRAIN Batch 20/7400 loss 8.367278 loss_att 11.788858 loss_ctc 11.515511 loss_rnnt 7.113654 hw_loss 0.280396 lr 0.00037878 rank 3
2023-02-22 14:54:11,203 DEBUG TRAIN Batch 20/7500 loss 11.135098 loss_att 13.572857 loss_ctc 13.621538 loss_rnnt 10.203160 hw_loss 0.211613 lr 0.00037870 rank 2
2023-02-22 14:54:11,206 DEBUG TRAIN Batch 20/7500 loss 9.401090 loss_att 12.498554 loss_ctc 13.460214 loss_rnnt 8.036538 hw_loss 0.382201 lr 0.00037867 rank 3
2023-02-22 14:54:11,210 DEBUG TRAIN Batch 20/7500 loss 6.197914 loss_att 8.907204 loss_ctc 9.392183 loss_rnnt 5.094381 hw_loss 0.254572 lr 0.00037873 rank 5
2023-02-22 14:54:11,211 DEBUG TRAIN Batch 20/7500 loss 5.426387 loss_att 7.583073 loss_ctc 7.553876 loss_rnnt 4.568978 hw_loss 0.267012 lr 0.00037877 rank 4
2023-02-22 14:54:11,214 DEBUG TRAIN Batch 20/7500 loss 12.943897 loss_att 15.188427 loss_ctc 18.521713 loss_rnnt 11.643373 hw_loss 0.202329 lr 0.00037865 rank 6
2023-02-22 14:54:11,216 DEBUG TRAIN Batch 20/7500 loss 17.391998 loss_att 19.400558 loss_ctc 24.691463 loss_rnnt 15.898028 hw_loss 0.223118 lr 0.00037877 rank 0
2023-02-22 14:54:11,234 DEBUG TRAIN Batch 20/7500 loss 8.435672 loss_att 11.437071 loss_ctc 10.688121 loss_rnnt 7.382080 hw_loss 0.286846 lr 0.00037872 rank 1
2023-02-22 14:54:11,285 DEBUG TRAIN Batch 20/7500 loss 5.497846 loss_att 8.235834 loss_ctc 6.876976 loss_rnnt 4.638574 hw_loss 0.239606 lr 0.00037865 rank 7
2023-02-22 14:55:23,326 DEBUG TRAIN Batch 20/7600 loss 6.945550 loss_att 7.813866 loss_ctc 9.355999 loss_rnnt 6.281956 hw_loss 0.316009 lr 0.00037859 rank 2
2023-02-22 14:55:23,332 DEBUG TRAIN Batch 20/7600 loss 4.447845 loss_att 6.526590 loss_ctc 5.698104 loss_rnnt 3.751418 hw_loss 0.213706 lr 0.00037856 rank 3
2023-02-22 14:55:23,334 DEBUG TRAIN Batch 20/7600 loss 10.499027 loss_att 13.313974 loss_ctc 16.550781 loss_rnnt 8.848514 hw_loss 0.526171 lr 0.00037854 rank 6
2023-02-22 14:55:23,335 DEBUG TRAIN Batch 20/7600 loss 5.110268 loss_att 8.282395 loss_ctc 5.873479 loss_rnnt 4.247203 hw_loss 0.237897 lr 0.00037866 rank 4
2023-02-22 14:55:23,335 DEBUG TRAIN Batch 20/7600 loss 6.275758 loss_att 9.025250 loss_ctc 7.239881 loss_rnnt 5.493875 hw_loss 0.193939 lr 0.00037861 rank 1
2023-02-22 14:55:23,336 DEBUG TRAIN Batch 20/7600 loss 7.805975 loss_att 7.946229 loss_ctc 10.393215 loss_rnnt 7.101578 hw_loss 0.621337 lr 0.00037863 rank 5
2023-02-22 14:55:23,342 DEBUG TRAIN Batch 20/7600 loss 10.622740 loss_att 10.297535 loss_ctc 14.509099 loss_rnnt 9.845898 hw_loss 0.606943 lr 0.00037866 rank 0
2023-02-22 14:55:23,382 DEBUG TRAIN Batch 20/7600 loss 11.049878 loss_att 13.579897 loss_ctc 15.765678 loss_rnnt 9.732244 hw_loss 0.342856 lr 0.00037854 rank 7
2023-02-22 14:56:35,278 DEBUG TRAIN Batch 20/7700 loss 11.496788 loss_att 10.764960 loss_ctc 12.749208 loss_rnnt 11.322902 hw_loss 0.287368 lr 0.00037848 rank 2
2023-02-22 14:56:35,279 DEBUG TRAIN Batch 20/7700 loss 9.203612 loss_att 11.339262 loss_ctc 13.963205 loss_rnnt 7.983602 hw_loss 0.296752 lr 0.00037845 rank 3
2023-02-22 14:56:35,282 DEBUG TRAIN Batch 20/7700 loss 17.612709 loss_att 18.414663 loss_ctc 26.343304 loss_rnnt 16.214178 hw_loss 0.138862 lr 0.00037850 rank 1
2023-02-22 14:56:35,283 DEBUG TRAIN Batch 20/7700 loss 16.497372 loss_att 16.364693 loss_ctc 21.510351 loss_rnnt 15.582938 hw_loss 0.511075 lr 0.00037852 rank 5
2023-02-22 14:56:35,283 DEBUG TRAIN Batch 20/7700 loss 19.036062 loss_att 22.835642 loss_ctc 27.749939 loss_rnnt 17.021040 hw_loss 0.174857 lr 0.00037855 rank 0
2023-02-22 14:56:35,284 DEBUG TRAIN Batch 20/7700 loss 5.231196 loss_att 4.907549 loss_ctc 6.425116 loss_rnnt 4.872638 hw_loss 0.495186 lr 0.00037843 rank 7
2023-02-22 14:56:35,285 DEBUG TRAIN Batch 20/7700 loss 3.601412 loss_att 7.158342 loss_ctc 4.320643 loss_rnnt 2.651425 hw_loss 0.267568 lr 0.00037855 rank 4
2023-02-22 14:56:35,287 DEBUG TRAIN Batch 20/7700 loss 12.348861 loss_att 16.213367 loss_ctc 13.673323 loss_rnnt 11.179868 hw_loss 0.411556 lr 0.00037843 rank 6
2023-02-22 14:57:49,004 DEBUG TRAIN Batch 20/7800 loss 10.792067 loss_att 14.262875 loss_ctc 17.476597 loss_rnnt 9.127991 hw_loss 0.147457 lr 0.00037838 rank 2
2023-02-22 14:57:49,010 DEBUG TRAIN Batch 20/7800 loss 7.869607 loss_att 11.296900 loss_ctc 10.969028 loss_rnnt 6.654541 hw_loss 0.218161 lr 0.00037832 rank 6
2023-02-22 14:57:49,011 DEBUG TRAIN Batch 20/7800 loss 15.709323 loss_att 15.129118 loss_ctc 17.488594 loss_rnnt 15.396101 hw_loss 0.360053 lr 0.00037835 rank 3
2023-02-22 14:57:49,017 DEBUG TRAIN Batch 20/7800 loss 10.266378 loss_att 12.332666 loss_ctc 11.933231 loss_rnnt 9.586402 hw_loss 0.083384 lr 0.00037844 rank 4
2023-02-22 14:57:49,018 DEBUG TRAIN Batch 20/7800 loss 10.121686 loss_att 13.051518 loss_ctc 11.761967 loss_rnnt 9.129004 hw_loss 0.352524 lr 0.00037840 rank 1
2023-02-22 14:57:49,027 DEBUG TRAIN Batch 20/7800 loss 7.078643 loss_att 11.047392 loss_ctc 11.438986 loss_rnnt 5.591963 hw_loss 0.209160 lr 0.00037832 rank 7
2023-02-22 14:57:49,059 DEBUG TRAIN Batch 20/7800 loss 7.857223 loss_att 10.969320 loss_ctc 11.061361 loss_rnnt 6.634998 hw_loss 0.323600 lr 0.00037841 rank 5
2023-02-22 14:57:49,064 DEBUG TRAIN Batch 20/7800 loss 10.216375 loss_att 17.102785 loss_ctc 24.247120 loss_rnnt 6.784451 hw_loss 0.344768 lr 0.00037844 rank 0
2023-02-22 14:59:03,176 DEBUG TRAIN Batch 20/7900 loss 13.503576 loss_att 17.528746 loss_ctc 19.083387 loss_rnnt 11.797346 hw_loss 0.294790 lr 0.00037827 rank 2
2023-02-22 14:59:03,182 DEBUG TRAIN Batch 20/7900 loss 7.703966 loss_att 10.940683 loss_ctc 12.877798 loss_rnnt 6.189519 hw_loss 0.332360 lr 0.00037824 rank 3
2023-02-22 14:59:03,184 DEBUG TRAIN Batch 20/7900 loss 12.871143 loss_att 14.626709 loss_ctc 14.984342 loss_rnnt 12.121435 hw_loss 0.219069 lr 0.00037829 rank 1
2023-02-22 14:59:03,186 DEBUG TRAIN Batch 20/7900 loss 9.733664 loss_att 13.527100 loss_ctc 15.935783 loss_rnnt 8.082097 hw_loss 0.123617 lr 0.00037833 rank 0
2023-02-22 14:59:03,186 DEBUG TRAIN Batch 20/7900 loss 13.642671 loss_att 14.252715 loss_ctc 18.039986 loss_rnnt 12.790258 hw_loss 0.270178 lr 0.00037822 rank 7
2023-02-22 14:59:03,190 DEBUG TRAIN Batch 20/7900 loss 6.039927 loss_att 10.342517 loss_ctc 10.718511 loss_rnnt 4.427067 hw_loss 0.240995 lr 0.00037833 rank 4
2023-02-22 14:59:03,191 DEBUG TRAIN Batch 20/7900 loss 11.639460 loss_att 13.560593 loss_ctc 15.745230 loss_rnnt 10.495281 hw_loss 0.398467 lr 0.00037821 rank 6
2023-02-22 14:59:03,237 DEBUG TRAIN Batch 20/7900 loss 6.109373 loss_att 8.029383 loss_ctc 7.858715 loss_rnnt 5.281460 hw_loss 0.394996 lr 0.00037830 rank 5
2023-02-22 15:00:15,028 DEBUG TRAIN Batch 20/8000 loss 11.752725 loss_att 16.902275 loss_ctc 16.787443 loss_rnnt 9.903778 hw_loss 0.277014 lr 0.00037816 rank 2
2023-02-22 15:00:15,030 DEBUG TRAIN Batch 20/8000 loss 6.303874 loss_att 9.094658 loss_ctc 11.925512 loss_rnnt 4.846651 hw_loss 0.280340 lr 0.00037813 rank 3
2023-02-22 15:00:15,031 DEBUG TRAIN Batch 20/8000 loss 3.417136 loss_att 4.855639 loss_ctc 3.947934 loss_rnnt 2.891171 hw_loss 0.314046 lr 0.00037822 rank 4
2023-02-22 15:00:15,032 DEBUG TRAIN Batch 20/8000 loss 13.697681 loss_att 13.527923 loss_ctc 17.496998 loss_rnnt 13.143054 hw_loss 0.153759 lr 0.00037818 rank 1
2023-02-22 15:00:15,035 DEBUG TRAIN Batch 20/8000 loss 6.955974 loss_att 10.190116 loss_ctc 9.258245 loss_rnnt 5.922065 hw_loss 0.150210 lr 0.00037822 rank 0
2023-02-22 15:00:15,037 DEBUG TRAIN Batch 20/8000 loss 4.789829 loss_att 9.000711 loss_ctc 8.135105 loss_rnnt 3.322584 hw_loss 0.335684 lr 0.00037810 rank 6
2023-02-22 15:00:15,045 DEBUG TRAIN Batch 20/8000 loss 13.364574 loss_att 15.880539 loss_ctc 21.388798 loss_rnnt 11.649057 hw_loss 0.267051 lr 0.00037819 rank 5
2023-02-22 15:00:15,082 DEBUG TRAIN Batch 20/8000 loss 9.837160 loss_att 13.807549 loss_ctc 11.988785 loss_rnnt 8.670061 hw_loss 0.161508 lr 0.00037811 rank 7
2023-02-22 15:01:27,390 DEBUG TRAIN Batch 20/8100 loss 17.189966 loss_att 17.584270 loss_ctc 27.430361 loss_rnnt 15.648005 hw_loss 0.183213 lr 0.00037800 rank 6
2023-02-22 15:01:27,398 DEBUG TRAIN Batch 20/8100 loss 12.379087 loss_att 16.261974 loss_ctc 22.474966 loss_rnnt 10.053514 hw_loss 0.380396 lr 0.00037802 rank 3
2023-02-22 15:01:27,403 DEBUG TRAIN Batch 20/8100 loss 11.102040 loss_att 14.462902 loss_ctc 15.445247 loss_rnnt 9.666940 hw_loss 0.344690 lr 0.00037807 rank 1
2023-02-22 15:01:27,403 DEBUG TRAIN Batch 20/8100 loss 8.706802 loss_att 11.790756 loss_ctc 14.460892 loss_rnnt 7.082561 hw_loss 0.450446 lr 0.00037805 rank 2
2023-02-22 15:01:27,404 DEBUG TRAIN Batch 20/8100 loss 7.363190 loss_att 9.271708 loss_ctc 13.143738 loss_rnnt 6.113978 hw_loss 0.181440 lr 0.00037812 rank 4
2023-02-22 15:01:27,409 DEBUG TRAIN Batch 20/8100 loss 13.079831 loss_att 16.596426 loss_ctc 18.218861 loss_rnnt 11.632450 hw_loss 0.110360 lr 0.00037812 rank 0
2023-02-22 15:01:27,410 DEBUG TRAIN Batch 20/8100 loss 3.815904 loss_att 7.334466 loss_ctc 6.385937 loss_rnnt 2.609040 hw_loss 0.300901 lr 0.00037800 rank 7
2023-02-22 15:01:27,454 DEBUG TRAIN Batch 20/8100 loss 10.872302 loss_att 13.147221 loss_ctc 14.509331 loss_rnnt 9.841286 hw_loss 0.170804 lr 0.00037808 rank 5
2023-02-22 15:02:40,512 DEBUG TRAIN Batch 20/8200 loss 11.356710 loss_att 14.557793 loss_ctc 17.623201 loss_rnnt 9.785176 hw_loss 0.179597 lr 0.00037791 rank 3
2023-02-22 15:02:40,513 DEBUG TRAIN Batch 20/8200 loss 11.900706 loss_att 13.687965 loss_ctc 13.190447 loss_rnnt 11.188711 hw_loss 0.342333 lr 0.00037794 rank 2
2023-02-22 15:02:40,515 DEBUG TRAIN Batch 20/8200 loss 8.647080 loss_att 11.770183 loss_ctc 10.845696 loss_rnnt 7.608936 hw_loss 0.225703 lr 0.00037789 rank 6
2023-02-22 15:02:40,517 DEBUG TRAIN Batch 20/8200 loss 11.183073 loss_att 13.810139 loss_ctc 12.764624 loss_rnnt 10.304337 hw_loss 0.267093 lr 0.00037796 rank 1
2023-02-22 15:02:40,519 DEBUG TRAIN Batch 20/8200 loss 7.782855 loss_att 11.210359 loss_ctc 11.770001 loss_rnnt 6.355695 hw_loss 0.393824 lr 0.00037789 rank 7
2023-02-22 15:02:40,519 DEBUG TRAIN Batch 20/8200 loss 13.288396 loss_att 13.599794 loss_ctc 14.829350 loss_rnnt 12.696859 hw_loss 0.607119 lr 0.00037801 rank 0
2023-02-22 15:02:40,519 DEBUG TRAIN Batch 20/8200 loss 8.057515 loss_att 9.107412 loss_ctc 10.964175 loss_rnnt 7.220990 hw_loss 0.448108 lr 0.00037801 rank 4
2023-02-22 15:02:40,519 DEBUG TRAIN Batch 20/8200 loss 15.717301 loss_att 16.621706 loss_ctc 22.004883 loss_rnnt 14.517490 hw_loss 0.338599 lr 0.00037798 rank 5
2023-02-22 15:03:53,115 DEBUG TRAIN Batch 20/8300 loss 11.986352 loss_att 9.112181 loss_ctc 12.914641 loss_rnnt 12.206842 hw_loss 0.432321 lr 0.00037784 rank 2
2023-02-22 15:03:53,121 DEBUG TRAIN Batch 20/8300 loss 5.735147 loss_att 8.447611 loss_ctc 8.246042 loss_rnnt 4.651469 hw_loss 0.386998 lr 0.00037778 rank 7
2023-02-22 15:03:53,122 DEBUG TRAIN Batch 20/8300 loss 16.607117 loss_att 18.956591 loss_ctc 21.617712 loss_rnnt 15.351805 hw_loss 0.220008 lr 0.00037785 rank 1
2023-02-22 15:03:53,125 DEBUG TRAIN Batch 20/8300 loss 9.462819 loss_att 11.283045 loss_ctc 11.982361 loss_rnnt 8.623797 hw_loss 0.260696 lr 0.00037790 rank 4
2023-02-22 15:03:53,125 DEBUG TRAIN Batch 20/8300 loss 4.721404 loss_att 8.881164 loss_ctc 6.686134 loss_rnnt 3.507099 hw_loss 0.225730 lr 0.00037790 rank 0
2023-02-22 15:03:53,125 DEBUG TRAIN Batch 20/8300 loss 7.924022 loss_att 10.411496 loss_ctc 11.458076 loss_rnnt 6.800463 hw_loss 0.290357 lr 0.00037787 rank 5
2023-02-22 15:03:53,127 DEBUG TRAIN Batch 20/8300 loss 5.597915 loss_att 6.745174 loss_ctc 8.446644 loss_rnnt 4.873558 hw_loss 0.215765 lr 0.00037778 rank 6
2023-02-22 15:04:52,998 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 6
2023-02-22 15:04:53,001 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 7
2023-02-22 15:04:53,002 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 4
2023-02-22 15:04:53,003 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 1
2023-02-22 15:04:53,004 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 5
2023-02-22 15:04:53,012 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 2
2023-02-22 15:04:53,019 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 3
2023-02-22 15:04:53,021 DEBUG CV Batch 20/0 loss 2.001704 loss_att 2.250857 loss_ctc 3.010186 loss_rnnt 1.450172 hw_loss 0.688570 history loss 1.927567 rank 0
2023-02-22 15:05:04,309 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 2
2023-02-22 15:05:04,394 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 3
2023-02-22 15:05:04,477 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 6
2023-02-22 15:05:04,544 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 5
2023-02-22 15:05:04,585 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 0
2023-02-22 15:05:04,638 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 7
2023-02-22 15:05:04,717 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 4
2023-02-22 15:05:04,965 DEBUG CV Batch 20/100 loss 7.244346 loss_att 8.079043 loss_ctc 11.341563 loss_rnnt 6.298495 hw_loss 0.436153 history loss 3.587651 rank 1
2023-02-22 15:05:17,700 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 2
2023-02-22 15:05:17,817 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 3
2023-02-22 15:05:17,950 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 6
2023-02-22 15:05:18,200 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 5
2023-02-22 15:05:18,284 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 0
2023-02-22 15:05:18,382 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 4
2023-02-22 15:05:18,411 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 7
2023-02-22 15:05:19,039 DEBUG CV Batch 20/200 loss 7.191874 loss_att 14.570580 loss_ctc 7.835175 loss_rnnt 5.519610 hw_loss 0.207655 history loss 4.196539 rank 1
2023-02-22 15:05:29,988 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 2
2023-02-22 15:05:30,036 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 3
2023-02-22 15:05:30,298 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 6
2023-02-22 15:05:30,592 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 7
2023-02-22 15:05:30,646 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 4
2023-02-22 15:05:30,657 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 5
2023-02-22 15:05:30,681 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 0
2023-02-22 15:05:31,719 DEBUG CV Batch 20/300 loss 5.230462 loss_att 5.837288 loss_ctc 7.422488 loss_rnnt 4.628490 hw_loss 0.353130 history loss 4.365728 rank 1
2023-02-22 15:05:42,076 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 2
2023-02-22 15:05:42,106 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 3
2023-02-22 15:05:42,414 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 6
2023-02-22 15:05:42,963 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 4
2023-02-22 15:05:43,001 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 7
2023-02-22 15:05:43,043 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 5
2023-02-22 15:05:43,315 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 0
2023-02-22 15:05:44,527 DEBUG CV Batch 20/400 loss 13.478511 loss_att 74.855103 loss_ctc 4.918080 loss_rnnt 2.266404 hw_loss 0.146586 history loss 5.357998 rank 1
2023-02-22 15:05:52,711 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 3
2023-02-22 15:05:52,735 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 2
2023-02-22 15:05:53,157 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 6
2023-02-22 15:05:53,798 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 4
2023-02-22 15:05:53,846 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 7
2023-02-22 15:05:54,024 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 5
2023-02-22 15:05:54,459 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 0
2023-02-22 15:05:55,746 DEBUG CV Batch 20/500 loss 6.619473 loss_att 6.529882 loss_ctc 7.517235 loss_rnnt 6.398794 hw_loss 0.222930 history loss 6.154522 rank 1
2023-02-22 15:06:04,839 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 3
2023-02-22 15:06:04,868 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 2
2023-02-22 15:06:05,324 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 6
2023-02-22 15:06:06,070 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 7
2023-02-22 15:06:06,246 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 4
2023-02-22 15:06:06,446 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 5
2023-02-22 15:06:07,130 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 0
2023-02-22 15:06:08,729 DEBUG CV Batch 20/600 loss 8.694242 loss_att 8.097651 loss_ctc 10.894259 loss_rnnt 8.170051 hw_loss 0.656579 history loss 7.148580 rank 1
2023-02-22 15:06:16,279 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 3
2023-02-22 15:06:16,309 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 2
2023-02-22 15:06:16,874 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 6
2023-02-22 15:06:17,694 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 7
2023-02-22 15:06:17,874 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 4
2023-02-22 15:06:18,099 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 5
2023-02-22 15:06:18,934 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 0
2023-02-22 15:06:20,799 DEBUG CV Batch 20/700 loss 17.955912 loss_att 42.156975 loss_ctc 19.775928 loss_rnnt 12.831893 hw_loss 0.077135 history loss 7.827292 rank 1
2023-02-22 15:06:27,721 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 3
2023-02-22 15:06:27,793 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 2
2023-02-22 15:06:28,319 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 6
2023-02-22 15:06:29,230 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 7
2023-02-22 15:06:29,452 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 4
2023-02-22 15:06:29,706 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 5
2023-02-22 15:06:30,632 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 0
2023-02-22 15:06:32,958 DEBUG CV Batch 20/800 loss 11.712342 loss_att 12.038681 loss_ctc 18.770802 loss_rnnt 10.495214 hw_loss 0.395122 history loss 7.255798 rank 1
2023-02-22 15:06:41,158 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 3
2023-02-22 15:06:41,203 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 2
2023-02-22 15:06:41,726 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 6
2023-02-22 15:06:42,738 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 7
2023-02-22 15:06:42,861 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 4
2023-02-22 15:06:43,162 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 5
2023-02-22 15:06:44,331 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 0
2023-02-22 15:06:46,733 DEBUG CV Batch 20/900 loss 17.356874 loss_att 18.273663 loss_ctc 30.418310 loss_rnnt 15.299094 hw_loss 0.249184 history loss 7.043442 rank 1
2023-02-22 15:06:53,466 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 3
2023-02-22 15:06:53,512 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 2
2023-02-22 15:06:54,037 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 6
2023-02-22 15:06:55,387 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 7
2023-02-22 15:06:55,587 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 4
2023-02-22 15:06:55,617 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 5
2023-02-22 15:06:57,197 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 0
2023-02-22 15:06:59,392 DEBUG CV Batch 20/1000 loss 5.437195 loss_att 5.875571 loss_ctc 6.863948 loss_rnnt 4.977055 hw_loss 0.341683 history loss 6.805330 rank 1
2023-02-22 15:07:05,520 DEBUG CV Batch 20/1100 loss 6.252310 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 3
2023-02-22 15:07:05,654 DEBUG CV Batch 20/1100 loss 6.252310 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 2
2023-02-22 15:07:06,085 DEBUG CV Batch 20/1100 loss 6.252310 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 6
2023-02-22 15:07:07,727 DEBUG CV Batch 20/1100 loss 6.252310 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 5
2023-02-22 15:07:07,903 DEBUG CV Batch 20/1100 loss 6.252309 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 7
2023-02-22 15:07:07,917 DEBUG CV Batch 20/1100 loss 6.252310 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 4
2023-02-22 15:07:09,584 DEBUG CV Batch 20/1100 loss 6.252310 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 0
2023-02-22 15:07:11,700 DEBUG CV Batch 20/1100 loss 6.252310 loss_att 5.774030 loss_ctc 8.218334 loss_rnnt 5.754968 hw_loss 0.620363 history loss 6.778124 rank 1
2023-02-22 15:07:16,350 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 3
2023-02-22 15:07:16,511 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 2
2023-02-22 15:07:16,909 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 6
2023-02-22 15:07:18,730 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 4
2023-02-22 15:07:18,866 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 7
2023-02-22 15:07:18,931 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 5
2023-02-22 15:07:20,841 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 0
2023-02-22 15:07:22,903 DEBUG CV Batch 20/1200 loss 8.357438 loss_att 8.516029 loss_ctc 9.470665 loss_rnnt 8.016524 hw_loss 0.301436 history loss 7.122092 rank 1
2023-02-22 15:07:28,477 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 3
2023-02-22 15:07:28,629 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 2
2023-02-22 15:07:29,021 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 6
2023-02-22 15:07:30,866 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 4
2023-02-22 15:07:31,249 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 5
2023-02-22 15:07:31,373 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 7
2023-02-22 15:07:33,777 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 0
2023-02-22 15:07:35,590 DEBUG CV Batch 20/1300 loss 6.299490 loss_att 6.120224 loss_ctc 8.255794 loss_rnnt 5.838377 hw_loss 0.442739 history loss 7.457727 rank 1
2023-02-22 15:07:39,778 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 3
2023-02-22 15:07:39,980 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 2
2023-02-22 15:07:40,471 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 6
2023-02-22 15:07:42,299 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 4
2023-02-22 15:07:42,885 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 5
2023-02-22 15:07:42,944 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 7
2023-02-22 15:07:45,640 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 0
2023-02-22 15:07:47,234 DEBUG CV Batch 20/1400 loss 7.868581 loss_att 17.018818 loss_ctc 8.018882 loss_rnnt 5.885974 hw_loss 0.248476 history loss 7.787877 rank 1
2023-02-22 15:07:51,434 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 3
2023-02-22 15:07:51,637 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 2
2023-02-22 15:07:52,085 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 6
2023-02-22 15:07:54,129 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 4
2023-02-22 15:07:54,810 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 5
2023-02-22 15:07:54,987 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 7
2023-02-22 15:07:57,762 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 0
2023-02-22 15:07:59,185 DEBUG CV Batch 20/1500 loss 6.298501 loss_att 7.194479 loss_ctc 6.450407 loss_rnnt 5.971251 hw_loss 0.239626 history loss 7.607857 rank 1
2023-02-22 15:08:04,547 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 3
2023-02-22 15:08:04,817 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 2
2023-02-22 15:08:05,229 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 6
2023-02-22 15:08:07,282 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 4
2023-02-22 15:08:08,302 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 7
2023-02-22 15:08:08,687 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 5
2023-02-22 15:08:11,324 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 0
2023-02-22 15:08:12,504 DEBUG CV Batch 20/1600 loss 8.373350 loss_att 13.524553 loss_ctc 10.809223 loss_rnnt 6.893075 hw_loss 0.234846 history loss 7.534781 rank 1
2023-02-22 15:08:17,018 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 3
2023-02-22 15:08:17,261 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 2
2023-02-22 15:08:17,663 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 6
2023-02-22 15:08:19,758 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 4
2023-02-22 15:08:20,961 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 7
2023-02-22 15:08:21,199 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 5
2023-02-22 15:08:24,157 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 0
2023-02-22 15:08:25,001 DEBUG CV Batch 20/1700 loss 9.869716 loss_att 9.364574 loss_ctc 15.894435 loss_rnnt 8.977310 hw_loss 0.356510 history loss 7.437941 rank 1
2023-02-22 15:08:26,142 INFO Epoch 20 CV info cv_loss 7.4048703315178255
2023-02-22 15:08:26,142 INFO Epoch 21 TRAIN info lr 0.00037781014210090213
2023-02-22 15:08:26,147 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:08:26,432 INFO Epoch 20 CV info cv_loss 7.404870332443899
2023-02-22 15:08:26,432 INFO Epoch 21 TRAIN info lr 0.0003777702411034562
2023-02-22 15:08:26,437 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:08:26,787 INFO Epoch 20 CV info cv_loss 7.4048703341539035
2023-02-22 15:08:26,787 INFO Epoch 21 TRAIN info lr 0.00037776053736681374
2023-02-22 15:08:26,792 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:08:28,900 INFO Epoch 20 CV info cv_loss 7.404870334102215
2023-02-22 15:08:28,901 INFO Epoch 21 TRAIN info lr 0.0003778414246955036
2023-02-22 15:08:28,907 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:08:30,051 INFO Epoch 20 CV info cv_loss 7.404870332344831
2023-02-22 15:08:30,052 INFO Epoch 21 TRAIN info lr 0.0003777476002144212
2023-02-22 15:08:30,054 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:08:30,196 INFO Epoch 20 CV info cv_loss 7.404870333348435
2023-02-22 15:08:30,196 INFO Epoch 21 TRAIN info lr 0.0003778112206817189
2023-02-22 15:08:30,198 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:08:33,436 INFO Epoch 20 CV info cv_loss 7.404870330027494
2023-02-22 15:08:33,436 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/20.pt
2023-02-22 15:08:34,058 INFO Epoch 21 TRAIN info lr 0.00037784034585598643
2023-02-22 15:08:34,061 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:08:34,507 INFO Epoch 20 CV info cv_loss 7.404870333964381
2023-02-22 15:08:34,507 INFO Epoch 21 TRAIN info lr 0.00037777347584851747
2023-02-22 15:08:34,510 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 15:09:36,166 DEBUG TRAIN Batch 21/0 loss 10.535889 loss_att 9.332172 loss_ctc 12.802756 loss_rnnt 10.131028 hw_loss 0.643790 lr 0.00037777 rank 2
2023-02-22 15:09:36,169 DEBUG TRAIN Batch 21/0 loss 7.487242 loss_att 6.559810 loss_ctc 8.986937 loss_rnnt 7.139329 hw_loss 0.625200 lr 0.00037777 rank 1
2023-02-22 15:09:36,170 DEBUG TRAIN Batch 21/0 loss 9.113261 loss_att 8.804170 loss_ctc 11.908370 loss_rnnt 8.478214 hw_loss 0.607847 lr 0.00037775 rank 7
2023-02-22 15:09:36,174 DEBUG TRAIN Batch 21/0 loss 8.570141 loss_att 8.201570 loss_ctc 10.493496 loss_rnnt 7.999161 hw_loss 0.727962 lr 0.00037781 rank 5
2023-02-22 15:09:36,184 DEBUG TRAIN Batch 21/0 loss 15.687533 loss_att 14.440817 loss_ctc 19.226404 loss_rnnt 15.155606 hw_loss 0.580162 lr 0.00037784 rank 4
2023-02-22 15:09:36,185 DEBUG TRAIN Batch 21/0 loss 8.950359 loss_att 7.815188 loss_ctc 11.103382 loss_rnnt 8.545133 hw_loss 0.647233 lr 0.00037781 rank 3
2023-02-22 15:09:36,188 DEBUG TRAIN Batch 21/0 loss 6.770606 loss_att 6.542986 loss_ctc 9.764756 loss_rnnt 6.126547 hw_loss 0.544428 lr 0.00037776 rank 6
2023-02-22 15:09:36,218 DEBUG TRAIN Batch 21/0 loss 7.622859 loss_att 7.595711 loss_ctc 9.613006 loss_rnnt 7.016748 hw_loss 0.649102 lr 0.00037784 rank 0
2023-02-22 15:10:47,723 DEBUG TRAIN Batch 21/100 loss 3.050748 loss_att 5.989609 loss_ctc 6.257032 loss_rnnt 1.964318 hw_loss 0.133413 lr 0.00037766 rank 2
2023-02-22 15:10:47,724 DEBUG TRAIN Batch 21/100 loss 7.675556 loss_att 9.338446 loss_ctc 10.819492 loss_rnnt 6.795375 hw_loss 0.240773 lr 0.00037773 rank 4
2023-02-22 15:10:47,724 DEBUG TRAIN Batch 21/100 loss 4.071639 loss_att 5.937098 loss_ctc 7.611365 loss_rnnt 3.077898 hw_loss 0.278784 lr 0.00037766 rank 1
2023-02-22 15:10:47,725 DEBUG TRAIN Batch 21/100 loss 4.850690 loss_att 8.539637 loss_ctc 7.011092 loss_rnnt 3.619880 hw_loss 0.384311 lr 0.00037764 rank 7
2023-02-22 15:10:47,725 DEBUG TRAIN Batch 21/100 loss 9.584374 loss_att 10.004276 loss_ctc 8.664898 loss_rnnt 9.467886 hw_loss 0.290819 lr 0.00037773 rank 0
2023-02-22 15:10:47,729 DEBUG TRAIN Batch 21/100 loss 7.546996 loss_att 10.114632 loss_ctc 10.929487 loss_rnnt 6.433185 hw_loss 0.279909 lr 0.00037765 rank 6
2023-02-22 15:10:47,730 DEBUG TRAIN Batch 21/100 loss 7.455672 loss_att 9.134732 loss_ctc 8.804661 loss_rnnt 6.658418 hw_loss 0.527957 lr 0.00037770 rank 3
2023-02-22 15:10:47,739 DEBUG TRAIN Batch 21/100 loss 5.104730 loss_att 7.439966 loss_ctc 7.447288 loss_rnnt 4.257720 hw_loss 0.126792 lr 0.00037770 rank 5
2023-02-22 15:11:59,385 DEBUG TRAIN Batch 21/200 loss 7.557762 loss_att 11.204509 loss_ctc 8.458857 loss_rnnt 6.585211 hw_loss 0.230730 lr 0.00037762 rank 4
2023-02-22 15:11:59,385 DEBUG TRAIN Batch 21/200 loss 6.885919 loss_att 9.456581 loss_ctc 8.827015 loss_rnnt 5.933147 hw_loss 0.337175 lr 0.00037755 rank 2
2023-02-22 15:11:59,388 DEBUG TRAIN Batch 21/200 loss 8.427642 loss_att 12.657971 loss_ctc 14.226324 loss_rnnt 6.764146 hw_loss 0.083011 lr 0.00037754 rank 6
2023-02-22 15:11:59,387 DEBUG TRAIN Batch 21/200 loss 6.791962 loss_att 9.274810 loss_ctc 11.598002 loss_rnnt 5.432111 hw_loss 0.417142 lr 0.00037759 rank 3
2023-02-22 15:11:59,388 DEBUG TRAIN Batch 21/200 loss 5.857897 loss_att 8.562295 loss_ctc 5.540030 loss_rnnt 5.147044 hw_loss 0.398167 lr 0.00037762 rank 0
2023-02-22 15:11:59,393 DEBUG TRAIN Batch 21/200 loss 1.927383 loss_att 6.315555 loss_ctc 2.405080 loss_rnnt 0.926222 hw_loss 0.112188 lr 0.00037753 rank 7
2023-02-22 15:11:59,424 DEBUG TRAIN Batch 21/200 loss 7.585238 loss_att 11.457710 loss_ctc 9.755499 loss_rnnt 6.396563 hw_loss 0.234026 lr 0.00037759 rank 5
2023-02-22 15:11:59,430 DEBUG TRAIN Batch 21/200 loss 16.302729 loss_att 16.447498 loss_ctc 25.794462 loss_rnnt 14.793180 hw_loss 0.403181 lr 0.00037756 rank 1
2023-02-22 15:13:12,543 DEBUG TRAIN Batch 21/300 loss 5.145368 loss_att 7.118300 loss_ctc 5.346369 loss_rnnt 4.525184 hw_loss 0.372746 lr 0.00037745 rank 2
2023-02-22 15:13:12,546 DEBUG TRAIN Batch 21/300 loss 13.344121 loss_att 19.173714 loss_ctc 22.565205 loss_rnnt 10.851553 hw_loss 0.182197 lr 0.00037749 rank 5
2023-02-22 15:13:12,546 DEBUG TRAIN Batch 21/300 loss 7.079303 loss_att 11.016331 loss_ctc 11.128816 loss_rnnt 5.614483 hw_loss 0.257773 lr 0.00037752 rank 0
2023-02-22 15:13:12,547 DEBUG TRAIN Batch 21/300 loss 10.636336 loss_att 13.359595 loss_ctc 17.706047 loss_rnnt 8.924968 hw_loss 0.420166 lr 0.00037744 rank 6
2023-02-22 15:13:12,548 DEBUG TRAIN Batch 21/300 loss 5.872593 loss_att 6.602662 loss_ctc 9.509296 loss_rnnt 5.107107 hw_loss 0.252337 lr 0.00037749 rank 3
2023-02-22 15:13:12,553 DEBUG TRAIN Batch 21/300 loss 8.435897 loss_att 11.103739 loss_ctc 10.414567 loss_rnnt 7.489361 hw_loss 0.279647 lr 0.00037745 rank 1
2023-02-22 15:13:12,556 DEBUG TRAIN Batch 21/300 loss 14.018050 loss_att 17.002869 loss_ctc 18.535479 loss_rnnt 12.657588 hw_loss 0.302202 lr 0.00037752 rank 4
2023-02-22 15:13:12,594 DEBUG TRAIN Batch 21/300 loss 5.813476 loss_att 7.535228 loss_ctc 6.795099 loss_rnnt 5.152540 hw_loss 0.348191 lr 0.00037742 rank 7
2023-02-22 15:14:25,862 DEBUG TRAIN Batch 21/400 loss 11.849295 loss_att 14.362049 loss_ctc 20.208752 loss_rnnt 10.110929 hw_loss 0.227289 lr 0.00037734 rank 2
2023-02-22 15:14:25,867 DEBUG TRAIN Batch 21/400 loss 5.688330 loss_att 6.626247 loss_ctc 7.023973 loss_rnnt 5.140356 hw_loss 0.341822 lr 0.00037733 rank 6
2023-02-22 15:14:25,867 DEBUG TRAIN Batch 21/400 loss 8.389152 loss_att 10.926323 loss_ctc 13.552940 loss_rnnt 7.067211 hw_loss 0.236251 lr 0.00037741 rank 0
2023-02-22 15:14:25,870 DEBUG TRAIN Batch 21/400 loss 13.394327 loss_att 15.616322 loss_ctc 21.414865 loss_rnnt 11.722483 hw_loss 0.296322 lr 0.00037738 rank 3
2023-02-22 15:14:25,872 DEBUG TRAIN Batch 21/400 loss 2.539955 loss_att 4.968069 loss_ctc 2.912643 loss_rnnt 1.834364 hw_loss 0.319268 lr 0.00037738 rank 5
2023-02-22 15:14:25,873 DEBUG TRAIN Batch 21/400 loss 14.369285 loss_att 21.685341 loss_ctc 19.295227 loss_rnnt 12.105925 hw_loss 0.268796 lr 0.00037741 rank 4
2023-02-22 15:14:25,873 DEBUG TRAIN Batch 21/400 loss 5.714693 loss_att 9.340711 loss_ctc 10.510385 loss_rnnt 4.226431 hw_loss 0.231811 lr 0.00037732 rank 7
2023-02-22 15:14:25,925 DEBUG TRAIN Batch 21/400 loss 7.601175 loss_att 9.908768 loss_ctc 12.606525 loss_rnnt 6.365998 hw_loss 0.199270 lr 0.00037734 rank 1
2023-02-22 15:15:38,005 DEBUG TRAIN Batch 21/500 loss 21.332994 loss_att 23.619749 loss_ctc 30.866917 loss_rnnt 19.489475 hw_loss 0.215581 lr 0.00037727 rank 3
2023-02-22 15:15:38,007 DEBUG TRAIN Batch 21/500 loss 17.854712 loss_att 19.675526 loss_ctc 22.421013 loss_rnnt 16.779846 hw_loss 0.190991 lr 0.00037730 rank 4
2023-02-22 15:15:38,008 DEBUG TRAIN Batch 21/500 loss 1.662095 loss_att 4.741406 loss_ctc 2.131395 loss_rnnt 0.815323 hw_loss 0.315632 lr 0.00037723 rank 2
2023-02-22 15:15:38,013 DEBUG TRAIN Batch 21/500 loss 6.256102 loss_att 9.030516 loss_ctc 8.633134 loss_rnnt 5.247709 hw_loss 0.256074 lr 0.00037723 rank 1
2023-02-22 15:15:38,014 DEBUG TRAIN Batch 21/500 loss 11.444597 loss_att 13.106972 loss_ctc 17.953636 loss_rnnt 10.059742 hw_loss 0.345955 lr 0.00037722 rank 6
2023-02-22 15:15:38,013 DEBUG TRAIN Batch 21/500 loss 5.932136 loss_att 11.278274 loss_ctc 8.640388 loss_rnnt 4.328410 hw_loss 0.325120 lr 0.00037721 rank 7
2023-02-22 15:15:38,019 DEBUG TRAIN Batch 21/500 loss 13.439508 loss_att 16.404964 loss_ctc 18.028435 loss_rnnt 12.092465 hw_loss 0.266428 lr 0.00037730 rank 0
2023-02-22 15:15:38,060 DEBUG TRAIN Batch 21/500 loss 10.157186 loss_att 11.772774 loss_ctc 13.273723 loss_rnnt 9.327138 hw_loss 0.171359 lr 0.00037727 rank 5
2023-02-22 15:16:50,155 DEBUG TRAIN Batch 21/600 loss 12.041095 loss_att 11.760506 loss_ctc 15.053411 loss_rnnt 11.446219 hw_loss 0.467532 lr 0.00037711 rank 6
2023-02-22 15:16:50,156 DEBUG TRAIN Batch 21/600 loss 10.757627 loss_att 10.391695 loss_ctc 15.661243 loss_rnnt 9.970348 hw_loss 0.387470 lr 0.00037719 rank 4
2023-02-22 15:16:50,157 DEBUG TRAIN Batch 21/600 loss 14.955454 loss_att 14.426323 loss_ctc 17.923492 loss_rnnt 14.377117 hw_loss 0.540796 lr 0.00037712 rank 2
2023-02-22 15:16:50,159 DEBUG TRAIN Batch 21/600 loss 9.574173 loss_att 13.581114 loss_ctc 17.081013 loss_rnnt 7.533267 hw_loss 0.447389 lr 0.00037716 rank 5
2023-02-22 15:16:50,160 DEBUG TRAIN Batch 21/600 loss 8.908931 loss_att 10.058029 loss_ctc 11.035950 loss_rnnt 8.212060 hw_loss 0.343966 lr 0.00037716 rank 3
2023-02-22 15:16:50,164 DEBUG TRAIN Batch 21/600 loss 11.425535 loss_att 11.694860 loss_ctc 13.301433 loss_rnnt 10.905986 hw_loss 0.404186 lr 0.00037713 rank 1
2023-02-22 15:16:50,165 DEBUG TRAIN Batch 21/600 loss 6.550066 loss_att 8.434142 loss_ctc 10.078122 loss_rnnt 5.516941 hw_loss 0.348567 lr 0.00037710 rank 7
2023-02-22 15:16:50,165 DEBUG TRAIN Batch 21/600 loss 9.562572 loss_att 9.933271 loss_ctc 16.615257 loss_rnnt 8.399206 hw_loss 0.279128 lr 0.00037719 rank 0
2023-02-22 15:18:05,107 DEBUG TRAIN Batch 21/700 loss 5.014348 loss_att 7.020446 loss_ctc 4.818358 loss_rnnt 4.554635 hw_loss 0.158671 lr 0.00037709 rank 4
2023-02-22 15:18:05,111 DEBUG TRAIN Batch 21/700 loss 8.393265 loss_att 12.885707 loss_ctc 8.621894 loss_rnnt 7.354770 hw_loss 0.205355 lr 0.00037702 rank 2
2023-02-22 15:18:05,115 DEBUG TRAIN Batch 21/700 loss 6.772974 loss_att 10.585630 loss_ctc 8.584625 loss_rnnt 5.660246 hw_loss 0.203707 lr 0.00037706 rank 5
2023-02-22 15:18:05,118 DEBUG TRAIN Batch 21/700 loss 4.815875 loss_att 9.118718 loss_ctc 8.722872 loss_rnnt 3.165436 hw_loss 0.504257 lr 0.00037701 rank 6
2023-02-22 15:18:05,117 DEBUG TRAIN Batch 21/700 loss 9.372968 loss_att 15.352358 loss_ctc 12.281841 loss_rnnt 7.700052 hw_loss 0.167227 lr 0.00037702 rank 1
2023-02-22 15:18:05,117 DEBUG TRAIN Batch 21/700 loss 5.037209 loss_att 9.804853 loss_ctc 8.751493 loss_rnnt 3.421739 hw_loss 0.312569 lr 0.00037699 rank 7
2023-02-22 15:18:05,119 DEBUG TRAIN Batch 21/700 loss 12.740351 loss_att 20.057856 loss_ctc 17.063213 loss_rnnt 10.622772 hw_loss 0.145678 lr 0.00037706 rank 3
2023-02-22 15:18:05,167 DEBUG TRAIN Batch 21/700 loss 14.379549 loss_att 17.367764 loss_ctc 19.451252 loss_rnnt 12.949890 hw_loss 0.292103 lr 0.00037709 rank 0
2023-02-22 15:19:18,022 DEBUG TRAIN Batch 21/800 loss 7.034101 loss_att 10.654177 loss_ctc 7.888595 loss_rnnt 6.071113 hw_loss 0.234450 lr 0.00037691 rank 2
2023-02-22 15:19:18,026 DEBUG TRAIN Batch 21/800 loss 6.455246 loss_att 7.581829 loss_ctc 10.212236 loss_rnnt 5.644800 hw_loss 0.157872 lr 0.00037689 rank 7
2023-02-22 15:19:18,028 DEBUG TRAIN Batch 21/800 loss 2.226791 loss_att 5.421339 loss_ctc 3.406913 loss_rnnt 1.284767 hw_loss 0.273308 lr 0.00037698 rank 0
2023-02-22 15:19:18,027 DEBUG TRAIN Batch 21/800 loss 11.606503 loss_att 18.687466 loss_ctc 15.584308 loss_rnnt 9.545634 hw_loss 0.214319 lr 0.00037695 rank 5
2023-02-22 15:19:18,028 DEBUG TRAIN Batch 21/800 loss 6.682109 loss_att 7.275652 loss_ctc 5.947712 loss_rnnt 6.435831 hw_loss 0.422791 lr 0.00037690 rank 6
2023-02-22 15:19:18,029 DEBUG TRAIN Batch 21/800 loss 13.771176 loss_att 17.924099 loss_ctc 22.469290 loss_rnnt 11.661423 hw_loss 0.223912 lr 0.00037695 rank 3
2023-02-22 15:19:18,033 DEBUG TRAIN Batch 21/800 loss 19.637516 loss_att 28.825214 loss_ctc 27.547699 loss_rnnt 16.664021 hw_loss 0.152370 lr 0.00037698 rank 4
2023-02-22 15:19:18,083 DEBUG TRAIN Batch 21/800 loss 2.520238 loss_att 6.284299 loss_ctc 4.203942 loss_rnnt 1.409245 hw_loss 0.250663 lr 0.00037691 rank 1
2023-02-22 15:20:30,769 DEBUG TRAIN Batch 21/900 loss 11.315024 loss_att 14.960060 loss_ctc 16.317310 loss_rnnt 9.774735 hw_loss 0.270581 lr 0.00037680 rank 2
2023-02-22 15:20:30,774 DEBUG TRAIN Batch 21/900 loss 17.103481 loss_att 18.268864 loss_ctc 23.645050 loss_rnnt 15.919378 hw_loss 0.147782 lr 0.00037687 rank 4
2023-02-22 15:20:30,775 DEBUG TRAIN Batch 21/900 loss 2.491735 loss_att 5.985098 loss_ctc 2.959423 loss_rnnt 1.571810 hw_loss 0.297928 lr 0.00037684 rank 3
2023-02-22 15:20:30,777 DEBUG TRAIN Batch 21/900 loss 8.292032 loss_att 10.939068 loss_ctc 15.224420 loss_rnnt 6.635629 hw_loss 0.380020 lr 0.00037679 rank 6
2023-02-22 15:20:30,778 DEBUG TRAIN Batch 21/900 loss 15.314658 loss_att 17.781956 loss_ctc 17.522581 loss_rnnt 14.335258 hw_loss 0.359156 lr 0.00037687 rank 0
2023-02-22 15:20:30,777 DEBUG TRAIN Batch 21/900 loss 7.922344 loss_att 11.855909 loss_ctc 10.703815 loss_rnnt 6.652225 hw_loss 0.211016 lr 0.00037684 rank 5
2023-02-22 15:20:30,779 DEBUG TRAIN Batch 21/900 loss 5.065381 loss_att 9.218868 loss_ctc 6.882031 loss_rnnt 3.851386 hw_loss 0.264521 lr 0.00037681 rank 1
2023-02-22 15:20:30,825 DEBUG TRAIN Batch 21/900 loss 12.998123 loss_att 11.843642 loss_ctc 14.876633 loss_rnnt 12.889486 hw_loss 0.166998 lr 0.00037678 rank 7
2023-02-22 15:21:44,331 DEBUG TRAIN Batch 21/1000 loss 9.989905 loss_att 11.174997 loss_ctc 15.461178 loss_rnnt 8.878946 hw_loss 0.270820 lr 0.00037669 rank 6
2023-02-22 15:21:44,335 DEBUG TRAIN Batch 21/1000 loss 17.334314 loss_att 20.825628 loss_ctc 19.767689 loss_rnnt 16.184355 hw_loss 0.238592 lr 0.00037667 rank 7
2023-02-22 15:21:44,344 DEBUG TRAIN Batch 21/1000 loss 9.530499 loss_att 11.184308 loss_ctc 10.050265 loss_rnnt 8.987756 hw_loss 0.267519 lr 0.00037674 rank 5
2023-02-22 15:21:44,344 DEBUG TRAIN Batch 21/1000 loss 7.518158 loss_att 11.513164 loss_ctc 14.280058 loss_rnnt 5.735409 hw_loss 0.154054 lr 0.00037670 rank 2
2023-02-22 15:21:44,347 DEBUG TRAIN Batch 21/1000 loss 10.340394 loss_att 12.660843 loss_ctc 15.873607 loss_rnnt 9.012789 hw_loss 0.235789 lr 0.00037677 rank 4
2023-02-22 15:21:44,348 DEBUG TRAIN Batch 21/1000 loss 13.137563 loss_att 15.618288 loss_ctc 18.564434 loss_rnnt 11.702072 hw_loss 0.404555 lr 0.00037677 rank 0
2023-02-22 15:21:44,350 DEBUG TRAIN Batch 21/1000 loss 7.023709 loss_att 10.500002 loss_ctc 7.538988 loss_rnnt 6.137012 hw_loss 0.230126 lr 0.00037674 rank 3
2023-02-22 15:21:44,394 DEBUG TRAIN Batch 21/1000 loss 9.348048 loss_att 11.191976 loss_ctc 11.664761 loss_rnnt 8.483847 hw_loss 0.349726 lr 0.00037670 rank 1
2023-02-22 15:22:58,761 DEBUG TRAIN Batch 21/1100 loss 4.952381 loss_att 9.364890 loss_ctc 7.961266 loss_rnnt 3.542705 hw_loss 0.236230 lr 0.00037659 rank 2
2023-02-22 15:22:58,762 DEBUG TRAIN Batch 21/1100 loss 3.023102 loss_att 6.025286 loss_ctc 4.426714 loss_rnnt 2.073033 hw_loss 0.304658 lr 0.00037663 rank 3
2023-02-22 15:22:58,770 DEBUG TRAIN Batch 21/1100 loss 7.537784 loss_att 9.915504 loss_ctc 10.249828 loss_rnnt 6.531332 hw_loss 0.317440 lr 0.00037659 rank 1
2023-02-22 15:22:58,771 DEBUG TRAIN Batch 21/1100 loss 5.247003 loss_att 7.233547 loss_ctc 8.909925 loss_rnnt 4.205727 hw_loss 0.291706 lr 0.00037657 rank 7
2023-02-22 15:22:58,773 DEBUG TRAIN Batch 21/1100 loss 5.491690 loss_att 8.840539 loss_ctc 9.321424 loss_rnnt 4.139692 hw_loss 0.321746 lr 0.00037666 rank 4
2023-02-22 15:22:58,774 DEBUG TRAIN Batch 21/1100 loss 4.197218 loss_att 7.738854 loss_ctc 7.549599 loss_rnnt 2.814071 hw_loss 0.427191 lr 0.00037658 rank 6
2023-02-22 15:22:58,776 DEBUG TRAIN Batch 21/1100 loss 12.314737 loss_att 14.111156 loss_ctc 19.790882 loss_rnnt 10.856329 hw_loss 0.191826 lr 0.00037663 rank 5
2023-02-22 15:22:58,778 DEBUG TRAIN Batch 21/1100 loss 5.997955 loss_att 7.880598 loss_ctc 9.408730 loss_rnnt 5.115355 hw_loss 0.096191 lr 0.00037666 rank 0
2023-02-22 15:24:11,750 DEBUG TRAIN Batch 21/1200 loss 7.425162 loss_att 7.942723 loss_ctc 8.870424 loss_rnnt 6.879360 hw_loss 0.467977 lr 0.00037648 rank 2
2023-02-22 15:24:11,753 DEBUG TRAIN Batch 21/1200 loss 3.061002 loss_att 5.348231 loss_ctc 5.213880 loss_rnnt 2.186822 hw_loss 0.243157 lr 0.00037646 rank 7
2023-02-22 15:24:11,757 DEBUG TRAIN Batch 21/1200 loss 21.407906 loss_att 21.192636 loss_ctc 31.477575 loss_rnnt 20.021646 hw_loss 0.162537 lr 0.00037655 rank 4
2023-02-22 15:24:11,757 DEBUG TRAIN Batch 21/1200 loss 8.693398 loss_att 10.306147 loss_ctc 13.970874 loss_rnnt 7.529562 hw_loss 0.258045 lr 0.00037652 rank 3
2023-02-22 15:24:11,757 DEBUG TRAIN Batch 21/1200 loss 12.467884 loss_att 13.435509 loss_ctc 17.467115 loss_rnnt 11.447769 hw_loss 0.300048 lr 0.00037649 rank 1
2023-02-22 15:24:11,760 DEBUG TRAIN Batch 21/1200 loss 14.124091 loss_att 14.202706 loss_ctc 17.912270 loss_rnnt 13.408199 hw_loss 0.365769 lr 0.00037647 rank 6
2023-02-22 15:24:11,763 DEBUG TRAIN Batch 21/1200 loss 10.372887 loss_att 12.024538 loss_ctc 17.943893 loss_rnnt 8.888618 hw_loss 0.270881 lr 0.00037652 rank 5
2023-02-22 15:24:11,803 DEBUG TRAIN Batch 21/1200 loss 10.801085 loss_att 12.098794 loss_ctc 14.157519 loss_rnnt 9.893064 hw_loss 0.376788 lr 0.00037655 rank 0
2023-02-22 15:25:25,240 DEBUG TRAIN Batch 21/1300 loss 12.236149 loss_att 12.181365 loss_ctc 19.585640 loss_rnnt 11.103255 hw_loss 0.307347 lr 0.00037638 rank 2
2023-02-22 15:25:25,241 DEBUG TRAIN Batch 21/1300 loss 7.473726 loss_att 9.309893 loss_ctc 11.234846 loss_rnnt 6.508187 hw_loss 0.181542 lr 0.00037642 rank 5
2023-02-22 15:25:25,243 DEBUG TRAIN Batch 21/1300 loss 6.665374 loss_att 11.405134 loss_ctc 10.126780 loss_rnnt 5.102767 hw_loss 0.287125 lr 0.00037644 rank 0
2023-02-22 15:25:25,243 DEBUG TRAIN Batch 21/1300 loss 2.465052 loss_att 6.988204 loss_ctc 3.123907 loss_rnnt 1.347407 hw_loss 0.234690 lr 0.00037641 rank 3
2023-02-22 15:25:25,247 DEBUG TRAIN Batch 21/1300 loss 9.009974 loss_att 13.175446 loss_ctc 13.154087 loss_rnnt 7.457874 hw_loss 0.312107 lr 0.00037637 rank 6
2023-02-22 15:25:25,249 DEBUG TRAIN Batch 21/1300 loss 8.505147 loss_att 9.506042 loss_ctc 11.560925 loss_rnnt 7.662419 hw_loss 0.440834 lr 0.00037638 rank 1
2023-02-22 15:25:25,253 DEBUG TRAIN Batch 21/1300 loss 5.443800 loss_att 7.927623 loss_ctc 9.636147 loss_rnnt 4.287498 hw_loss 0.188548 lr 0.00037635 rank 7
2023-02-22 15:25:25,301 DEBUG TRAIN Batch 21/1300 loss 10.514173 loss_att 15.322901 loss_ctc 15.452154 loss_rnnt 8.773089 hw_loss 0.226761 lr 0.00037645 rank 4
2023-02-22 15:26:40,205 DEBUG TRAIN Batch 21/1400 loss 8.422324 loss_att 10.627276 loss_ctc 9.117044 loss_rnnt 7.721536 hw_loss 0.313439 lr 0.00037626 rank 6
2023-02-22 15:26:40,207 DEBUG TRAIN Batch 21/1400 loss 9.210803 loss_att 10.707660 loss_ctc 10.980826 loss_rnnt 8.546326 hw_loss 0.242069 lr 0.00037631 rank 5
2023-02-22 15:26:40,209 DEBUG TRAIN Batch 21/1400 loss 16.556631 loss_att 17.619625 loss_ctc 19.046001 loss_rnnt 15.972549 hw_loss 0.074186 lr 0.00037634 rank 0
2023-02-22 15:26:40,209 DEBUG TRAIN Batch 21/1400 loss 13.369342 loss_att 15.223234 loss_ctc 23.881224 loss_rnnt 11.457148 hw_loss 0.262182 lr 0.00037631 rank 3
2023-02-22 15:26:40,211 DEBUG TRAIN Batch 21/1400 loss 2.297342 loss_att 5.207331 loss_ctc 3.910009 loss_rnnt 1.371261 hw_loss 0.241989 lr 0.00037627 rank 2
2023-02-22 15:26:40,213 DEBUG TRAIN Batch 21/1400 loss 7.410053 loss_att 8.980130 loss_ctc 8.245560 loss_rnnt 6.840453 hw_loss 0.270345 lr 0.00037634 rank 4
2023-02-22 15:26:40,214 DEBUG TRAIN Batch 21/1400 loss 6.003675 loss_att 10.958054 loss_ctc 9.465282 loss_rnnt 4.445360 hw_loss 0.198547 lr 0.00037625 rank 7
2023-02-22 15:26:40,248 DEBUG TRAIN Batch 21/1400 loss 6.787686 loss_att 8.679087 loss_ctc 7.000002 loss_rnnt 6.198028 hw_loss 0.343255 lr 0.00037627 rank 1
2023-02-22 15:27:53,677 DEBUG TRAIN Batch 21/1500 loss 15.536476 loss_att 16.343870 loss_ctc 22.100063 loss_rnnt 14.350928 hw_loss 0.279230 lr 0.00037623 rank 4
2023-02-22 15:27:53,677 DEBUG TRAIN Batch 21/1500 loss 18.109716 loss_att 18.582075 loss_ctc 25.458324 loss_rnnt 16.879887 hw_loss 0.291644 lr 0.00037616 rank 2
2023-02-22 15:27:53,678 DEBUG TRAIN Batch 21/1500 loss 4.385314 loss_att 7.963048 loss_ctc 7.658859 loss_rnnt 3.124878 hw_loss 0.203281 lr 0.00037615 rank 6
2023-02-22 15:27:53,680 DEBUG TRAIN Batch 21/1500 loss 13.867944 loss_att 15.471733 loss_ctc 19.738024 loss_rnnt 12.608940 hw_loss 0.291690 lr 0.00037620 rank 3
2023-02-22 15:27:53,683 DEBUG TRAIN Batch 21/1500 loss 8.274796 loss_att 14.471146 loss_ctc 8.409376 loss_rnnt 6.874843 hw_loss 0.267637 lr 0.00037620 rank 5
2023-02-22 15:27:53,685 DEBUG TRAIN Batch 21/1500 loss 8.181857 loss_att 10.895519 loss_ctc 12.465095 loss_rnnt 6.964481 hw_loss 0.194148 lr 0.00037617 rank 1
2023-02-22 15:27:53,686 DEBUG TRAIN Batch 21/1500 loss 4.077657 loss_att 6.624332 loss_ctc 5.296596 loss_rnnt 3.293177 hw_loss 0.211161 lr 0.00037623 rank 0
2023-02-22 15:27:53,729 DEBUG TRAIN Batch 21/1500 loss 9.393730 loss_att 12.502337 loss_ctc 16.425205 loss_rnnt 7.793931 hw_loss 0.076027 lr 0.00037614 rank 7
2023-02-22 15:29:05,571 DEBUG TRAIN Batch 21/1600 loss 9.831598 loss_att 12.567476 loss_ctc 13.180645 loss_rnnt 8.719339 hw_loss 0.222268 lr 0.00037610 rank 3
2023-02-22 15:29:05,572 DEBUG TRAIN Batch 21/1600 loss 8.677869 loss_att 10.019030 loss_ctc 10.708858 loss_rnnt 8.027210 hw_loss 0.209303 lr 0.00037606 rank 2
2023-02-22 15:29:05,577 DEBUG TRAIN Batch 21/1600 loss 11.238911 loss_att 13.569176 loss_ctc 18.446766 loss_rnnt 9.667224 hw_loss 0.271099 lr 0.00037605 rank 6
2023-02-22 15:29:05,579 DEBUG TRAIN Batch 21/1600 loss 14.346398 loss_att 18.623013 loss_ctc 17.793486 loss_rnnt 12.939041 hw_loss 0.173292 lr 0.00037613 rank 4
2023-02-22 15:29:05,578 DEBUG TRAIN Batch 21/1600 loss 3.508807 loss_att 6.330731 loss_ctc 4.556353 loss_rnnt 2.668678 hw_loss 0.255133 lr 0.00037610 rank 5
2023-02-22 15:29:05,582 DEBUG TRAIN Batch 21/1600 loss 9.432413 loss_att 13.433479 loss_ctc 12.983017 loss_rnnt 8.054932 hw_loss 0.194726 lr 0.00037612 rank 0
2023-02-22 15:29:05,582 DEBUG TRAIN Batch 21/1600 loss 6.601724 loss_att 7.924421 loss_ctc 8.941471 loss_rnnt 5.872220 hw_loss 0.286871 lr 0.00037603 rank 7
2023-02-22 15:29:05,588 DEBUG TRAIN Batch 21/1600 loss 5.815973 loss_att 8.569178 loss_ctc 8.043749 loss_rnnt 4.882151 hw_loss 0.161520 lr 0.00037606 rank 1
2023-02-22 15:30:18,444 DEBUG TRAIN Batch 21/1700 loss 8.952792 loss_att 11.689785 loss_ctc 11.615287 loss_rnnt 7.899281 hw_loss 0.283339 lr 0.00037599 rank 3
2023-02-22 15:30:18,445 DEBUG TRAIN Batch 21/1700 loss 6.071951 loss_att 10.621136 loss_ctc 8.910624 loss_rnnt 4.628577 hw_loss 0.290713 lr 0.00037595 rank 2
2023-02-22 15:30:18,446 DEBUG TRAIN Batch 21/1700 loss 10.052313 loss_att 11.212585 loss_ctc 11.040884 loss_rnnt 9.409909 hw_loss 0.522262 lr 0.00037599 rank 5
2023-02-22 15:30:18,447 DEBUG TRAIN Batch 21/1700 loss 4.566951 loss_att 6.860918 loss_ctc 6.019067 loss_rnnt 3.733099 hw_loss 0.340205 lr 0.00037594 rank 6
2023-02-22 15:30:18,448 DEBUG TRAIN Batch 21/1700 loss 19.335796 loss_att 21.516703 loss_ctc 24.090593 loss_rnnt 18.141842 hw_loss 0.232129 lr 0.00037595 rank 1
2023-02-22 15:30:18,466 DEBUG TRAIN Batch 21/1700 loss 10.021350 loss_att 14.260767 loss_ctc 14.504517 loss_rnnt 8.455450 hw_loss 0.225488 lr 0.00037593 rank 7
2023-02-22 15:30:18,471 DEBUG TRAIN Batch 21/1700 loss 10.678492 loss_att 14.075404 loss_ctc 21.924747 loss_rnnt 8.395191 hw_loss 0.195779 lr 0.00037602 rank 4
2023-02-22 15:30:18,475 DEBUG TRAIN Batch 21/1700 loss 10.945894 loss_att 11.882008 loss_ctc 12.294784 loss_rnnt 10.364075 hw_loss 0.402647 lr 0.00037602 rank 0
2023-02-22 15:31:34,117 DEBUG TRAIN Batch 21/1800 loss 6.691561 loss_att 7.810679 loss_ctc 9.477112 loss_rnnt 5.879183 hw_loss 0.407154 lr 0.00037584 rank 2
2023-02-22 15:31:34,123 DEBUG TRAIN Batch 21/1800 loss 14.308125 loss_att 17.461580 loss_ctc 19.003725 loss_rnnt 12.926455 hw_loss 0.234187 lr 0.00037582 rank 7
2023-02-22 15:31:34,125 DEBUG TRAIN Batch 21/1800 loss 4.745042 loss_att 8.267925 loss_ctc 7.831508 loss_rnnt 3.497905 hw_loss 0.245684 lr 0.00037588 rank 3
2023-02-22 15:31:34,128 DEBUG TRAIN Batch 21/1800 loss 9.270860 loss_att 12.679296 loss_ctc 17.777021 loss_rnnt 7.317241 hw_loss 0.258331 lr 0.00037585 rank 1
2023-02-22 15:31:34,135 DEBUG TRAIN Batch 21/1800 loss 9.385767 loss_att 11.317736 loss_ctc 13.251264 loss_rnnt 8.352263 hw_loss 0.246956 lr 0.00037588 rank 5
2023-02-22 15:31:34,136 DEBUG TRAIN Batch 21/1800 loss 2.861112 loss_att 5.159822 loss_ctc 5.742453 loss_rnnt 1.791539 hw_loss 0.423098 lr 0.00037591 rank 0
2023-02-22 15:31:34,139 DEBUG TRAIN Batch 21/1800 loss 6.886341 loss_att 8.380730 loss_ctc 9.334766 loss_rnnt 6.133575 hw_loss 0.238932 lr 0.00037583 rank 6
2023-02-22 15:31:34,179 DEBUG TRAIN Batch 21/1800 loss 5.337014 loss_att 7.858527 loss_ctc 9.143345 loss_rnnt 4.206850 hw_loss 0.221910 lr 0.00037591 rank 4
2023-02-22 15:32:47,638 DEBUG TRAIN Batch 21/1900 loss 9.547430 loss_att 12.213880 loss_ctc 14.587521 loss_rnnt 8.091820 hw_loss 0.469328 lr 0.00037581 rank 4
2023-02-22 15:32:47,649 DEBUG TRAIN Batch 21/1900 loss 7.409700 loss_att 9.779237 loss_ctc 11.650546 loss_rnnt 6.112824 hw_loss 0.482853 lr 0.00037581 rank 0
2023-02-22 15:32:47,651 DEBUG TRAIN Batch 21/1900 loss 12.014242 loss_att 13.296802 loss_ctc 14.001614 loss_rnnt 11.300860 hw_loss 0.359788 lr 0.00037578 rank 3
2023-02-22 15:32:47,654 DEBUG TRAIN Batch 21/1900 loss 5.915116 loss_att 9.021160 loss_ctc 9.460998 loss_rnnt 4.716102 hw_loss 0.196914 lr 0.00037574 rank 1
2023-02-22 15:32:47,655 DEBUG TRAIN Batch 21/1900 loss 7.180221 loss_att 9.965816 loss_ctc 10.597519 loss_rnnt 6.087840 hw_loss 0.149292 lr 0.00037578 rank 5
2023-02-22 15:32:47,656 DEBUG TRAIN Batch 21/1900 loss 7.451932 loss_att 8.956919 loss_ctc 7.877637 loss_rnnt 6.955102 hw_loss 0.260760 lr 0.00037574 rank 2
2023-02-22 15:32:47,658 DEBUG TRAIN Batch 21/1900 loss 5.774158 loss_att 9.232036 loss_ctc 5.218421 loss_rnnt 5.039742 hw_loss 0.219260 lr 0.00037573 rank 6
2023-02-22 15:32:47,659 DEBUG TRAIN Batch 21/1900 loss 8.902123 loss_att 12.801384 loss_ctc 11.281558 loss_rnnt 7.690681 hw_loss 0.214374 lr 0.00037571 rank 7
2023-02-22 15:33:59,514 DEBUG TRAIN Batch 21/2000 loss 20.442518 loss_att 19.911554 loss_ctc 32.296234 loss_rnnt 18.884750 hw_loss 0.156499 lr 0.00037562 rank 6
2023-02-22 15:33:59,514 DEBUG TRAIN Batch 21/2000 loss 17.448086 loss_att 20.947052 loss_ctc 24.859053 loss_rnnt 15.592169 hw_loss 0.314987 lr 0.00037567 rank 3
2023-02-22 15:33:59,516 DEBUG TRAIN Batch 21/2000 loss 1.498559 loss_att 4.465737 loss_ctc 2.555062 loss_rnnt 0.539510 hw_loss 0.421399 lr 0.00037563 rank 2
2023-02-22 15:33:59,521 DEBUG TRAIN Batch 21/2000 loss 6.389444 loss_att 10.035155 loss_ctc 11.920131 loss_rnnt 4.813224 hw_loss 0.205598 lr 0.00037570 rank 4
2023-02-22 15:33:59,521 DEBUG TRAIN Batch 21/2000 loss 4.226957 loss_att 10.163105 loss_ctc 6.858365 loss_rnnt 2.542616 hw_loss 0.274233 lr 0.00037567 rank 5
2023-02-22 15:33:59,526 DEBUG TRAIN Batch 21/2000 loss 7.843844 loss_att 11.775344 loss_ctc 10.982407 loss_rnnt 6.564210 hw_loss 0.140361 lr 0.00037570 rank 0
2023-02-22 15:33:59,528 DEBUG TRAIN Batch 21/2000 loss 11.430125 loss_att 13.001682 loss_ctc 17.873051 loss_rnnt 10.032395 hw_loss 0.420678 lr 0.00037563 rank 1
2023-02-22 15:33:59,572 DEBUG TRAIN Batch 21/2000 loss 16.366179 loss_att 18.426203 loss_ctc 23.556156 loss_rnnt 14.873289 hw_loss 0.229163 lr 0.00037561 rank 7
2023-02-22 15:35:14,175 DEBUG TRAIN Batch 21/2100 loss 5.975393 loss_att 8.455135 loss_ctc 8.356009 loss_rnnt 5.002798 hw_loss 0.298559 lr 0.00037550 rank 7
2023-02-22 15:35:14,180 DEBUG TRAIN Batch 21/2100 loss 5.203929 loss_att 9.809742 loss_ctc 7.457050 loss_rnnt 3.882072 hw_loss 0.188023 lr 0.00037557 rank 5
2023-02-22 15:35:14,181 DEBUG TRAIN Batch 21/2100 loss 10.053531 loss_att 11.979385 loss_ctc 14.773190 loss_rnnt 8.921535 hw_loss 0.220382 lr 0.00037553 rank 2
2023-02-22 15:35:14,189 DEBUG TRAIN Batch 21/2100 loss 12.533235 loss_att 13.652969 loss_ctc 13.163923 loss_rnnt 12.117801 hw_loss 0.201366 lr 0.00037556 rank 3
2023-02-22 15:35:14,195 DEBUG TRAIN Batch 21/2100 loss 9.354882 loss_att 10.197840 loss_ctc 13.106293 loss_rnnt 8.523017 hw_loss 0.305786 lr 0.00037559 rank 4
2023-02-22 15:35:14,195 DEBUG TRAIN Batch 21/2100 loss 7.826175 loss_att 13.733613 loss_ctc 8.780733 loss_rnnt 6.429537 hw_loss 0.164767 lr 0.00037552 rank 6
2023-02-22 15:35:14,197 DEBUG TRAIN Batch 21/2100 loss 11.598929 loss_att 14.955632 loss_ctc 17.649954 loss_rnnt 9.975020 hw_loss 0.273308 lr 0.00037559 rank 0
2023-02-22 15:35:14,197 DEBUG TRAIN Batch 21/2100 loss 3.470978 loss_att 6.756602 loss_ctc 8.846001 loss_rnnt 1.952545 hw_loss 0.271197 lr 0.00037553 rank 1
2023-02-22 15:36:28,009 DEBUG TRAIN Batch 21/2200 loss 7.893979 loss_att 14.412627 loss_ctc 14.504219 loss_rnnt 5.510739 hw_loss 0.371519 lr 0.00037541 rank 6
2023-02-22 15:36:28,009 DEBUG TRAIN Batch 21/2200 loss 7.873773 loss_att 12.988013 loss_ctc 15.780375 loss_rnnt 5.631815 hw_loss 0.309179 lr 0.00037546 rank 3
2023-02-22 15:36:28,010 DEBUG TRAIN Batch 21/2200 loss 15.072272 loss_att 17.462933 loss_ctc 19.887527 loss_rnnt 13.839983 hw_loss 0.210231 lr 0.00037540 rank 7
2023-02-22 15:36:28,011 DEBUG TRAIN Batch 21/2200 loss 5.789703 loss_att 8.502363 loss_ctc 6.790232 loss_rnnt 4.996881 hw_loss 0.219161 lr 0.00037542 rank 2
2023-02-22 15:36:28,012 DEBUG TRAIN Batch 21/2200 loss 4.481584 loss_att 6.329418 loss_ctc 6.033823 loss_rnnt 3.716746 hw_loss 0.353072 lr 0.00037549 rank 4
2023-02-22 15:36:28,017 DEBUG TRAIN Batch 21/2200 loss 13.412280 loss_att 15.939015 loss_ctc 15.080467 loss_rnnt 12.589355 hw_loss 0.178410 lr 0.00037542 rank 1
2023-02-22 15:36:28,018 DEBUG TRAIN Batch 21/2200 loss 10.218668 loss_att 15.252831 loss_ctc 13.213005 loss_rnnt 8.635653 hw_loss 0.331757 lr 0.00037546 rank 5
2023-02-22 15:36:28,074 DEBUG TRAIN Batch 21/2200 loss 8.021446 loss_att 11.332867 loss_ctc 14.239336 loss_rnnt 6.414865 hw_loss 0.216084 lr 0.00037549 rank 0
2023-02-22 15:37:39,597 DEBUG TRAIN Batch 21/2300 loss 8.381127 loss_att 11.260567 loss_ctc 13.867512 loss_rnnt 6.974779 hw_loss 0.185518 lr 0.00037531 rank 2
2023-02-22 15:37:39,600 DEBUG TRAIN Batch 21/2300 loss 6.072731 loss_att 8.685044 loss_ctc 9.524408 loss_rnnt 5.027682 hw_loss 0.116929 lr 0.00037532 rank 1
2023-02-22 15:37:39,602 DEBUG TRAIN Batch 21/2300 loss 7.677420 loss_att 8.046727 loss_ctc 10.722551 loss_rnnt 7.094930 hw_loss 0.192395 lr 0.00037535 rank 5
2023-02-22 15:37:39,602 DEBUG TRAIN Batch 21/2300 loss 9.119468 loss_att 11.963940 loss_ctc 13.085058 loss_rnnt 7.885422 hw_loss 0.255760 lr 0.00037529 rank 7
2023-02-22 15:37:39,602 DEBUG TRAIN Batch 21/2300 loss 12.330616 loss_att 15.961164 loss_ctc 18.338005 loss_rnnt 10.687796 hw_loss 0.216987 lr 0.00037535 rank 3
2023-02-22 15:37:39,604 DEBUG TRAIN Batch 21/2300 loss 6.390995 loss_att 10.240563 loss_ctc 10.576807 loss_rnnt 4.933769 hw_loss 0.242259 lr 0.00037530 rank 6
2023-02-22 15:37:39,606 DEBUG TRAIN Batch 21/2300 loss 5.367868 loss_att 8.593409 loss_ctc 8.896965 loss_rnnt 4.137984 hw_loss 0.214181 lr 0.00037538 rank 4
2023-02-22 15:37:39,608 DEBUG TRAIN Batch 21/2300 loss 6.323329 loss_att 9.524452 loss_ctc 11.655761 loss_rnnt 4.857797 hw_loss 0.214344 lr 0.00037538 rank 0
2023-02-22 15:38:52,766 DEBUG TRAIN Batch 21/2400 loss 12.610857 loss_att 15.020598 loss_ctc 16.265003 loss_rnnt 11.475841 hw_loss 0.310966 lr 0.00037525 rank 5
2023-02-22 15:38:52,773 DEBUG TRAIN Batch 21/2400 loss 6.589388 loss_att 9.228014 loss_ctc 11.016819 loss_rnnt 5.260493 hw_loss 0.395336 lr 0.00037521 rank 2
2023-02-22 15:38:52,781 DEBUG TRAIN Batch 21/2400 loss 6.746280 loss_att 10.505169 loss_ctc 11.380588 loss_rnnt 5.210608 hw_loss 0.311223 lr 0.00037525 rank 3
2023-02-22 15:38:52,781 DEBUG TRAIN Batch 21/2400 loss 2.379853 loss_att 4.560969 loss_ctc 3.004634 loss_rnnt 1.750008 hw_loss 0.206847 lr 0.00037521 rank 1
2023-02-22 15:38:52,785 DEBUG TRAIN Batch 21/2400 loss 10.058840 loss_att 11.791653 loss_ctc 14.272519 loss_rnnt 9.045558 hw_loss 0.196680 lr 0.00037520 rank 6
2023-02-22 15:38:52,785 DEBUG TRAIN Batch 21/2400 loss 8.784780 loss_att 10.879299 loss_ctc 10.367076 loss_rnnt 7.917140 hw_loss 0.445805 lr 0.00037519 rank 7
2023-02-22 15:38:52,789 DEBUG TRAIN Batch 21/2400 loss 7.010251 loss_att 8.212850 loss_ctc 11.869134 loss_rnnt 5.957542 hw_loss 0.308132 lr 0.00037528 rank 4
2023-02-22 15:38:52,814 DEBUG TRAIN Batch 21/2400 loss 8.784462 loss_att 11.771112 loss_ctc 11.420401 loss_rnnt 7.643162 hw_loss 0.360958 lr 0.00037528 rank 0
2023-02-22 15:40:08,599 DEBUG TRAIN Batch 21/2500 loss 23.414387 loss_att 25.370367 loss_ctc 29.293526 loss_rnnt 22.084356 hw_loss 0.290533 lr 0.00037509 rank 6
2023-02-22 15:40:08,599 DEBUG TRAIN Batch 21/2500 loss 6.967964 loss_att 9.301060 loss_ctc 10.450115 loss_rnnt 5.887671 hw_loss 0.280101 lr 0.00037510 rank 2
2023-02-22 15:40:08,602 DEBUG TRAIN Batch 21/2500 loss 3.060923 loss_att 8.415462 loss_ctc 4.310942 loss_rnnt 1.641545 hw_loss 0.340878 lr 0.00037508 rank 7
2023-02-22 15:40:08,604 DEBUG TRAIN Batch 21/2500 loss 10.496834 loss_att 13.762678 loss_ctc 14.211039 loss_rnnt 9.181527 hw_loss 0.312957 lr 0.00037511 rank 1
2023-02-22 15:40:08,605 DEBUG TRAIN Batch 21/2500 loss 6.500439 loss_att 9.382087 loss_ctc 11.357836 loss_rnnt 5.158953 hw_loss 0.220320 lr 0.00037517 rank 4
2023-02-22 15:40:08,605 DEBUG TRAIN Batch 21/2500 loss 9.786990 loss_att 12.379339 loss_ctc 15.201014 loss_rnnt 8.336535 hw_loss 0.393965 lr 0.00037514 rank 3
2023-02-22 15:40:08,607 DEBUG TRAIN Batch 21/2500 loss 7.679341 loss_att 8.470200 loss_ctc 11.681621 loss_rnnt 6.889889 hw_loss 0.183082 lr 0.00037514 rank 5
2023-02-22 15:40:08,654 DEBUG TRAIN Batch 21/2500 loss 6.320551 loss_att 7.850573 loss_ctc 6.579517 loss_rnnt 5.736296 hw_loss 0.456976 lr 0.00037517 rank 0
2023-02-22 15:41:20,954 DEBUG TRAIN Batch 21/2600 loss 8.173831 loss_att 14.227521 loss_ctc 10.451297 loss_rnnt 6.554096 hw_loss 0.197502 lr 0.00037499 rank 6
2023-02-22 15:41:20,956 DEBUG TRAIN Batch 21/2600 loss 15.590201 loss_att 18.241560 loss_ctc 19.891495 loss_rnnt 14.370823 hw_loss 0.216753 lr 0.00037500 rank 2
2023-02-22 15:41:20,959 DEBUG TRAIN Batch 21/2600 loss 4.574758 loss_att 5.490283 loss_ctc 5.506772 loss_rnnt 4.017651 hw_loss 0.468249 lr 0.00037504 rank 3
2023-02-22 15:41:20,959 DEBUG TRAIN Batch 21/2600 loss 6.285604 loss_att 9.101885 loss_ctc 8.724422 loss_rnnt 5.277012 hw_loss 0.225299 lr 0.00037504 rank 5
2023-02-22 15:41:20,960 DEBUG TRAIN Batch 21/2600 loss 3.864227 loss_att 8.104053 loss_ctc 7.856552 loss_rnnt 2.362067 hw_loss 0.228533 lr 0.00037500 rank 1
2023-02-22 15:41:20,960 DEBUG TRAIN Batch 21/2600 loss 10.729533 loss_att 10.367034 loss_ctc 13.532628 loss_rnnt 10.165918 hw_loss 0.491940 lr 0.00037507 rank 0
2023-02-22 15:41:20,962 DEBUG TRAIN Batch 21/2600 loss 7.969454 loss_att 9.856303 loss_ctc 10.429831 loss_rnnt 7.041078 hw_loss 0.418042 lr 0.00037497 rank 7
2023-02-22 15:41:20,965 DEBUG TRAIN Batch 21/2600 loss 5.840397 loss_att 7.896660 loss_ctc 8.083731 loss_rnnt 5.052093 hw_loss 0.146140 lr 0.00037507 rank 4
2023-02-22 15:42:32,908 DEBUG TRAIN Batch 21/2700 loss 6.226142 loss_att 9.862047 loss_ctc 13.930369 loss_rnnt 4.293118 hw_loss 0.334898 lr 0.00037493 rank 3
2023-02-22 15:42:32,909 DEBUG TRAIN Batch 21/2700 loss 6.239970 loss_att 9.409864 loss_ctc 9.978858 loss_rnnt 5.065794 hw_loss 0.078147 lr 0.00037489 rank 2
2023-02-22 15:42:32,911 DEBUG TRAIN Batch 21/2700 loss 5.627325 loss_att 8.871507 loss_ctc 8.789413 loss_rnnt 4.474359 hw_loss 0.154722 lr 0.00037489 rank 1
2023-02-22 15:42:32,913 DEBUG TRAIN Batch 21/2700 loss 14.164127 loss_att 17.203009 loss_ctc 17.501173 loss_rnnt 12.956363 hw_loss 0.290719 lr 0.00037493 rank 5
2023-02-22 15:42:32,914 DEBUG TRAIN Batch 21/2700 loss 9.460505 loss_att 12.729526 loss_ctc 15.742081 loss_rnnt 7.836986 hw_loss 0.247825 lr 0.00037488 rank 6
2023-02-22 15:42:32,918 DEBUG TRAIN Batch 21/2700 loss 8.104397 loss_att 11.225280 loss_ctc 9.197877 loss_rnnt 7.238444 hw_loss 0.179961 lr 0.00037496 rank 0
2023-02-22 15:42:32,920 DEBUG TRAIN Batch 21/2700 loss 4.784546 loss_att 8.611293 loss_ctc 8.505974 loss_rnnt 3.298411 hw_loss 0.421118 lr 0.00037487 rank 7
2023-02-22 15:42:32,971 DEBUG TRAIN Batch 21/2700 loss 10.487463 loss_att 13.283759 loss_ctc 13.855414 loss_rnnt 9.259243 hw_loss 0.412315 lr 0.00037496 rank 4
2023-02-22 15:43:47,141 DEBUG TRAIN Batch 21/2800 loss 10.233712 loss_att 14.482630 loss_ctc 16.779478 loss_rnnt 8.415710 hw_loss 0.178966 lr 0.00037476 rank 7
2023-02-22 15:43:47,140 DEBUG TRAIN Batch 21/2800 loss 5.570974 loss_att 8.922422 loss_ctc 8.083099 loss_rnnt 4.392453 hw_loss 0.324903 lr 0.00037486 rank 4
2023-02-22 15:43:47,140 DEBUG TRAIN Batch 21/2800 loss 5.698487 loss_att 8.471873 loss_ctc 7.009891 loss_rnnt 4.904859 hw_loss 0.120183 lr 0.00037478 rank 6
2023-02-22 15:43:47,141 DEBUG TRAIN Batch 21/2800 loss 12.426579 loss_att 18.881035 loss_ctc 21.134762 loss_rnnt 9.813211 hw_loss 0.302595 lr 0.00037482 rank 3
2023-02-22 15:43:47,141 DEBUG TRAIN Batch 21/2800 loss 10.674007 loss_att 13.681627 loss_ctc 15.202068 loss_rnnt 9.237011 hw_loss 0.434496 lr 0.00037483 rank 5
2023-02-22 15:43:47,142 DEBUG TRAIN Batch 21/2800 loss 5.711631 loss_att 7.816405 loss_ctc 6.503337 loss_rnnt 5.067581 hw_loss 0.220376 lr 0.00037485 rank 0
2023-02-22 15:43:47,143 DEBUG TRAIN Batch 21/2800 loss 8.232736 loss_att 11.656967 loss_ctc 11.462759 loss_rnnt 6.956001 hw_loss 0.302284 lr 0.00037479 rank 2
2023-02-22 15:43:47,146 DEBUG TRAIN Batch 21/2800 loss 7.425636 loss_att 11.405485 loss_ctc 13.872847 loss_rnnt 5.584816 hw_loss 0.347293 lr 0.00037479 rank 1
2023-02-22 15:45:01,015 DEBUG TRAIN Batch 21/2900 loss 9.502658 loss_att 10.922462 loss_ctc 10.765667 loss_rnnt 8.968553 hw_loss 0.153267 lr 0.00037466 rank 7
2023-02-22 15:45:01,022 DEBUG TRAIN Batch 21/2900 loss 6.776314 loss_att 8.783894 loss_ctc 10.975822 loss_rnnt 5.742513 hw_loss 0.135657 lr 0.00037472 rank 5
2023-02-22 15:45:01,024 DEBUG TRAIN Batch 21/2900 loss 12.712849 loss_att 15.088449 loss_ctc 25.247805 loss_rnnt 10.425509 hw_loss 0.264172 lr 0.00037468 rank 1
2023-02-22 15:45:01,024 DEBUG TRAIN Batch 21/2900 loss 8.712668 loss_att 13.193718 loss_ctc 13.265379 loss_rnnt 7.110309 hw_loss 0.185854 lr 0.00037475 rank 0
2023-02-22 15:45:01,027 DEBUG TRAIN Batch 21/2900 loss 19.209423 loss_att 22.875471 loss_ctc 24.579929 loss_rnnt 17.673845 hw_loss 0.161813 lr 0.00037468 rank 2
2023-02-22 15:45:01,028 DEBUG TRAIN Batch 21/2900 loss 23.984409 loss_att 27.033247 loss_ctc 33.083992 loss_rnnt 22.056675 hw_loss 0.196291 lr 0.00037475 rank 4
2023-02-22 15:45:01,029 DEBUG TRAIN Batch 21/2900 loss 3.721319 loss_att 7.169730 loss_ctc 6.530520 loss_rnnt 2.574902 hw_loss 0.154077 lr 0.00037472 rank 3
2023-02-22 15:45:01,029 DEBUG TRAIN Batch 21/2900 loss 14.225315 loss_att 18.119530 loss_ctc 21.294083 loss_rnnt 12.368494 hw_loss 0.254016 lr 0.00037467 rank 6
2023-02-22 15:46:13,694 DEBUG TRAIN Batch 21/3000 loss 11.894711 loss_att 14.990376 loss_ctc 19.861271 loss_rnnt 10.092891 hw_loss 0.225897 lr 0.00037458 rank 2
2023-02-22 15:46:13,695 DEBUG TRAIN Batch 21/3000 loss 14.376764 loss_att 18.568029 loss_ctc 21.568430 loss_rnnt 12.444571 hw_loss 0.253224 lr 0.00037455 rank 7
2023-02-22 15:46:13,697 DEBUG TRAIN Batch 21/3000 loss 7.579667 loss_att 9.232717 loss_ctc 9.534885 loss_rnnt 6.791817 hw_loss 0.368522 lr 0.00037464 rank 0
2023-02-22 15:46:13,697 DEBUG TRAIN Batch 21/3000 loss 11.505559 loss_att 13.602006 loss_ctc 16.575308 loss_rnnt 10.293658 hw_loss 0.218709 lr 0.00037462 rank 5
2023-02-22 15:46:13,697 DEBUG TRAIN Batch 21/3000 loss 18.811604 loss_att 20.128468 loss_ctc 27.007038 loss_rnnt 17.244272 hw_loss 0.396061 lr 0.00037457 rank 6
2023-02-22 15:46:13,698 DEBUG TRAIN Batch 21/3000 loss 12.002920 loss_att 17.785450 loss_ctc 19.241459 loss_rnnt 9.759501 hw_loss 0.228328 lr 0.00037458 rank 1
2023-02-22 15:46:13,699 DEBUG TRAIN Batch 21/3000 loss 6.599674 loss_att 8.810762 loss_ctc 10.815728 loss_rnnt 5.483548 hw_loss 0.209565 lr 0.00037464 rank 4
2023-02-22 15:46:13,706 DEBUG TRAIN Batch 21/3000 loss 5.439907 loss_att 8.029596 loss_ctc 5.370971 loss_rnnt 4.828401 hw_loss 0.192674 lr 0.00037461 rank 3
2023-02-22 15:47:26,486 DEBUG TRAIN Batch 21/3100 loss 7.578588 loss_att 14.419662 loss_ctc 12.771334 loss_rnnt 5.395088 hw_loss 0.230471 lr 0.00037446 rank 6
2023-02-22 15:47:26,490 DEBUG TRAIN Batch 21/3100 loss 9.674829 loss_att 11.270093 loss_ctc 13.320923 loss_rnnt 8.672129 hw_loss 0.370317 lr 0.00037451 rank 3
2023-02-22 15:47:26,491 DEBUG TRAIN Batch 21/3100 loss 8.329939 loss_att 13.096748 loss_ctc 13.196102 loss_rnnt 6.525762 hw_loss 0.378738 lr 0.00037454 rank 0
2023-02-22 15:47:26,491 DEBUG TRAIN Batch 21/3100 loss 8.787939 loss_att 10.001108 loss_ctc 11.817378 loss_rnnt 8.019991 hw_loss 0.227604 lr 0.00037445 rank 7
2023-02-22 15:47:26,492 DEBUG TRAIN Batch 21/3100 loss 16.813114 loss_att 17.048386 loss_ctc 22.477676 loss_rnnt 15.801336 hw_loss 0.392718 lr 0.00037454 rank 4
2023-02-22 15:47:26,493 DEBUG TRAIN Batch 21/3100 loss 7.270735 loss_att 8.545751 loss_ctc 13.080863 loss_rnnt 6.083924 hw_loss 0.294607 lr 0.00037451 rank 5
2023-02-22 15:47:26,496 DEBUG TRAIN Batch 21/3100 loss 9.991650 loss_att 14.869008 loss_ctc 18.016705 loss_rnnt 7.840255 hw_loss 0.198593 lr 0.00037447 rank 2
2023-02-22 15:47:26,541 DEBUG TRAIN Batch 21/3100 loss 6.367942 loss_att 7.821793 loss_ctc 9.885278 loss_rnnt 5.497743 hw_loss 0.207096 lr 0.00037447 rank 1
2023-02-22 15:48:42,086 DEBUG TRAIN Batch 21/3200 loss 9.761801 loss_att 15.516745 loss_ctc 12.301342 loss_rnnt 8.185847 hw_loss 0.161923 lr 0.00037436 rank 6
2023-02-22 15:48:42,089 DEBUG TRAIN Batch 21/3200 loss 12.939951 loss_att 15.814705 loss_ctc 16.663300 loss_rnnt 11.755939 hw_loss 0.211153 lr 0.00037443 rank 0
2023-02-22 15:48:42,089 DEBUG TRAIN Batch 21/3200 loss 5.369680 loss_att 9.454442 loss_ctc 5.962719 loss_rnnt 4.296728 hw_loss 0.331740 lr 0.00037434 rank 7
2023-02-22 15:48:42,090 DEBUG TRAIN Batch 21/3200 loss 13.073101 loss_att 13.259798 loss_ctc 17.758141 loss_rnnt 12.194175 hw_loss 0.406715 lr 0.00037440 rank 3
2023-02-22 15:48:42,091 DEBUG TRAIN Batch 21/3200 loss 6.453709 loss_att 11.748400 loss_ctc 7.472950 loss_rnnt 5.090120 hw_loss 0.316410 lr 0.00037441 rank 5
2023-02-22 15:48:42,093 DEBUG TRAIN Batch 21/3200 loss 4.718890 loss_att 6.934463 loss_ctc 6.295661 loss_rnnt 3.941648 hw_loss 0.232297 lr 0.00037437 rank 2
2023-02-22 15:48:42,093 DEBUG TRAIN Batch 21/3200 loss 5.046376 loss_att 9.752127 loss_ctc 8.213568 loss_rnnt 3.553863 hw_loss 0.242009 lr 0.00037443 rank 4
2023-02-22 15:48:42,096 DEBUG TRAIN Batch 21/3200 loss 9.240386 loss_att 10.250430 loss_ctc 12.325871 loss_rnnt 8.456296 hw_loss 0.320031 lr 0.00037437 rank 1
2023-02-22 15:49:54,946 DEBUG TRAIN Batch 21/3300 loss 11.967866 loss_att 16.893211 loss_ctc 22.631460 loss_rnnt 9.394927 hw_loss 0.311359 lr 0.00037425 rank 6
2023-02-22 15:49:54,947 DEBUG TRAIN Batch 21/3300 loss 5.320558 loss_att 7.406245 loss_ctc 9.109379 loss_rnnt 4.258242 hw_loss 0.262503 lr 0.00037424 rank 7
2023-02-22 15:49:54,949 DEBUG TRAIN Batch 21/3300 loss 11.595727 loss_att 13.381313 loss_ctc 18.679071 loss_rnnt 10.136265 hw_loss 0.296058 lr 0.00037433 rank 0
2023-02-22 15:49:54,949 DEBUG TRAIN Batch 21/3300 loss 8.213153 loss_att 12.034260 loss_ctc 9.083775 loss_rnnt 7.217458 hw_loss 0.216357 lr 0.00037430 rank 5
2023-02-22 15:49:54,950 DEBUG TRAIN Batch 21/3300 loss 5.209506 loss_att 6.413417 loss_ctc 8.052034 loss_rnnt 4.421822 hw_loss 0.314809 lr 0.00037426 rank 2
2023-02-22 15:49:54,951 DEBUG TRAIN Batch 21/3300 loss 8.200969 loss_att 11.824327 loss_ctc 11.780815 loss_rnnt 6.839294 hw_loss 0.299419 lr 0.00037426 rank 1
2023-02-22 15:49:54,957 DEBUG TRAIN Batch 21/3300 loss 3.511722 loss_att 6.971858 loss_ctc 5.202559 loss_rnnt 2.467114 hw_loss 0.238379 lr 0.00037433 rank 4
2023-02-22 15:49:54,957 DEBUG TRAIN Batch 21/3300 loss 10.762171 loss_att 13.570312 loss_ctc 14.939792 loss_rnnt 9.559581 hw_loss 0.157400 lr 0.00037430 rank 3
2023-02-22 15:51:07,644 DEBUG TRAIN Batch 21/3400 loss 9.362114 loss_att 9.925777 loss_ctc 11.735373 loss_rnnt 8.737316 hw_loss 0.366806 lr 0.00037416 rank 1
2023-02-22 15:51:07,645 DEBUG TRAIN Batch 21/3400 loss 16.728235 loss_att 20.971598 loss_ctc 20.613764 loss_rnnt 15.050872 hw_loss 0.582415 lr 0.00037413 rank 7
2023-02-22 15:51:07,646 DEBUG TRAIN Batch 21/3400 loss 7.808580 loss_att 9.206471 loss_ctc 10.637393 loss_rnnt 7.008550 hw_loss 0.268645 lr 0.00037416 rank 2
2023-02-22 15:51:07,646 DEBUG TRAIN Batch 21/3400 loss 12.337737 loss_att 17.079758 loss_ctc 14.724369 loss_rnnt 11.001616 hw_loss 0.130310 lr 0.00037415 rank 6
2023-02-22 15:51:07,648 DEBUG TRAIN Batch 21/3400 loss 3.190426 loss_att 5.182894 loss_ctc 4.322361 loss_rnnt 2.386869 hw_loss 0.476510 lr 0.00037419 rank 3
2023-02-22 15:51:07,652 DEBUG TRAIN Batch 21/3400 loss 6.194062 loss_att 11.892839 loss_ctc 10.688745 loss_rnnt 4.367355 hw_loss 0.164364 lr 0.00037422 rank 4
2023-02-22 15:51:07,654 DEBUG TRAIN Batch 21/3400 loss 4.736681 loss_att 8.142305 loss_ctc 8.700762 loss_rnnt 3.464216 hw_loss 0.117742 lr 0.00037422 rank 0
2023-02-22 15:51:07,656 DEBUG TRAIN Batch 21/3400 loss 11.999792 loss_att 13.370242 loss_ctc 15.442471 loss_rnnt 11.088378 hw_loss 0.334315 lr 0.00037420 rank 5
2023-02-22 15:52:20,262 DEBUG TRAIN Batch 21/3500 loss 4.048931 loss_att 7.114243 loss_ctc 7.520748 loss_rnnt 2.803509 hw_loss 0.317718 lr 0.00037409 rank 5
2023-02-22 15:52:20,270 DEBUG TRAIN Batch 21/3500 loss 6.067651 loss_att 8.697899 loss_ctc 10.730654 loss_rnnt 4.838530 hw_loss 0.152511 lr 0.00037405 rank 2
2023-02-22 15:52:20,270 DEBUG TRAIN Batch 21/3500 loss 4.656939 loss_att 6.887994 loss_ctc 6.755654 loss_rnnt 3.771584 hw_loss 0.298716 lr 0.00037412 rank 0
2023-02-22 15:52:20,272 DEBUG TRAIN Batch 21/3500 loss 22.843391 loss_att 23.724442 loss_ctc 23.481842 loss_rnnt 22.511009 hw_loss 0.133210 lr 0.00037403 rank 7
2023-02-22 15:52:20,273 DEBUG TRAIN Batch 21/3500 loss 7.524057 loss_att 10.008348 loss_ctc 9.183114 loss_rnnt 6.685380 hw_loss 0.226146 lr 0.00037409 rank 3
2023-02-22 15:52:20,278 DEBUG TRAIN Batch 21/3500 loss 2.249530 loss_att 4.365107 loss_ctc 2.462625 loss_rnnt 1.690175 hw_loss 0.202176 lr 0.00037405 rank 1
2023-02-22 15:52:20,281 DEBUG TRAIN Batch 21/3500 loss 10.962032 loss_att 11.324764 loss_ctc 14.043071 loss_rnnt 10.216990 hw_loss 0.490670 lr 0.00037404 rank 6
2023-02-22 15:52:20,308 DEBUG TRAIN Batch 21/3500 loss 7.780748 loss_att 11.005518 loss_ctc 11.191345 loss_rnnt 6.586227 hw_loss 0.177789 lr 0.00037412 rank 4
2023-02-22 15:53:34,249 DEBUG TRAIN Batch 21/3600 loss 5.533425 loss_att 8.022598 loss_ctc 9.996094 loss_rnnt 4.249722 hw_loss 0.357836 lr 0.00037399 rank 5
2023-02-22 15:53:34,258 DEBUG TRAIN Batch 21/3600 loss 13.657668 loss_att 14.891922 loss_ctc 16.352131 loss_rnnt 12.903702 hw_loss 0.277225 lr 0.00037395 rank 2
2023-02-22 15:53:34,258 DEBUG TRAIN Batch 21/3600 loss 7.501295 loss_att 8.903588 loss_ctc 9.435551 loss_rnnt 6.824093 hw_loss 0.260329 lr 0.00037392 rank 7
2023-02-22 15:53:34,260 DEBUG TRAIN Batch 21/3600 loss 21.733751 loss_att 22.157633 loss_ctc 26.444525 loss_rnnt 20.884871 hw_loss 0.255001 lr 0.00037399 rank 3
2023-02-22 15:53:34,262 DEBUG TRAIN Batch 21/3600 loss 6.644976 loss_att 8.335751 loss_ctc 7.453041 loss_rnnt 6.094774 hw_loss 0.195569 lr 0.00037402 rank 4
2023-02-22 15:53:34,264 DEBUG TRAIN Batch 21/3600 loss 6.467121 loss_att 8.709353 loss_ctc 10.276991 loss_rnnt 5.399066 hw_loss 0.209298 lr 0.00037401 rank 0
2023-02-22 15:53:34,264 DEBUG TRAIN Batch 21/3600 loss 6.035305 loss_att 6.946381 loss_ctc 9.818254 loss_rnnt 5.193123 hw_loss 0.291699 lr 0.00037394 rank 6
2023-02-22 15:53:34,316 DEBUG TRAIN Batch 21/3600 loss 17.631445 loss_att 22.175001 loss_ctc 24.182552 loss_rnnt 15.749991 hw_loss 0.186113 lr 0.00037395 rank 1
2023-02-22 15:54:47,517 DEBUG TRAIN Batch 21/3700 loss 11.026218 loss_att 13.443233 loss_ctc 16.441435 loss_rnnt 9.595313 hw_loss 0.422765 lr 0.00037391 rank 4
2023-02-22 15:54:47,530 DEBUG TRAIN Batch 21/3700 loss 16.794987 loss_att 26.651451 loss_ctc 27.390320 loss_rnnt 13.350828 hw_loss 0.112790 lr 0.00037384 rank 2
2023-02-22 15:54:47,532 DEBUG TRAIN Batch 21/3700 loss 6.984370 loss_att 8.215835 loss_ctc 9.372691 loss_rnnt 6.217310 hw_loss 0.379356 lr 0.00037384 rank 1
2023-02-22 15:54:47,533 DEBUG TRAIN Batch 21/3700 loss 11.381488 loss_att 14.641946 loss_ctc 16.160412 loss_rnnt 10.014635 hw_loss 0.145444 lr 0.00037391 rank 0
2023-02-22 15:54:47,533 DEBUG TRAIN Batch 21/3700 loss 6.203670 loss_att 9.079878 loss_ctc 8.879246 loss_rnnt 5.055083 hw_loss 0.406128 lr 0.00037388 rank 3
2023-02-22 15:54:47,536 DEBUG TRAIN Batch 21/3700 loss 5.346770 loss_att 6.720176 loss_ctc 7.334096 loss_rnnt 4.577013 hw_loss 0.431435 lr 0.00037383 rank 6
2023-02-22 15:54:47,536 DEBUG TRAIN Batch 21/3700 loss 5.807292 loss_att 7.539243 loss_ctc 7.228395 loss_rnnt 5.137214 hw_loss 0.251637 lr 0.00037388 rank 5
2023-02-22 15:54:47,538 DEBUG TRAIN Batch 21/3700 loss 10.803468 loss_att 11.363467 loss_ctc 12.064877 loss_rnnt 10.391605 hw_loss 0.246890 lr 0.00037382 rank 7
2023-02-22 15:56:00,233 DEBUG TRAIN Batch 21/3800 loss 17.432346 loss_att 16.915016 loss_ctc 22.602877 loss_rnnt 16.655758 hw_loss 0.357473 lr 0.00037372 rank 7
2023-02-22 15:56:00,234 DEBUG TRAIN Batch 21/3800 loss 11.870132 loss_att 14.057304 loss_ctc 22.296631 loss_rnnt 9.868886 hw_loss 0.325523 lr 0.00037374 rank 2
2023-02-22 15:56:00,237 DEBUG TRAIN Batch 21/3800 loss 5.308452 loss_att 7.820940 loss_ctc 7.539163 loss_rnnt 4.424480 hw_loss 0.157586 lr 0.00037381 rank 0
2023-02-22 15:56:00,237 DEBUG TRAIN Batch 21/3800 loss 5.730840 loss_att 8.889990 loss_ctc 8.008283 loss_rnnt 4.639172 hw_loss 0.292835 lr 0.00037378 rank 3
2023-02-22 15:56:00,237 DEBUG TRAIN Batch 21/3800 loss 9.905872 loss_att 12.857091 loss_ctc 14.285141 loss_rnnt 8.597248 hw_loss 0.252148 lr 0.00037374 rank 1
2023-02-22 15:56:00,241 DEBUG TRAIN Batch 21/3800 loss 12.068810 loss_att 12.840626 loss_ctc 17.373083 loss_rnnt 11.040594 hw_loss 0.312405 lr 0.00037373 rank 6
2023-02-22 15:56:00,242 DEBUG TRAIN Batch 21/3800 loss 10.620422 loss_att 11.089935 loss_ctc 15.107186 loss_rnnt 9.726532 hw_loss 0.378288 lr 0.00037381 rank 4
2023-02-22 15:56:00,247 DEBUG TRAIN Batch 21/3800 loss 6.166256 loss_att 11.569399 loss_ctc 8.011925 loss_rnnt 4.705640 hw_loss 0.251061 lr 0.00037378 rank 5
2023-02-22 15:57:15,569 DEBUG TRAIN Batch 21/3900 loss 10.207286 loss_att 13.127810 loss_ctc 14.767200 loss_rnnt 8.901477 hw_loss 0.213217 lr 0.00037361 rank 7
2023-02-22 15:57:15,571 DEBUG TRAIN Batch 21/3900 loss 11.310179 loss_att 12.126584 loss_ctc 16.411432 loss_rnnt 10.298501 hw_loss 0.315429 lr 0.00037370 rank 0
2023-02-22 15:57:15,575 DEBUG TRAIN Batch 21/3900 loss 8.238998 loss_att 11.117275 loss_ctc 14.108589 loss_rnnt 6.669161 hw_loss 0.396692 lr 0.00037363 rank 2
2023-02-22 15:57:15,579 DEBUG TRAIN Batch 21/3900 loss 6.256499 loss_att 8.144865 loss_ctc 6.611570 loss_rnnt 5.707666 hw_loss 0.232156 lr 0.00037362 rank 6
2023-02-22 15:57:15,583 DEBUG TRAIN Batch 21/3900 loss 5.918578 loss_att 10.201913 loss_ctc 10.793464 loss_rnnt 4.324509 hw_loss 0.163907 lr 0.00037367 rank 5
2023-02-22 15:57:15,585 DEBUG TRAIN Batch 21/3900 loss 10.081512 loss_att 14.017466 loss_ctc 17.592617 loss_rnnt 8.216570 hw_loss 0.143009 lr 0.00037370 rank 4
2023-02-22 15:57:15,585 DEBUG TRAIN Batch 21/3900 loss 9.504851 loss_att 13.200171 loss_ctc 12.844116 loss_rnnt 8.257692 hw_loss 0.117862 lr 0.00037367 rank 3
2023-02-22 15:57:15,610 DEBUG TRAIN Batch 21/3900 loss 4.810758 loss_att 8.215652 loss_ctc 6.434661 loss_rnnt 3.762035 hw_loss 0.283543 lr 0.00037364 rank 1
2023-02-22 15:58:27,816 DEBUG TRAIN Batch 21/4000 loss 7.260447 loss_att 10.738347 loss_ctc 14.154803 loss_rnnt 5.431374 hw_loss 0.401711 lr 0.00037353 rank 2
2023-02-22 15:58:27,820 DEBUG TRAIN Batch 21/4000 loss 20.103745 loss_att 23.408279 loss_ctc 25.611496 loss_rnnt 18.563345 hw_loss 0.272112 lr 0.00037351 rank 7
2023-02-22 15:58:27,821 DEBUG TRAIN Batch 21/4000 loss 5.052647 loss_att 9.420998 loss_ctc 7.926970 loss_rnnt 3.608480 hw_loss 0.351099 lr 0.00037353 rank 1
2023-02-22 15:58:27,821 DEBUG TRAIN Batch 21/4000 loss 7.016617 loss_att 11.230625 loss_ctc 11.978644 loss_rnnt 5.412179 hw_loss 0.187562 lr 0.00037357 rank 3
2023-02-22 15:58:27,823 DEBUG TRAIN Batch 21/4000 loss 4.866694 loss_att 7.878031 loss_ctc 7.485671 loss_rnnt 3.806024 hw_loss 0.204761 lr 0.00037352 rank 6
2023-02-22 15:58:27,825 DEBUG TRAIN Batch 21/4000 loss 5.892603 loss_att 10.638695 loss_ctc 7.882114 loss_rnnt 4.540179 hw_loss 0.258634 lr 0.00037360 rank 4
2023-02-22 15:58:27,827 DEBUG TRAIN Batch 21/4000 loss 10.408895 loss_att 14.259117 loss_ctc 15.389900 loss_rnnt 8.824917 hw_loss 0.280874 lr 0.00037357 rank 5
2023-02-22 15:58:27,877 DEBUG TRAIN Batch 21/4000 loss 6.182735 loss_att 7.324620 loss_ctc 10.624965 loss_rnnt 5.223676 hw_loss 0.259472 lr 0.00037360 rank 0
2023-02-22 15:59:40,558 DEBUG TRAIN Batch 21/4100 loss 4.153724 loss_att 7.807734 loss_ctc 9.266253 loss_rnnt 2.603260 hw_loss 0.258734 lr 0.00037343 rank 1
2023-02-22 15:59:40,574 DEBUG TRAIN Batch 21/4100 loss 3.583803 loss_att 6.835726 loss_ctc 6.600918 loss_rnnt 2.353771 hw_loss 0.332559 lr 0.00037349 rank 0
2023-02-22 15:59:40,576 DEBUG TRAIN Batch 21/4100 loss 5.605092 loss_att 8.464542 loss_ctc 9.507828 loss_rnnt 4.411934 hw_loss 0.189193 lr 0.00037340 rank 7
2023-02-22 15:59:40,576 DEBUG TRAIN Batch 21/4100 loss 2.445762 loss_att 6.374529 loss_ctc 3.198930 loss_rnnt 1.367423 hw_loss 0.360305 lr 0.00037346 rank 3
2023-02-22 15:59:40,578 DEBUG TRAIN Batch 21/4100 loss 13.193751 loss_att 14.452728 loss_ctc 19.757759 loss_rnnt 11.922985 hw_loss 0.269567 lr 0.00037342 rank 2
2023-02-22 15:59:40,580 DEBUG TRAIN Batch 21/4100 loss 8.472306 loss_att 12.105152 loss_ctc 13.459507 loss_rnnt 6.970056 hw_loss 0.207604 lr 0.00037342 rank 6
2023-02-22 15:59:40,593 DEBUG TRAIN Batch 21/4100 loss 13.565631 loss_att 16.198090 loss_ctc 21.456667 loss_rnnt 11.850321 hw_loss 0.256274 lr 0.00037346 rank 5
2023-02-22 15:59:40,624 DEBUG TRAIN Batch 21/4100 loss 6.233581 loss_att 7.564069 loss_ctc 8.557993 loss_rnnt 5.459883 hw_loss 0.370646 lr 0.00037349 rank 4
2023-02-22 16:00:54,363 DEBUG TRAIN Batch 21/4200 loss 6.902917 loss_att 8.468390 loss_ctc 8.588057 loss_rnnt 6.171164 hw_loss 0.363700 lr 0.00037332 rank 2
2023-02-22 16:00:54,364 DEBUG TRAIN Batch 21/4200 loss 10.578801 loss_att 10.770572 loss_ctc 13.294615 loss_rnnt 10.054632 hw_loss 0.231950 lr 0.00037336 rank 3
2023-02-22 16:00:54,369 DEBUG TRAIN Batch 21/4200 loss 11.462622 loss_att 14.949614 loss_ctc 16.432072 loss_rnnt 9.923290 hw_loss 0.336260 lr 0.00037339 rank 4
2023-02-22 16:00:54,369 DEBUG TRAIN Batch 21/4200 loss 14.049906 loss_att 14.837843 loss_ctc 17.777187 loss_rnnt 13.259974 hw_loss 0.253825 lr 0.00037339 rank 0
2023-02-22 16:00:54,368 DEBUG TRAIN Batch 21/4200 loss 10.100314 loss_att 11.396793 loss_ctc 12.613049 loss_rnnt 9.318135 hw_loss 0.352221 lr 0.00037331 rank 6
2023-02-22 16:00:54,373 DEBUG TRAIN Batch 21/4200 loss 10.267609 loss_att 13.493751 loss_ctc 14.906559 loss_rnnt 8.858210 hw_loss 0.273081 lr 0.00037330 rank 7
2023-02-22 16:00:54,374 DEBUG TRAIN Batch 21/4200 loss 12.253715 loss_att 12.865221 loss_ctc 15.887260 loss_rnnt 11.495232 hw_loss 0.284454 lr 0.00037332 rank 1
2023-02-22 16:00:54,407 DEBUG TRAIN Batch 21/4200 loss 9.231769 loss_att 14.951788 loss_ctc 18.219223 loss_rnnt 6.757730 hw_loss 0.246953 lr 0.00037336 rank 5
2023-02-22 16:02:08,879 DEBUG TRAIN Batch 21/4300 loss 13.875237 loss_att 14.229303 loss_ctc 17.609108 loss_rnnt 13.099081 hw_loss 0.389051 lr 0.00037321 rank 6
2023-02-22 16:02:08,882 DEBUG TRAIN Batch 21/4300 loss 5.730783 loss_att 8.221313 loss_ctc 8.232860 loss_rnnt 4.689622 hw_loss 0.392709 lr 0.00037322 rank 2
2023-02-22 16:02:08,885 DEBUG TRAIN Batch 21/4300 loss 13.327604 loss_att 15.209628 loss_ctc 21.106306 loss_rnnt 11.806882 hw_loss 0.200918 lr 0.00037329 rank 4
2023-02-22 16:02:08,886 DEBUG TRAIN Batch 21/4300 loss 13.688382 loss_att 18.177801 loss_ctc 20.588247 loss_rnnt 11.784050 hw_loss 0.162125 lr 0.00037328 rank 0
2023-02-22 16:02:08,886 DEBUG TRAIN Batch 21/4300 loss 9.917365 loss_att 11.646732 loss_ctc 13.348042 loss_rnnt 9.018800 hw_loss 0.178626 lr 0.00037325 rank 3
2023-02-22 16:02:08,889 DEBUG TRAIN Batch 21/4300 loss 4.765429 loss_att 6.487384 loss_ctc 6.397293 loss_rnnt 4.081540 hw_loss 0.228593 lr 0.00037326 rank 5
2023-02-22 16:02:08,893 DEBUG TRAIN Batch 21/4300 loss 9.019797 loss_att 12.010177 loss_ctc 11.861932 loss_rnnt 7.963748 hw_loss 0.148165 lr 0.00037319 rank 7
2023-02-22 16:02:08,896 DEBUG TRAIN Batch 21/4300 loss 5.748455 loss_att 8.906597 loss_ctc 9.520593 loss_rnnt 4.511374 hw_loss 0.192190 lr 0.00037322 rank 1
2023-02-22 16:03:21,062 DEBUG TRAIN Batch 21/4400 loss 7.541166 loss_att 11.013791 loss_ctc 11.500484 loss_rnnt 6.176088 hw_loss 0.267458 lr 0.00037311 rank 2
2023-02-22 16:03:21,074 DEBUG TRAIN Batch 21/4400 loss 15.799747 loss_att 18.786819 loss_ctc 22.264740 loss_rnnt 14.158121 hw_loss 0.341648 lr 0.00037315 rank 3
2023-02-22 16:03:21,074 DEBUG TRAIN Batch 21/4400 loss 10.298908 loss_att 12.902631 loss_ctc 14.336715 loss_rnnt 9.088328 hw_loss 0.283990 lr 0.00037312 rank 1
2023-02-22 16:03:21,075 DEBUG TRAIN Batch 21/4400 loss 6.758499 loss_att 9.744238 loss_ctc 7.357802 loss_rnnt 6.033494 hw_loss 0.089905 lr 0.00037310 rank 6
2023-02-22 16:03:21,080 DEBUG TRAIN Batch 21/4400 loss 9.524914 loss_att 9.633728 loss_ctc 12.858221 loss_rnnt 8.901306 hw_loss 0.295134 lr 0.00037315 rank 5
2023-02-22 16:03:21,080 DEBUG TRAIN Batch 21/4400 loss 8.334480 loss_att 9.431756 loss_ctc 10.693199 loss_rnnt 7.512710 hw_loss 0.539661 lr 0.00037318 rank 4
2023-02-22 16:03:21,082 DEBUG TRAIN Batch 21/4400 loss 12.586081 loss_att 14.905378 loss_ctc 17.476303 loss_rnnt 11.350845 hw_loss 0.223774 lr 0.00037309 rank 7
2023-02-22 16:03:21,130 DEBUG TRAIN Batch 21/4400 loss 10.100614 loss_att 11.192745 loss_ctc 10.934585 loss_rnnt 9.544935 hw_loss 0.423854 lr 0.00037318 rank 0
2023-02-22 16:04:33,315 DEBUG TRAIN Batch 21/4500 loss 5.138977 loss_att 8.370575 loss_ctc 5.900746 loss_rnnt 4.224851 hw_loss 0.311694 lr 0.00037301 rank 2
2023-02-22 16:04:33,316 DEBUG TRAIN Batch 21/4500 loss 9.903864 loss_att 8.591707 loss_ctc 12.415526 loss_rnnt 9.484617 hw_loss 0.650229 lr 0.00037305 rank 3
2023-02-22 16:04:33,317 DEBUG TRAIN Batch 21/4500 loss 9.742797 loss_att 12.698010 loss_ctc 11.150363 loss_rnnt 8.839201 hw_loss 0.234147 lr 0.00037308 rank 4
2023-02-22 16:04:33,317 DEBUG TRAIN Batch 21/4500 loss 3.327180 loss_att 5.248886 loss_ctc 4.732145 loss_rnnt 2.503010 hw_loss 0.473438 lr 0.00037300 rank 6
2023-02-22 16:04:33,317 DEBUG TRAIN Batch 21/4500 loss 7.031826 loss_att 8.299559 loss_ctc 9.145433 loss_rnnt 6.097654 hw_loss 0.747772 lr 0.00037308 rank 0
2023-02-22 16:04:33,318 DEBUG TRAIN Batch 21/4500 loss 8.609659 loss_att 8.652406 loss_ctc 11.135922 loss_rnnt 7.968600 hw_loss 0.554389 lr 0.00037301 rank 1
2023-02-22 16:04:33,321 DEBUG TRAIN Batch 21/4500 loss 2.573565 loss_att 5.722541 loss_ctc 5.985681 loss_rnnt 1.338947 hw_loss 0.281014 lr 0.00037305 rank 5
2023-02-22 16:04:33,322 DEBUG TRAIN Batch 21/4500 loss 6.826838 loss_att 10.052677 loss_ctc 11.831200 loss_rnnt 5.416090 hw_loss 0.184372 lr 0.00037299 rank 7
2023-02-22 16:05:48,309 DEBUG TRAIN Batch 21/4600 loss 3.073763 loss_att 5.341863 loss_ctc 5.379463 loss_rnnt 2.216822 hw_loss 0.179802 lr 0.00037294 rank 3
2023-02-22 16:05:48,310 DEBUG TRAIN Batch 21/4600 loss 15.682818 loss_att 18.060936 loss_ctc 24.826618 loss_rnnt 13.860842 hw_loss 0.238458 lr 0.00037290 rank 2
2023-02-22 16:05:48,312 DEBUG TRAIN Batch 21/4600 loss 8.980321 loss_att 11.762564 loss_ctc 16.939861 loss_rnnt 7.233565 hw_loss 0.241943 lr 0.00037297 rank 4
2023-02-22 16:05:48,313 DEBUG TRAIN Batch 21/4600 loss 11.880645 loss_att 14.853515 loss_ctc 18.146633 loss_rnnt 10.344978 hw_loss 0.198052 lr 0.00037294 rank 5
2023-02-22 16:05:48,313 DEBUG TRAIN Batch 21/4600 loss 14.590199 loss_att 13.825997 loss_ctc 19.049297 loss_rnnt 14.046473 hw_loss 0.191282 lr 0.00037290 rank 6
2023-02-22 16:05:48,327 DEBUG TRAIN Batch 21/4600 loss 12.763677 loss_att 14.327827 loss_ctc 17.289000 loss_rnnt 11.789076 hw_loss 0.109488 lr 0.00037297 rank 0
2023-02-22 16:05:48,353 DEBUG TRAIN Batch 21/4600 loss 5.889073 loss_att 9.617554 loss_ctc 9.921913 loss_rnnt 4.372303 hw_loss 0.437554 lr 0.00037288 rank 7
2023-02-22 16:05:48,363 DEBUG TRAIN Batch 21/4600 loss 7.109873 loss_att 9.811729 loss_ctc 8.704283 loss_rnnt 6.151000 hw_loss 0.386089 lr 0.00037291 rank 1
2023-02-22 16:07:01,790 DEBUG TRAIN Batch 21/4700 loss 11.770885 loss_att 13.501408 loss_ctc 15.459552 loss_rnnt 10.684204 hw_loss 0.466411 lr 0.00037280 rank 2
2023-02-22 16:07:01,791 DEBUG TRAIN Batch 21/4700 loss 6.135184 loss_att 9.975551 loss_ctc 9.380937 loss_rnnt 4.736251 hw_loss 0.371423 lr 0.00037284 rank 3
2023-02-22 16:07:01,793 DEBUG TRAIN Batch 21/4700 loss 5.273115 loss_att 8.765060 loss_ctc 11.424471 loss_rnnt 3.588165 hw_loss 0.311962 lr 0.00037278 rank 7
2023-02-22 16:07:01,793 DEBUG TRAIN Batch 21/4700 loss 12.081310 loss_att 14.377073 loss_ctc 16.560291 loss_rnnt 10.826632 hw_loss 0.371867 lr 0.00037279 rank 6
2023-02-22 16:07:01,794 DEBUG TRAIN Batch 21/4700 loss 5.632166 loss_att 8.922276 loss_ctc 7.310938 loss_rnnt 4.629385 hw_loss 0.226730 lr 0.00037287 rank 4
2023-02-22 16:07:01,798 DEBUG TRAIN Batch 21/4700 loss 21.114649 loss_att 21.731400 loss_ctc 22.923767 loss_rnnt 20.630016 hw_loss 0.225126 lr 0.00037280 rank 1
2023-02-22 16:07:01,799 DEBUG TRAIN Batch 21/4700 loss 10.538842 loss_att 12.433516 loss_ctc 17.773117 loss_rnnt 9.098779 hw_loss 0.181049 lr 0.00037287 rank 0
2023-02-22 16:07:01,800 DEBUG TRAIN Batch 21/4700 loss 9.644907 loss_att 11.758389 loss_ctc 14.971860 loss_rnnt 8.343497 hw_loss 0.315849 lr 0.00037284 rank 5
2023-02-22 16:08:14,482 DEBUG TRAIN Batch 21/4800 loss 14.751474 loss_att 16.390005 loss_ctc 21.491112 loss_rnnt 13.276945 hw_loss 0.465386 lr 0.00037269 rank 6
2023-02-22 16:08:14,498 DEBUG TRAIN Batch 21/4800 loss 6.806674 loss_att 9.348141 loss_ctc 9.294779 loss_rnnt 5.826255 hw_loss 0.263211 lr 0.00037270 rank 2
2023-02-22 16:08:14,500 DEBUG TRAIN Batch 21/4800 loss 6.886542 loss_att 10.488184 loss_ctc 12.915490 loss_rnnt 5.207365 hw_loss 0.290603 lr 0.00037274 rank 5
2023-02-22 16:08:14,502 DEBUG TRAIN Batch 21/4800 loss 5.916923 loss_att 8.148628 loss_ctc 9.565483 loss_rnnt 4.880316 hw_loss 0.194609 lr 0.00037274 rank 3
2023-02-22 16:08:14,504 DEBUG TRAIN Batch 21/4800 loss 5.946503 loss_att 9.484841 loss_ctc 7.934291 loss_rnnt 4.798390 hw_loss 0.328887 lr 0.00037268 rank 7
2023-02-22 16:08:14,504 DEBUG TRAIN Batch 21/4800 loss 11.897481 loss_att 13.271007 loss_ctc 15.831075 loss_rnnt 11.002027 hw_loss 0.180506 lr 0.00037277 rank 4
2023-02-22 16:08:14,506 DEBUG TRAIN Batch 21/4800 loss 7.626110 loss_att 10.266382 loss_ctc 14.204176 loss_rnnt 6.105318 hw_loss 0.216867 lr 0.00037270 rank 1
2023-02-22 16:08:14,552 DEBUG TRAIN Batch 21/4800 loss 17.905533 loss_att 21.285013 loss_ctc 26.980640 loss_rnnt 15.903049 hw_loss 0.218574 lr 0.00037276 rank 0
2023-02-22 16:09:27,217 DEBUG TRAIN Batch 21/4900 loss 7.699168 loss_att 9.938168 loss_ctc 13.270614 loss_rnnt 6.272624 hw_loss 0.442284 lr 0.00037257 rank 7
2023-02-22 16:09:27,232 DEBUG TRAIN Batch 21/4900 loss 9.984066 loss_att 12.341446 loss_ctc 13.592765 loss_rnnt 8.883225 hw_loss 0.277881 lr 0.00037266 rank 0
2023-02-22 16:09:27,233 DEBUG TRAIN Batch 21/4900 loss 9.594913 loss_att 10.388372 loss_ctc 13.355964 loss_rnnt 8.825419 hw_loss 0.204989 lr 0.00037259 rank 2
2023-02-22 16:09:27,233 DEBUG TRAIN Batch 21/4900 loss 4.528819 loss_att 6.114430 loss_ctc 6.724317 loss_rnnt 3.683905 hw_loss 0.440735 lr 0.00037258 rank 6
2023-02-22 16:09:27,238 DEBUG TRAIN Batch 21/4900 loss 13.279334 loss_att 17.256950 loss_ctc 14.553654 loss_rnnt 12.225758 hw_loss 0.165270 lr 0.00037263 rank 3
2023-02-22 16:09:27,240 DEBUG TRAIN Batch 21/4900 loss 12.371372 loss_att 14.152124 loss_ctc 16.753891 loss_rnnt 11.249470 hw_loss 0.340154 lr 0.00037266 rank 4
2023-02-22 16:09:27,243 DEBUG TRAIN Batch 21/4900 loss 19.216673 loss_att 21.533396 loss_ctc 26.715809 loss_rnnt 17.559551 hw_loss 0.363547 lr 0.00037260 rank 1
2023-02-22 16:09:27,244 DEBUG TRAIN Batch 21/4900 loss 8.074853 loss_att 10.053920 loss_ctc 14.098953 loss_rnnt 6.809914 hw_loss 0.123585 lr 0.00037263 rank 5
2023-02-22 16:10:42,528 DEBUG TRAIN Batch 21/5000 loss 11.004650 loss_att 12.827007 loss_ctc 20.664848 loss_rnnt 9.300800 hw_loss 0.096283 lr 0.00037253 rank 3
2023-02-22 16:10:42,531 DEBUG TRAIN Batch 21/5000 loss 5.846998 loss_att 7.528301 loss_ctc 7.890759 loss_rnnt 5.166118 hw_loss 0.135220 lr 0.00037247 rank 7
2023-02-22 16:10:42,532 DEBUG TRAIN Batch 21/5000 loss 3.929170 loss_att 6.649352 loss_ctc 6.350347 loss_rnnt 2.939484 hw_loss 0.230298 lr 0.00037249 rank 2
2023-02-22 16:10:42,534 DEBUG TRAIN Batch 21/5000 loss 10.818581 loss_att 11.607079 loss_ctc 13.881265 loss_rnnt 10.043218 hw_loss 0.392446 lr 0.00037253 rank 5
2023-02-22 16:10:42,533 DEBUG TRAIN Batch 21/5000 loss 13.813366 loss_att 16.079622 loss_ctc 21.076603 loss_rnnt 12.236696 hw_loss 0.290599 lr 0.00037249 rank 1
2023-02-22 16:10:42,535 DEBUG TRAIN Batch 21/5000 loss 11.363572 loss_att 10.786816 loss_ctc 16.555258 loss_rnnt 10.537773 hw_loss 0.466736 lr 0.00037248 rank 6
2023-02-22 16:10:42,539 DEBUG TRAIN Batch 21/5000 loss 5.534399 loss_att 7.887528 loss_ctc 9.071795 loss_rnnt 4.423198 hw_loss 0.316730 lr 0.00037256 rank 0
2023-02-22 16:10:42,541 DEBUG TRAIN Batch 21/5000 loss 16.409607 loss_att 18.680292 loss_ctc 19.441225 loss_rnnt 15.334743 hw_loss 0.405958 lr 0.00037256 rank 4
2023-02-22 16:11:56,231 DEBUG TRAIN Batch 21/5100 loss 11.471843 loss_att 13.356571 loss_ctc 17.488943 loss_rnnt 10.123610 hw_loss 0.316889 lr 0.00037243 rank 3
2023-02-22 16:11:56,241 DEBUG TRAIN Batch 21/5100 loss 10.490735 loss_att 13.509031 loss_ctc 14.008705 loss_rnnt 9.291415 hw_loss 0.237371 lr 0.00037239 rank 2
2023-02-22 16:11:56,242 DEBUG TRAIN Batch 21/5100 loss 7.690543 loss_att 11.067028 loss_ctc 11.644609 loss_rnnt 6.358553 hw_loss 0.242783 lr 0.00037238 rank 6
2023-02-22 16:11:56,246 DEBUG TRAIN Batch 21/5100 loss 12.241032 loss_att 14.814495 loss_ctc 20.345495 loss_rnnt 10.583466 hw_loss 0.116769 lr 0.00037245 rank 0
2023-02-22 16:11:56,246 DEBUG TRAIN Batch 21/5100 loss 7.242755 loss_att 12.258017 loss_ctc 10.037895 loss_rnnt 5.770616 hw_loss 0.180753 lr 0.00037246 rank 4
2023-02-22 16:11:56,251 DEBUG TRAIN Batch 21/5100 loss 8.663549 loss_att 13.821690 loss_ctc 13.806707 loss_rnnt 6.799931 hw_loss 0.274194 lr 0.00037237 rank 7
2023-02-22 16:11:56,251 DEBUG TRAIN Batch 21/5100 loss 7.759580 loss_att 7.193980 loss_ctc 13.597869 loss_rnnt 6.984342 hw_loss 0.206098 lr 0.00037239 rank 1
2023-02-22 16:11:56,301 DEBUG TRAIN Batch 21/5100 loss 10.166774 loss_att 11.340491 loss_ctc 20.344463 loss_rnnt 8.496095 hw_loss 0.147956 lr 0.00037243 rank 5
2023-02-22 16:13:09,022 DEBUG TRAIN Batch 21/5200 loss 5.779830 loss_att 10.541073 loss_ctc 12.002787 loss_rnnt 3.879003 hw_loss 0.222845 lr 0.00037228 rank 2
2023-02-22 16:13:09,039 DEBUG TRAIN Batch 21/5200 loss 7.511672 loss_att 13.663731 loss_ctc 15.192820 loss_rnnt 5.206843 hw_loss 0.094245 lr 0.00037232 rank 3
2023-02-22 16:13:09,043 DEBUG TRAIN Batch 21/5200 loss 7.767606 loss_att 12.769981 loss_ctc 14.152817 loss_rnnt 5.784669 hw_loss 0.245812 lr 0.00037227 rank 6
2023-02-22 16:13:09,045 DEBUG TRAIN Batch 21/5200 loss 7.108831 loss_att 9.117371 loss_ctc 7.596996 loss_rnnt 6.514215 hw_loss 0.239662 lr 0.00037229 rank 1
2023-02-22 16:13:09,046 DEBUG TRAIN Batch 21/5200 loss 6.585943 loss_att 10.883018 loss_ctc 9.946164 loss_rnnt 5.236086 hw_loss 0.079523 lr 0.00037226 rank 7
2023-02-22 16:13:09,047 DEBUG TRAIN Batch 21/5200 loss 14.510899 loss_att 20.212772 loss_ctc 20.020126 loss_rnnt 12.506365 hw_loss 0.242991 lr 0.00037235 rank 0
2023-02-22 16:13:09,049 DEBUG TRAIN Batch 21/5200 loss 2.589443 loss_att 8.517657 loss_ctc 4.983642 loss_rnnt 0.948952 hw_loss 0.254291 lr 0.00037235 rank 4
2023-02-22 16:13:09,052 DEBUG TRAIN Batch 21/5200 loss 6.908628 loss_att 6.978831 loss_ctc 6.791757 loss_rnnt 6.663549 hw_loss 0.462413 lr 0.00037232 rank 5
2023-02-22 16:14:23,993 DEBUG TRAIN Batch 21/5300 loss 4.040133 loss_att 6.268192 loss_ctc 5.880983 loss_rnnt 3.230653 hw_loss 0.222042 lr 0.00037218 rank 1
2023-02-22 16:14:23,997 DEBUG TRAIN Batch 21/5300 loss 10.029365 loss_att 11.872385 loss_ctc 13.352065 loss_rnnt 9.115005 hw_loss 0.192613 lr 0.00037222 rank 5
2023-02-22 16:14:23,999 DEBUG TRAIN Batch 21/5300 loss 14.104406 loss_att 20.556110 loss_ctc 19.997570 loss_rnnt 11.943660 hw_loss 0.158719 lr 0.00037225 rank 0
2023-02-22 16:14:24,001 DEBUG TRAIN Batch 21/5300 loss 11.330128 loss_att 15.688915 loss_ctc 21.354055 loss_rnnt 9.005955 hw_loss 0.217297 lr 0.00037222 rank 3
2023-02-22 16:14:24,008 DEBUG TRAIN Batch 21/5300 loss 12.900079 loss_att 13.025623 loss_ctc 19.262463 loss_rnnt 11.855163 hw_loss 0.321544 lr 0.00037218 rank 2
2023-02-22 16:14:24,009 DEBUG TRAIN Batch 21/5300 loss 5.359760 loss_att 8.773686 loss_ctc 10.581144 loss_rnnt 3.840586 hw_loss 0.262881 lr 0.00037216 rank 7
2023-02-22 16:14:24,010 DEBUG TRAIN Batch 21/5300 loss 11.132251 loss_att 13.662873 loss_ctc 16.376675 loss_rnnt 9.752449 hw_loss 0.327038 lr 0.00037217 rank 6
2023-02-22 16:14:24,011 DEBUG TRAIN Batch 21/5300 loss 6.807958 loss_att 11.607821 loss_ctc 8.347813 loss_rnnt 5.531971 hw_loss 0.207562 lr 0.00037225 rank 4
2023-02-22 16:15:38,471 DEBUG TRAIN Batch 21/5400 loss 17.331104 loss_att 19.544014 loss_ctc 23.265226 loss_rnnt 15.985504 hw_loss 0.209628 lr 0.00037206 rank 7
2023-02-22 16:15:38,475 DEBUG TRAIN Batch 21/5400 loss 11.588469 loss_att 15.250241 loss_ctc 16.569010 loss_rnnt 10.022160 hw_loss 0.318528 lr 0.00037215 rank 4
2023-02-22 16:15:38,482 DEBUG TRAIN Batch 21/5400 loss 9.002630 loss_att 10.739378 loss_ctc 11.075238 loss_rnnt 8.292118 hw_loss 0.162778 lr 0.00037208 rank 2
2023-02-22 16:15:38,484 DEBUG TRAIN Batch 21/5400 loss 17.334890 loss_att 19.245850 loss_ctc 27.069973 loss_rnnt 15.546926 hw_loss 0.202055 lr 0.00037212 rank 3
2023-02-22 16:15:38,487 DEBUG TRAIN Batch 21/5400 loss 6.199660 loss_att 7.847207 loss_ctc 7.383800 loss_rnnt 5.577765 hw_loss 0.252189 lr 0.00037214 rank 0
2023-02-22 16:15:38,496 DEBUG TRAIN Batch 21/5400 loss 14.186212 loss_att 18.153906 loss_ctc 21.570280 loss_rnnt 12.203013 hw_loss 0.384595 lr 0.00037212 rank 5
2023-02-22 16:15:38,498 DEBUG TRAIN Batch 21/5400 loss 10.041312 loss_att 12.177242 loss_ctc 13.345885 loss_rnnt 9.028824 hw_loss 0.271296 lr 0.00037207 rank 6
2023-02-22 16:15:38,536 DEBUG TRAIN Batch 21/5400 loss 3.550053 loss_att 7.356199 loss_ctc 5.750825 loss_rnnt 2.346039 hw_loss 0.280028 lr 0.00037208 rank 1
2023-02-22 16:16:52,225 DEBUG TRAIN Batch 21/5500 loss 5.899452 loss_att 6.643829 loss_ctc 10.544094 loss_rnnt 4.921298 hw_loss 0.393736 lr 0.00037198 rank 2
2023-02-22 16:16:52,230 DEBUG TRAIN Batch 21/5500 loss 3.567759 loss_att 5.680176 loss_ctc 5.373165 loss_rnnt 2.819650 hw_loss 0.159197 lr 0.00037198 rank 1
2023-02-22 16:16:52,232 DEBUG TRAIN Batch 21/5500 loss 4.916355 loss_att 7.437730 loss_ctc 6.613170 loss_rnnt 4.053559 hw_loss 0.248022 lr 0.00037201 rank 5
2023-02-22 16:16:52,233 DEBUG TRAIN Batch 21/5500 loss 6.447884 loss_att 9.292143 loss_ctc 9.887117 loss_rnnt 5.305763 hw_loss 0.215071 lr 0.00037201 rank 3
2023-02-22 16:16:52,233 DEBUG TRAIN Batch 21/5500 loss 7.413199 loss_att 8.966587 loss_ctc 11.442339 loss_rnnt 6.437269 hw_loss 0.240066 lr 0.00037197 rank 6
2023-02-22 16:16:52,235 DEBUG TRAIN Batch 21/5500 loss 10.641181 loss_att 13.360745 loss_ctc 16.645262 loss_rnnt 9.192725 hw_loss 0.194997 lr 0.00037204 rank 0
2023-02-22 16:16:52,235 DEBUG TRAIN Batch 21/5500 loss 6.253093 loss_att 8.975163 loss_ctc 9.409161 loss_rnnt 5.126817 hw_loss 0.301975 lr 0.00037204 rank 4
2023-02-22 16:16:52,235 DEBUG TRAIN Batch 21/5500 loss 11.519505 loss_att 13.797450 loss_ctc 14.443344 loss_rnnt 10.467483 hw_loss 0.387353 lr 0.00037195 rank 7
2023-02-22 16:18:05,039 DEBUG TRAIN Batch 21/5600 loss 8.003656 loss_att 9.705288 loss_ctc 11.018943 loss_rnnt 7.134228 hw_loss 0.238245 lr 0.00037194 rank 4
2023-02-22 16:18:05,042 DEBUG TRAIN Batch 21/5600 loss 9.390669 loss_att 12.690510 loss_ctc 15.788774 loss_rnnt 7.748711 hw_loss 0.241704 lr 0.00037188 rank 1
2023-02-22 16:18:05,046 DEBUG TRAIN Batch 21/5600 loss 12.585692 loss_att 14.795279 loss_ctc 21.848770 loss_rnnt 10.773396 hw_loss 0.253689 lr 0.00037191 rank 3
2023-02-22 16:18:05,047 DEBUG TRAIN Batch 21/5600 loss 5.114089 loss_att 6.078197 loss_ctc 7.412648 loss_rnnt 4.426980 hw_loss 0.352148 lr 0.00037187 rank 2
2023-02-22 16:18:05,049 DEBUG TRAIN Batch 21/5600 loss 7.238354 loss_att 8.126419 loss_ctc 10.610379 loss_rnnt 6.425147 hw_loss 0.348733 lr 0.00037186 rank 6
2023-02-22 16:18:05,051 DEBUG TRAIN Batch 21/5600 loss 3.160122 loss_att 5.069446 loss_ctc 4.825300 loss_rnnt 2.386223 hw_loss 0.318770 lr 0.00037194 rank 0
2023-02-22 16:18:05,055 DEBUG TRAIN Batch 21/5600 loss 5.783856 loss_att 6.906450 loss_ctc 6.802254 loss_rnnt 5.243500 hw_loss 0.337595 lr 0.00037185 rank 7
2023-02-22 16:18:05,063 DEBUG TRAIN Batch 21/5600 loss 11.065396 loss_att 15.279325 loss_ctc 16.778685 loss_rnnt 9.254539 hw_loss 0.386813 lr 0.00037191 rank 5
2023-02-22 16:19:21,048 DEBUG TRAIN Batch 21/5700 loss 9.293980 loss_att 8.942663 loss_ctc 11.573505 loss_rnnt 8.730754 hw_loss 0.617911 lr 0.00037175 rank 7
2023-02-22 16:19:21,048 DEBUG TRAIN Batch 21/5700 loss 7.826961 loss_att 7.865026 loss_ctc 10.461960 loss_rnnt 7.266091 hw_loss 0.378604 lr 0.00037184 rank 4
2023-02-22 16:19:21,049 DEBUG TRAIN Batch 21/5700 loss 6.075243 loss_att 8.383247 loss_ctc 8.807657 loss_rnnt 5.176653 hw_loss 0.136250 lr 0.00037181 rank 5
2023-02-22 16:19:21,049 DEBUG TRAIN Batch 21/5700 loss 7.897290 loss_att 10.255939 loss_ctc 12.049769 loss_rnnt 6.750009 hw_loss 0.228538 lr 0.00037184 rank 0
2023-02-22 16:19:21,050 DEBUG TRAIN Batch 21/5700 loss 8.431872 loss_att 11.849900 loss_ctc 17.322634 loss_rnnt 6.387660 hw_loss 0.328449 lr 0.00037177 rank 2
2023-02-22 16:19:21,051 DEBUG TRAIN Batch 21/5700 loss 6.331437 loss_att 8.003164 loss_ctc 7.935884 loss_rnnt 5.482687 hw_loss 0.563394 lr 0.00037181 rank 3
2023-02-22 16:19:21,054 DEBUG TRAIN Batch 21/5700 loss 7.478111 loss_att 10.257706 loss_ctc 13.368163 loss_rnnt 5.949106 hw_loss 0.352024 lr 0.00037177 rank 1
2023-02-22 16:19:21,091 DEBUG TRAIN Batch 21/5700 loss 6.172307 loss_att 7.219945 loss_ctc 7.737793 loss_rnnt 5.637200 hw_loss 0.219089 lr 0.00037176 rank 6
2023-02-22 16:20:34,517 DEBUG TRAIN Batch 21/5800 loss 10.053419 loss_att 13.097319 loss_ctc 14.005886 loss_rnnt 8.736950 hw_loss 0.338801 lr 0.00037165 rank 7
2023-02-22 16:20:34,519 DEBUG TRAIN Batch 21/5800 loss 7.851301 loss_att 7.326775 loss_ctc 10.136689 loss_rnnt 7.363784 hw_loss 0.539445 lr 0.00037170 rank 3
2023-02-22 16:20:34,520 DEBUG TRAIN Batch 21/5800 loss 12.291587 loss_att 11.635619 loss_ctc 15.834239 loss_rnnt 11.735567 hw_loss 0.402861 lr 0.00037173 rank 0
2023-02-22 16:20:34,524 DEBUG TRAIN Batch 21/5800 loss 10.832241 loss_att 13.394629 loss_ctc 14.654728 loss_rnnt 9.720211 hw_loss 0.168538 lr 0.00037167 rank 2
2023-02-22 16:20:34,524 DEBUG TRAIN Batch 21/5800 loss 10.275431 loss_att 11.580704 loss_ctc 12.607684 loss_rnnt 9.484964 hw_loss 0.409584 lr 0.00037171 rank 5
2023-02-22 16:20:34,525 DEBUG TRAIN Batch 21/5800 loss 14.246469 loss_att 15.106080 loss_ctc 17.689705 loss_rnnt 13.437831 hw_loss 0.333035 lr 0.00037167 rank 1
2023-02-22 16:20:34,525 DEBUG TRAIN Batch 21/5800 loss 4.745656 loss_att 6.668697 loss_ctc 6.965173 loss_rnnt 3.961723 hw_loss 0.193853 lr 0.00037166 rank 6
2023-02-22 16:20:34,529 DEBUG TRAIN Batch 21/5800 loss 4.118920 loss_att 7.987481 loss_ctc 4.499688 loss_rnnt 3.176759 hw_loss 0.220650 lr 0.00037173 rank 4
2023-02-22 16:21:47,790 DEBUG TRAIN Batch 21/5900 loss 10.324256 loss_att 12.180552 loss_ctc 11.964010 loss_rnnt 9.546940 hw_loss 0.351419 lr 0.00037156 rank 2
2023-02-22 16:21:47,795 DEBUG TRAIN Batch 21/5900 loss 14.676380 loss_att 18.315907 loss_ctc 17.918785 loss_rnnt 13.390830 hw_loss 0.234983 lr 0.00037163 rank 0
2023-02-22 16:21:47,797 DEBUG TRAIN Batch 21/5900 loss 9.870305 loss_att 13.665392 loss_ctc 17.813383 loss_rnnt 7.885146 hw_loss 0.313245 lr 0.00037160 rank 3
2023-02-22 16:21:47,800 DEBUG TRAIN Batch 21/5900 loss 11.381854 loss_att 13.323994 loss_ctc 16.302219 loss_rnnt 10.129044 hw_loss 0.390625 lr 0.00037155 rank 6
2023-02-22 16:21:47,801 DEBUG TRAIN Batch 21/5900 loss 10.638972 loss_att 13.201555 loss_ctc 14.445517 loss_rnnt 9.554228 hw_loss 0.121290 lr 0.00037157 rank 1
2023-02-22 16:21:47,804 DEBUG TRAIN Batch 21/5900 loss 8.867370 loss_att 9.746700 loss_ctc 13.765624 loss_rnnt 7.933052 hw_loss 0.197532 lr 0.00037163 rank 4
2023-02-22 16:21:47,803 DEBUG TRAIN Batch 21/5900 loss 3.986174 loss_att 7.372715 loss_ctc 7.973351 loss_rnnt 2.642296 hw_loss 0.253024 lr 0.00037154 rank 7
2023-02-22 16:21:47,859 DEBUG TRAIN Batch 21/5900 loss 5.508604 loss_att 8.334143 loss_ctc 7.762615 loss_rnnt 4.390368 hw_loss 0.473610 lr 0.00037160 rank 5
2023-02-22 16:23:02,552 DEBUG TRAIN Batch 21/6000 loss 13.459432 loss_att 17.274778 loss_ctc 20.554922 loss_rnnt 11.555522 hw_loss 0.365202 lr 0.00037145 rank 6
2023-02-22 16:23:02,555 DEBUG TRAIN Batch 21/6000 loss 9.439390 loss_att 10.558725 loss_ctc 13.839752 loss_rnnt 8.395771 hw_loss 0.436945 lr 0.00037146 rank 2
2023-02-22 16:23:02,558 DEBUG TRAIN Batch 21/6000 loss 12.492729 loss_att 13.133764 loss_ctc 14.376383 loss_rnnt 12.009737 hw_loss 0.194306 lr 0.00037150 rank 5
2023-02-22 16:23:02,561 DEBUG TRAIN Batch 21/6000 loss 11.198092 loss_att 16.414646 loss_ctc 14.230024 loss_rnnt 9.648701 hw_loss 0.190916 lr 0.00037150 rank 3
2023-02-22 16:23:02,563 DEBUG TRAIN Batch 21/6000 loss 10.937700 loss_att 12.315324 loss_ctc 9.782103 loss_rnnt 10.697096 hw_loss 0.223426 lr 0.00037153 rank 0
2023-02-22 16:23:02,579 DEBUG TRAIN Batch 21/6000 loss 9.157583 loss_att 10.104313 loss_ctc 10.110007 loss_rnnt 8.711344 hw_loss 0.243568 lr 0.00037153 rank 4
2023-02-22 16:23:02,579 DEBUG TRAIN Batch 21/6000 loss 8.848984 loss_att 12.575979 loss_ctc 12.956961 loss_rnnt 7.343389 hw_loss 0.398371 lr 0.00037144 rank 7
2023-02-22 16:23:02,610 DEBUG TRAIN Batch 21/6000 loss 14.960334 loss_att 14.201378 loss_ctc 20.183035 loss_rnnt 14.228520 hw_loss 0.351081 lr 0.00037146 rank 1
2023-02-22 16:24:16,821 DEBUG TRAIN Batch 21/6100 loss 4.760436 loss_att 6.689816 loss_ctc 5.187422 loss_rnnt 4.178071 hw_loss 0.261670 lr 0.00037143 rank 4
2023-02-22 16:24:16,826 DEBUG TRAIN Batch 21/6100 loss 13.538165 loss_att 15.593398 loss_ctc 19.109440 loss_rnnt 12.183470 hw_loss 0.376522 lr 0.00037134 rank 7
2023-02-22 16:24:16,830 DEBUG TRAIN Batch 21/6100 loss 6.449060 loss_att 8.988535 loss_ctc 10.281567 loss_rnnt 5.287899 hw_loss 0.266748 lr 0.00037140 rank 5
2023-02-22 16:24:16,832 DEBUG TRAIN Batch 21/6100 loss 2.937957 loss_att 5.370325 loss_ctc 6.910404 loss_rnnt 1.788129 hw_loss 0.250677 lr 0.00037135 rank 6
2023-02-22 16:24:16,832 DEBUG TRAIN Batch 21/6100 loss 5.560710 loss_att 7.389025 loss_ctc 8.003344 loss_rnnt 4.692879 hw_loss 0.330907 lr 0.00037140 rank 3
2023-02-22 16:24:16,834 DEBUG TRAIN Batch 21/6100 loss 14.908206 loss_att 15.116467 loss_ctc 27.250631 loss_rnnt 12.988241 hw_loss 0.436230 lr 0.00037136 rank 2
2023-02-22 16:24:16,838 DEBUG TRAIN Batch 21/6100 loss 5.068918 loss_att 8.712233 loss_ctc 10.848861 loss_rnnt 3.444948 hw_loss 0.233714 lr 0.00037136 rank 1
2023-02-22 16:24:16,839 DEBUG TRAIN Batch 21/6100 loss 7.384385 loss_att 10.596652 loss_ctc 10.814333 loss_rnnt 6.207751 hw_loss 0.144102 lr 0.00037143 rank 0
2023-02-22 16:25:29,698 DEBUG TRAIN Batch 21/6200 loss 9.231849 loss_att 11.093134 loss_ctc 13.544863 loss_rnnt 8.111897 hw_loss 0.323671 lr 0.00037129 rank 3
2023-02-22 16:25:29,699 DEBUG TRAIN Batch 21/6200 loss 5.286182 loss_att 10.683813 loss_ctc 9.251021 loss_rnnt 3.584835 hw_loss 0.174704 lr 0.00037126 rank 2
2023-02-22 16:25:29,701 DEBUG TRAIN Batch 21/6200 loss 5.436069 loss_att 9.038471 loss_ctc 8.571871 loss_rnnt 4.194572 hw_loss 0.192953 lr 0.00037126 rank 1
2023-02-22 16:25:29,701 DEBUG TRAIN Batch 21/6200 loss 4.786448 loss_att 5.857957 loss_ctc 4.909845 loss_rnnt 4.363045 hw_loss 0.361217 lr 0.00037132 rank 0
2023-02-22 16:25:29,702 DEBUG TRAIN Batch 21/6200 loss 12.244390 loss_att 13.251152 loss_ctc 17.640099 loss_rnnt 11.091540 hw_loss 0.435132 lr 0.00037125 rank 6
2023-02-22 16:25:29,704 DEBUG TRAIN Batch 21/6200 loss 5.826157 loss_att 9.528656 loss_ctc 9.241140 loss_rnnt 4.512402 hw_loss 0.221108 lr 0.00037124 rank 7
2023-02-22 16:25:29,704 DEBUG TRAIN Batch 21/6200 loss 8.516615 loss_att 9.843819 loss_ctc 10.239149 loss_rnnt 7.870483 hw_loss 0.283162 lr 0.00037132 rank 4
2023-02-22 16:25:29,709 DEBUG TRAIN Batch 21/6200 loss 8.473222 loss_att 10.113729 loss_ctc 12.567024 loss_rnnt 7.414542 hw_loss 0.346385 lr 0.00037130 rank 5
2023-02-22 16:26:42,134 DEBUG TRAIN Batch 21/6300 loss 4.251303 loss_att 5.972022 loss_ctc 5.699966 loss_rnnt 3.622256 hw_loss 0.172027 lr 0.00037115 rank 6
2023-02-22 16:26:42,139 DEBUG TRAIN Batch 21/6300 loss 13.994000 loss_att 14.932346 loss_ctc 17.631973 loss_rnnt 13.077587 hw_loss 0.456904 lr 0.00037119 rank 3
2023-02-22 16:26:42,140 DEBUG TRAIN Batch 21/6300 loss 9.907077 loss_att 12.233923 loss_ctc 12.691374 loss_rnnt 8.922846 hw_loss 0.276791 lr 0.00037113 rank 7
2023-02-22 16:26:42,139 DEBUG TRAIN Batch 21/6300 loss 9.333638 loss_att 12.397952 loss_ctc 14.469907 loss_rnnt 7.832335 hw_loss 0.381757 lr 0.00037116 rank 1
2023-02-22 16:26:42,140 DEBUG TRAIN Batch 21/6300 loss 3.335234 loss_att 8.367599 loss_ctc 4.307950 loss_rnnt 2.049550 hw_loss 0.280343 lr 0.00037115 rank 2
2023-02-22 16:26:42,144 DEBUG TRAIN Batch 21/6300 loss 16.604111 loss_att 21.089628 loss_ctc 26.182560 loss_rnnt 14.241399 hw_loss 0.353405 lr 0.00037122 rank 4
2023-02-22 16:26:42,149 DEBUG TRAIN Batch 21/6300 loss 5.409550 loss_att 8.537850 loss_ctc 8.322395 loss_rnnt 4.318082 hw_loss 0.145179 lr 0.00037119 rank 5
2023-02-22 16:26:42,191 DEBUG TRAIN Batch 21/6300 loss 11.142452 loss_att 11.789570 loss_ctc 16.785290 loss_rnnt 10.039045 hw_loss 0.415509 lr 0.00037122 rank 0
2023-02-22 16:27:56,856 DEBUG TRAIN Batch 21/6400 loss 8.179815 loss_att 10.922150 loss_ctc 12.158932 loss_rnnt 7.007678 hw_loss 0.174605 lr 0.00037105 rank 2
2023-02-22 16:27:56,859 DEBUG TRAIN Batch 21/6400 loss 13.987467 loss_att 17.297014 loss_ctc 26.332748 loss_rnnt 11.542735 hw_loss 0.256471 lr 0.00037112 rank 4
2023-02-22 16:27:56,867 DEBUG TRAIN Batch 21/6400 loss 12.464417 loss_att 16.014605 loss_ctc 16.505424 loss_rnnt 11.073494 hw_loss 0.266409 lr 0.00037109 rank 3
2023-02-22 16:27:56,869 DEBUG TRAIN Batch 21/6400 loss 10.723589 loss_att 11.960275 loss_ctc 12.391249 loss_rnnt 10.069975 hw_loss 0.344853 lr 0.00037112 rank 0
2023-02-22 16:27:56,873 DEBUG TRAIN Batch 21/6400 loss 15.985898 loss_att 16.512726 loss_ctc 20.861868 loss_rnnt 15.065826 hw_loss 0.308580 lr 0.00037103 rank 7
2023-02-22 16:27:56,880 DEBUG TRAIN Batch 21/6400 loss 15.269706 loss_att 16.739559 loss_ctc 20.185017 loss_rnnt 14.217196 hw_loss 0.193434 lr 0.00037104 rank 6
2023-02-22 16:27:56,910 DEBUG TRAIN Batch 21/6400 loss 9.341533 loss_att 12.547262 loss_ctc 13.995418 loss_rnnt 7.985948 hw_loss 0.176101 lr 0.00037106 rank 1
2023-02-22 16:27:56,942 DEBUG TRAIN Batch 21/6400 loss 12.780416 loss_att 15.349043 loss_ctc 15.653093 loss_rnnt 11.758245 hw_loss 0.235167 lr 0.00037109 rank 5
2023-02-22 16:29:09,757 DEBUG TRAIN Batch 21/6500 loss 21.389519 loss_att 25.836151 loss_ctc 29.679539 loss_rnnt 19.255089 hw_loss 0.262059 lr 0.00037095 rank 2
2023-02-22 16:29:09,760 DEBUG TRAIN Batch 21/6500 loss 8.251271 loss_att 12.426210 loss_ctc 10.125348 loss_rnnt 7.008122 hw_loss 0.296780 lr 0.00037099 rank 3
2023-02-22 16:29:09,762 DEBUG TRAIN Batch 21/6500 loss 12.780965 loss_att 12.991277 loss_ctc 16.284819 loss_rnnt 12.149135 hw_loss 0.229851 lr 0.00037093 rank 7
2023-02-22 16:29:09,764 DEBUG TRAIN Batch 21/6500 loss 7.484420 loss_att 9.473155 loss_ctc 10.643007 loss_rnnt 6.461712 hw_loss 0.382155 lr 0.00037102 rank 4
2023-02-22 16:29:09,766 DEBUG TRAIN Batch 21/6500 loss 8.938384 loss_att 13.277349 loss_ctc 17.069878 loss_rnnt 6.855639 hw_loss 0.245162 lr 0.00037102 rank 0
2023-02-22 16:29:09,768 DEBUG TRAIN Batch 21/6500 loss 17.843483 loss_att 18.160763 loss_ctc 20.426888 loss_rnnt 17.264566 hw_loss 0.320636 lr 0.00037094 rank 6
2023-02-22 16:29:09,770 DEBUG TRAIN Batch 21/6500 loss 10.320557 loss_att 12.958882 loss_ctc 12.507511 loss_rnnt 9.443834 hw_loss 0.107743 lr 0.00037099 rank 5
2023-02-22 16:29:09,771 DEBUG TRAIN Batch 21/6500 loss 14.932835 loss_att 18.062729 loss_ctc 21.673223 loss_rnnt 13.278761 hw_loss 0.242580 lr 0.00037095 rank 1
2023-02-22 16:30:22,014 DEBUG TRAIN Batch 21/6600 loss 6.933959 loss_att 8.233847 loss_ctc 9.156147 loss_rnnt 6.207439 hw_loss 0.319220 lr 0.00037092 rank 4
2023-02-22 16:30:22,031 DEBUG TRAIN Batch 21/6600 loss 4.722272 loss_att 7.679016 loss_ctc 7.453664 loss_rnnt 3.672238 hw_loss 0.177187 lr 0.00037091 rank 0
2023-02-22 16:30:22,031 DEBUG TRAIN Batch 21/6600 loss 10.843275 loss_att 13.144816 loss_ctc 15.238847 loss_rnnt 9.663271 hw_loss 0.250538 lr 0.00037084 rank 6
2023-02-22 16:30:22,031 DEBUG TRAIN Batch 21/6600 loss 4.908875 loss_att 8.484207 loss_ctc 8.761567 loss_rnnt 3.637253 hw_loss 0.080369 lr 0.00037083 rank 7
2023-02-22 16:30:22,032 DEBUG TRAIN Batch 21/6600 loss 8.411434 loss_att 10.160628 loss_ctc 13.309248 loss_rnnt 7.224324 hw_loss 0.345429 lr 0.00037085 rank 2
2023-02-22 16:30:22,037 DEBUG TRAIN Batch 21/6600 loss 4.421762 loss_att 8.483037 loss_ctc 4.224878 loss_rnnt 3.534638 hw_loss 0.189599 lr 0.00037089 rank 3
2023-02-22 16:30:22,037 DEBUG TRAIN Batch 21/6600 loss 12.922492 loss_att 16.752249 loss_ctc 18.319117 loss_rnnt 11.314594 hw_loss 0.229493 lr 0.00037089 rank 5
2023-02-22 16:30:22,039 DEBUG TRAIN Batch 21/6600 loss 12.095486 loss_att 17.503454 loss_ctc 18.849430 loss_rnnt 9.986589 hw_loss 0.237703 lr 0.00037085 rank 1
2023-02-22 16:31:35,480 DEBUG TRAIN Batch 21/6700 loss 12.391748 loss_att 17.119640 loss_ctc 18.569317 loss_rnnt 10.482269 hw_loss 0.262921 lr 0.00037081 rank 4
2023-02-22 16:31:35,487 DEBUG TRAIN Batch 21/6700 loss 2.433789 loss_att 4.759674 loss_ctc 3.334215 loss_rnnt 1.737799 hw_loss 0.207669 lr 0.00037075 rank 1
2023-02-22 16:31:35,488 DEBUG TRAIN Batch 21/6700 loss 11.980844 loss_att 13.437782 loss_ctc 15.471842 loss_rnnt 11.118863 hw_loss 0.197116 lr 0.00037081 rank 0
2023-02-22 16:31:35,493 DEBUG TRAIN Batch 21/6700 loss 18.811230 loss_att 22.305618 loss_ctc 25.036564 loss_rnnt 17.075596 hw_loss 0.387580 lr 0.00037074 rank 6
2023-02-22 16:31:35,496 DEBUG TRAIN Batch 21/6700 loss 12.119665 loss_att 14.704020 loss_ctc 18.206175 loss_rnnt 10.614235 hw_loss 0.331923 lr 0.00037072 rank 7
2023-02-22 16:31:35,496 DEBUG TRAIN Batch 21/6700 loss 14.822984 loss_att 19.901554 loss_ctc 20.980383 loss_rnnt 12.903205 hw_loss 0.155771 lr 0.00037078 rank 3
2023-02-22 16:31:35,497 DEBUG TRAIN Batch 21/6700 loss 14.707242 loss_att 15.069132 loss_ctc 15.944590 loss_rnnt 14.339119 hw_loss 0.245186 lr 0.00037075 rank 2
2023-02-22 16:31:35,500 DEBUG TRAIN Batch 21/6700 loss 10.907405 loss_att 11.543612 loss_ctc 11.717757 loss_rnnt 10.491318 hw_loss 0.338999 lr 0.00037078 rank 5
2023-02-22 16:32:49,839 DEBUG TRAIN Batch 21/6800 loss 15.846465 loss_att 18.562193 loss_ctc 17.500542 loss_rnnt 14.956413 hw_loss 0.236929 lr 0.00037064 rank 2
2023-02-22 16:32:49,847 DEBUG TRAIN Batch 21/6800 loss 10.014575 loss_att 10.195355 loss_ctc 14.152306 loss_rnnt 9.258038 hw_loss 0.316282 lr 0.00037068 rank 3
2023-02-22 16:32:49,848 DEBUG TRAIN Batch 21/6800 loss 9.742688 loss_att 12.603386 loss_ctc 16.176706 loss_rnnt 8.169704 hw_loss 0.268077 lr 0.00037071 rank 4
2023-02-22 16:32:49,849 DEBUG TRAIN Batch 21/6800 loss 15.769026 loss_att 17.464211 loss_ctc 22.011356 loss_rnnt 14.465602 hw_loss 0.247642 lr 0.00037063 rank 6
2023-02-22 16:32:49,851 DEBUG TRAIN Batch 21/6800 loss 24.579847 loss_att 24.447842 loss_ctc 27.369314 loss_rnnt 24.025667 hw_loss 0.391219 lr 0.00037071 rank 0
2023-02-22 16:32:49,852 DEBUG TRAIN Batch 21/6800 loss 4.413695 loss_att 8.216143 loss_ctc 7.675609 loss_rnnt 3.038814 hw_loss 0.336507 lr 0.00037065 rank 1
2023-02-22 16:32:49,855 DEBUG TRAIN Batch 21/6800 loss 7.988032 loss_att 8.011071 loss_ctc 6.695985 loss_rnnt 8.060930 hw_loss 0.177688 lr 0.00037068 rank 5
2023-02-22 16:32:49,898 DEBUG TRAIN Batch 21/6800 loss 6.940212 loss_att 8.711262 loss_ctc 8.392078 loss_rnnt 6.181287 hw_loss 0.395874 lr 0.00037062 rank 7
2023-02-22 16:34:01,626 DEBUG TRAIN Batch 21/6900 loss 5.054109 loss_att 6.010981 loss_ctc 5.859817 loss_rnnt 4.540002 hw_loss 0.403697 lr 0.00037053 rank 6
2023-02-22 16:34:01,640 DEBUG TRAIN Batch 21/6900 loss 9.497334 loss_att 14.829300 loss_ctc 13.651083 loss_rnnt 7.809772 hw_loss 0.126255 lr 0.00037054 rank 2
2023-02-22 16:34:01,644 DEBUG TRAIN Batch 21/6900 loss 6.755395 loss_att 8.764977 loss_ctc 10.343820 loss_rnnt 5.742023 hw_loss 0.249375 lr 0.00037061 rank 4
2023-02-22 16:34:01,646 DEBUG TRAIN Batch 21/6900 loss 10.826112 loss_att 11.363037 loss_ctc 13.599216 loss_rnnt 10.120593 hw_loss 0.428227 lr 0.00037058 rank 5
2023-02-22 16:34:01,646 DEBUG TRAIN Batch 21/6900 loss 7.334651 loss_att 10.510974 loss_ctc 15.033802 loss_rnnt 5.521604 hw_loss 0.283553 lr 0.00037058 rank 3
2023-02-22 16:34:01,649 DEBUG TRAIN Batch 21/6900 loss 4.014910 loss_att 6.258595 loss_ctc 7.030948 loss_rnnt 2.948837 hw_loss 0.403495 lr 0.00037052 rank 7
2023-02-22 16:34:01,650 DEBUG TRAIN Batch 21/6900 loss 16.217474 loss_att 16.053143 loss_ctc 25.293259 loss_rnnt 14.925634 hw_loss 0.214877 lr 0.00037061 rank 0
2023-02-22 16:34:01,650 DEBUG TRAIN Batch 21/6900 loss 12.173798 loss_att 13.040154 loss_ctc 17.111837 loss_rnnt 11.238219 hw_loss 0.194816 lr 0.00037055 rank 1
2023-02-22 16:35:14,398 DEBUG TRAIN Batch 21/7000 loss 6.434777 loss_att 8.561509 loss_ctc 10.172550 loss_rnnt 5.293735 hw_loss 0.407487 lr 0.00037042 rank 7
2023-02-22 16:35:14,409 DEBUG TRAIN Batch 21/7000 loss 12.300286 loss_att 21.235912 loss_ctc 14.222240 loss_rnnt 10.202852 hw_loss 0.101340 lr 0.00037044 rank 2
2023-02-22 16:35:14,413 DEBUG TRAIN Batch 21/7000 loss 3.733299 loss_att 4.607821 loss_ctc 3.845104 loss_rnnt 3.277438 hw_loss 0.498842 lr 0.00037048 rank 3
2023-02-22 16:35:14,420 DEBUG TRAIN Batch 21/7000 loss 8.421833 loss_att 9.719547 loss_ctc 12.720136 loss_rnnt 7.494562 hw_loss 0.177414 lr 0.00037051 rank 0
2023-02-22 16:35:14,420 DEBUG TRAIN Batch 21/7000 loss 26.986446 loss_att 28.489681 loss_ctc 36.967403 loss_rnnt 25.198002 hw_loss 0.294377 lr 0.00037043 rank 6
2023-02-22 16:35:14,421 DEBUG TRAIN Batch 21/7000 loss 9.810549 loss_att 10.536823 loss_ctc 14.442433 loss_rnnt 8.772170 hw_loss 0.516637 lr 0.00037051 rank 4
2023-02-22 16:35:14,422 DEBUG TRAIN Batch 21/7000 loss 9.501259 loss_att 9.973182 loss_ctc 12.711553 loss_rnnt 8.654181 hw_loss 0.608727 lr 0.00037044 rank 1
2023-02-22 16:35:14,470 DEBUG TRAIN Batch 21/7000 loss 12.746693 loss_att 16.364761 loss_ctc 14.446627 loss_rnnt 11.694458 hw_loss 0.191179 lr 0.00037048 rank 5
2023-02-22 16:36:29,261 DEBUG TRAIN Batch 21/7100 loss 10.098830 loss_att 10.783362 loss_ctc 13.106981 loss_rnnt 9.318264 hw_loss 0.454824 lr 0.00037040 rank 0
2023-02-22 16:36:29,261 DEBUG TRAIN Batch 21/7100 loss 7.535176 loss_att 9.867855 loss_ctc 11.926640 loss_rnnt 6.366908 hw_loss 0.217881 lr 0.00037032 rank 7
2023-02-22 16:36:29,264 DEBUG TRAIN Batch 21/7100 loss 11.483801 loss_att 14.315353 loss_ctc 16.632011 loss_rnnt 10.110965 hw_loss 0.225182 lr 0.00037034 rank 1
2023-02-22 16:36:29,264 DEBUG TRAIN Batch 21/7100 loss 9.571637 loss_att 14.614773 loss_ctc 12.729933 loss_rnnt 7.913217 hw_loss 0.428789 lr 0.00037038 rank 3
2023-02-22 16:36:29,264 DEBUG TRAIN Batch 21/7100 loss 18.807714 loss_att 22.004698 loss_ctc 25.007225 loss_rnnt 17.235447 hw_loss 0.199255 lr 0.00037033 rank 6
2023-02-22 16:36:29,267 DEBUG TRAIN Batch 21/7100 loss 7.903184 loss_att 10.348273 loss_ctc 12.273654 loss_rnnt 6.661112 hw_loss 0.319360 lr 0.00037038 rank 5
2023-02-22 16:36:29,279 DEBUG TRAIN Batch 21/7100 loss 13.537981 loss_att 16.416771 loss_ctc 19.493851 loss_rnnt 12.021842 hw_loss 0.274249 lr 0.00037034 rank 2
2023-02-22 16:36:29,313 DEBUG TRAIN Batch 21/7100 loss 5.603484 loss_att 7.976934 loss_ctc 7.260372 loss_rnnt 4.767044 hw_loss 0.264060 lr 0.00037041 rank 4
2023-02-22 16:37:42,566 DEBUG TRAIN Batch 21/7200 loss 9.415173 loss_att 11.300972 loss_ctc 13.304067 loss_rnnt 8.395496 hw_loss 0.232495 lr 0.00037024 rank 2
2023-02-22 16:37:42,569 DEBUG TRAIN Batch 21/7200 loss 8.984667 loss_att 12.788992 loss_ctc 8.845818 loss_rnnt 8.029518 hw_loss 0.398993 lr 0.00037023 rank 6
2023-02-22 16:37:42,572 DEBUG TRAIN Batch 21/7200 loss 6.924469 loss_att 10.951501 loss_ctc 12.328949 loss_rnnt 5.271511 hw_loss 0.238039 lr 0.00037022 rank 7
2023-02-22 16:37:42,572 DEBUG TRAIN Batch 21/7200 loss 18.355804 loss_att 19.771278 loss_ctc 24.241352 loss_rnnt 17.153511 hw_loss 0.252110 lr 0.00037027 rank 3
2023-02-22 16:37:42,572 DEBUG TRAIN Batch 21/7200 loss 7.786342 loss_att 10.480229 loss_ctc 10.514236 loss_rnnt 6.790512 hw_loss 0.174999 lr 0.00037028 rank 5
2023-02-22 16:37:42,573 DEBUG TRAIN Batch 21/7200 loss 9.923917 loss_att 14.001592 loss_ctc 21.063702 loss_rnnt 7.542216 hw_loss 0.151615 lr 0.00037030 rank 0
2023-02-22 16:37:42,576 DEBUG TRAIN Batch 21/7200 loss 6.493525 loss_att 8.504673 loss_ctc 8.661917 loss_rnnt 5.633259 hw_loss 0.316720 lr 0.00037030 rank 4
2023-02-22 16:37:42,579 DEBUG TRAIN Batch 21/7200 loss 8.889618 loss_att 12.650337 loss_ctc 17.637272 loss_rnnt 6.793699 hw_loss 0.332664 lr 0.00037024 rank 1
2023-02-22 16:38:55,030 DEBUG TRAIN Batch 21/7300 loss 11.272561 loss_att 13.519825 loss_ctc 18.475790 loss_rnnt 9.699713 hw_loss 0.305557 lr 0.00037014 rank 2
2023-02-22 16:38:55,031 DEBUG TRAIN Batch 21/7300 loss 9.452435 loss_att 10.784058 loss_ctc 15.975197 loss_rnnt 8.114700 hw_loss 0.378202 lr 0.00037014 rank 1
2023-02-22 16:38:55,031 DEBUG TRAIN Batch 21/7300 loss 24.841114 loss_att 24.488186 loss_ctc 34.201603 loss_rnnt 23.477108 hw_loss 0.349742 lr 0.00037017 rank 3
2023-02-22 16:38:55,033 DEBUG TRAIN Batch 21/7300 loss 6.297610 loss_att 10.081034 loss_ctc 9.051016 loss_rnnt 4.942356 hw_loss 0.433966 lr 0.00037020 rank 0
2023-02-22 16:38:55,033 DEBUG TRAIN Batch 21/7300 loss 13.772404 loss_att 16.738186 loss_ctc 20.902287 loss_rnnt 12.105257 hw_loss 0.231259 lr 0.00037013 rank 6
2023-02-22 16:38:55,038 DEBUG TRAIN Batch 21/7300 loss 10.787120 loss_att 12.109065 loss_ctc 13.505404 loss_rnnt 10.075820 hw_loss 0.158389 lr 0.00037017 rank 5
2023-02-22 16:38:55,069 DEBUG TRAIN Batch 21/7300 loss 8.544047 loss_att 11.091469 loss_ctc 14.661993 loss_rnnt 7.139980 hw_loss 0.147858 lr 0.00037020 rank 4
2023-02-22 16:38:55,075 DEBUG TRAIN Batch 21/7300 loss 12.528701 loss_att 14.996638 loss_ctc 19.427769 loss_rnnt 10.988050 hw_loss 0.238479 lr 0.00037011 rank 7
2023-02-22 16:40:07,504 DEBUG TRAIN Batch 21/7400 loss 4.342831 loss_att 5.311649 loss_ctc 6.561073 loss_rnnt 3.724834 hw_loss 0.240878 lr 0.00037003 rank 2
2023-02-22 16:40:07,506 DEBUG TRAIN Batch 21/7400 loss 4.199040 loss_att 6.601037 loss_ctc 6.674579 loss_rnnt 3.278102 hw_loss 0.207124 lr 0.00037007 rank 3
2023-02-22 16:40:07,508 DEBUG TRAIN Batch 21/7400 loss 13.669066 loss_att 18.621262 loss_ctc 16.579508 loss_rnnt 12.185088 hw_loss 0.197778 lr 0.00037003 rank 6
2023-02-22 16:40:07,508 DEBUG TRAIN Batch 21/7400 loss 12.041055 loss_att 15.370518 loss_ctc 17.252827 loss_rnnt 10.504380 hw_loss 0.329774 lr 0.00037010 rank 4
2023-02-22 16:40:07,509 DEBUG TRAIN Batch 21/7400 loss 9.701626 loss_att 13.597483 loss_ctc 19.289928 loss_rnnt 7.520196 hw_loss 0.232157 lr 0.00037001 rank 7
2023-02-22 16:40:07,512 DEBUG TRAIN Batch 21/7400 loss 6.094438 loss_att 7.102361 loss_ctc 6.993676 loss_rnnt 5.625133 hw_loss 0.277165 lr 0.00037007 rank 5
2023-02-22 16:40:07,513 DEBUG TRAIN Batch 21/7400 loss 11.718118 loss_att 13.671453 loss_ctc 19.576752 loss_rnnt 10.147793 hw_loss 0.247199 lr 0.00037010 rank 0
2023-02-22 16:40:07,550 DEBUG TRAIN Batch 21/7400 loss 6.262031 loss_att 9.940485 loss_ctc 7.006292 loss_rnnt 5.360014 hw_loss 0.125796 lr 0.00037004 rank 1
2023-02-22 16:41:22,418 DEBUG TRAIN Batch 21/7500 loss 14.620787 loss_att 21.197111 loss_ctc 24.606573 loss_rnnt 11.900004 hw_loss 0.138897 lr 0.00036992 rank 6
2023-02-22 16:41:22,419 DEBUG TRAIN Batch 21/7500 loss 11.725002 loss_att 11.854037 loss_ctc 15.621305 loss_rnnt 10.987958 hw_loss 0.359496 lr 0.00036993 rank 2
2023-02-22 16:41:22,420 DEBUG TRAIN Batch 21/7500 loss 12.464728 loss_att 11.338145 loss_ctc 16.010090 loss_rnnt 11.915188 hw_loss 0.566515 lr 0.00036997 rank 5
2023-02-22 16:41:22,420 DEBUG TRAIN Batch 21/7500 loss 4.670651 loss_att 7.052354 loss_ctc 7.611615 loss_rnnt 3.717030 hw_loss 0.159661 lr 0.00037000 rank 0
2023-02-22 16:41:22,422 DEBUG TRAIN Batch 21/7500 loss 7.864197 loss_att 8.202066 loss_ctc 10.790668 loss_rnnt 7.195415 hw_loss 0.395648 lr 0.00036997 rank 3
2023-02-22 16:41:22,426 DEBUG TRAIN Batch 21/7500 loss 7.528688 loss_att 10.134782 loss_ctc 11.369100 loss_rnnt 6.308514 hw_loss 0.350438 lr 0.00037000 rank 4
2023-02-22 16:41:22,427 DEBUG TRAIN Batch 21/7500 loss 4.558092 loss_att 7.705375 loss_ctc 7.502800 loss_rnnt 3.432575 hw_loss 0.193936 lr 0.00036994 rank 1
2023-02-22 16:41:22,428 DEBUG TRAIN Batch 21/7500 loss 4.122589 loss_att 6.117969 loss_ctc 5.817314 loss_rnnt 3.391601 hw_loss 0.198651 lr 0.00036991 rank 7
2023-02-22 16:42:35,273 DEBUG TRAIN Batch 21/7600 loss 8.403892 loss_att 11.592993 loss_ctc 9.845092 loss_rnnt 7.471477 hw_loss 0.192066 lr 0.00036987 rank 3
2023-02-22 16:42:35,290 DEBUG TRAIN Batch 21/7600 loss 6.381999 loss_att 6.593362 loss_ctc 8.506853 loss_rnnt 5.807157 hw_loss 0.467356 lr 0.00036981 rank 7
2023-02-22 16:42:35,290 DEBUG TRAIN Batch 21/7600 loss 3.263433 loss_att 6.667898 loss_ctc 5.751853 loss_rnnt 2.068954 hw_loss 0.340867 lr 0.00036982 rank 6
2023-02-22 16:42:35,292 DEBUG TRAIN Batch 21/7600 loss 25.116316 loss_att 32.227776 loss_ctc 36.069473 loss_rnnt 22.157280 hw_loss 0.143106 lr 0.00036983 rank 2
2023-02-22 16:42:35,294 DEBUG TRAIN Batch 21/7600 loss 2.871980 loss_att 3.358422 loss_ctc 2.893671 loss_rnnt 2.508168 hw_loss 0.494310 lr 0.00036984 rank 1
2023-02-22 16:42:35,293 DEBUG TRAIN Batch 21/7600 loss 14.260034 loss_att 19.808546 loss_ctc 20.435085 loss_rnnt 12.240143 hw_loss 0.162841 lr 0.00036990 rank 0
2023-02-22 16:42:35,296 DEBUG TRAIN Batch 21/7600 loss 7.285448 loss_att 8.960258 loss_ctc 8.735970 loss_rnnt 6.572332 hw_loss 0.346406 lr 0.00036990 rank 4
2023-02-22 16:42:35,298 DEBUG TRAIN Batch 21/7600 loss 4.602708 loss_att 9.373192 loss_ctc 6.671896 loss_rnnt 3.219592 hw_loss 0.287114 lr 0.00036987 rank 5
2023-02-22 16:43:47,896 DEBUG TRAIN Batch 21/7700 loss 10.269823 loss_att 10.465252 loss_ctc 12.454300 loss_rnnt 9.620708 hw_loss 0.597684 lr 0.00036977 rank 3
2023-02-22 16:43:47,897 DEBUG TRAIN Batch 21/7700 loss 5.380601 loss_att 8.384974 loss_ctc 10.757193 loss_rnnt 3.911232 hw_loss 0.284280 lr 0.00036973 rank 2
2023-02-22 16:43:47,897 DEBUG TRAIN Batch 21/7700 loss 4.090127 loss_att 6.037945 loss_ctc 7.049803 loss_rnnt 3.167620 hw_loss 0.259350 lr 0.00036971 rank 7
2023-02-22 16:43:47,900 DEBUG TRAIN Batch 21/7700 loss 11.258175 loss_att 13.950508 loss_ctc 15.963950 loss_rnnt 9.895031 hw_loss 0.369827 lr 0.00036972 rank 6
2023-02-22 16:43:47,905 DEBUG TRAIN Batch 21/7700 loss 4.857016 loss_att 9.356407 loss_ctc 7.740415 loss_rnnt 3.433409 hw_loss 0.261141 lr 0.00036977 rank 5
2023-02-22 16:43:47,933 DEBUG TRAIN Batch 21/7700 loss 9.008456 loss_att 9.397207 loss_ctc 13.025965 loss_rnnt 8.228699 hw_loss 0.311887 lr 0.00036980 rank 0
2023-02-22 16:43:47,936 DEBUG TRAIN Batch 21/7700 loss 4.438823 loss_att 8.842030 loss_ctc 5.005801 loss_rnnt 3.402552 hw_loss 0.150061 lr 0.00036980 rank 4
2023-02-22 16:43:47,951 DEBUG TRAIN Batch 21/7700 loss 6.297829 loss_att 8.358866 loss_ctc 8.102283 loss_rnnt 5.559222 hw_loss 0.160885 lr 0.00036973 rank 1
2023-02-22 16:45:02,315 DEBUG TRAIN Batch 21/7800 loss 11.271863 loss_att 15.628849 loss_ctc 20.986038 loss_rnnt 8.935266 hw_loss 0.318705 lr 0.00036970 rank 4
2023-02-22 16:45:02,315 DEBUG TRAIN Batch 21/7800 loss 5.585019 loss_att 7.947824 loss_ctc 7.373176 loss_rnnt 4.755548 hw_loss 0.222164 lr 0.00036963 rank 2
2023-02-22 16:45:02,317 DEBUG TRAIN Batch 21/7800 loss 10.736655 loss_att 14.988143 loss_ctc 17.746695 loss_rnnt 8.806432 hw_loss 0.272351 lr 0.00036967 rank 3
2023-02-22 16:45:02,319 DEBUG TRAIN Batch 21/7800 loss 9.322162 loss_att 10.661600 loss_ctc 11.488909 loss_rnnt 8.575778 hw_loss 0.355495 lr 0.00036967 rank 5
2023-02-22 16:45:02,319 DEBUG TRAIN Batch 21/7800 loss 7.168655 loss_att 9.030424 loss_ctc 9.797411 loss_rnnt 6.313282 hw_loss 0.248471 lr 0.00036970 rank 0
2023-02-22 16:45:02,323 DEBUG TRAIN Batch 21/7800 loss 2.960419 loss_att 6.680162 loss_ctc 6.956161 loss_rnnt 1.537163 hw_loss 0.274767 lr 0.00036962 rank 6
2023-02-22 16:45:02,331 DEBUG TRAIN Batch 21/7800 loss 5.886670 loss_att 7.754203 loss_ctc 6.693611 loss_rnnt 5.194021 hw_loss 0.396657 lr 0.00036963 rank 1
2023-02-22 16:45:02,372 DEBUG TRAIN Batch 21/7800 loss 13.563076 loss_att 17.712711 loss_ctc 16.830402 loss_rnnt 12.113043 hw_loss 0.345867 lr 0.00036961 rank 7
2023-02-22 16:46:16,195 DEBUG TRAIN Batch 21/7900 loss 4.918389 loss_att 7.315594 loss_ctc 7.735090 loss_rnnt 3.923218 hw_loss 0.262820 lr 0.00036953 rank 2
2023-02-22 16:46:16,200 DEBUG TRAIN Batch 21/7900 loss 6.883989 loss_att 10.804241 loss_ctc 9.953959 loss_rnnt 5.565779 hw_loss 0.234058 lr 0.00036957 rank 3
2023-02-22 16:46:16,203 DEBUG TRAIN Batch 21/7900 loss 8.670843 loss_att 11.287840 loss_ctc 13.451368 loss_rnnt 7.324362 hw_loss 0.348147 lr 0.00036952 rank 6
2023-02-22 16:46:16,204 DEBUG TRAIN Batch 21/7900 loss 8.222308 loss_att 11.030490 loss_ctc 10.049515 loss_rnnt 7.292564 hw_loss 0.233399 lr 0.00036959 rank 0
2023-02-22 16:46:16,206 DEBUG TRAIN Batch 21/7900 loss 18.777657 loss_att 24.205256 loss_ctc 27.599945 loss_rnnt 16.421619 hw_loss 0.176651 lr 0.00036953 rank 1
2023-02-22 16:46:16,206 DEBUG TRAIN Batch 21/7900 loss 10.854659 loss_att 10.150791 loss_ctc 12.293623 loss_rnnt 10.609034 hw_loss 0.364759 lr 0.00036957 rank 5
2023-02-22 16:46:16,206 DEBUG TRAIN Batch 21/7900 loss 16.592766 loss_att 20.265717 loss_ctc 20.011583 loss_rnnt 15.223211 hw_loss 0.335854 lr 0.00036960 rank 4
2023-02-22 16:46:16,209 DEBUG TRAIN Batch 21/7900 loss 11.753711 loss_att 12.928026 loss_ctc 21.102432 loss_rnnt 10.106892 hw_loss 0.310235 lr 0.00036951 rank 7
2023-02-22 16:47:28,919 DEBUG TRAIN Batch 21/8000 loss 4.646695 loss_att 7.068673 loss_ctc 6.883926 loss_rnnt 3.724942 hw_loss 0.260737 lr 0.00036943 rank 2
2023-02-22 16:47:28,925 DEBUG TRAIN Batch 21/8000 loss 6.092041 loss_att 9.825684 loss_ctc 10.164559 loss_rnnt 4.586108 hw_loss 0.405379 lr 0.00036942 rank 6
2023-02-22 16:47:28,929 DEBUG TRAIN Batch 21/8000 loss 9.053658 loss_att 11.336782 loss_ctc 10.493248 loss_rnnt 8.231288 hw_loss 0.325874 lr 0.00036949 rank 4
2023-02-22 16:47:28,929 DEBUG TRAIN Batch 21/8000 loss 9.939192 loss_att 15.154943 loss_ctc 17.155527 loss_rnnt 7.798769 hw_loss 0.253301 lr 0.00036949 rank 0
2023-02-22 16:47:28,930 DEBUG TRAIN Batch 21/8000 loss 11.861008 loss_att 14.659318 loss_ctc 18.326366 loss_rnnt 10.334580 hw_loss 0.196342 lr 0.00036947 rank 3
2023-02-22 16:47:28,932 DEBUG TRAIN Batch 21/8000 loss 11.989829 loss_att 13.722334 loss_ctc 16.629913 loss_rnnt 10.863089 hw_loss 0.302927 lr 0.00036943 rank 1
2023-02-22 16:47:28,932 DEBUG TRAIN Batch 21/8000 loss 3.014294 loss_att 7.160342 loss_ctc 4.700232 loss_rnnt 1.883784 hw_loss 0.143454 lr 0.00036941 rank 7
2023-02-22 16:47:28,933 DEBUG TRAIN Batch 21/8000 loss 4.189567 loss_att 5.908522 loss_ctc 5.514956 loss_rnnt 3.559711 hw_loss 0.205025 lr 0.00036947 rank 5
2023-02-22 16:48:41,793 DEBUG TRAIN Batch 21/8100 loss 8.788453 loss_att 10.599691 loss_ctc 7.668284 loss_rnnt 8.408124 hw_loss 0.313946 lr 0.00036931 rank 7
2023-02-22 16:48:41,793 DEBUG TRAIN Batch 21/8100 loss 7.249021 loss_att 9.078869 loss_ctc 9.356429 loss_rnnt 6.381698 hw_loss 0.413187 lr 0.00036939 rank 0
2023-02-22 16:48:41,799 DEBUG TRAIN Batch 21/8100 loss 8.850189 loss_att 10.536507 loss_ctc 11.351734 loss_rnnt 8.028631 hw_loss 0.282667 lr 0.00036936 rank 3
2023-02-22 16:48:41,801 DEBUG TRAIN Batch 21/8100 loss 11.105262 loss_att 13.515485 loss_ctc 14.922989 loss_rnnt 9.907710 hw_loss 0.387144 lr 0.00036933 rank 2
2023-02-22 16:48:41,805 DEBUG TRAIN Batch 21/8100 loss 12.046989 loss_att 13.987331 loss_ctc 14.572561 loss_rnnt 11.136990 hw_loss 0.347228 lr 0.00036933 rank 1
2023-02-22 16:48:41,804 DEBUG TRAIN Batch 21/8100 loss 3.110369 loss_att 5.134290 loss_ctc 5.029895 loss_rnnt 2.276809 hw_loss 0.324073 lr 0.00036939 rank 4
2023-02-22 16:48:41,804 DEBUG TRAIN Batch 21/8100 loss 9.229161 loss_att 10.992757 loss_ctc 13.481863 loss_rnnt 8.071362 hw_loss 0.446348 lr 0.00036932 rank 6
2023-02-22 16:48:41,804 DEBUG TRAIN Batch 21/8100 loss 10.668272 loss_att 11.482784 loss_ctc 16.126532 loss_rnnt 9.538749 hw_loss 0.447851 lr 0.00036937 rank 5
2023-02-22 16:49:55,114 DEBUG TRAIN Batch 21/8200 loss 6.059652 loss_att 9.050520 loss_ctc 10.198652 loss_rnnt 4.802635 hw_loss 0.200582 lr 0.00036923 rank 2
2023-02-22 16:49:55,116 DEBUG TRAIN Batch 21/8200 loss 14.254221 loss_att 14.696230 loss_ctc 18.738029 loss_rnnt 13.435431 hw_loss 0.248527 lr 0.00036926 rank 3
2023-02-22 16:49:55,119 DEBUG TRAIN Batch 21/8200 loss 10.555984 loss_att 14.082943 loss_ctc 14.698744 loss_rnnt 9.138563 hw_loss 0.299361 lr 0.00036923 rank 1
2023-02-22 16:49:55,119 DEBUG TRAIN Batch 21/8200 loss 8.526841 loss_att 10.691950 loss_ctc 10.404337 loss_rnnt 7.734861 hw_loss 0.203675 lr 0.00036929 rank 4
2023-02-22 16:49:55,119 DEBUG TRAIN Batch 21/8200 loss 10.045489 loss_att 11.533686 loss_ctc 12.727335 loss_rnnt 9.263979 hw_loss 0.236797 lr 0.00036926 rank 5
2023-02-22 16:49:55,122 DEBUG TRAIN Batch 21/8200 loss 7.252161 loss_att 12.755604 loss_ctc 14.310267 loss_rnnt 5.086738 hw_loss 0.231851 lr 0.00036922 rank 6
2023-02-22 16:49:55,122 DEBUG TRAIN Batch 21/8200 loss 6.883364 loss_att 7.970792 loss_ctc 10.032562 loss_rnnt 6.051562 hw_loss 0.364542 lr 0.00036921 rank 7
2023-02-22 16:49:55,123 DEBUG TRAIN Batch 21/8200 loss 17.250296 loss_att 19.082165 loss_ctc 27.217442 loss_rnnt 15.413860 hw_loss 0.264578 lr 0.00036929 rank 0
2023-02-22 16:51:07,601 DEBUG TRAIN Batch 21/8300 loss 7.422239 loss_att 12.227657 loss_ctc 10.432246 loss_rnnt 5.938928 hw_loss 0.226675 lr 0.00036916 rank 3
2023-02-22 16:51:07,602 DEBUG TRAIN Batch 21/8300 loss 8.486641 loss_att 11.731873 loss_ctc 11.737707 loss_rnnt 7.260042 hw_loss 0.270146 lr 0.00036912 rank 6
2023-02-22 16:51:07,602 DEBUG TRAIN Batch 21/8300 loss 12.776683 loss_att 15.267937 loss_ctc 20.646990 loss_rnnt 11.058516 hw_loss 0.319767 lr 0.00036913 rank 2
2023-02-22 16:51:07,604 DEBUG TRAIN Batch 21/8300 loss 4.962380 loss_att 6.732406 loss_ctc 7.313468 loss_rnnt 4.137609 hw_loss 0.294913 lr 0.00036910 rank 7
2023-02-22 16:51:07,604 DEBUG TRAIN Batch 21/8300 loss 5.390431 loss_att 7.902538 loss_ctc 7.524304 loss_rnnt 4.421516 hw_loss 0.341206 lr 0.00036919 rank 4
2023-02-22 16:51:07,606 DEBUG TRAIN Batch 21/8300 loss 9.455941 loss_att 13.399328 loss_ctc 10.915037 loss_rnnt 8.279917 hw_loss 0.361502 lr 0.00036916 rank 5
2023-02-22 16:51:07,611 DEBUG TRAIN Batch 21/8300 loss 8.722801 loss_att 11.647439 loss_ctc 11.929790 loss_rnnt 7.481136 hw_loss 0.429635 lr 0.00036913 rank 1
2023-02-22 16:51:07,655 DEBUG TRAIN Batch 21/8300 loss 16.512667 loss_att 19.332623 loss_ctc 19.494957 loss_rnnt 15.320689 hw_loss 0.431907 lr 0.00036919 rank 0
2023-02-22 16:52:04,661 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 1
2023-02-22 16:52:04,661 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 5
2023-02-22 16:52:04,663 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 0
2023-02-22 16:52:04,665 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 3
2023-02-22 16:52:04,668 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 2
2023-02-22 16:52:04,670 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 4
2023-02-22 16:52:04,675 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 7
2023-02-22 16:52:04,678 DEBUG CV Batch 21/0 loss 2.242794 loss_att 2.269458 loss_ctc 2.778304 loss_rnnt 1.690343 hw_loss 0.891967 history loss 2.159727 rank 6
2023-02-22 16:52:16,043 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 1
2023-02-22 16:52:16,064 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 4
2023-02-22 16:52:16,108 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 3
2023-02-22 16:52:16,124 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 0
2023-02-22 16:52:16,134 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 2
2023-02-22 16:52:16,148 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 7
2023-02-22 16:52:16,513 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 5
2023-02-22 16:52:16,580 DEBUG CV Batch 21/100 loss 5.977314 loss_att 7.265907 loss_ctc 10.536951 loss_rnnt 4.982965 hw_loss 0.241273 history loss 3.459954 rank 6
2023-02-22 16:52:29,608 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 0
2023-02-22 16:52:29,636 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 2
2023-02-22 16:52:29,692 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 4
2023-02-22 16:52:29,713 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 1
2023-02-22 16:52:29,731 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 7
2023-02-22 16:52:29,745 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 3
2023-02-22 16:52:30,125 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 5
2023-02-22 16:52:30,609 DEBUG CV Batch 21/200 loss 6.724814 loss_att 15.205742 loss_ctc 6.091982 loss_rnnt 4.986778 hw_loss 0.236678 history loss 4.114291 rank 6
2023-02-22 16:52:41,705 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 1
2023-02-22 16:52:41,916 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 7
2023-02-22 16:52:42,058 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 0
2023-02-22 16:52:42,066 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 4
2023-02-22 16:52:42,128 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 2
2023-02-22 16:52:42,249 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 3
2023-02-22 16:52:42,574 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 5
2023-02-22 16:52:43,048 DEBUG CV Batch 21/300 loss 4.697736 loss_att 5.229096 loss_ctc 6.454124 loss_rnnt 4.211002 hw_loss 0.274268 history loss 4.291447 rank 6
2023-02-22 16:52:53,816 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 1
2023-02-22 16:52:54,039 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 7
2023-02-22 16:52:54,342 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 0
2023-02-22 16:52:54,369 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 2
2023-02-22 16:52:54,563 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 3
2023-02-22 16:52:54,619 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 5
2023-02-22 16:52:54,821 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 4
2023-02-22 16:52:55,634 DEBUG CV Batch 21/400 loss 21.154713 loss_att 95.229622 loss_ctc 7.346835 loss_rnnt 8.127237 hw_loss 0.100394 history loss 5.207013 rank 6
2023-02-22 16:53:04,356 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 1
2023-02-22 16:53:05,010 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 7
2023-02-22 16:53:05,292 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 2
2023-02-22 16:53:05,380 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 3
2023-02-22 16:53:05,433 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 0
2023-02-22 16:53:05,559 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 5
2023-02-22 16:53:05,593 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 4
2023-02-22 16:53:06,694 DEBUG CV Batch 21/500 loss 5.552743 loss_att 5.828121 loss_ctc 7.469026 loss_rnnt 5.087389 hw_loss 0.290204 history loss 5.882762 rank 6
2023-02-22 16:53:16,353 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 1
2023-02-22 16:53:17,439 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 7
2023-02-22 16:53:17,617 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 2
2023-02-22 16:53:17,636 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 3
2023-02-22 16:53:17,804 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 0
2023-02-22 16:53:17,820 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 5
2023-02-22 16:53:17,863 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 4
2023-02-22 16:53:19,338 DEBUG CV Batch 21/600 loss 6.049710 loss_att 6.132257 loss_ctc 8.193931 loss_rnnt 5.442098 hw_loss 0.572262 history loss 6.823007 rank 6
2023-02-22 16:53:27,839 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 1
2023-02-22 16:53:28,830 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 7
2023-02-22 16:53:29,180 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 2
2023-02-22 16:53:29,251 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 3
2023-02-22 16:53:29,275 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 4
2023-02-22 16:53:29,459 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 0
2023-02-22 16:53:29,610 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 5
2023-02-22 16:53:31,155 DEBUG CV Batch 21/700 loss 12.828811 loss_att 36.352062 loss_ctc 18.482080 loss_rnnt 7.329187 hw_loss 0.077259 history loss 7.498275 rank 6
2023-02-22 16:53:39,225 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 1
2023-02-22 16:53:40,351 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 7
2023-02-22 16:53:40,765 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 2
2023-02-22 16:53:40,886 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 3
2023-02-22 16:53:40,960 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 4
2023-02-22 16:53:41,246 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 5
2023-02-22 16:53:41,370 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 0
2023-02-22 16:53:42,820 DEBUG CV Batch 21/800 loss 9.354630 loss_att 10.411267 loss_ctc 17.038816 loss_rnnt 8.044736 hw_loss 0.138764 history loss 6.952203 rank 6
2023-02-22 16:53:52,575 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 1
2023-02-22 16:53:53,789 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 7
2023-02-22 16:53:54,198 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 4
2023-02-22 16:53:54,372 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 2
2023-02-22 16:53:54,418 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 3
2023-02-22 16:53:54,649 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 5
2023-02-22 16:53:55,400 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 0
2023-02-22 16:53:56,565 DEBUG CV Batch 21/900 loss 11.061882 loss_att 16.258356 loss_ctc 25.703947 loss_rnnt 7.952692 hw_loss 0.220538 history loss 6.769490 rank 6
2023-02-22 16:54:04,998 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 1
2023-02-22 16:54:06,282 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 7
2023-02-22 16:54:06,699 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 4
2023-02-22 16:54:06,742 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 3
2023-02-22 16:54:06,805 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 2
2023-02-22 16:54:07,300 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 5
2023-02-22 16:54:08,176 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 0
2023-02-22 16:54:09,468 DEBUG CV Batch 21/1000 loss 3.543863 loss_att 4.077045 loss_ctc 5.058388 loss_rnnt 3.053085 hw_loss 0.341632 history loss 6.551400 rank 6
2023-02-22 16:54:17,133 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768979 history loss 6.532617 rank 1
2023-02-22 16:54:18,344 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768979 history loss 6.532617 rank 7
2023-02-22 16:54:18,554 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768979 history loss 6.532617 rank 4
2023-02-22 16:54:18,990 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768979 history loss 6.532617 rank 3
2023-02-22 16:54:19,050 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768979 history loss 6.532617 rank 2
2023-02-22 16:54:19,319 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768979 history loss 6.532617 rank 5
2023-02-22 16:54:20,512 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768980 history loss 6.532617 rank 0
2023-02-22 16:54:21,839 DEBUG CV Batch 21/1100 loss 6.436934 loss_att 5.591720 loss_ctc 8.612848 loss_rnnt 5.905733 hw_loss 0.768979 history loss 6.532617 rank 6
2023-02-22 16:54:28,236 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 1
2023-02-22 16:54:29,345 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 7
2023-02-22 16:54:29,358 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 4
2023-02-22 16:54:29,911 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 3
2023-02-22 16:54:30,055 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 2
2023-02-22 16:54:30,323 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 5
2023-02-22 16:54:31,669 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 0
2023-02-22 16:54:33,109 DEBUG CV Batch 21/1200 loss 5.527248 loss_att 6.254475 loss_ctc 8.116628 loss_rnnt 4.827981 hw_loss 0.391072 history loss 6.822156 rank 6
2023-02-22 16:54:40,311 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 1
2023-02-22 16:54:41,381 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 4
2023-02-22 16:54:41,866 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 7
2023-02-22 16:54:42,243 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 3
2023-02-22 16:54:42,340 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 2
2023-02-22 16:54:42,710 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 5
2023-02-22 16:54:44,235 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 0
2023-02-22 16:54:45,662 DEBUG CV Batch 21/1300 loss 5.052783 loss_att 4.981540 loss_ctc 6.909522 loss_rnnt 4.568119 hw_loss 0.471277 history loss 7.129649 rank 6
2023-02-22 16:54:51,512 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 1
2023-02-22 16:54:53,069 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 4
2023-02-22 16:54:53,307 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 7
2023-02-22 16:54:53,774 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 3
2023-02-22 16:54:53,867 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 2
2023-02-22 16:54:54,105 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 5
2023-02-22 16:54:55,975 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 0
2023-02-22 16:54:57,458 DEBUG CV Batch 21/1400 loss 5.292017 loss_att 22.110615 loss_ctc 2.928158 loss_rnnt 2.110952 hw_loss 0.248486 history loss 7.459775 rank 6
2023-02-22 16:55:02,981 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 1
2023-02-22 16:55:04,797 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 4
2023-02-22 16:55:05,218 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 7
2023-02-22 16:55:05,551 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 3
2023-02-22 16:55:05,650 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 2
2023-02-22 16:55:05,858 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 5
2023-02-22 16:55:08,211 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 0
2023-02-22 16:55:09,586 DEBUG CV Batch 21/1500 loss 6.833026 loss_att 7.402799 loss_ctc 7.109037 loss_rnnt 6.528989 hw_loss 0.287402 history loss 7.293317 rank 6
2023-02-22 16:55:15,964 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 1
2023-02-22 16:55:17,862 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 4
2023-02-22 16:55:18,605 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 7
2023-02-22 16:55:18,862 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 3
2023-02-22 16:55:18,964 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 2
2023-02-22 16:55:19,256 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 5
2023-02-22 16:55:21,518 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 0
2023-02-22 16:55:23,001 DEBUG CV Batch 21/1600 loss 10.489199 loss_att 17.471855 loss_ctc 10.824145 loss_rnnt 8.931152 hw_loss 0.219105 history loss 7.238070 rank 6
2023-02-22 16:55:28,801 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 1
2023-02-22 16:55:30,359 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 4
2023-02-22 16:55:31,373 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 3
2023-02-22 16:55:31,376 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 7
2023-02-22 16:55:31,430 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 2
2023-02-22 16:55:31,831 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 5
2023-02-22 16:55:34,164 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 0
2023-02-22 16:55:35,526 DEBUG CV Batch 21/1700 loss 7.440969 loss_att 7.431813 loss_ctc 12.773354 loss_rnnt 6.402415 hw_loss 0.617626 history loss 7.154317 rank 6
2023-02-22 16:55:37,838 INFO Epoch 21 CV info cv_loss 7.128258483915388
2023-02-22 16:55:37,839 INFO Epoch 22 TRAIN info lr 0.00036909667826959746
2023-02-22 16:55:37,844 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:55:39,411 INFO Epoch 21 CV info cv_loss 7.128258481951252
2023-02-22 16:55:39,412 INFO Epoch 22 TRAIN info lr 0.00036915904488261865
2023-02-22 16:55:39,416 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:55:40,458 INFO Epoch 21 CV info cv_loss 7.12825848116732
2023-02-22 16:55:40,458 INFO Epoch 22 TRAIN info lr 0.0003691359051925666
2023-02-22 16:55:40,463 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:55:40,489 INFO Epoch 21 CV info cv_loss 7.128258481516213
2023-02-22 16:55:40,489 INFO Epoch 22 TRAIN info lr 0.0003690655068141615
2023-02-22 16:55:40,491 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:55:40,551 INFO Epoch 21 CV info cv_loss 7.128258481253467
2023-02-22 16:55:40,552 INFO Epoch 22 TRAIN info lr 0.0003690574638495398
2023-02-22 16:55:40,556 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:55:41,155 INFO Epoch 21 CV info cv_loss 7.128258482687803
2023-02-22 16:55:41,156 INFO Epoch 22 TRAIN info lr 0.00036909667826959746
2023-02-22 16:55:41,161 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:55:43,446 INFO Epoch 21 CV info cv_loss 7.128258479285023
2023-02-22 16:55:43,447 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/21.pt
2023-02-22 16:55:44,034 INFO Epoch 22 TRAIN info lr 0.000369168100728576
2023-02-22 16:55:44,039 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:55:44,857 INFO Epoch 21 CV info cv_loss 7.1282584814860614
2023-02-22 16:55:44,858 INFO Epoch 22 TRAIN info lr 0.00036904540038848823
2023-02-22 16:55:44,864 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:56:45,498 DEBUG TRAIN Batch 22/0 loss 9.200948 loss_att 9.849995 loss_ctc 11.956852 loss_rnnt 8.368005 hw_loss 0.629399 lr 0.00036906 rank 7
2023-02-22 16:56:45,499 DEBUG TRAIN Batch 22/0 loss 8.183882 loss_att 8.051763 loss_ctc 11.566550 loss_rnnt 7.470851 hw_loss 0.540810 lr 0.00036916 rank 4
2023-02-22 16:56:45,499 DEBUG TRAIN Batch 22/0 loss 7.954798 loss_att 8.451332 loss_ctc 10.259432 loss_rnnt 7.259774 hw_loss 0.540809 lr 0.00036913 rank 3
2023-02-22 16:56:45,501 DEBUG TRAIN Batch 22/0 loss 11.419920 loss_att 10.133994 loss_ctc 13.883113 loss_rnnt 10.976049 hw_loss 0.698682 lr 0.00036906 rank 2
2023-02-22 16:56:45,504 DEBUG TRAIN Batch 22/0 loss 6.788454 loss_att 6.864835 loss_ctc 8.719997 loss_rnnt 6.268960 hw_loss 0.462521 lr 0.00036910 rank 1
2023-02-22 16:56:45,505 DEBUG TRAIN Batch 22/0 loss 14.416430 loss_att 12.817940 loss_ctc 17.108759 loss_rnnt 14.162915 hw_loss 0.401690 lr 0.00036910 rank 5
2023-02-22 16:56:45,539 DEBUG TRAIN Batch 22/0 loss 10.349165 loss_att 9.934367 loss_ctc 13.745297 loss_rnnt 9.674100 hw_loss 0.572262 lr 0.00036917 rank 0
2023-02-22 16:56:45,552 DEBUG TRAIN Batch 22/0 loss 6.955812 loss_att 6.993463 loss_ctc 9.558536 loss_rnnt 6.372155 hw_loss 0.429557 lr 0.00036904 rank 6
2023-02-22 16:57:57,335 DEBUG TRAIN Batch 22/100 loss 4.991649 loss_att 7.595595 loss_ctc 8.954877 loss_rnnt 3.759234 hw_loss 0.343491 lr 0.00036906 rank 4
2023-02-22 16:57:57,344 DEBUG TRAIN Batch 22/100 loss 8.703361 loss_att 9.840874 loss_ctc 7.903429 loss_rnnt 8.467241 hw_loss 0.216139 lr 0.00036900 rank 1
2023-02-22 16:57:57,346 DEBUG TRAIN Batch 22/100 loss 4.640775 loss_att 7.299184 loss_ctc 6.486652 loss_rnnt 3.709167 hw_loss 0.288393 lr 0.00036894 rank 6
2023-02-22 16:57:57,351 DEBUG TRAIN Batch 22/100 loss 8.346284 loss_att 11.646214 loss_ctc 12.104851 loss_rnnt 7.015865 hw_loss 0.317418 lr 0.00036896 rank 2
2023-02-22 16:57:57,353 DEBUG TRAIN Batch 22/100 loss 10.286041 loss_att 12.319519 loss_ctc 14.637790 loss_rnnt 9.195961 hw_loss 0.193408 lr 0.00036900 rank 5
2023-02-22 16:57:57,356 DEBUG TRAIN Batch 22/100 loss 13.935215 loss_att 18.687157 loss_ctc 18.319992 loss_rnnt 12.323512 hw_loss 0.143771 lr 0.00036896 rank 7
2023-02-22 16:57:57,355 DEBUG TRAIN Batch 22/100 loss 14.699979 loss_att 20.755733 loss_ctc 19.824261 loss_rnnt 12.719123 hw_loss 0.162127 lr 0.00036907 rank 0
2023-02-22 16:57:57,356 DEBUG TRAIN Batch 22/100 loss 8.121531 loss_att 9.697723 loss_ctc 9.016115 loss_rnnt 7.432667 hw_loss 0.476904 lr 0.00036903 rank 3
2023-02-22 16:59:09,937 DEBUG TRAIN Batch 22/200 loss 6.768174 loss_att 11.287826 loss_ctc 14.020178 loss_rnnt 4.661037 hw_loss 0.443010 lr 0.00036884 rank 6
2023-02-22 16:59:09,938 DEBUG TRAIN Batch 22/200 loss 4.684945 loss_att 6.910816 loss_ctc 6.488114 loss_rnnt 3.821486 hw_loss 0.333490 lr 0.00036886 rank 2
2023-02-22 16:59:09,941 DEBUG TRAIN Batch 22/200 loss 12.732670 loss_att 14.273130 loss_ctc 19.972137 loss_rnnt 11.328685 hw_loss 0.244931 lr 0.00036893 rank 3
2023-02-22 16:59:09,943 DEBUG TRAIN Batch 22/200 loss 13.073366 loss_att 17.837593 loss_ctc 17.896118 loss_rnnt 11.230345 hw_loss 0.463393 lr 0.00036886 rank 7
2023-02-22 16:59:09,944 DEBUG TRAIN Batch 22/200 loss 6.684657 loss_att 8.202887 loss_ctc 8.042731 loss_rnnt 5.946849 hw_loss 0.474534 lr 0.00036889 rank 1
2023-02-22 16:59:09,945 DEBUG TRAIN Batch 22/200 loss 3.589093 loss_att 6.530601 loss_ctc 4.859118 loss_rnnt 2.738310 hw_loss 0.174646 lr 0.00036896 rank 4
2023-02-22 16:59:09,946 DEBUG TRAIN Batch 22/200 loss 16.796139 loss_att 17.671530 loss_ctc 23.808147 loss_rnnt 15.378540 hw_loss 0.576725 lr 0.00036889 rank 5
2023-02-22 16:59:09,948 DEBUG TRAIN Batch 22/200 loss 7.452273 loss_att 14.590174 loss_ctc 11.925690 loss_rnnt 5.261466 hw_loss 0.312697 lr 0.00036897 rank 0
2023-02-22 17:00:23,303 DEBUG TRAIN Batch 22/300 loss 13.466058 loss_att 17.612484 loss_ctc 21.330564 loss_rnnt 11.393126 hw_loss 0.365712 lr 0.00036883 rank 3
2023-02-22 17:00:23,306 DEBUG TRAIN Batch 22/300 loss 3.424232 loss_att 5.552439 loss_ctc 7.592109 loss_rnnt 2.310833 hw_loss 0.247575 lr 0.00036879 rank 1
2023-02-22 17:00:23,308 DEBUG TRAIN Batch 22/300 loss 4.836150 loss_att 9.233135 loss_ctc 11.622051 loss_rnnt 2.937391 hw_loss 0.214828 lr 0.00036876 rank 2
2023-02-22 17:00:23,308 DEBUG TRAIN Batch 22/300 loss 9.394231 loss_att 11.117027 loss_ctc 14.683255 loss_rnnt 8.212981 hw_loss 0.246538 lr 0.00036874 rank 6
2023-02-22 17:00:23,309 DEBUG TRAIN Batch 22/300 loss 23.126541 loss_att 24.031260 loss_ctc 30.905207 loss_rnnt 21.812588 hw_loss 0.179728 lr 0.00036876 rank 7
2023-02-22 17:00:23,314 DEBUG TRAIN Batch 22/300 loss 3.569934 loss_att 6.404538 loss_ctc 5.384798 loss_rnnt 2.640200 hw_loss 0.226559 lr 0.00036887 rank 0
2023-02-22 17:00:23,321 DEBUG TRAIN Batch 22/300 loss 9.977442 loss_att 10.918016 loss_ctc 12.525087 loss_rnnt 9.333035 hw_loss 0.218635 lr 0.00036886 rank 4
2023-02-22 17:00:23,365 DEBUG TRAIN Batch 22/300 loss 7.349158 loss_att 10.932123 loss_ctc 9.787148 loss_rnnt 6.249149 hw_loss 0.109408 lr 0.00036879 rank 5
2023-02-22 17:01:36,698 DEBUG TRAIN Batch 22/400 loss 5.848741 loss_att 9.311274 loss_ctc 7.963720 loss_rnnt 4.717528 hw_loss 0.293829 lr 0.00036866 rank 2
2023-02-22 17:01:36,701 DEBUG TRAIN Batch 22/400 loss 2.446945 loss_att 3.892557 loss_ctc 3.301394 loss_rnnt 1.920274 hw_loss 0.231791 lr 0.00036864 rank 6
2023-02-22 17:01:36,702 DEBUG TRAIN Batch 22/400 loss 8.570516 loss_att 9.153065 loss_ctc 11.239616 loss_rnnt 7.970207 hw_loss 0.239846 lr 0.00036876 rank 4
2023-02-22 17:01:36,702 DEBUG TRAIN Batch 22/400 loss 9.847048 loss_att 12.696629 loss_ctc 13.898087 loss_rnnt 8.564569 hw_loss 0.323294 lr 0.00036865 rank 7
2023-02-22 17:01:36,703 DEBUG TRAIN Batch 22/400 loss 14.173100 loss_att 14.019363 loss_ctc 17.188995 loss_rnnt 13.538113 hw_loss 0.494278 lr 0.00036869 rank 1
2023-02-22 17:01:36,703 DEBUG TRAIN Batch 22/400 loss 9.792016 loss_att 13.994152 loss_ctc 13.618671 loss_rnnt 8.334560 hw_loss 0.200264 lr 0.00036869 rank 5
2023-02-22 17:01:36,709 DEBUG TRAIN Batch 22/400 loss 7.926116 loss_att 10.228659 loss_ctc 8.551732 loss_rnnt 7.268392 hw_loss 0.213375 lr 0.00036873 rank 3
2023-02-22 17:01:36,713 DEBUG TRAIN Batch 22/400 loss 6.665604 loss_att 10.630307 loss_ctc 7.883657 loss_rnnt 5.518386 hw_loss 0.359758 lr 0.00036877 rank 0
2023-02-22 17:02:48,971 DEBUG TRAIN Batch 22/500 loss 12.137407 loss_att 15.019863 loss_ctc 14.806976 loss_rnnt 11.103710 hw_loss 0.189870 lr 0.00036855 rank 7
2023-02-22 17:02:48,973 DEBUG TRAIN Batch 22/500 loss 10.621380 loss_att 13.816862 loss_ctc 15.927299 loss_rnnt 9.114655 hw_loss 0.300322 lr 0.00036856 rank 2
2023-02-22 17:02:48,975 DEBUG TRAIN Batch 22/500 loss 6.338158 loss_att 7.993140 loss_ctc 7.535029 loss_rnnt 5.739869 hw_loss 0.201954 lr 0.00036866 rank 4
2023-02-22 17:02:48,977 DEBUG TRAIN Batch 22/500 loss 5.592536 loss_att 7.286270 loss_ctc 6.638729 loss_rnnt 4.940890 hw_loss 0.325138 lr 0.00036854 rank 6
2023-02-22 17:02:48,979 DEBUG TRAIN Batch 22/500 loss 23.301142 loss_att 28.313330 loss_ctc 35.258183 loss_rnnt 20.534863 hw_loss 0.317941 lr 0.00036867 rank 0
2023-02-22 17:02:48,979 DEBUG TRAIN Batch 22/500 loss 6.568620 loss_att 11.660069 loss_ctc 10.258873 loss_rnnt 4.874886 hw_loss 0.343893 lr 0.00036863 rank 3
2023-02-22 17:02:48,982 DEBUG TRAIN Batch 22/500 loss 20.462717 loss_att 25.000984 loss_ctc 33.567207 loss_rnnt 17.677279 hw_loss 0.244728 lr 0.00036859 rank 1
2023-02-22 17:02:48,983 DEBUG TRAIN Batch 22/500 loss 13.735442 loss_att 13.391644 loss_ctc 17.577934 loss_rnnt 13.171354 hw_loss 0.225966 lr 0.00036859 rank 5
2023-02-22 17:04:02,493 DEBUG TRAIN Batch 22/600 loss 4.788925 loss_att 8.898413 loss_ctc 8.090216 loss_rnnt 3.382679 hw_loss 0.270330 lr 0.00036846 rank 2
2023-02-22 17:04:02,495 DEBUG TRAIN Batch 22/600 loss 7.574869 loss_att 7.911435 loss_ctc 9.874779 loss_rnnt 6.958288 hw_loss 0.454899 lr 0.00036845 rank 7
2023-02-22 17:04:02,496 DEBUG TRAIN Batch 22/600 loss 11.367770 loss_att 11.758915 loss_ctc 15.858126 loss_rnnt 10.423418 hw_loss 0.501393 lr 0.00036844 rank 6
2023-02-22 17:04:02,498 DEBUG TRAIN Batch 22/600 loss 12.044545 loss_att 13.938814 loss_ctc 17.122673 loss_rnnt 10.843184 hw_loss 0.272669 lr 0.00036853 rank 3
2023-02-22 17:04:02,503 DEBUG TRAIN Batch 22/600 loss 5.378040 loss_att 5.656318 loss_ctc 6.728379 loss_rnnt 4.978808 hw_loss 0.306621 lr 0.00036849 rank 1
2023-02-22 17:04:02,504 DEBUG TRAIN Batch 22/600 loss 8.603915 loss_att 9.001134 loss_ctc 11.816476 loss_rnnt 7.857948 hw_loss 0.446592 lr 0.00036849 rank 5
2023-02-22 17:04:02,505 DEBUG TRAIN Batch 22/600 loss 9.618612 loss_att 10.733046 loss_ctc 9.003284 loss_rnnt 9.243166 hw_loss 0.439880 lr 0.00036856 rank 0
2023-02-22 17:04:02,509 DEBUG TRAIN Batch 22/600 loss 9.494579 loss_att 10.500157 loss_ctc 14.391672 loss_rnnt 8.501432 hw_loss 0.260784 lr 0.00036856 rank 4
2023-02-22 17:05:17,674 DEBUG TRAIN Batch 22/700 loss 8.999526 loss_att 11.859875 loss_ctc 11.905491 loss_rnnt 7.960420 hw_loss 0.149203 lr 0.00036846 rank 4
2023-02-22 17:05:17,681 DEBUG TRAIN Batch 22/700 loss 12.917521 loss_att 12.956362 loss_ctc 20.872297 loss_rnnt 11.691244 hw_loss 0.296012 lr 0.00036836 rank 2
2023-02-22 17:05:17,691 DEBUG TRAIN Batch 22/700 loss 9.444027 loss_att 9.639316 loss_ctc 8.382368 loss_rnnt 9.410543 hw_loss 0.254963 lr 0.00036839 rank 5
2023-02-22 17:05:17,691 DEBUG TRAIN Batch 22/700 loss 6.442120 loss_att 12.326878 loss_ctc 7.344268 loss_rnnt 5.061647 hw_loss 0.156066 lr 0.00036835 rank 7
2023-02-22 17:05:17,698 DEBUG TRAIN Batch 22/700 loss 7.081107 loss_att 12.113726 loss_ctc 9.519298 loss_rnnt 5.655780 hw_loss 0.175709 lr 0.00036843 rank 3
2023-02-22 17:05:17,701 DEBUG TRAIN Batch 22/700 loss 1.763287 loss_att 4.899190 loss_ctc 4.134393 loss_rnnt 0.686088 hw_loss 0.251009 lr 0.00036839 rank 1
2023-02-22 17:05:17,706 DEBUG TRAIN Batch 22/700 loss 7.305876 loss_att 11.904770 loss_ctc 10.720866 loss_rnnt 5.765405 hw_loss 0.310049 lr 0.00036846 rank 0
2023-02-22 17:05:17,719 DEBUG TRAIN Batch 22/700 loss 8.600485 loss_att 12.452656 loss_ctc 13.177153 loss_rnnt 7.019489 hw_loss 0.375637 lr 0.00036834 rank 6
2023-02-22 17:06:31,338 DEBUG TRAIN Batch 22/800 loss 10.247680 loss_att 13.645832 loss_ctc 14.087423 loss_rnnt 8.928730 hw_loss 0.238787 lr 0.00036826 rank 2
2023-02-22 17:06:31,339 DEBUG TRAIN Batch 22/800 loss 8.456287 loss_att 10.820449 loss_ctc 15.346885 loss_rnnt 6.980134 hw_loss 0.158577 lr 0.00036836 rank 0
2023-02-22 17:06:31,341 DEBUG TRAIN Batch 22/800 loss 9.415941 loss_att 10.434105 loss_ctc 17.854532 loss_rnnt 7.967351 hw_loss 0.224648 lr 0.00036824 rank 6
2023-02-22 17:06:31,345 DEBUG TRAIN Batch 22/800 loss 9.663465 loss_att 12.119843 loss_ctc 15.822281 loss_rnnt 8.175647 hw_loss 0.328815 lr 0.00036829 rank 1
2023-02-22 17:06:31,347 DEBUG TRAIN Batch 22/800 loss 12.254414 loss_att 13.411691 loss_ctc 22.407650 loss_rnnt 10.561788 hw_loss 0.201386 lr 0.00036825 rank 7
2023-02-22 17:06:31,348 DEBUG TRAIN Batch 22/800 loss 19.090836 loss_att 22.324450 loss_ctc 24.573614 loss_rnnt 17.587921 hw_loss 0.234667 lr 0.00036833 rank 3
2023-02-22 17:06:31,349 DEBUG TRAIN Batch 22/800 loss 11.459124 loss_att 14.511160 loss_ctc 20.077763 loss_rnnt 9.594256 hw_loss 0.197454 lr 0.00036829 rank 5
2023-02-22 17:06:31,390 DEBUG TRAIN Batch 22/800 loss 10.505915 loss_att 13.388351 loss_ctc 14.607872 loss_rnnt 9.156542 hw_loss 0.423669 lr 0.00036836 rank 4
2023-02-22 17:07:43,708 DEBUG TRAIN Batch 22/900 loss 7.499332 loss_att 11.028270 loss_ctc 8.183661 loss_rnnt 6.616281 hw_loss 0.161287 lr 0.00036816 rank 2
2023-02-22 17:07:43,709 DEBUG TRAIN Batch 22/900 loss 1.875837 loss_att 4.314954 loss_ctc 2.698145 loss_rnnt 1.075392 hw_loss 0.380590 lr 0.00036814 rank 6
2023-02-22 17:07:43,712 DEBUG TRAIN Batch 22/900 loss 23.157907 loss_att 27.887146 loss_ctc 27.903692 loss_rnnt 21.474966 hw_loss 0.195603 lr 0.00036819 rank 1
2023-02-22 17:07:43,713 DEBUG TRAIN Batch 22/900 loss 3.721882 loss_att 7.151671 loss_ctc 6.952004 loss_rnnt 2.447621 hw_loss 0.295538 lr 0.00036815 rank 7
2023-02-22 17:07:43,714 DEBUG TRAIN Batch 22/900 loss 9.912634 loss_att 10.740047 loss_ctc 11.925103 loss_rnnt 9.301136 hw_loss 0.333161 lr 0.00036826 rank 4
2023-02-22 17:07:43,714 DEBUG TRAIN Batch 22/900 loss 16.287483 loss_att 19.411537 loss_ctc 22.386002 loss_rnnt 14.706341 hw_loss 0.268488 lr 0.00036823 rank 3
2023-02-22 17:07:43,714 DEBUG TRAIN Batch 22/900 loss 12.191591 loss_att 14.280865 loss_ctc 13.098886 loss_rnnt 11.535467 hw_loss 0.219931 lr 0.00036819 rank 5
2023-02-22 17:07:43,715 DEBUG TRAIN Batch 22/900 loss 11.789133 loss_att 14.476099 loss_ctc 18.389065 loss_rnnt 10.249502 hw_loss 0.229210 lr 0.00036826 rank 0
2023-02-22 17:08:56,993 DEBUG TRAIN Batch 22/1000 loss 15.805878 loss_att 16.554337 loss_ctc 24.113089 loss_rnnt 14.448167 hw_loss 0.188231 lr 0.00036816 rank 0
2023-02-22 17:08:57,004 DEBUG TRAIN Batch 22/1000 loss 9.563227 loss_att 11.644179 loss_ctc 11.622414 loss_rnnt 8.683905 hw_loss 0.353574 lr 0.00036813 rank 3
2023-02-22 17:08:57,004 DEBUG TRAIN Batch 22/1000 loss 19.239061 loss_att 21.802368 loss_ctc 25.905075 loss_rnnt 17.690845 hw_loss 0.275160 lr 0.00036809 rank 1
2023-02-22 17:08:57,007 DEBUG TRAIN Batch 22/1000 loss 7.573921 loss_att 10.397924 loss_ctc 11.801203 loss_rnnt 6.306828 hw_loss 0.259976 lr 0.00036806 rank 2
2023-02-22 17:08:57,012 DEBUG TRAIN Batch 22/1000 loss 12.809688 loss_att 16.806812 loss_ctc 16.582500 loss_rnnt 11.444840 hw_loss 0.116964 lr 0.00036804 rank 6
2023-02-22 17:08:57,013 DEBUG TRAIN Batch 22/1000 loss 6.149116 loss_att 8.686367 loss_ctc 10.910924 loss_rnnt 4.803672 hw_loss 0.380786 lr 0.00036809 rank 5
2023-02-22 17:08:57,016 DEBUG TRAIN Batch 22/1000 loss 6.552780 loss_att 10.675841 loss_ctc 10.272812 loss_rnnt 5.121284 hw_loss 0.207900 lr 0.00036806 rank 7
2023-02-22 17:08:57,074 DEBUG TRAIN Batch 22/1000 loss 8.675537 loss_att 10.340263 loss_ctc 8.147688 loss_rnnt 8.308932 hw_loss 0.195073 lr 0.00036816 rank 4
2023-02-22 17:10:10,981 DEBUG TRAIN Batch 22/1100 loss 12.656775 loss_att 17.793125 loss_ctc 21.255541 loss_rnnt 10.265933 hw_loss 0.407004 lr 0.00036794 rank 6
2023-02-22 17:10:10,984 DEBUG TRAIN Batch 22/1100 loss 5.375616 loss_att 9.320416 loss_ctc 7.961629 loss_rnnt 4.024258 hw_loss 0.407992 lr 0.00036796 rank 2
2023-02-22 17:10:10,985 DEBUG TRAIN Batch 22/1100 loss 10.949015 loss_att 14.937789 loss_ctc 14.810615 loss_rnnt 9.491669 hw_loss 0.271332 lr 0.00036799 rank 1
2023-02-22 17:10:10,988 DEBUG TRAIN Batch 22/1100 loss 10.104645 loss_att 12.907104 loss_ctc 11.955259 loss_rnnt 9.215837 hw_loss 0.152937 lr 0.00036807 rank 0
2023-02-22 17:10:10,989 DEBUG TRAIN Batch 22/1100 loss 6.505722 loss_att 9.434846 loss_ctc 9.231186 loss_rnnt 5.418886 hw_loss 0.258031 lr 0.00036803 rank 3
2023-02-22 17:10:10,991 DEBUG TRAIN Batch 22/1100 loss 9.862828 loss_att 12.058373 loss_ctc 15.965217 loss_rnnt 8.517638 hw_loss 0.173303 lr 0.00036799 rank 5
2023-02-22 17:10:10,991 DEBUG TRAIN Batch 22/1100 loss 6.772438 loss_att 10.009876 loss_ctc 8.781601 loss_rnnt 5.671333 hw_loss 0.348242 lr 0.00036806 rank 4
2023-02-22 17:10:11,039 DEBUG TRAIN Batch 22/1100 loss 10.717653 loss_att 11.911251 loss_ctc 15.027341 loss_rnnt 9.671627 hw_loss 0.436277 lr 0.00036796 rank 7
2023-02-22 17:11:24,158 DEBUG TRAIN Batch 22/1200 loss 11.829642 loss_att 12.272571 loss_ctc 14.262189 loss_rnnt 11.227407 hw_loss 0.354954 lr 0.00036793 rank 3
2023-02-22 17:11:24,160 DEBUG TRAIN Batch 22/1200 loss 10.268212 loss_att 11.276546 loss_ctc 10.326065 loss_rnnt 9.832851 hw_loss 0.423715 lr 0.00036786 rank 2
2023-02-22 17:11:24,164 DEBUG TRAIN Batch 22/1200 loss 6.902374 loss_att 8.765185 loss_ctc 9.164581 loss_rnnt 6.116914 hw_loss 0.208631 lr 0.00036797 rank 0
2023-02-22 17:11:24,165 DEBUG TRAIN Batch 22/1200 loss 18.017260 loss_att 22.124489 loss_ctc 27.665363 loss_rnnt 15.756392 hw_loss 0.286887 lr 0.00036784 rank 6
2023-02-22 17:11:24,165 DEBUG TRAIN Batch 22/1200 loss 10.600579 loss_att 11.488468 loss_ctc 17.410442 loss_rnnt 9.313345 hw_loss 0.378139 lr 0.00036789 rank 5
2023-02-22 17:11:24,167 DEBUG TRAIN Batch 22/1200 loss 7.528370 loss_att 7.882164 loss_ctc 10.175957 loss_rnnt 6.913727 hw_loss 0.357885 lr 0.00036786 rank 7
2023-02-22 17:11:24,195 DEBUG TRAIN Batch 22/1200 loss 17.654869 loss_att 16.798994 loss_ctc 28.395908 loss_rnnt 16.266500 hw_loss 0.238885 lr 0.00036796 rank 4
2023-02-22 17:11:24,203 DEBUG TRAIN Batch 22/1200 loss 8.956186 loss_att 10.031767 loss_ctc 14.133441 loss_rnnt 7.866390 hw_loss 0.345710 lr 0.00036789 rank 1
2023-02-22 17:12:36,124 DEBUG TRAIN Batch 22/1300 loss 7.380938 loss_att 11.191545 loss_ctc 12.192503 loss_rnnt 5.887455 hw_loss 0.168410 lr 0.00036776 rank 2
2023-02-22 17:12:36,125 DEBUG TRAIN Batch 22/1300 loss 6.713319 loss_att 11.166806 loss_ctc 8.925721 loss_rnnt 5.352279 hw_loss 0.328793 lr 0.00036776 rank 7
2023-02-22 17:12:36,126 DEBUG TRAIN Batch 22/1300 loss 14.212390 loss_att 13.836666 loss_ctc 18.277800 loss_rnnt 13.504869 hw_loss 0.451148 lr 0.00036783 rank 3
2023-02-22 17:12:36,127 DEBUG TRAIN Batch 22/1300 loss 8.837393 loss_att 8.710231 loss_ctc 11.441061 loss_rnnt 8.165515 hw_loss 0.656539 lr 0.00036787 rank 0
2023-02-22 17:12:36,129 DEBUG TRAIN Batch 22/1300 loss 4.354309 loss_att 9.833336 loss_ctc 8.872619 loss_rnnt 2.531025 hw_loss 0.234446 lr 0.00036780 rank 1
2023-02-22 17:12:36,129 DEBUG TRAIN Batch 22/1300 loss 2.675735 loss_att 5.116646 loss_ctc 5.277618 loss_rnnt 1.763824 hw_loss 0.144021 lr 0.00036774 rank 6
2023-02-22 17:12:36,131 DEBUG TRAIN Batch 22/1300 loss 6.496127 loss_att 8.221396 loss_ctc 8.161957 loss_rnnt 5.794250 hw_loss 0.252587 lr 0.00036786 rank 4
2023-02-22 17:12:36,136 DEBUG TRAIN Batch 22/1300 loss 4.129215 loss_att 9.539869 loss_ctc 6.015019 loss_rnnt 2.633611 hw_loss 0.303811 lr 0.00036780 rank 5
2023-02-22 17:13:50,899 DEBUG TRAIN Batch 22/1400 loss 4.930323 loss_att 6.868743 loss_ctc 4.247322 loss_rnnt 4.520740 hw_loss 0.211810 lr 0.00036776 rank 4
2023-02-22 17:13:50,899 DEBUG TRAIN Batch 22/1400 loss 3.480206 loss_att 7.120556 loss_ctc 7.471071 loss_rnnt 2.107917 hw_loss 0.210193 lr 0.00036773 rank 3
2023-02-22 17:13:50,900 DEBUG TRAIN Batch 22/1400 loss 10.610989 loss_att 14.781240 loss_ctc 14.000830 loss_rnnt 9.226335 hw_loss 0.184922 lr 0.00036765 rank 6
2023-02-22 17:13:50,900 DEBUG TRAIN Batch 22/1400 loss 6.440206 loss_att 8.347724 loss_ctc 9.473116 loss_rnnt 5.543835 hw_loss 0.207148 lr 0.00036770 rank 1
2023-02-22 17:13:50,901 DEBUG TRAIN Batch 22/1400 loss 7.981019 loss_att 12.755164 loss_ctc 13.679331 loss_rnnt 6.123923 hw_loss 0.267172 lr 0.00036766 rank 2
2023-02-22 17:13:50,905 DEBUG TRAIN Batch 22/1400 loss 9.807986 loss_att 12.173050 loss_ctc 12.926910 loss_rnnt 8.749311 hw_loss 0.318385 lr 0.00036770 rank 5
2023-02-22 17:13:50,928 DEBUG TRAIN Batch 22/1400 loss 8.742120 loss_att 14.186760 loss_ctc 18.028614 loss_rnnt 6.241060 hw_loss 0.326126 lr 0.00036777 rank 0
2023-02-22 17:13:50,932 DEBUG TRAIN Batch 22/1400 loss 11.359035 loss_att 16.236151 loss_ctc 13.446831 loss_rnnt 9.875456 hw_loss 0.430841 lr 0.00036766 rank 7
2023-02-22 17:15:03,611 DEBUG TRAIN Batch 22/1500 loss 5.342211 loss_att 9.075224 loss_ctc 8.177272 loss_rnnt 4.160190 hw_loss 0.107644 lr 0.00036764 rank 3
2023-02-22 17:15:03,614 DEBUG TRAIN Batch 22/1500 loss 6.576645 loss_att 11.628052 loss_ctc 9.399550 loss_rnnt 5.027069 hw_loss 0.305451 lr 0.00036757 rank 2
2023-02-22 17:15:03,616 DEBUG TRAIN Batch 22/1500 loss 8.766470 loss_att 11.386381 loss_ctc 10.046918 loss_rnnt 7.967824 hw_loss 0.194882 lr 0.00036766 rank 4
2023-02-22 17:15:03,617 DEBUG TRAIN Batch 22/1500 loss 10.192858 loss_att 16.531931 loss_ctc 16.314854 loss_rnnt 8.025421 hw_loss 0.156294 lr 0.00036760 rank 1
2023-02-22 17:15:03,619 DEBUG TRAIN Batch 22/1500 loss 7.244901 loss_att 9.301422 loss_ctc 7.906669 loss_rnnt 6.680242 hw_loss 0.122098 lr 0.00036767 rank 0
2023-02-22 17:15:03,619 DEBUG TRAIN Batch 22/1500 loss 7.140149 loss_att 12.471710 loss_ctc 11.883250 loss_rnnt 5.284435 hw_loss 0.294353 lr 0.00036755 rank 6
2023-02-22 17:15:03,620 DEBUG TRAIN Batch 22/1500 loss 19.690668 loss_att 23.272936 loss_ctc 27.247152 loss_rnnt 17.744423 hw_loss 0.416742 lr 0.00036760 rank 5
2023-02-22 17:15:03,659 DEBUG TRAIN Batch 22/1500 loss 13.619116 loss_att 14.079119 loss_ctc 23.140888 loss_rnnt 12.075613 hw_loss 0.341124 lr 0.00036756 rank 7
2023-02-22 17:16:15,845 DEBUG TRAIN Batch 22/1600 loss 9.566244 loss_att 12.704847 loss_ctc 17.608673 loss_rnnt 7.694605 hw_loss 0.321738 lr 0.00036747 rank 2
2023-02-22 17:16:15,845 DEBUG TRAIN Batch 22/1600 loss 9.556700 loss_att 12.408447 loss_ctc 17.217365 loss_rnnt 7.853904 hw_loss 0.208170 lr 0.00036757 rank 0
2023-02-22 17:16:15,846 DEBUG TRAIN Batch 22/1600 loss 6.037349 loss_att 8.338796 loss_ctc 7.622917 loss_rnnt 5.181969 hw_loss 0.344402 lr 0.00036756 rank 4
2023-02-22 17:16:15,847 DEBUG TRAIN Batch 22/1600 loss 10.265635 loss_att 14.733601 loss_ctc 13.086977 loss_rnnt 8.894176 hw_loss 0.190661 lr 0.00036754 rank 3
2023-02-22 17:16:15,848 DEBUG TRAIN Batch 22/1600 loss 10.053021 loss_att 13.270681 loss_ctc 16.228874 loss_rnnt 8.429657 hw_loss 0.293221 lr 0.00036745 rank 6
2023-02-22 17:16:15,848 DEBUG TRAIN Batch 22/1600 loss 9.349319 loss_att 12.301142 loss_ctc 13.923991 loss_rnnt 8.040257 hw_loss 0.203889 lr 0.00036746 rank 7
2023-02-22 17:16:15,850 DEBUG TRAIN Batch 22/1600 loss 5.098556 loss_att 7.220804 loss_ctc 7.483341 loss_rnnt 4.182797 hw_loss 0.325008 lr 0.00036750 rank 1
2023-02-22 17:16:15,902 DEBUG TRAIN Batch 22/1600 loss 5.749459 loss_att 8.972807 loss_ctc 6.950550 loss_rnnt 4.793505 hw_loss 0.283386 lr 0.00036750 rank 5
2023-02-22 17:17:29,269 DEBUG TRAIN Batch 22/1700 loss 11.060289 loss_att 13.683198 loss_ctc 12.384506 loss_rnnt 10.157480 hw_loss 0.378122 lr 0.00036736 rank 7
2023-02-22 17:17:29,270 DEBUG TRAIN Batch 22/1700 loss 4.836721 loss_att 6.192746 loss_ctc 5.738613 loss_rnnt 4.314861 hw_loss 0.244506 lr 0.00036740 rank 1
2023-02-22 17:17:29,271 DEBUG TRAIN Batch 22/1700 loss 5.415908 loss_att 8.075291 loss_ctc 8.268277 loss_rnnt 4.373409 hw_loss 0.244325 lr 0.00036735 rank 6
2023-02-22 17:17:29,272 DEBUG TRAIN Batch 22/1700 loss 6.892330 loss_att 11.794035 loss_ctc 8.383091 loss_rnnt 5.575440 hw_loss 0.258337 lr 0.00036737 rank 2
2023-02-22 17:17:29,274 DEBUG TRAIN Batch 22/1700 loss 6.616842 loss_att 10.508059 loss_ctc 9.900262 loss_rnnt 5.294529 hw_loss 0.199273 lr 0.00036744 rank 3
2023-02-22 17:17:29,277 DEBUG TRAIN Batch 22/1700 loss 13.210289 loss_att 13.902802 loss_ctc 18.893295 loss_rnnt 12.151579 hw_loss 0.304638 lr 0.00036740 rank 5
2023-02-22 17:17:29,280 DEBUG TRAIN Batch 22/1700 loss 8.373320 loss_att 10.278932 loss_ctc 9.474237 loss_rnnt 7.711915 hw_loss 0.250298 lr 0.00036746 rank 4
2023-02-22 17:17:29,324 DEBUG TRAIN Batch 22/1700 loss 15.698159 loss_att 18.300163 loss_ctc 22.623459 loss_rnnt 14.147335 hw_loss 0.200717 lr 0.00036747 rank 0
2023-02-22 17:18:43,730 DEBUG TRAIN Batch 22/1800 loss 8.574110 loss_att 10.539593 loss_ctc 11.106630 loss_rnnt 7.637164 hw_loss 0.386589 lr 0.00036736 rank 4
2023-02-22 17:18:43,731 DEBUG TRAIN Batch 22/1800 loss 10.772905 loss_att 12.083203 loss_ctc 13.669672 loss_rnnt 10.002905 hw_loss 0.228195 lr 0.00036730 rank 1
2023-02-22 17:18:43,733 DEBUG TRAIN Batch 22/1800 loss 11.907310 loss_att 13.913340 loss_ctc 18.602976 loss_rnnt 10.496910 hw_loss 0.218323 lr 0.00036725 rank 6
2023-02-22 17:18:43,734 DEBUG TRAIN Batch 22/1800 loss 11.036967 loss_att 13.487328 loss_ctc 12.751249 loss_rnnt 10.099319 hw_loss 0.410635 lr 0.00036727 rank 2
2023-02-22 17:18:43,736 DEBUG TRAIN Batch 22/1800 loss 8.817475 loss_att 12.167694 loss_ctc 14.165988 loss_rnnt 7.342020 hw_loss 0.173017 lr 0.00036734 rank 3
2023-02-22 17:18:43,737 DEBUG TRAIN Batch 22/1800 loss 4.261485 loss_att 7.234735 loss_ctc 6.920156 loss_rnnt 3.206053 hw_loss 0.199299 lr 0.00036726 rank 7
2023-02-22 17:18:43,738 DEBUG TRAIN Batch 22/1800 loss 2.517956 loss_att 4.131305 loss_ctc 3.359805 loss_rnnt 1.958456 hw_loss 0.233593 lr 0.00036730 rank 5
2023-02-22 17:18:43,759 DEBUG TRAIN Batch 22/1800 loss 10.934367 loss_att 13.510133 loss_ctc 14.960859 loss_rnnt 9.761139 hw_loss 0.227269 lr 0.00036737 rank 0
2023-02-22 17:19:56,559 DEBUG TRAIN Batch 22/1900 loss 7.216571 loss_att 9.993607 loss_ctc 10.019086 loss_rnnt 6.199608 hw_loss 0.164789 lr 0.00036717 rank 2
2023-02-22 17:19:56,561 DEBUG TRAIN Batch 22/1900 loss 7.999758 loss_att 10.227869 loss_ctc 12.154197 loss_rnnt 6.735639 hw_loss 0.496071 lr 0.00036724 rank 3
2023-02-22 17:19:56,561 DEBUG TRAIN Batch 22/1900 loss 9.214226 loss_att 10.455159 loss_ctc 13.630958 loss_rnnt 8.096611 hw_loss 0.525995 lr 0.00036715 rank 6
2023-02-22 17:19:56,562 DEBUG TRAIN Batch 22/1900 loss 4.007855 loss_att 8.309891 loss_ctc 4.564426 loss_rnnt 2.969220 hw_loss 0.195033 lr 0.00036726 rank 4
2023-02-22 17:19:56,565 DEBUG TRAIN Batch 22/1900 loss 8.047906 loss_att 11.154942 loss_ctc 13.624357 loss_rnnt 6.616437 hw_loss 0.124752 lr 0.00036720 rank 5
2023-02-22 17:19:56,597 DEBUG TRAIN Batch 22/1900 loss 14.897957 loss_att 16.355175 loss_ctc 20.744408 loss_rnnt 13.667069 hw_loss 0.299841 lr 0.00036720 rank 1
2023-02-22 17:19:56,606 DEBUG TRAIN Batch 22/1900 loss 7.494904 loss_att 8.841629 loss_ctc 11.305412 loss_rnnt 6.529609 hw_loss 0.352279 lr 0.00036727 rank 0
2023-02-22 17:19:56,614 DEBUG TRAIN Batch 22/1900 loss 8.469665 loss_att 8.608252 loss_ctc 11.039045 loss_rnnt 7.819673 hw_loss 0.524418 lr 0.00036716 rank 7
2023-02-22 17:21:09,063 DEBUG TRAIN Batch 22/2000 loss 6.579303 loss_att 10.642069 loss_ctc 9.927156 loss_rnnt 5.225821 hw_loss 0.177276 lr 0.00036710 rank 1
2023-02-22 17:21:09,071 DEBUG TRAIN Batch 22/2000 loss 4.837439 loss_att 8.992992 loss_ctc 8.329852 loss_rnnt 3.394904 hw_loss 0.273317 lr 0.00036714 rank 3
2023-02-22 17:21:09,075 DEBUG TRAIN Batch 22/2000 loss 4.297870 loss_att 5.819157 loss_ctc 4.258406 loss_rnnt 3.825539 hw_loss 0.325004 lr 0.00036705 rank 6
2023-02-22 17:21:09,077 DEBUG TRAIN Batch 22/2000 loss 7.819052 loss_att 9.450799 loss_ctc 10.889942 loss_rnnt 7.012321 hw_loss 0.132995 lr 0.00036707 rank 2
2023-02-22 17:21:09,079 DEBUG TRAIN Batch 22/2000 loss 7.000000 loss_att 9.897630 loss_ctc 11.465662 loss_rnnt 5.640783 hw_loss 0.345504 lr 0.00036717 rank 0
2023-02-22 17:21:09,079 DEBUG TRAIN Batch 22/2000 loss 5.862623 loss_att 7.188810 loss_ctc 7.397593 loss_rnnt 5.271286 hw_loss 0.227692 lr 0.00036706 rank 7
2023-02-22 17:21:09,081 DEBUG TRAIN Batch 22/2000 loss 5.548775 loss_att 6.372828 loss_ctc 6.258204 loss_rnnt 5.201189 hw_loss 0.165346 lr 0.00036710 rank 5
2023-02-22 17:21:09,082 DEBUG TRAIN Batch 22/2000 loss 5.962038 loss_att 10.049980 loss_ctc 7.274786 loss_rnnt 4.784333 hw_loss 0.347029 lr 0.00036716 rank 4
2023-02-22 17:22:24,037 DEBUG TRAIN Batch 22/2100 loss 9.550390 loss_att 14.091068 loss_ctc 14.210139 loss_rnnt 7.906448 hw_loss 0.214700 lr 0.00036700 rank 5
2023-02-22 17:22:24,041 DEBUG TRAIN Batch 22/2100 loss 2.188886 loss_att 5.339518 loss_ctc 2.953397 loss_rnnt 1.393881 hw_loss 0.118019 lr 0.00036707 rank 0
2023-02-22 17:22:24,046 DEBUG TRAIN Batch 22/2100 loss 11.696706 loss_att 14.599524 loss_ctc 19.035767 loss_rnnt 9.987440 hw_loss 0.281552 lr 0.00036697 rank 2
2023-02-22 17:22:24,049 DEBUG TRAIN Batch 22/2100 loss 12.273185 loss_att 16.211885 loss_ctc 19.254034 loss_rnnt 10.335058 hw_loss 0.411764 lr 0.00036706 rank 4
2023-02-22 17:22:24,052 DEBUG TRAIN Batch 22/2100 loss 3.656238 loss_att 6.419456 loss_ctc 4.978789 loss_rnnt 2.828129 hw_loss 0.185861 lr 0.00036696 rank 7
2023-02-22 17:22:24,054 DEBUG TRAIN Batch 22/2100 loss 11.587003 loss_att 14.307808 loss_ctc 15.296600 loss_rnnt 10.470299 hw_loss 0.146117 lr 0.00036704 rank 3
2023-02-22 17:22:24,054 DEBUG TRAIN Batch 22/2100 loss 6.582242 loss_att 8.136023 loss_ctc 6.769315 loss_rnnt 6.128059 hw_loss 0.222155 lr 0.00036700 rank 1
2023-02-22 17:22:24,056 DEBUG TRAIN Batch 22/2100 loss 14.591997 loss_att 16.405144 loss_ctc 20.442684 loss_rnnt 13.333553 hw_loss 0.216979 lr 0.00036695 rank 6
2023-02-22 17:23:37,745 DEBUG TRAIN Batch 22/2200 loss 5.603286 loss_att 7.676971 loss_ctc 8.827443 loss_rnnt 4.570213 hw_loss 0.353338 lr 0.00036694 rank 3
2023-02-22 17:23:37,746 DEBUG TRAIN Batch 22/2200 loss 11.656870 loss_att 13.236435 loss_ctc 14.717674 loss_rnnt 10.752770 hw_loss 0.337648 lr 0.00036690 rank 1
2023-02-22 17:23:37,748 DEBUG TRAIN Batch 22/2200 loss 9.764276 loss_att 12.887097 loss_ctc 10.466015 loss_rnnt 8.854675 hw_loss 0.359008 lr 0.00036687 rank 2
2023-02-22 17:23:37,749 DEBUG TRAIN Batch 22/2200 loss 4.237641 loss_att 6.152221 loss_ctc 4.050741 loss_rnnt 3.757670 hw_loss 0.228704 lr 0.00036685 rank 6
2023-02-22 17:23:37,750 DEBUG TRAIN Batch 22/2200 loss 10.031843 loss_att 11.120838 loss_ctc 13.303302 loss_rnnt 9.168607 hw_loss 0.392331 lr 0.00036686 rank 7
2023-02-22 17:23:37,755 DEBUG TRAIN Batch 22/2200 loss 12.385507 loss_att 12.870647 loss_ctc 15.432334 loss_rnnt 11.749176 hw_loss 0.249484 lr 0.00036697 rank 0
2023-02-22 17:23:37,755 DEBUG TRAIN Batch 22/2200 loss 10.397313 loss_att 13.349412 loss_ctc 11.933967 loss_rnnt 9.456576 hw_loss 0.272682 lr 0.00036690 rank 5
2023-02-22 17:23:37,757 DEBUG TRAIN Batch 22/2200 loss 7.530598 loss_att 10.748020 loss_ctc 10.331238 loss_rnnt 6.396224 hw_loss 0.220258 lr 0.00036696 rank 4
2023-02-22 17:24:49,924 DEBUG TRAIN Batch 22/2300 loss 9.909348 loss_att 13.804306 loss_ctc 13.852594 loss_rnnt 8.410833 hw_loss 0.363296 lr 0.00036687 rank 0
2023-02-22 17:24:49,929 DEBUG TRAIN Batch 22/2300 loss 13.306394 loss_att 15.881081 loss_ctc 19.923494 loss_rnnt 11.800312 hw_loss 0.204120 lr 0.00036677 rank 2
2023-02-22 17:24:49,929 DEBUG TRAIN Batch 22/2300 loss 6.239568 loss_att 9.243189 loss_ctc 10.154591 loss_rnnt 4.987432 hw_loss 0.242642 lr 0.00036675 rank 6
2023-02-22 17:24:49,929 DEBUG TRAIN Batch 22/2300 loss 14.000122 loss_att 16.027149 loss_ctc 18.964294 loss_rnnt 12.817767 hw_loss 0.215737 lr 0.00036684 rank 3
2023-02-22 17:24:49,929 DEBUG TRAIN Batch 22/2300 loss 6.827555 loss_att 9.221746 loss_ctc 9.901327 loss_rnnt 5.845521 hw_loss 0.175048 lr 0.00036680 rank 1
2023-02-22 17:24:49,938 DEBUG TRAIN Batch 22/2300 loss 14.317592 loss_att 13.639050 loss_ctc 17.847975 loss_rnnt 13.827469 hw_loss 0.290838 lr 0.00036687 rank 4
2023-02-22 17:24:49,940 DEBUG TRAIN Batch 22/2300 loss 9.089552 loss_att 12.683319 loss_ctc 11.384529 loss_rnnt 7.896036 hw_loss 0.316437 lr 0.00036680 rank 5
2023-02-22 17:24:49,978 DEBUG TRAIN Batch 22/2300 loss 8.340332 loss_att 10.184213 loss_ctc 12.754884 loss_rnnt 7.219238 hw_loss 0.306956 lr 0.00036677 rank 7
2023-02-22 17:26:03,379 DEBUG TRAIN Batch 22/2400 loss 8.154881 loss_att 11.635817 loss_ctc 13.921162 loss_rnnt 6.513780 hw_loss 0.330142 lr 0.00036667 rank 7
2023-02-22 17:26:03,392 DEBUG TRAIN Batch 22/2400 loss 8.955344 loss_att 9.764729 loss_ctc 14.808173 loss_rnnt 7.853095 hw_loss 0.299991 lr 0.00036667 rank 2
2023-02-22 17:26:03,393 DEBUG TRAIN Batch 22/2400 loss 9.987381 loss_att 14.434765 loss_ctc 15.398459 loss_rnnt 8.245680 hw_loss 0.245150 lr 0.00036671 rank 1
2023-02-22 17:26:03,393 DEBUG TRAIN Batch 22/2400 loss 4.522971 loss_att 7.465405 loss_ctc 5.331028 loss_rnnt 3.759188 hw_loss 0.126666 lr 0.00036678 rank 0
2023-02-22 17:26:03,396 DEBUG TRAIN Batch 22/2400 loss 7.723872 loss_att 10.695417 loss_ctc 12.428419 loss_rnnt 6.367981 hw_loss 0.251828 lr 0.00036671 rank 5
2023-02-22 17:26:03,404 DEBUG TRAIN Batch 22/2400 loss 13.608677 loss_att 17.364843 loss_ctc 16.217968 loss_rnnt 12.415869 hw_loss 0.175631 lr 0.00036674 rank 3
2023-02-22 17:26:03,405 DEBUG TRAIN Batch 22/2400 loss 10.078030 loss_att 14.953484 loss_ctc 17.373478 loss_rnnt 7.949312 hw_loss 0.339187 lr 0.00036666 rank 6
2023-02-22 17:26:03,442 DEBUG TRAIN Batch 22/2400 loss 8.015615 loss_att 8.952442 loss_ctc 9.781399 loss_rnnt 7.347343 hw_loss 0.460253 lr 0.00036677 rank 4
2023-02-22 17:27:19,059 DEBUG TRAIN Batch 22/2500 loss 9.796300 loss_att 10.617543 loss_ctc 12.626742 loss_rnnt 9.030514 hw_loss 0.420272 lr 0.00036658 rank 2
2023-02-22 17:27:19,059 DEBUG TRAIN Batch 22/2500 loss 7.319914 loss_att 10.186840 loss_ctc 12.650489 loss_rnnt 5.845140 hw_loss 0.357460 lr 0.00036665 rank 3
2023-02-22 17:27:19,061 DEBUG TRAIN Batch 22/2500 loss 10.880024 loss_att 12.735079 loss_ctc 13.934293 loss_rnnt 9.948757 hw_loss 0.286909 lr 0.00036656 rank 6
2023-02-22 17:27:19,062 DEBUG TRAIN Batch 22/2500 loss 8.091824 loss_att 11.317146 loss_ctc 10.225532 loss_rnnt 7.002095 hw_loss 0.300318 lr 0.00036661 rank 1
2023-02-22 17:27:19,068 DEBUG TRAIN Batch 22/2500 loss 9.867730 loss_att 13.679157 loss_ctc 14.769841 loss_rnnt 8.370978 hw_loss 0.151598 lr 0.00036668 rank 0
2023-02-22 17:27:19,069 DEBUG TRAIN Batch 22/2500 loss 7.809511 loss_att 8.609079 loss_ctc 11.471320 loss_rnnt 6.878990 hw_loss 0.529436 lr 0.00036657 rank 7
2023-02-22 17:27:19,069 DEBUG TRAIN Batch 22/2500 loss 11.379529 loss_att 12.318174 loss_ctc 14.354900 loss_rnnt 10.624572 hw_loss 0.319713 lr 0.00036661 rank 5
2023-02-22 17:27:19,112 DEBUG TRAIN Batch 22/2500 loss 2.545862 loss_att 6.606727 loss_ctc 4.152160 loss_rnnt 1.442356 hw_loss 0.144677 lr 0.00036667 rank 4
2023-02-22 17:28:31,165 DEBUG TRAIN Batch 22/2600 loss 6.229333 loss_att 9.562641 loss_ctc 7.119670 loss_rnnt 5.241288 hw_loss 0.380008 lr 0.00036657 rank 4
2023-02-22 17:28:31,170 DEBUG TRAIN Batch 22/2600 loss 5.074040 loss_att 8.462152 loss_ctc 6.488384 loss_rnnt 4.146544 hw_loss 0.114928 lr 0.00036648 rank 2
2023-02-22 17:28:31,170 DEBUG TRAIN Batch 22/2600 loss 11.396867 loss_att 11.313251 loss_ctc 14.292515 loss_rnnt 10.784520 hw_loss 0.455591 lr 0.00036646 rank 6
2023-02-22 17:28:31,171 DEBUG TRAIN Batch 22/2600 loss 13.539042 loss_att 16.769701 loss_ctc 18.388508 loss_rnnt 12.072392 hw_loss 0.326104 lr 0.00036655 rank 3
2023-02-22 17:28:31,172 DEBUG TRAIN Batch 22/2600 loss 9.662043 loss_att 11.024446 loss_ctc 15.610670 loss_rnnt 8.474853 hw_loss 0.227923 lr 0.00036651 rank 5
2023-02-22 17:28:31,177 DEBUG TRAIN Batch 22/2600 loss 4.135618 loss_att 7.320442 loss_ctc 5.929567 loss_rnnt 3.160965 hw_loss 0.184676 lr 0.00036651 rank 1
2023-02-22 17:28:31,201 DEBUG TRAIN Batch 22/2600 loss 7.247416 loss_att 10.608458 loss_ctc 9.546522 loss_rnnt 6.197160 hw_loss 0.134064 lr 0.00036647 rank 7
2023-02-22 17:28:31,219 DEBUG TRAIN Batch 22/2600 loss 9.968367 loss_att 13.687006 loss_ctc 17.906530 loss_rnnt 7.979627 hw_loss 0.349856 lr 0.00036658 rank 0
2023-02-22 17:29:43,879 DEBUG TRAIN Batch 22/2700 loss 6.189854 loss_att 9.196485 loss_ctc 9.170813 loss_rnnt 5.043142 hw_loss 0.277359 lr 0.00036645 rank 3
2023-02-22 17:29:43,884 DEBUG TRAIN Batch 22/2700 loss 17.665424 loss_att 12.664438 loss_ctc 19.840445 loss_rnnt 18.237724 hw_loss 0.258550 lr 0.00036637 rank 7
2023-02-22 17:29:43,889 DEBUG TRAIN Batch 22/2700 loss 9.548181 loss_att 11.715841 loss_ctc 16.416739 loss_rnnt 8.158206 hw_loss 0.076189 lr 0.00036638 rank 2
2023-02-22 17:29:43,892 DEBUG TRAIN Batch 22/2700 loss 7.586062 loss_att 15.216834 loss_ctc 13.282701 loss_rnnt 5.106925 hw_loss 0.362681 lr 0.00036641 rank 5
2023-02-22 17:29:43,894 DEBUG TRAIN Batch 22/2700 loss 9.050127 loss_att 12.210163 loss_ctc 13.299708 loss_rnnt 7.748670 hw_loss 0.192822 lr 0.00036636 rank 6
2023-02-22 17:29:43,895 DEBUG TRAIN Batch 22/2700 loss 12.121810 loss_att 17.079052 loss_ctc 18.486340 loss_rnnt 10.114436 hw_loss 0.313728 lr 0.00036648 rank 0
2023-02-22 17:29:43,895 DEBUG TRAIN Batch 22/2700 loss 6.992206 loss_att 7.794556 loss_ctc 7.496445 loss_rnnt 6.636755 hw_loss 0.239531 lr 0.00036641 rank 1
2023-02-22 17:29:43,937 DEBUG TRAIN Batch 22/2700 loss 13.216815 loss_att 19.103857 loss_ctc 23.068657 loss_rnnt 10.554261 hw_loss 0.321687 lr 0.00036647 rank 4
2023-02-22 17:30:57,693 DEBUG TRAIN Batch 22/2800 loss 10.355070 loss_att 13.188133 loss_ctc 11.792430 loss_rnnt 9.450281 hw_loss 0.274742 lr 0.00036627 rank 7
2023-02-22 17:30:57,704 DEBUG TRAIN Batch 22/2800 loss 16.574196 loss_att 18.355907 loss_ctc 19.355560 loss_rnnt 15.583670 hw_loss 0.493753 lr 0.00036628 rank 2
2023-02-22 17:30:57,704 DEBUG TRAIN Batch 22/2800 loss 13.657301 loss_att 15.088941 loss_ctc 19.844664 loss_rnnt 12.256735 hw_loss 0.542358 lr 0.00036635 rank 3
2023-02-22 17:30:57,705 DEBUG TRAIN Batch 22/2800 loss 7.610047 loss_att 10.198128 loss_ctc 11.786127 loss_rnnt 6.396529 hw_loss 0.260797 lr 0.00036631 rank 5
2023-02-22 17:30:57,709 DEBUG TRAIN Batch 22/2800 loss 7.967385 loss_att 11.877501 loss_ctc 9.384861 loss_rnnt 6.953472 hw_loss 0.080426 lr 0.00036626 rank 6
2023-02-22 17:30:57,711 DEBUG TRAIN Batch 22/2800 loss 11.695410 loss_att 15.216978 loss_ctc 18.335670 loss_rnnt 9.999680 hw_loss 0.198842 lr 0.00036638 rank 0
2023-02-22 17:30:57,711 DEBUG TRAIN Batch 22/2800 loss 10.474652 loss_att 11.085453 loss_ctc 17.878540 loss_rnnt 9.279930 hw_loss 0.160083 lr 0.00036637 rank 4
2023-02-22 17:30:57,727 DEBUG TRAIN Batch 22/2800 loss 4.535947 loss_att 7.319552 loss_ctc 5.975269 loss_rnnt 3.663147 hw_loss 0.232818 lr 0.00036631 rank 1
2023-02-22 17:32:11,598 DEBUG TRAIN Batch 22/2900 loss 19.145569 loss_att 21.613310 loss_ctc 23.457394 loss_rnnt 17.969284 hw_loss 0.202172 lr 0.00036616 rank 6
2023-02-22 17:32:11,600 DEBUG TRAIN Batch 22/2900 loss 12.564218 loss_att 15.546870 loss_ctc 17.018845 loss_rnnt 11.283184 hw_loss 0.169787 lr 0.00036625 rank 3
2023-02-22 17:32:11,605 DEBUG TRAIN Batch 22/2900 loss 5.612188 loss_att 8.801502 loss_ctc 9.430281 loss_rnnt 4.374537 hw_loss 0.170081 lr 0.00036618 rank 2
2023-02-22 17:32:11,607 DEBUG TRAIN Batch 22/2900 loss 10.128271 loss_att 10.099276 loss_ctc 11.682911 loss_rnnt 9.803397 hw_loss 0.231353 lr 0.00036618 rank 7
2023-02-22 17:32:11,606 DEBUG TRAIN Batch 22/2900 loss 7.867326 loss_att 11.328040 loss_ctc 8.827183 loss_rnnt 6.801506 hw_loss 0.460681 lr 0.00036621 rank 1
2023-02-22 17:32:11,608 DEBUG TRAIN Batch 22/2900 loss 11.394738 loss_att 13.155397 loss_ctc 13.359997 loss_rnnt 10.583282 hw_loss 0.369919 lr 0.00036621 rank 5
2023-02-22 17:32:11,610 DEBUG TRAIN Batch 22/2900 loss 8.889219 loss_att 10.394808 loss_ctc 15.940492 loss_rnnt 7.536405 hw_loss 0.209111 lr 0.00036627 rank 4
2023-02-22 17:32:11,611 DEBUG TRAIN Batch 22/2900 loss 3.888878 loss_att 6.901397 loss_ctc 8.675965 loss_rnnt 2.541642 hw_loss 0.199600 lr 0.00036628 rank 0
2023-02-22 17:33:24,466 DEBUG TRAIN Batch 22/3000 loss 7.640345 loss_att 10.304125 loss_ctc 10.782876 loss_rnnt 6.527696 hw_loss 0.301667 lr 0.00036608 rank 2
2023-02-22 17:33:24,468 DEBUG TRAIN Batch 22/3000 loss 4.528606 loss_att 5.860839 loss_ctc 4.521241 loss_rnnt 4.116825 hw_loss 0.274343 lr 0.00036615 rank 3
2023-02-22 17:33:24,470 DEBUG TRAIN Batch 22/3000 loss 8.557355 loss_att 11.767245 loss_ctc 13.067957 loss_rnnt 7.168102 hw_loss 0.273490 lr 0.00036608 rank 7
2023-02-22 17:33:24,475 DEBUG TRAIN Batch 22/3000 loss 8.065005 loss_att 9.291845 loss_ctc 12.888915 loss_rnnt 7.050534 hw_loss 0.236090 lr 0.00036618 rank 4
2023-02-22 17:33:24,476 DEBUG TRAIN Batch 22/3000 loss 8.878478 loss_att 10.874632 loss_ctc 14.436139 loss_rnnt 7.630865 hw_loss 0.201302 lr 0.00036618 rank 0
2023-02-22 17:33:24,478 DEBUG TRAIN Batch 22/3000 loss 12.484704 loss_att 13.407419 loss_ctc 15.641291 loss_rnnt 11.677542 hw_loss 0.378265 lr 0.00036612 rank 1
2023-02-22 17:33:24,481 DEBUG TRAIN Batch 22/3000 loss 7.004394 loss_att 11.433092 loss_ctc 10.428677 loss_rnnt 5.489306 hw_loss 0.323956 lr 0.00036607 rank 6
2023-02-22 17:33:24,483 DEBUG TRAIN Batch 22/3000 loss 4.274070 loss_att 5.710094 loss_ctc 5.506746 loss_rnnt 3.715311 hw_loss 0.200996 lr 0.00036612 rank 5
2023-02-22 17:34:37,014 DEBUG TRAIN Batch 22/3100 loss 6.002527 loss_att 9.711201 loss_ctc 10.371734 loss_rnnt 4.541656 hw_loss 0.256076 lr 0.00036606 rank 3
2023-02-22 17:34:37,016 DEBUG TRAIN Batch 22/3100 loss 11.208545 loss_att 13.474031 loss_ctc 14.607097 loss_rnnt 10.111076 hw_loss 0.358558 lr 0.00036599 rank 2
2023-02-22 17:34:37,021 DEBUG TRAIN Batch 22/3100 loss 12.885426 loss_att 12.781950 loss_ctc 16.044939 loss_rnnt 12.169970 hw_loss 0.590403 lr 0.00036608 rank 4
2023-02-22 17:34:37,023 DEBUG TRAIN Batch 22/3100 loss 10.176070 loss_att 9.966275 loss_ctc 11.726046 loss_rnnt 9.802166 hw_loss 0.392249 lr 0.00036602 rank 1
2023-02-22 17:34:37,024 DEBUG TRAIN Batch 22/3100 loss 15.235590 loss_att 18.131165 loss_ctc 19.919657 loss_rnnt 13.891797 hw_loss 0.262755 lr 0.00036609 rank 0
2023-02-22 17:34:37,026 DEBUG TRAIN Batch 22/3100 loss 6.999347 loss_att 8.756851 loss_ctc 9.639655 loss_rnnt 6.148636 hw_loss 0.275942 lr 0.00036602 rank 5
2023-02-22 17:34:37,028 DEBUG TRAIN Batch 22/3100 loss 10.765296 loss_att 13.299827 loss_ctc 16.279333 loss_rnnt 9.421740 hw_loss 0.190211 lr 0.00036597 rank 6
2023-02-22 17:34:37,070 DEBUG TRAIN Batch 22/3100 loss 8.457476 loss_att 9.308773 loss_ctc 11.074569 loss_rnnt 7.787395 hw_loss 0.282894 lr 0.00036598 rank 7
2023-02-22 17:35:51,938 DEBUG TRAIN Batch 22/3200 loss 14.162680 loss_att 18.526628 loss_ctc 18.004526 loss_rnnt 12.658774 hw_loss 0.222880 lr 0.00036596 rank 3
2023-02-22 17:35:51,940 DEBUG TRAIN Batch 22/3200 loss 5.495218 loss_att 10.717232 loss_ctc 6.856380 loss_rnnt 4.130062 hw_loss 0.261121 lr 0.00036589 rank 2
2023-02-22 17:35:51,941 DEBUG TRAIN Batch 22/3200 loss 10.011456 loss_att 9.622726 loss_ctc 12.916795 loss_rnnt 9.390543 hw_loss 0.583650 lr 0.00036599 rank 0
2023-02-22 17:35:51,943 DEBUG TRAIN Batch 22/3200 loss 6.341513 loss_att 9.419392 loss_ctc 11.010539 loss_rnnt 5.063213 hw_loss 0.075351 lr 0.00036592 rank 5
2023-02-22 17:35:51,945 DEBUG TRAIN Batch 22/3200 loss 9.732016 loss_att 9.896316 loss_ctc 12.251091 loss_rnnt 9.148188 hw_loss 0.403294 lr 0.00036587 rank 6
2023-02-22 17:35:51,946 DEBUG TRAIN Batch 22/3200 loss 4.928269 loss_att 7.410800 loss_ctc 5.523376 loss_rnnt 4.122221 hw_loss 0.431615 lr 0.00036592 rank 1
2023-02-22 17:35:51,966 DEBUG TRAIN Batch 22/3200 loss 4.434041 loss_att 7.403281 loss_ctc 7.880897 loss_rnnt 3.282507 hw_loss 0.183947 lr 0.00036598 rank 4
2023-02-22 17:35:51,979 DEBUG TRAIN Batch 22/3200 loss 9.562497 loss_att 12.652155 loss_ctc 12.468594 loss_rnnt 8.379542 hw_loss 0.332894 lr 0.00036588 rank 7
2023-02-22 17:37:04,575 DEBUG TRAIN Batch 22/3300 loss 8.502019 loss_att 15.831598 loss_ctc 14.089298 loss_rnnt 6.133569 hw_loss 0.295431 lr 0.00036577 rank 6
2023-02-22 17:37:04,577 DEBUG TRAIN Batch 22/3300 loss 6.053546 loss_att 9.011144 loss_ctc 7.234097 loss_rnnt 5.169092 hw_loss 0.254115 lr 0.00036586 rank 3
2023-02-22 17:37:04,579 DEBUG TRAIN Batch 22/3300 loss 6.087865 loss_att 8.892836 loss_ctc 8.290102 loss_rnnt 5.029725 hw_loss 0.381590 lr 0.00036582 rank 1
2023-02-22 17:37:04,581 DEBUG TRAIN Batch 22/3300 loss 7.075333 loss_att 11.762099 loss_ctc 7.397221 loss_rnnt 5.943460 hw_loss 0.284251 lr 0.00036579 rank 2
2023-02-22 17:37:04,582 DEBUG TRAIN Batch 22/3300 loss 17.110792 loss_att 23.016235 loss_ctc 26.968868 loss_rnnt 14.470503 hw_loss 0.271480 lr 0.00036582 rank 5
2023-02-22 17:37:04,585 DEBUG TRAIN Batch 22/3300 loss 11.646154 loss_att 12.465225 loss_ctc 16.946438 loss_rnnt 10.626034 hw_loss 0.280503 lr 0.00036589 rank 0
2023-02-22 17:37:04,587 DEBUG TRAIN Batch 22/3300 loss 8.810005 loss_att 12.993816 loss_ctc 13.257612 loss_rnnt 7.186168 hw_loss 0.363866 lr 0.00036578 rank 7
2023-02-22 17:37:04,592 DEBUG TRAIN Batch 22/3300 loss 9.033710 loss_att 12.764557 loss_ctc 12.450164 loss_rnnt 7.653778 hw_loss 0.334195 lr 0.00036588 rank 4
2023-02-22 17:38:17,177 DEBUG TRAIN Batch 22/3400 loss 3.574784 loss_att 5.274096 loss_ctc 5.326789 loss_rnnt 2.882441 hw_loss 0.222899 lr 0.00036576 rank 3
2023-02-22 17:38:17,182 DEBUG TRAIN Batch 22/3400 loss 12.405124 loss_att 11.314562 loss_ctc 11.663448 loss_rnnt 12.531261 hw_loss 0.357872 lr 0.00036569 rank 2
2023-02-22 17:38:17,185 DEBUG TRAIN Batch 22/3400 loss 6.535305 loss_att 8.849474 loss_ctc 9.668683 loss_rnnt 5.438044 hw_loss 0.406207 lr 0.00036579 rank 0
2023-02-22 17:38:17,187 DEBUG TRAIN Batch 22/3400 loss 7.039008 loss_att 9.767828 loss_ctc 11.289711 loss_rnnt 5.817958 hw_loss 0.203487 lr 0.00036578 rank 4
2023-02-22 17:38:17,188 DEBUG TRAIN Batch 22/3400 loss 8.952876 loss_att 13.057666 loss_ctc 14.425255 loss_rnnt 7.295064 hw_loss 0.201007 lr 0.00036567 rank 6
2023-02-22 17:38:17,189 DEBUG TRAIN Batch 22/3400 loss 9.659597 loss_att 14.342421 loss_ctc 13.768476 loss_rnnt 8.109199 hw_loss 0.123721 lr 0.00036572 rank 1
2023-02-22 17:38:17,189 DEBUG TRAIN Batch 22/3400 loss 2.197836 loss_att 5.152472 loss_ctc 3.660831 loss_rnnt 1.175609 hw_loss 0.442938 lr 0.00036569 rank 7
2023-02-22 17:38:17,199 DEBUG TRAIN Batch 22/3400 loss 9.226540 loss_att 12.096123 loss_ctc 14.387081 loss_rnnt 7.748731 hw_loss 0.404661 lr 0.00036572 rank 5
2023-02-22 17:39:31,031 DEBUG TRAIN Batch 22/3500 loss 9.419350 loss_att 11.660397 loss_ctc 15.335739 loss_rnnt 8.037592 hw_loss 0.271306 lr 0.00036560 rank 2
2023-02-22 17:39:31,044 DEBUG TRAIN Batch 22/3500 loss 9.506082 loss_att 11.597997 loss_ctc 11.907227 loss_rnnt 8.626173 hw_loss 0.265074 lr 0.00036569 rank 0
2023-02-22 17:39:31,045 DEBUG TRAIN Batch 22/3500 loss 7.895660 loss_att 11.627510 loss_ctc 10.605480 loss_rnnt 6.624080 hw_loss 0.307317 lr 0.00036566 rank 3
2023-02-22 17:39:31,045 DEBUG TRAIN Batch 22/3500 loss 9.171965 loss_att 13.637007 loss_ctc 13.669035 loss_rnnt 7.506874 hw_loss 0.323387 lr 0.00036569 rank 4
2023-02-22 17:39:31,046 DEBUG TRAIN Batch 22/3500 loss 4.426459 loss_att 7.052691 loss_ctc 5.356713 loss_rnnt 3.601376 hw_loss 0.329630 lr 0.00036563 rank 5
2023-02-22 17:39:31,047 DEBUG TRAIN Batch 22/3500 loss 14.701844 loss_att 17.156559 loss_ctc 21.467827 loss_rnnt 13.182671 hw_loss 0.236438 lr 0.00036559 rank 7
2023-02-22 17:39:31,049 DEBUG TRAIN Batch 22/3500 loss 15.607688 loss_att 18.073742 loss_ctc 21.266663 loss_rnnt 14.213659 hw_loss 0.274290 lr 0.00036563 rank 1
2023-02-22 17:39:31,051 DEBUG TRAIN Batch 22/3500 loss 14.518682 loss_att 16.887993 loss_ctc 20.419401 loss_rnnt 13.138153 hw_loss 0.224820 lr 0.00036558 rank 6
2023-02-22 17:40:45,127 DEBUG TRAIN Batch 22/3600 loss 11.658240 loss_att 13.135487 loss_ctc 14.493424 loss_rnnt 10.865619 hw_loss 0.223400 lr 0.00036559 rank 4
2023-02-22 17:40:45,127 DEBUG TRAIN Batch 22/3600 loss 11.727722 loss_att 12.552979 loss_ctc 15.167615 loss_rnnt 10.994399 hw_loss 0.205535 lr 0.00036557 rank 3
2023-02-22 17:40:45,128 DEBUG TRAIN Batch 22/3600 loss 8.455344 loss_att 13.774039 loss_ctc 12.298621 loss_rnnt 6.765430 hw_loss 0.213259 lr 0.00036549 rank 7
2023-02-22 17:40:45,128 DEBUG TRAIN Batch 22/3600 loss 3.285362 loss_att 6.354037 loss_ctc 4.283425 loss_rnnt 2.434445 hw_loss 0.195201 lr 0.00036548 rank 6
2023-02-22 17:40:45,129 DEBUG TRAIN Batch 22/3600 loss 5.235991 loss_att 7.793439 loss_ctc 7.998408 loss_rnnt 4.298275 hw_loss 0.108572 lr 0.00036550 rank 2
2023-02-22 17:40:45,128 DEBUG TRAIN Batch 22/3600 loss 5.447922 loss_att 7.603897 loss_ctc 9.281055 loss_rnnt 4.340395 hw_loss 0.309839 lr 0.00036553 rank 1
2023-02-22 17:40:45,137 DEBUG TRAIN Batch 22/3600 loss 10.155518 loss_att 12.710089 loss_ctc 13.562380 loss_rnnt 9.009275 hw_loss 0.339526 lr 0.00036560 rank 0
2023-02-22 17:40:45,137 DEBUG TRAIN Batch 22/3600 loss 7.122833 loss_att 10.031729 loss_ctc 10.373578 loss_rnnt 5.994909 hw_loss 0.211336 lr 0.00036553 rank 5
2023-02-22 17:41:57,619 DEBUG TRAIN Batch 22/3700 loss 4.113521 loss_att 6.147544 loss_ctc 5.761538 loss_rnnt 3.302635 hw_loss 0.345648 lr 0.00036540 rank 2
2023-02-22 17:41:57,623 DEBUG TRAIN Batch 22/3700 loss 21.828394 loss_att 22.201824 loss_ctc 25.949659 loss_rnnt 21.038725 hw_loss 0.310278 lr 0.00036539 rank 7
2023-02-22 17:41:57,626 DEBUG TRAIN Batch 22/3700 loss 11.541568 loss_att 14.248108 loss_ctc 17.964867 loss_rnnt 10.003319 hw_loss 0.263438 lr 0.00036547 rank 3
2023-02-22 17:41:57,627 DEBUG TRAIN Batch 22/3700 loss 7.072935 loss_att 8.993116 loss_ctc 9.064976 loss_rnnt 6.255753 hw_loss 0.314139 lr 0.00036550 rank 0
2023-02-22 17:41:57,627 DEBUG TRAIN Batch 22/3700 loss 7.686228 loss_att 10.374136 loss_ctc 9.800626 loss_rnnt 6.681839 hw_loss 0.346664 lr 0.00036543 rank 1
2023-02-22 17:41:57,630 DEBUG TRAIN Batch 22/3700 loss 6.498239 loss_att 8.285311 loss_ctc 10.384903 loss_rnnt 5.446397 hw_loss 0.330384 lr 0.00036543 rank 5
2023-02-22 17:41:57,630 DEBUG TRAIN Batch 22/3700 loss 3.810072 loss_att 8.158607 loss_ctc 5.809999 loss_rnnt 2.575160 hw_loss 0.184779 lr 0.00036538 rank 6
2023-02-22 17:41:57,678 DEBUG TRAIN Batch 22/3700 loss 16.078310 loss_att 18.004007 loss_ctc 21.920988 loss_rnnt 14.768923 hw_loss 0.272294 lr 0.00036549 rank 4
2023-02-22 17:43:09,867 DEBUG TRAIN Batch 22/3800 loss 6.418956 loss_att 8.921305 loss_ctc 8.946559 loss_rnnt 5.461567 hw_loss 0.224824 lr 0.00036540 rank 0
2023-02-22 17:43:09,869 DEBUG TRAIN Batch 22/3800 loss 18.485510 loss_att 21.739613 loss_ctc 24.693182 loss_rnnt 16.824905 hw_loss 0.341425 lr 0.00036539 rank 4
2023-02-22 17:43:09,868 DEBUG TRAIN Batch 22/3800 loss 10.024746 loss_att 10.733497 loss_ctc 13.240307 loss_rnnt 9.347279 hw_loss 0.200578 lr 0.00036529 rank 7
2023-02-22 17:43:09,869 DEBUG TRAIN Batch 22/3800 loss 18.408594 loss_att 21.508814 loss_ctc 29.187780 loss_rnnt 16.191015 hw_loss 0.300584 lr 0.00036528 rank 6
2023-02-22 17:43:09,870 DEBUG TRAIN Batch 22/3800 loss 5.761367 loss_att 6.913887 loss_ctc 7.315966 loss_rnnt 5.186335 hw_loss 0.257340 lr 0.00036530 rank 2
2023-02-22 17:43:09,870 DEBUG TRAIN Batch 22/3800 loss 8.114856 loss_att 9.297939 loss_ctc 12.926834 loss_rnnt 6.969747 hw_loss 0.500428 lr 0.00036533 rank 1
2023-02-22 17:43:09,872 DEBUG TRAIN Batch 22/3800 loss 4.637362 loss_att 5.799046 loss_ctc 5.881171 loss_rnnt 4.047085 hw_loss 0.360186 lr 0.00036537 rank 3
2023-02-22 17:43:09,871 DEBUG TRAIN Batch 22/3800 loss 7.986016 loss_att 7.846061 loss_ctc 9.241427 loss_rnnt 7.703368 hw_loss 0.268595 lr 0.00036533 rank 5
2023-02-22 17:44:25,137 DEBUG TRAIN Batch 22/3900 loss 5.594342 loss_att 7.439423 loss_ctc 8.634954 loss_rnnt 4.641210 hw_loss 0.335066 lr 0.00036530 rank 0
2023-02-22 17:44:25,140 DEBUG TRAIN Batch 22/3900 loss 7.362509 loss_att 12.713741 loss_ctc 9.830664 loss_rnnt 5.738517 hw_loss 0.421234 lr 0.00036520 rank 2
2023-02-22 17:44:25,141 DEBUG TRAIN Batch 22/3900 loss 11.646874 loss_att 16.539127 loss_ctc 15.362244 loss_rnnt 10.055766 hw_loss 0.219892 lr 0.00036519 rank 6
2023-02-22 17:44:25,143 DEBUG TRAIN Batch 22/3900 loss 8.431448 loss_att 13.448256 loss_ctc 19.372894 loss_rnnt 5.847385 hw_loss 0.228452 lr 0.00036527 rank 3
2023-02-22 17:44:25,148 DEBUG TRAIN Batch 22/3900 loss 5.415957 loss_att 9.112240 loss_ctc 7.671966 loss_rnnt 4.270092 hw_loss 0.198389 lr 0.00036530 rank 4
2023-02-22 17:44:25,149 DEBUG TRAIN Batch 22/3900 loss 14.708813 loss_att 16.976843 loss_ctc 27.112762 loss_rnnt 12.501305 hw_loss 0.187579 lr 0.00036524 rank 5
2023-02-22 17:44:25,152 DEBUG TRAIN Batch 22/3900 loss 6.666517 loss_att 7.826557 loss_ctc 9.062538 loss_rnnt 5.968814 hw_loss 0.274174 lr 0.00036524 rank 1
2023-02-22 17:44:25,178 DEBUG TRAIN Batch 22/3900 loss 8.633907 loss_att 9.029104 loss_ctc 9.156345 loss_rnnt 8.340574 hw_loss 0.271192 lr 0.00036520 rank 7
2023-02-22 17:45:37,554 DEBUG TRAIN Batch 22/4000 loss 11.467404 loss_att 13.233459 loss_ctc 17.044647 loss_rnnt 10.141094 hw_loss 0.430250 lr 0.00036514 rank 1
2023-02-22 17:45:37,569 DEBUG TRAIN Batch 22/4000 loss 7.283946 loss_att 12.825884 loss_ctc 16.248615 loss_rnnt 4.800786 hw_loss 0.336531 lr 0.00036518 rank 3
2023-02-22 17:45:37,569 DEBUG TRAIN Batch 22/4000 loss 6.538582 loss_att 8.183857 loss_ctc 9.098383 loss_rnnt 5.694587 hw_loss 0.325562 lr 0.00036509 rank 6
2023-02-22 17:45:37,572 DEBUG TRAIN Batch 22/4000 loss 1.866100 loss_att 5.540905 loss_ctc 4.420826 loss_rnnt 0.702119 hw_loss 0.165731 lr 0.00036511 rank 2
2023-02-22 17:45:37,573 DEBUG TRAIN Batch 22/4000 loss 7.795057 loss_att 12.121937 loss_ctc 11.915790 loss_rnnt 6.265200 hw_loss 0.215719 lr 0.00036520 rank 4
2023-02-22 17:45:37,573 DEBUG TRAIN Batch 22/4000 loss 12.157481 loss_att 16.409128 loss_ctc 21.778318 loss_rnnt 9.879125 hw_loss 0.272340 lr 0.00036514 rank 5
2023-02-22 17:45:37,579 DEBUG TRAIN Batch 22/4000 loss 6.510160 loss_att 10.072350 loss_ctc 10.310233 loss_rnnt 5.205653 hw_loss 0.160112 lr 0.00036521 rank 0
2023-02-22 17:45:37,579 DEBUG TRAIN Batch 22/4000 loss 6.322386 loss_att 10.107705 loss_ctc 12.218349 loss_rnnt 4.611794 hw_loss 0.313875 lr 0.00036510 rank 7
2023-02-22 17:46:50,306 DEBUG TRAIN Batch 22/4100 loss 5.989635 loss_att 7.966047 loss_ctc 11.564316 loss_rnnt 4.709479 hw_loss 0.265468 lr 0.00036501 rank 2
2023-02-22 17:46:50,309 DEBUG TRAIN Batch 22/4100 loss 5.882689 loss_att 9.109390 loss_ctc 8.143391 loss_rnnt 4.777250 hw_loss 0.297509 lr 0.00036504 rank 1
2023-02-22 17:46:50,313 DEBUG TRAIN Batch 22/4100 loss 17.360168 loss_att 21.954683 loss_ctc 20.848070 loss_rnnt 15.827530 hw_loss 0.278780 lr 0.00036508 rank 3
2023-02-22 17:46:50,315 DEBUG TRAIN Batch 22/4100 loss 8.991645 loss_att 12.176491 loss_ctc 13.153255 loss_rnnt 7.630052 hw_loss 0.318267 lr 0.00036499 rank 6
2023-02-22 17:46:50,319 DEBUG TRAIN Batch 22/4100 loss 10.909105 loss_att 13.446496 loss_ctc 18.390152 loss_rnnt 9.291019 hw_loss 0.212129 lr 0.00036511 rank 0
2023-02-22 17:46:50,320 DEBUG TRAIN Batch 22/4100 loss 10.176100 loss_att 15.361824 loss_ctc 11.767000 loss_rnnt 8.713479 hw_loss 0.400043 lr 0.00036504 rank 5
2023-02-22 17:46:50,324 DEBUG TRAIN Batch 22/4100 loss 9.431403 loss_att 12.109142 loss_ctc 11.133279 loss_rnnt 8.559103 hw_loss 0.205942 lr 0.00036510 rank 4
2023-02-22 17:46:50,361 DEBUG TRAIN Batch 22/4100 loss 9.398451 loss_att 13.611235 loss_ctc 14.095659 loss_rnnt 7.736217 hw_loss 0.362595 lr 0.00036500 rank 7
2023-02-22 17:48:03,806 DEBUG TRAIN Batch 22/4200 loss 8.842645 loss_att 11.972042 loss_ctc 12.557907 loss_rnnt 7.562850 hw_loss 0.297276 lr 0.00036500 rank 4
2023-02-22 17:48:03,807 DEBUG TRAIN Batch 22/4200 loss 5.758829 loss_att 10.282926 loss_ctc 8.714275 loss_rnnt 4.236013 hw_loss 0.419881 lr 0.00036491 rank 2
2023-02-22 17:48:03,808 DEBUG TRAIN Batch 22/4200 loss 5.619186 loss_att 7.787974 loss_ctc 7.076105 loss_rnnt 4.888889 hw_loss 0.191781 lr 0.00036498 rank 3
2023-02-22 17:48:03,809 DEBUG TRAIN Batch 22/4200 loss 10.726787 loss_att 13.169617 loss_ctc 18.550386 loss_rnnt 9.083407 hw_loss 0.209374 lr 0.00036491 rank 7
2023-02-22 17:48:03,810 DEBUG TRAIN Batch 22/4200 loss 11.646145 loss_att 13.599380 loss_ctc 14.218575 loss_rnnt 10.783695 hw_loss 0.241520 lr 0.00036494 rank 5
2023-02-22 17:48:03,811 DEBUG TRAIN Batch 22/4200 loss 9.944769 loss_att 13.475220 loss_ctc 13.873144 loss_rnnt 8.628434 hw_loss 0.162116 lr 0.00036489 rank 6
2023-02-22 17:48:03,811 DEBUG TRAIN Batch 22/4200 loss 6.214972 loss_att 8.635872 loss_ctc 7.211445 loss_rnnt 5.455538 hw_loss 0.266981 lr 0.00036501 rank 0
2023-02-22 17:48:03,812 DEBUG TRAIN Batch 22/4200 loss 10.808077 loss_att 12.056921 loss_ctc 15.015558 loss_rnnt 9.814164 hw_loss 0.343400 lr 0.00036494 rank 1
2023-02-22 17:49:17,901 DEBUG TRAIN Batch 22/4300 loss 8.574269 loss_att 10.381618 loss_ctc 12.449909 loss_rnnt 7.541041 hw_loss 0.290637 lr 0.00036482 rank 2
2023-02-22 17:49:17,905 DEBUG TRAIN Batch 22/4300 loss 19.198204 loss_att 22.259941 loss_ctc 26.057205 loss_rnnt 17.527092 hw_loss 0.270433 lr 0.00036488 rank 3
2023-02-22 17:49:17,907 DEBUG TRAIN Batch 22/4300 loss 8.794503 loss_att 11.329719 loss_ctc 11.379798 loss_rnnt 7.826145 hw_loss 0.218643 lr 0.00036485 rank 1
2023-02-22 17:49:17,908 DEBUG TRAIN Batch 22/4300 loss 10.772495 loss_att 12.558647 loss_ctc 15.483784 loss_rnnt 9.695597 hw_loss 0.171556 lr 0.00036480 rank 6
2023-02-22 17:49:17,911 DEBUG TRAIN Batch 22/4300 loss 4.701928 loss_att 7.021999 loss_ctc 6.009712 loss_rnnt 3.886324 hw_loss 0.332284 lr 0.00036485 rank 5
2023-02-22 17:49:17,912 DEBUG TRAIN Batch 22/4300 loss 15.251538 loss_att 19.753088 loss_ctc 21.590397 loss_rnnt 13.342439 hw_loss 0.306767 lr 0.00036481 rank 7
2023-02-22 17:49:17,916 DEBUG TRAIN Batch 22/4300 loss 12.936002 loss_att 15.236191 loss_ctc 19.240944 loss_rnnt 11.493376 hw_loss 0.266117 lr 0.00036491 rank 0
2023-02-22 17:49:17,958 DEBUG TRAIN Batch 22/4300 loss 11.475513 loss_att 14.002257 loss_ctc 16.637741 loss_rnnt 10.105611 hw_loss 0.330479 lr 0.00036491 rank 4
2023-02-22 17:50:31,451 DEBUG TRAIN Batch 22/4400 loss 4.613650 loss_att 6.162939 loss_ctc 6.732698 loss_rnnt 3.857975 hw_loss 0.306145 lr 0.00036472 rank 2
2023-02-22 17:50:31,454 DEBUG TRAIN Batch 22/4400 loss 4.429368 loss_att 6.635997 loss_ctc 7.691884 loss_rnnt 3.376334 hw_loss 0.331323 lr 0.00036479 rank 3
2023-02-22 17:50:31,458 DEBUG TRAIN Batch 22/4400 loss 8.457460 loss_att 8.819444 loss_ctc 10.192828 loss_rnnt 7.866519 hw_loss 0.538430 lr 0.00036481 rank 4
2023-02-22 17:50:31,458 DEBUG TRAIN Batch 22/4400 loss 7.396677 loss_att 9.095966 loss_ctc 11.697222 loss_rnnt 6.373931 hw_loss 0.205278 lr 0.00036470 rank 6
2023-02-22 17:50:31,459 DEBUG TRAIN Batch 22/4400 loss 2.890733 loss_att 5.044023 loss_ctc 5.039463 loss_rnnt 2.003918 hw_loss 0.318112 lr 0.00036471 rank 7
2023-02-22 17:50:31,462 DEBUG TRAIN Batch 22/4400 loss 21.773613 loss_att 25.091322 loss_ctc 29.886505 loss_rnnt 19.904902 hw_loss 0.231468 lr 0.00036482 rank 0
2023-02-22 17:50:31,462 DEBUG TRAIN Batch 22/4400 loss 7.724465 loss_att 9.859832 loss_ctc 11.431749 loss_rnnt 6.641931 hw_loss 0.302167 lr 0.00036475 rank 1
2023-02-22 17:50:31,464 DEBUG TRAIN Batch 22/4400 loss 12.241438 loss_att 14.478489 loss_ctc 17.280069 loss_rnnt 10.893559 hw_loss 0.428720 lr 0.00036475 rank 5
2023-02-22 17:51:43,627 DEBUG TRAIN Batch 22/4500 loss 8.834718 loss_att 11.722335 loss_ctc 14.480774 loss_rnnt 7.356922 hw_loss 0.276496 lr 0.00036469 rank 3
2023-02-22 17:51:43,627 DEBUG TRAIN Batch 22/4500 loss 6.931744 loss_att 9.386269 loss_ctc 13.190275 loss_rnnt 5.430819 hw_loss 0.329155 lr 0.00036460 rank 6
2023-02-22 17:51:43,629 DEBUG TRAIN Batch 22/4500 loss 6.183378 loss_att 9.717550 loss_ctc 6.729098 loss_rnnt 5.281546 hw_loss 0.229192 lr 0.00036471 rank 4
2023-02-22 17:51:43,631 DEBUG TRAIN Batch 22/4500 loss 12.335476 loss_att 15.385692 loss_ctc 13.055902 loss_rnnt 11.519760 hw_loss 0.205528 lr 0.00036462 rank 2
2023-02-22 17:51:43,634 DEBUG TRAIN Batch 22/4500 loss 10.172639 loss_att 12.822440 loss_ctc 14.549479 loss_rnnt 8.931431 hw_loss 0.239380 lr 0.00036465 rank 1
2023-02-22 17:51:43,637 DEBUG TRAIN Batch 22/4500 loss 9.171397 loss_att 11.784289 loss_ctc 20.961033 loss_rnnt 7.033143 hw_loss 0.081981 lr 0.00036465 rank 5
2023-02-22 17:51:43,639 DEBUG TRAIN Batch 22/4500 loss 6.737310 loss_att 9.208295 loss_ctc 10.038641 loss_rnnt 5.656341 hw_loss 0.274867 lr 0.00036472 rank 0
2023-02-22 17:51:43,683 DEBUG TRAIN Batch 22/4500 loss 7.465312 loss_att 11.524698 loss_ctc 9.062637 loss_rnnt 6.250707 hw_loss 0.355784 lr 0.00036461 rank 7
2023-02-22 17:52:58,837 DEBUG TRAIN Batch 22/4600 loss 15.518893 loss_att 18.796610 loss_ctc 20.968021 loss_rnnt 13.920349 hw_loss 0.405845 lr 0.00036452 rank 2
2023-02-22 17:52:58,838 DEBUG TRAIN Batch 22/4600 loss 3.333045 loss_att 5.267443 loss_ctc 4.585159 loss_rnnt 2.738425 hw_loss 0.076484 lr 0.00036459 rank 3
2023-02-22 17:52:58,839 DEBUG TRAIN Batch 22/4600 loss 9.127992 loss_att 11.370771 loss_ctc 11.120584 loss_rnnt 8.258268 hw_loss 0.291540 lr 0.00036455 rank 5
2023-02-22 17:52:58,839 DEBUG TRAIN Batch 22/4600 loss 6.476171 loss_att 9.935107 loss_ctc 9.761206 loss_rnnt 5.162665 hw_loss 0.344465 lr 0.00036455 rank 1
2023-02-22 17:52:58,840 DEBUG TRAIN Batch 22/4600 loss 4.650179 loss_att 9.502003 loss_ctc 10.335625 loss_rnnt 2.799139 hw_loss 0.229904 lr 0.00036461 rank 4
2023-02-22 17:52:58,842 DEBUG TRAIN Batch 22/4600 loss 14.217958 loss_att 19.302670 loss_ctc 24.609350 loss_rnnt 11.735446 hw_loss 0.150094 lr 0.00036452 rank 7
2023-02-22 17:52:58,842 DEBUG TRAIN Batch 22/4600 loss 5.322948 loss_att 8.335798 loss_ctc 8.408555 loss_rnnt 4.123775 hw_loss 0.347226 lr 0.00036451 rank 6
2023-02-22 17:52:58,865 DEBUG TRAIN Batch 22/4600 loss 3.293827 loss_att 6.001986 loss_ctc 4.969247 loss_rnnt 2.455528 hw_loss 0.137396 lr 0.00036462 rank 0
2023-02-22 17:54:12,383 DEBUG TRAIN Batch 22/4700 loss 2.726104 loss_att 5.305008 loss_ctc 4.408426 loss_rnnt 1.798411 hw_loss 0.351755 lr 0.00036443 rank 2
2023-02-22 17:54:12,387 DEBUG TRAIN Batch 22/4700 loss 3.947119 loss_att 6.338307 loss_ctc 5.860448 loss_rnnt 3.086426 hw_loss 0.238771 lr 0.00036450 rank 3
2023-02-22 17:54:12,389 DEBUG TRAIN Batch 22/4700 loss 9.135762 loss_att 11.818617 loss_ctc 10.512742 loss_rnnt 8.368082 hw_loss 0.089085 lr 0.00036446 rank 5
2023-02-22 17:54:12,391 DEBUG TRAIN Batch 22/4700 loss 8.755776 loss_att 13.130098 loss_ctc 13.442760 loss_rnnt 7.130414 hw_loss 0.235438 lr 0.00036452 rank 4
2023-02-22 17:54:12,391 DEBUG TRAIN Batch 22/4700 loss 8.676988 loss_att 10.766393 loss_ctc 9.436003 loss_rnnt 7.977617 hw_loss 0.338040 lr 0.00036441 rank 6
2023-02-22 17:54:12,391 DEBUG TRAIN Batch 22/4700 loss 6.438224 loss_att 8.842355 loss_ctc 14.836329 loss_rnnt 4.666101 hw_loss 0.321653 lr 0.00036453 rank 0
2023-02-22 17:54:12,393 DEBUG TRAIN Batch 22/4700 loss 8.768035 loss_att 13.231781 loss_ctc 9.700344 loss_rnnt 7.635789 hw_loss 0.215980 lr 0.00036446 rank 1
2023-02-22 17:54:12,440 DEBUG TRAIN Batch 22/4700 loss 8.442426 loss_att 7.957376 loss_ctc 9.247513 loss_rnnt 8.315050 hw_loss 0.219450 lr 0.00036442 rank 7
2023-02-22 17:55:25,469 DEBUG TRAIN Batch 22/4800 loss 13.407693 loss_att 17.113270 loss_ctc 18.774019 loss_rnnt 11.848059 hw_loss 0.193141 lr 0.00036436 rank 5
2023-02-22 17:55:25,474 DEBUG TRAIN Batch 22/4800 loss 9.044929 loss_att 11.311701 loss_ctc 13.906586 loss_rnnt 7.804597 hw_loss 0.260167 lr 0.00036433 rank 2
2023-02-22 17:55:25,477 DEBUG TRAIN Batch 22/4800 loss 10.597645 loss_att 13.870697 loss_ctc 17.780186 loss_rnnt 8.832323 hw_loss 0.286949 lr 0.00036440 rank 3
2023-02-22 17:55:25,480 DEBUG TRAIN Batch 22/4800 loss 4.779213 loss_att 8.061076 loss_ctc 8.179333 loss_rnnt 3.534267 hw_loss 0.253546 lr 0.00036431 rank 6
2023-02-22 17:55:25,482 DEBUG TRAIN Batch 22/4800 loss 6.185193 loss_att 8.513477 loss_ctc 6.875185 loss_rnnt 5.521859 hw_loss 0.198143 lr 0.00036436 rank 1
2023-02-22 17:55:25,483 DEBUG TRAIN Batch 22/4800 loss 7.834230 loss_att 12.270040 loss_ctc 9.834418 loss_rnnt 6.595079 hw_loss 0.159932 lr 0.00036432 rank 7
2023-02-22 17:55:25,485 DEBUG TRAIN Batch 22/4800 loss 2.183828 loss_att 3.933628 loss_ctc 3.872856 loss_rnnt 1.449112 hw_loss 0.299160 lr 0.00036442 rank 4
2023-02-22 17:55:25,486 DEBUG TRAIN Batch 22/4800 loss 7.004444 loss_att 9.182838 loss_ctc 9.153569 loss_rnnt 6.138701 hw_loss 0.269088 lr 0.00036443 rank 0
2023-02-22 17:56:37,574 DEBUG TRAIN Batch 22/4900 loss 13.960170 loss_att 16.868818 loss_ctc 20.792107 loss_rnnt 12.275574 hw_loss 0.359890 lr 0.00036433 rank 0
2023-02-22 17:56:37,576 DEBUG TRAIN Batch 22/4900 loss 21.851566 loss_att 22.371889 loss_ctc 30.938786 loss_rnnt 20.408646 hw_loss 0.238550 lr 0.00036432 rank 4
2023-02-22 17:56:37,576 DEBUG TRAIN Batch 22/4900 loss 8.686792 loss_att 11.085054 loss_ctc 11.219527 loss_rnnt 7.710612 hw_loss 0.297807 lr 0.00036426 rank 1
2023-02-22 17:56:37,577 DEBUG TRAIN Batch 22/4900 loss 10.097269 loss_att 14.278159 loss_ctc 16.246454 loss_rnnt 8.284349 hw_loss 0.294093 lr 0.00036430 rank 3
2023-02-22 17:56:37,578 DEBUG TRAIN Batch 22/4900 loss 18.629612 loss_att 22.907005 loss_ctc 25.400166 loss_rnnt 16.746639 hw_loss 0.233914 lr 0.00036423 rank 7
2023-02-22 17:56:37,579 DEBUG TRAIN Batch 22/4900 loss 9.734699 loss_att 12.038069 loss_ctc 12.272242 loss_rnnt 8.807489 hw_loss 0.240368 lr 0.00036426 rank 5
2023-02-22 17:56:37,585 DEBUG TRAIN Batch 22/4900 loss 5.337744 loss_att 7.148083 loss_ctc 6.709519 loss_rnnt 4.628160 hw_loss 0.308649 lr 0.00036423 rank 2
2023-02-22 17:56:37,588 DEBUG TRAIN Batch 22/4900 loss 10.079409 loss_att 12.910437 loss_ctc 15.188634 loss_rnnt 8.709229 hw_loss 0.230142 lr 0.00036422 rank 6
2023-02-22 17:57:52,397 DEBUG TRAIN Batch 22/5000 loss 8.854887 loss_att 12.950770 loss_ctc 11.958084 loss_rnnt 7.549614 hw_loss 0.135632 lr 0.00036421 rank 3
2023-02-22 17:57:52,399 DEBUG TRAIN Batch 22/5000 loss 8.907297 loss_att 11.888217 loss_ctc 13.664731 loss_rnnt 7.473436 hw_loss 0.381286 lr 0.00036414 rank 2
2023-02-22 17:57:52,400 DEBUG TRAIN Batch 22/5000 loss 5.353508 loss_att 6.980502 loss_ctc 6.160001 loss_rnnt 4.751946 hw_loss 0.316183 lr 0.00036417 rank 1
2023-02-22 17:57:52,401 DEBUG TRAIN Batch 22/5000 loss 7.744616 loss_att 9.472114 loss_ctc 10.526891 loss_rnnt 6.860628 hw_loss 0.314099 lr 0.00036424 rank 0
2023-02-22 17:57:52,401 DEBUG TRAIN Batch 22/5000 loss 9.191141 loss_att 12.733218 loss_ctc 16.810509 loss_rnnt 7.321489 hw_loss 0.272477 lr 0.00036412 rank 6
2023-02-22 17:57:52,402 DEBUG TRAIN Batch 22/5000 loss 12.531215 loss_att 13.062172 loss_ctc 18.004166 loss_rnnt 11.598559 hw_loss 0.181382 lr 0.00036417 rank 5
2023-02-22 17:57:52,405 DEBUG TRAIN Batch 22/5000 loss 8.072035 loss_att 9.262088 loss_ctc 9.847919 loss_rnnt 7.436194 hw_loss 0.301962 lr 0.00036423 rank 4
2023-02-22 17:57:52,406 DEBUG TRAIN Batch 22/5000 loss 15.206614 loss_att 15.673624 loss_ctc 18.509598 loss_rnnt 14.447951 hw_loss 0.421617 lr 0.00036413 rank 7
2023-02-22 17:59:06,220 DEBUG TRAIN Batch 22/5100 loss 7.410564 loss_att 8.989670 loss_ctc 12.264208 loss_rnnt 6.226503 hw_loss 0.414538 lr 0.00036411 rank 3
2023-02-22 17:59:06,223 DEBUG TRAIN Batch 22/5100 loss 14.082942 loss_att 13.665882 loss_ctc 20.482857 loss_rnnt 13.096318 hw_loss 0.406339 lr 0.00036404 rank 2
2023-02-22 17:59:06,224 DEBUG TRAIN Batch 22/5100 loss 6.422901 loss_att 11.618346 loss_ctc 11.653543 loss_rnnt 4.516852 hw_loss 0.317888 lr 0.00036413 rank 4
2023-02-22 17:59:06,224 DEBUG TRAIN Batch 22/5100 loss 6.873087 loss_att 8.114055 loss_ctc 9.934737 loss_rnnt 5.972456 hw_loss 0.457908 lr 0.00036407 rank 1
2023-02-22 17:59:06,228 DEBUG TRAIN Batch 22/5100 loss 7.623799 loss_att 13.129135 loss_ctc 12.413122 loss_rnnt 5.809164 hw_loss 0.140610 lr 0.00036414 rank 0
2023-02-22 17:59:06,229 DEBUG TRAIN Batch 22/5100 loss 17.613611 loss_att 20.686796 loss_ctc 26.418898 loss_rnnt 15.733768 hw_loss 0.170940 lr 0.00036403 rank 7
2023-02-22 17:59:06,230 DEBUG TRAIN Batch 22/5100 loss 9.314318 loss_att 9.608522 loss_ctc 12.291523 loss_rnnt 8.669861 hw_loss 0.353727 lr 0.00036402 rank 6
2023-02-22 17:59:06,280 DEBUG TRAIN Batch 22/5100 loss 11.110476 loss_att 15.713711 loss_ctc 12.132022 loss_rnnt 9.833490 hw_loss 0.412751 lr 0.00036407 rank 5
2023-02-22 18:00:18,508 DEBUG TRAIN Batch 22/5200 loss 9.078037 loss_att 10.292838 loss_ctc 14.101080 loss_rnnt 8.103813 hw_loss 0.115360 lr 0.00036397 rank 1
2023-02-22 18:00:18,522 DEBUG TRAIN Batch 22/5200 loss 7.722863 loss_att 11.781866 loss_ctc 13.906451 loss_rnnt 5.980025 hw_loss 0.199797 lr 0.00036394 rank 2
2023-02-22 18:00:18,526 DEBUG TRAIN Batch 22/5200 loss 9.184666 loss_att 10.302298 loss_ctc 11.513363 loss_rnnt 8.549931 hw_loss 0.188841 lr 0.00036401 rank 3
2023-02-22 18:00:18,529 DEBUG TRAIN Batch 22/5200 loss 15.357994 loss_att 20.757793 loss_ctc 21.672697 loss_rnnt 13.270866 hw_loss 0.309763 lr 0.00036403 rank 4
2023-02-22 18:00:18,531 DEBUG TRAIN Batch 22/5200 loss 6.563391 loss_att 9.182410 loss_ctc 11.411840 loss_rnnt 5.253295 hw_loss 0.262184 lr 0.00036397 rank 5
2023-02-22 18:00:18,532 DEBUG TRAIN Batch 22/5200 loss 9.043062 loss_att 9.076465 loss_ctc 9.668468 loss_rnnt 8.855624 hw_loss 0.182569 lr 0.00036394 rank 7
2023-02-22 18:00:18,536 DEBUG TRAIN Batch 22/5200 loss 6.791362 loss_att 10.772688 loss_ctc 7.503023 loss_rnnt 5.754396 hw_loss 0.273398 lr 0.00036393 rank 6
2023-02-22 18:00:18,580 DEBUG TRAIN Batch 22/5200 loss 11.757012 loss_att 13.444054 loss_ctc 12.742213 loss_rnnt 11.201258 hw_loss 0.163097 lr 0.00036404 rank 0
2023-02-22 18:01:32,233 DEBUG TRAIN Batch 22/5300 loss 9.555317 loss_att 10.625269 loss_ctc 13.793863 loss_rnnt 8.669301 hw_loss 0.200411 lr 0.00036385 rank 2
2023-02-22 18:01:32,233 DEBUG TRAIN Batch 22/5300 loss 7.723405 loss_att 10.376021 loss_ctc 11.277733 loss_rnnt 6.598004 hw_loss 0.226812 lr 0.00036388 rank 5
2023-02-22 18:01:32,235 DEBUG TRAIN Batch 22/5300 loss 2.440723 loss_att 6.430636 loss_ctc 5.966487 loss_rnnt 1.062442 hw_loss 0.206618 lr 0.00036392 rank 3
2023-02-22 18:01:32,238 DEBUG TRAIN Batch 22/5300 loss 14.733063 loss_att 17.843357 loss_ctc 20.000336 loss_rnnt 13.259289 hw_loss 0.280147 lr 0.00036394 rank 4
2023-02-22 18:01:32,238 DEBUG TRAIN Batch 22/5300 loss 9.123600 loss_att 9.902275 loss_ctc 15.763267 loss_rnnt 7.972170 hw_loss 0.207012 lr 0.00036383 rank 6
2023-02-22 18:01:32,239 DEBUG TRAIN Batch 22/5300 loss 2.476738 loss_att 4.561908 loss_ctc 4.216839 loss_rnnt 1.676275 hw_loss 0.283903 lr 0.00036388 rank 1
2023-02-22 18:01:32,252 DEBUG TRAIN Batch 22/5300 loss 2.378762 loss_att 4.663446 loss_ctc 4.351124 loss_rnnt 1.567301 hw_loss 0.171643 lr 0.00036395 rank 0
2023-02-22 18:01:32,283 DEBUG TRAIN Batch 22/5300 loss 6.064487 loss_att 8.105463 loss_ctc 7.005962 loss_rnnt 5.349761 hw_loss 0.339376 lr 0.00036384 rank 7
2023-02-22 18:02:45,689 DEBUG TRAIN Batch 22/5400 loss 7.912261 loss_att 12.128339 loss_ctc 11.503563 loss_rnnt 6.511058 hw_loss 0.148402 lr 0.00036373 rank 6
2023-02-22 18:02:45,700 DEBUG TRAIN Batch 22/5400 loss 7.146202 loss_att 10.004175 loss_ctc 8.232910 loss_rnnt 6.299813 hw_loss 0.243562 lr 0.00036384 rank 4
2023-02-22 18:02:45,710 DEBUG TRAIN Batch 22/5400 loss 4.902125 loss_att 7.201881 loss_ctc 5.689861 loss_rnnt 4.253659 hw_loss 0.156530 lr 0.00036375 rank 2
2023-02-22 18:02:45,711 DEBUG TRAIN Batch 22/5400 loss 6.286364 loss_att 9.864449 loss_ctc 9.831562 loss_rnnt 5.016020 hw_loss 0.153814 lr 0.00036385 rank 0
2023-02-22 18:02:45,716 DEBUG TRAIN Batch 22/5400 loss 6.878362 loss_att 7.591115 loss_ctc 7.910718 loss_rnnt 6.397398 hw_loss 0.376438 lr 0.00036382 rank 3
2023-02-22 18:02:45,716 DEBUG TRAIN Batch 22/5400 loss 9.167020 loss_att 10.473398 loss_ctc 14.755194 loss_rnnt 8.054527 hw_loss 0.198988 lr 0.00036378 rank 1
2023-02-22 18:02:45,721 DEBUG TRAIN Batch 22/5400 loss 17.168831 loss_att 17.593964 loss_ctc 25.659077 loss_rnnt 15.763515 hw_loss 0.352979 lr 0.00036378 rank 5
2023-02-22 18:02:45,759 DEBUG TRAIN Batch 22/5400 loss 11.055676 loss_att 14.869974 loss_ctc 14.970842 loss_rnnt 9.526396 hw_loss 0.458245 lr 0.00036374 rank 7
2023-02-22 18:03:57,703 DEBUG TRAIN Batch 22/5500 loss 16.391777 loss_att 16.891811 loss_ctc 23.028120 loss_rnnt 15.232538 hw_loss 0.326973 lr 0.00036366 rank 2
2023-02-22 18:03:57,704 DEBUG TRAIN Batch 22/5500 loss 15.583877 loss_att 20.353580 loss_ctc 26.325733 loss_rnnt 13.088003 hw_loss 0.205661 lr 0.00036372 rank 3
2023-02-22 18:03:57,708 DEBUG TRAIN Batch 22/5500 loss 18.727036 loss_att 22.321396 loss_ctc 26.328270 loss_rnnt 16.831022 hw_loss 0.306828 lr 0.00036365 rank 7
2023-02-22 18:03:57,709 DEBUG TRAIN Batch 22/5500 loss 11.584813 loss_att 13.685382 loss_ctc 16.559841 loss_rnnt 10.322131 hw_loss 0.336058 lr 0.00036364 rank 6
2023-02-22 18:03:57,711 DEBUG TRAIN Batch 22/5500 loss 6.521632 loss_att 7.911766 loss_ctc 6.713679 loss_rnnt 6.008285 hw_loss 0.393217 lr 0.00036369 rank 5
2023-02-22 18:03:57,711 DEBUG TRAIN Batch 22/5500 loss 7.207435 loss_att 11.111323 loss_ctc 8.685558 loss_rnnt 6.098644 hw_loss 0.245494 lr 0.00036375 rank 4
2023-02-22 18:03:57,712 DEBUG TRAIN Batch 22/5500 loss 8.874429 loss_att 11.352059 loss_ctc 15.836319 loss_rnnt 7.361275 hw_loss 0.167577 lr 0.00036375 rank 0
2023-02-22 18:03:57,762 DEBUG TRAIN Batch 22/5500 loss 8.580412 loss_att 9.187757 loss_ctc 8.407204 loss_rnnt 8.279222 hw_loss 0.380278 lr 0.00036369 rank 1
2023-02-22 18:05:10,700 DEBUG TRAIN Batch 22/5600 loss 14.645963 loss_att 19.622456 loss_ctc 25.473686 loss_rnnt 12.111602 hw_loss 0.178812 lr 0.00036359 rank 1
2023-02-22 18:05:10,703 DEBUG TRAIN Batch 22/5600 loss 11.108616 loss_att 12.290502 loss_ctc 12.886683 loss_rnnt 10.445097 hw_loss 0.356373 lr 0.00036356 rank 2
2023-02-22 18:05:10,704 DEBUG TRAIN Batch 22/5600 loss 4.417387 loss_att 7.893179 loss_ctc 5.183887 loss_rnnt 3.523679 hw_loss 0.180653 lr 0.00036354 rank 6
2023-02-22 18:05:10,706 DEBUG TRAIN Batch 22/5600 loss 12.238064 loss_att 15.375004 loss_ctc 17.732744 loss_rnnt 10.706743 hw_loss 0.321203 lr 0.00036359 rank 5
2023-02-22 18:05:10,707 DEBUG TRAIN Batch 22/5600 loss 8.789919 loss_att 11.877470 loss_ctc 14.204443 loss_rnnt 7.313082 hw_loss 0.257603 lr 0.00036363 rank 3
2023-02-22 18:05:10,710 DEBUG TRAIN Batch 22/5600 loss 8.176748 loss_att 8.919030 loss_ctc 9.984279 loss_rnnt 7.694329 hw_loss 0.174297 lr 0.00036355 rank 7
2023-02-22 18:05:10,710 DEBUG TRAIN Batch 22/5600 loss 7.062175 loss_att 10.295100 loss_ctc 10.495375 loss_rnnt 5.852599 hw_loss 0.197307 lr 0.00036366 rank 0
2023-02-22 18:05:10,718 DEBUG TRAIN Batch 22/5600 loss 12.953716 loss_att 15.190249 loss_ctc 18.666172 loss_rnnt 11.612967 hw_loss 0.247090 lr 0.00036365 rank 4
2023-02-22 18:06:26,066 DEBUG TRAIN Batch 22/5700 loss 7.807003 loss_att 11.436608 loss_ctc 15.157084 loss_rnnt 5.864923 hw_loss 0.442777 lr 0.00036356 rank 0
2023-02-22 18:06:26,067 DEBUG TRAIN Batch 22/5700 loss 5.553374 loss_att 8.697929 loss_ctc 8.914001 loss_rnnt 4.300949 hw_loss 0.328931 lr 0.00036346 rank 2
2023-02-22 18:06:26,069 DEBUG TRAIN Batch 22/5700 loss 12.580065 loss_att 12.984277 loss_ctc 17.518129 loss_rnnt 11.589647 hw_loss 0.470936 lr 0.00036349 rank 1
2023-02-22 18:06:26,075 DEBUG TRAIN Batch 22/5700 loss 8.866714 loss_att 11.038352 loss_ctc 14.917934 loss_rnnt 7.466637 hw_loss 0.297973 lr 0.00036353 rank 3
2023-02-22 18:06:26,078 DEBUG TRAIN Batch 22/5700 loss 11.619787 loss_att 12.074100 loss_ctc 16.615898 loss_rnnt 10.672011 hw_loss 0.357686 lr 0.00036344 rank 6
2023-02-22 18:06:26,080 DEBUG TRAIN Batch 22/5700 loss 12.574035 loss_att 13.102020 loss_ctc 15.003160 loss_rnnt 11.907977 hw_loss 0.443582 lr 0.00036346 rank 7
2023-02-22 18:06:26,098 DEBUG TRAIN Batch 22/5700 loss 7.448294 loss_att 10.306274 loss_ctc 8.806105 loss_rnnt 6.508037 hw_loss 0.351787 lr 0.00036355 rank 4
2023-02-22 18:06:26,131 DEBUG TRAIN Batch 22/5700 loss 3.712656 loss_att 6.758185 loss_ctc 6.747459 loss_rnnt 2.600233 hw_loss 0.185018 lr 0.00036349 rank 5
2023-02-22 18:07:38,480 DEBUG TRAIN Batch 22/5800 loss 8.862899 loss_att 13.443036 loss_ctc 10.742802 loss_rnnt 7.506673 hw_loss 0.355396 lr 0.00036335 rank 6
2023-02-22 18:07:38,481 DEBUG TRAIN Batch 22/5800 loss 9.411401 loss_att 10.374671 loss_ctc 12.843414 loss_rnnt 8.574671 hw_loss 0.349638 lr 0.00036337 rank 2
2023-02-22 18:07:38,483 DEBUG TRAIN Batch 22/5800 loss 8.807697 loss_att 12.632685 loss_ctc 14.594719 loss_rnnt 7.152966 hw_loss 0.221493 lr 0.00036346 rank 4
2023-02-22 18:07:38,482 DEBUG TRAIN Batch 22/5800 loss 5.137767 loss_att 11.161218 loss_ctc 7.254772 loss_rnnt 3.350711 hw_loss 0.562683 lr 0.00036340 rank 1
2023-02-22 18:07:38,483 DEBUG TRAIN Batch 22/5800 loss 11.722884 loss_att 14.961742 loss_ctc 19.712067 loss_rnnt 9.863334 hw_loss 0.274789 lr 0.00036340 rank 5
2023-02-22 18:07:38,483 DEBUG TRAIN Batch 22/5800 loss 7.575048 loss_att 7.930242 loss_ctc 9.965264 loss_rnnt 7.036016 hw_loss 0.279934 lr 0.00036344 rank 3
2023-02-22 18:07:38,491 DEBUG TRAIN Batch 22/5800 loss 22.345505 loss_att 27.331810 loss_ctc 30.681196 loss_rnnt 20.069168 hw_loss 0.314344 lr 0.00036336 rank 7
2023-02-22 18:07:38,493 DEBUG TRAIN Batch 22/5800 loss 16.363882 loss_att 17.901640 loss_ctc 21.153790 loss_rnnt 15.355198 hw_loss 0.117145 lr 0.00036347 rank 0
2023-02-22 18:08:50,354 DEBUG TRAIN Batch 22/5900 loss 19.608053 loss_att 19.889833 loss_ctc 27.490973 loss_rnnt 18.451647 hw_loss 0.091864 lr 0.00036336 rank 4
2023-02-22 18:08:50,357 DEBUG TRAIN Batch 22/5900 loss 4.212558 loss_att 5.921692 loss_ctc 4.328776 loss_rnnt 3.773402 hw_loss 0.153438 lr 0.00036327 rank 2
2023-02-22 18:08:50,359 DEBUG TRAIN Batch 22/5900 loss 10.353266 loss_att 13.079282 loss_ctc 14.274772 loss_rnnt 9.156986 hw_loss 0.240393 lr 0.00036326 rank 7
2023-02-22 18:08:50,358 DEBUG TRAIN Batch 22/5900 loss 16.701363 loss_att 17.911446 loss_ctc 27.354073 loss_rnnt 14.925493 hw_loss 0.212795 lr 0.00036330 rank 5
2023-02-22 18:08:50,360 DEBUG TRAIN Batch 22/5900 loss 12.215193 loss_att 15.238787 loss_ctc 19.075485 loss_rnnt 10.510864 hw_loss 0.346693 lr 0.00036337 rank 0
2023-02-22 18:08:50,361 DEBUG TRAIN Batch 22/5900 loss 7.011916 loss_att 9.690420 loss_ctc 10.448301 loss_rnnt 5.827666 hw_loss 0.356932 lr 0.00036334 rank 3
2023-02-22 18:08:50,363 DEBUG TRAIN Batch 22/5900 loss 5.731390 loss_att 8.933363 loss_ctc 8.474508 loss_rnnt 4.530005 hw_loss 0.366075 lr 0.00036330 rank 1
2023-02-22 18:08:50,364 DEBUG TRAIN Batch 22/5900 loss 10.030929 loss_att 16.565062 loss_ctc 15.686728 loss_rnnt 7.885528 hw_loss 0.158379 lr 0.00036325 rank 6
2023-02-22 18:10:04,429 DEBUG TRAIN Batch 22/6000 loss 7.864674 loss_att 10.666974 loss_ctc 11.017659 loss_rnnt 6.751293 hw_loss 0.248479 lr 0.00036327 rank 4
2023-02-22 18:10:04,432 DEBUG TRAIN Batch 22/6000 loss 10.546392 loss_att 13.597389 loss_ctc 15.951945 loss_rnnt 9.095618 hw_loss 0.224689 lr 0.00036327 rank 0
2023-02-22 18:10:04,436 DEBUG TRAIN Batch 22/6000 loss 10.759086 loss_att 12.688998 loss_ctc 17.793337 loss_rnnt 9.262568 hw_loss 0.323691 lr 0.00036324 rank 3
2023-02-22 18:10:04,436 DEBUG TRAIN Batch 22/6000 loss 7.465204 loss_att 11.016331 loss_ctc 10.769253 loss_rnnt 6.232480 hw_loss 0.153672 lr 0.00036321 rank 1
2023-02-22 18:10:04,438 DEBUG TRAIN Batch 22/6000 loss 6.303715 loss_att 8.829340 loss_ctc 12.744247 loss_rnnt 4.844577 hw_loss 0.178641 lr 0.00036318 rank 2
2023-02-22 18:10:04,440 DEBUG TRAIN Batch 22/6000 loss 12.646698 loss_att 14.390644 loss_ctc 14.601309 loss_rnnt 11.907627 hw_loss 0.243124 lr 0.00036316 rank 6
2023-02-22 18:10:04,442 DEBUG TRAIN Batch 22/6000 loss 7.144109 loss_att 9.799173 loss_ctc 9.061056 loss_rnnt 6.254002 hw_loss 0.194064 lr 0.00036317 rank 7
2023-02-22 18:10:04,445 DEBUG TRAIN Batch 22/6000 loss 13.586432 loss_att 18.577772 loss_ctc 23.676079 loss_rnnt 11.086491 hw_loss 0.293224 lr 0.00036321 rank 5
2023-02-22 18:11:18,067 DEBUG TRAIN Batch 22/6100 loss 6.977025 loss_att 10.717793 loss_ctc 9.517973 loss_rnnt 5.759617 hw_loss 0.244613 lr 0.00036308 rank 2
2023-02-22 18:11:18,071 DEBUG TRAIN Batch 22/6100 loss 3.014794 loss_att 6.073557 loss_ctc 7.171560 loss_rnnt 1.755858 hw_loss 0.174278 lr 0.00036315 rank 3
2023-02-22 18:11:18,073 DEBUG TRAIN Batch 22/6100 loss 16.120365 loss_att 18.561991 loss_ctc 24.855831 loss_rnnt 14.317726 hw_loss 0.280470 lr 0.00036307 rank 7
2023-02-22 18:11:18,073 DEBUG TRAIN Batch 22/6100 loss 14.143173 loss_att 16.519844 loss_ctc 19.278116 loss_rnnt 12.796095 hw_loss 0.350785 lr 0.00036311 rank 5
2023-02-22 18:11:18,075 DEBUG TRAIN Batch 22/6100 loss 11.166498 loss_att 13.125409 loss_ctc 16.484631 loss_rnnt 9.978392 hw_loss 0.163577 lr 0.00036317 rank 4
2023-02-22 18:11:18,074 DEBUG TRAIN Batch 22/6100 loss 11.679682 loss_att 13.750834 loss_ctc 15.239450 loss_rnnt 10.647831 hw_loss 0.268098 lr 0.00036306 rank 6
2023-02-22 18:11:18,075 DEBUG TRAIN Batch 22/6100 loss 5.832253 loss_att 8.298276 loss_ctc 8.435940 loss_rnnt 4.901241 hw_loss 0.169965 lr 0.00036318 rank 0
2023-02-22 18:11:18,123 DEBUG TRAIN Batch 22/6100 loss 12.554535 loss_att 14.909389 loss_ctc 23.279228 loss_rnnt 10.534520 hw_loss 0.223285 lr 0.00036311 rank 1
2023-02-22 18:12:29,674 DEBUG TRAIN Batch 22/6200 loss 5.951473 loss_att 10.325104 loss_ctc 10.170538 loss_rnnt 4.368619 hw_loss 0.272972 lr 0.00036305 rank 3
2023-02-22 18:12:29,675 DEBUG TRAIN Batch 22/6200 loss 10.841978 loss_att 15.145031 loss_ctc 12.812238 loss_rnnt 9.579951 hw_loss 0.260090 lr 0.00036298 rank 2
2023-02-22 18:12:29,676 DEBUG TRAIN Batch 22/6200 loss 8.737075 loss_att 12.800325 loss_ctc 11.909403 loss_rnnt 7.285284 hw_loss 0.405307 lr 0.00036297 rank 6
2023-02-22 18:12:29,678 DEBUG TRAIN Batch 22/6200 loss 6.316935 loss_att 7.738665 loss_ctc 7.583093 loss_rnnt 5.656515 hw_loss 0.388598 lr 0.00036301 rank 5
2023-02-22 18:12:29,677 DEBUG TRAIN Batch 22/6200 loss 7.810983 loss_att 9.456470 loss_ctc 10.370298 loss_rnnt 7.023931 hw_loss 0.218836 lr 0.00036308 rank 0
2023-02-22 18:12:29,679 DEBUG TRAIN Batch 22/6200 loss 6.316813 loss_att 7.311097 loss_ctc 9.829729 loss_rnnt 5.561093 hw_loss 0.165889 lr 0.00036298 rank 7
2023-02-22 18:12:29,681 DEBUG TRAIN Batch 22/6200 loss 15.816373 loss_att 18.032969 loss_ctc 20.702578 loss_rnnt 14.535700 hw_loss 0.348485 lr 0.00036307 rank 4
2023-02-22 18:12:29,728 DEBUG TRAIN Batch 22/6200 loss 6.152818 loss_att 9.524017 loss_ctc 8.550478 loss_rnnt 5.058360 hw_loss 0.188493 lr 0.00036301 rank 1
2023-02-22 18:13:42,897 DEBUG TRAIN Batch 22/6300 loss 9.392666 loss_att 11.348747 loss_ctc 11.861373 loss_rnnt 8.513260 hw_loss 0.298178 lr 0.00036289 rank 2
2023-02-22 18:13:42,900 DEBUG TRAIN Batch 22/6300 loss 3.851086 loss_att 5.777001 loss_ctc 6.441020 loss_rnnt 3.003504 hw_loss 0.219514 lr 0.00036287 rank 6
2023-02-22 18:13:42,903 DEBUG TRAIN Batch 22/6300 loss 8.875481 loss_att 10.128793 loss_ctc 10.194941 loss_rnnt 8.218996 hw_loss 0.431050 lr 0.00036292 rank 5
2023-02-22 18:13:42,903 DEBUG TRAIN Batch 22/6300 loss 9.041286 loss_att 10.158805 loss_ctc 11.996114 loss_rnnt 8.207380 hw_loss 0.405797 lr 0.00036299 rank 0
2023-02-22 18:13:42,904 DEBUG TRAIN Batch 22/6300 loss 11.070801 loss_att 13.289001 loss_ctc 16.395632 loss_rnnt 9.768478 hw_loss 0.278821 lr 0.00036292 rank 1
2023-02-22 18:13:42,905 DEBUG TRAIN Batch 22/6300 loss 4.746780 loss_att 8.073035 loss_ctc 8.974692 loss_rnnt 3.374909 hw_loss 0.267935 lr 0.00036296 rank 3
2023-02-22 18:13:42,907 DEBUG TRAIN Batch 22/6300 loss 10.318981 loss_att 11.759194 loss_ctc 16.077477 loss_rnnt 8.996508 hw_loss 0.499934 lr 0.00036288 rank 7
2023-02-22 18:13:42,908 DEBUG TRAIN Batch 22/6300 loss 9.768479 loss_att 14.720322 loss_ctc 16.763443 loss_rnnt 7.721097 hw_loss 0.233159 lr 0.00036298 rank 4
2023-02-22 18:14:57,473 DEBUG TRAIN Batch 22/6400 loss 2.387524 loss_att 4.270531 loss_ctc 3.572557 loss_rnnt 1.723992 hw_loss 0.241737 lr 0.00036282 rank 5
2023-02-22 18:14:57,474 DEBUG TRAIN Batch 22/6400 loss 5.685583 loss_att 9.014441 loss_ctc 6.960986 loss_rnnt 4.736789 hw_loss 0.211814 lr 0.00036286 rank 3
2023-02-22 18:14:57,479 DEBUG TRAIN Batch 22/6400 loss 7.851126 loss_att 10.586464 loss_ctc 13.283494 loss_rnnt 6.344627 hw_loss 0.440842 lr 0.00036279 rank 2
2023-02-22 18:14:57,481 DEBUG TRAIN Batch 22/6400 loss 7.546614 loss_att 13.453667 loss_ctc 12.122527 loss_rnnt 5.549510 hw_loss 0.385447 lr 0.00036288 rank 4
2023-02-22 18:14:57,483 DEBUG TRAIN Batch 22/6400 loss 14.542344 loss_att 14.227312 loss_ctc 17.480747 loss_rnnt 14.045588 hw_loss 0.314953 lr 0.00036282 rank 1
2023-02-22 18:14:57,483 DEBUG TRAIN Batch 22/6400 loss 12.153128 loss_att 16.892818 loss_ctc 15.936119 loss_rnnt 10.482295 hw_loss 0.409678 lr 0.00036279 rank 7
2023-02-22 18:14:57,494 DEBUG TRAIN Batch 22/6400 loss 9.392632 loss_att 8.645078 loss_ctc 13.425490 loss_rnnt 8.759081 hw_loss 0.460028 lr 0.00036277 rank 6
2023-02-22 18:14:57,532 DEBUG TRAIN Batch 22/6400 loss 4.203329 loss_att 6.391515 loss_ctc 6.985601 loss_rnnt 3.281375 hw_loss 0.212526 lr 0.00036289 rank 0
2023-02-22 18:16:09,836 DEBUG TRAIN Batch 22/6500 loss 5.573729 loss_att 8.892284 loss_ctc 7.754707 loss_rnnt 4.510540 hw_loss 0.203777 lr 0.00036270 rank 2
2023-02-22 18:16:09,840 DEBUG TRAIN Batch 22/6500 loss 12.490545 loss_att 18.783943 loss_ctc 16.427944 loss_rnnt 10.559719 hw_loss 0.275924 lr 0.00036269 rank 7
2023-02-22 18:16:09,841 DEBUG TRAIN Batch 22/6500 loss 11.161603 loss_att 10.756487 loss_ctc 11.950237 loss_rnnt 11.045527 hw_loss 0.172404 lr 0.00036280 rank 0
2023-02-22 18:16:09,841 DEBUG TRAIN Batch 22/6500 loss 5.038490 loss_att 7.856252 loss_ctc 7.878175 loss_rnnt 3.992254 hw_loss 0.195111 lr 0.00036268 rank 6
2023-02-22 18:16:09,841 DEBUG TRAIN Batch 22/6500 loss 10.274259 loss_att 11.584045 loss_ctc 15.266535 loss_rnnt 9.203222 hw_loss 0.268953 lr 0.00036279 rank 4
2023-02-22 18:16:09,846 DEBUG TRAIN Batch 22/6500 loss 5.013432 loss_att 9.598839 loss_ctc 8.230790 loss_rnnt 3.573901 hw_loss 0.175253 lr 0.00036276 rank 3
2023-02-22 18:16:09,846 DEBUG TRAIN Batch 22/6500 loss 8.372766 loss_att 14.144695 loss_ctc 12.217466 loss_rnnt 6.601366 hw_loss 0.195727 lr 0.00036273 rank 5
2023-02-22 18:16:09,851 DEBUG TRAIN Batch 22/6500 loss 6.255751 loss_att 8.657993 loss_ctc 12.530216 loss_rnnt 4.770631 hw_loss 0.315143 lr 0.00036273 rank 1
2023-02-22 18:17:22,947 DEBUG TRAIN Batch 22/6600 loss 8.857377 loss_att 11.517712 loss_ctc 10.823161 loss_rnnt 7.938989 hw_loss 0.232904 lr 0.00036260 rank 2
2023-02-22 18:17:22,949 DEBUG TRAIN Batch 22/6600 loss 14.602119 loss_att 15.783630 loss_ctc 18.257637 loss_rnnt 13.774299 hw_loss 0.195218 lr 0.00036258 rank 6
2023-02-22 18:17:22,949 DEBUG TRAIN Batch 22/6600 loss 3.967651 loss_att 7.054308 loss_ctc 6.031746 loss_rnnt 2.909933 hw_loss 0.309702 lr 0.00036267 rank 3
2023-02-22 18:17:22,950 DEBUG TRAIN Batch 22/6600 loss 6.424873 loss_att 9.689743 loss_ctc 11.960020 loss_rnnt 4.929114 hw_loss 0.196435 lr 0.00036260 rank 7
2023-02-22 18:17:22,955 DEBUG TRAIN Batch 22/6600 loss 7.590929 loss_att 9.409782 loss_ctc 12.400621 loss_rnnt 6.499793 hw_loss 0.161386 lr 0.00036269 rank 4
2023-02-22 18:17:22,959 DEBUG TRAIN Batch 22/6600 loss 15.039843 loss_att 16.744686 loss_ctc 22.469109 loss_rnnt 13.574347 hw_loss 0.251175 lr 0.00036263 rank 5
2023-02-22 18:17:22,970 DEBUG TRAIN Batch 22/6600 loss 6.571305 loss_att 8.896778 loss_ctc 13.771744 loss_rnnt 5.025679 hw_loss 0.225887 lr 0.00036263 rank 1
2023-02-22 18:17:23,003 DEBUG TRAIN Batch 22/6600 loss 8.481468 loss_att 11.093223 loss_ctc 11.156418 loss_rnnt 7.412004 hw_loss 0.357097 lr 0.00036270 rank 0
2023-02-22 18:18:35,659 DEBUG TRAIN Batch 22/6700 loss 15.996445 loss_att 17.125137 loss_ctc 19.651495 loss_rnnt 15.164949 hw_loss 0.222030 lr 0.00036250 rank 7
2023-02-22 18:18:35,663 DEBUG TRAIN Batch 22/6700 loss 4.084167 loss_att 6.004287 loss_ctc 5.218451 loss_rnnt 3.413171 hw_loss 0.254502 lr 0.00036251 rank 2
2023-02-22 18:18:35,670 DEBUG TRAIN Batch 22/6700 loss 12.148040 loss_att 13.614014 loss_ctc 14.027223 loss_rnnt 11.507927 hw_loss 0.180675 lr 0.00036249 rank 6
2023-02-22 18:18:35,672 DEBUG TRAIN Batch 22/6700 loss 5.305032 loss_att 6.868210 loss_ctc 5.243280 loss_rnnt 4.863554 hw_loss 0.257016 lr 0.00036260 rank 0
2023-02-22 18:18:35,675 DEBUG TRAIN Batch 22/6700 loss 10.440962 loss_att 11.719234 loss_ctc 14.399328 loss_rnnt 9.518794 hw_loss 0.260122 lr 0.00036254 rank 5
2023-02-22 18:18:35,679 DEBUG TRAIN Batch 22/6700 loss 9.865738 loss_att 13.938040 loss_ctc 14.136584 loss_rnnt 8.380465 hw_loss 0.190062 lr 0.00036257 rank 3
2023-02-22 18:18:35,681 DEBUG TRAIN Batch 22/6700 loss 14.285036 loss_att 16.450251 loss_ctc 21.000397 loss_rnnt 12.831289 hw_loss 0.234979 lr 0.00036260 rank 4
2023-02-22 18:18:35,720 DEBUG TRAIN Batch 22/6700 loss 11.263439 loss_att 13.561256 loss_ctc 17.776043 loss_rnnt 9.828631 hw_loss 0.200434 lr 0.00036254 rank 1
2023-02-22 18:19:49,879 DEBUG TRAIN Batch 22/6800 loss 5.711883 loss_att 8.480877 loss_ctc 9.636337 loss_rnnt 4.545374 hw_loss 0.167718 lr 0.00036248 rank 3
2023-02-22 18:19:49,880 DEBUG TRAIN Batch 22/6800 loss 4.521248 loss_att 8.100127 loss_ctc 7.355179 loss_rnnt 3.270791 hw_loss 0.294044 lr 0.00036239 rank 6
2023-02-22 18:19:49,882 DEBUG TRAIN Batch 22/6800 loss 6.041108 loss_att 8.572691 loss_ctc 8.749887 loss_rnnt 5.052376 hw_loss 0.227334 lr 0.00036241 rank 2
2023-02-22 18:19:49,884 DEBUG TRAIN Batch 22/6800 loss 9.459949 loss_att 12.978086 loss_ctc 17.744759 loss_rnnt 7.516552 hw_loss 0.253365 lr 0.00036250 rank 4
2023-02-22 18:19:49,885 DEBUG TRAIN Batch 22/6800 loss 16.579689 loss_att 18.760336 loss_ctc 22.804993 loss_rnnt 15.111296 hw_loss 0.379172 lr 0.00036240 rank 7
2023-02-22 18:19:49,887 DEBUG TRAIN Batch 22/6800 loss 12.102779 loss_att 13.564181 loss_ctc 16.532064 loss_rnnt 11.140322 hw_loss 0.149259 lr 0.00036251 rank 0
2023-02-22 18:19:49,888 DEBUG TRAIN Batch 22/6800 loss 19.086111 loss_att 18.017010 loss_ctc 19.951939 loss_rnnt 19.044546 hw_loss 0.262392 lr 0.00036244 rank 5
2023-02-22 18:19:49,892 DEBUG TRAIN Batch 22/6800 loss 10.445311 loss_att 11.953006 loss_ctc 14.892614 loss_rnnt 9.413415 hw_loss 0.257592 lr 0.00036244 rank 1
2023-02-22 18:21:02,993 DEBUG TRAIN Batch 22/6900 loss 6.802275 loss_att 9.040098 loss_ctc 10.123054 loss_rnnt 5.722894 hw_loss 0.354461 lr 0.00036238 rank 3
2023-02-22 18:21:02,995 DEBUG TRAIN Batch 22/6900 loss 7.931218 loss_att 10.353151 loss_ctc 11.424902 loss_rnnt 6.829781 hw_loss 0.283548 lr 0.00036232 rank 2
2023-02-22 18:21:02,998 DEBUG TRAIN Batch 22/6900 loss 5.512185 loss_att 7.708180 loss_ctc 5.816927 loss_rnnt 4.922008 hw_loss 0.206898 lr 0.00036235 rank 1
2023-02-22 18:21:02,998 DEBUG TRAIN Batch 22/6900 loss 10.408592 loss_att 12.322435 loss_ctc 14.282738 loss_rnnt 9.293036 hw_loss 0.405440 lr 0.00036231 rank 7
2023-02-22 18:21:02,998 DEBUG TRAIN Batch 22/6900 loss 6.988446 loss_att 8.944699 loss_ctc 9.924155 loss_rnnt 6.107598 hw_loss 0.184067 lr 0.00036230 rank 6
2023-02-22 18:21:03,001 DEBUG TRAIN Batch 22/6900 loss 3.181800 loss_att 5.378261 loss_ctc 6.118060 loss_rnnt 2.171288 hw_loss 0.336973 lr 0.00036241 rank 0
2023-02-22 18:21:03,003 DEBUG TRAIN Batch 22/6900 loss 9.816550 loss_att 11.664874 loss_ctc 13.808969 loss_rnnt 8.690838 hw_loss 0.419483 lr 0.00036235 rank 5
2023-02-22 18:21:03,049 DEBUG TRAIN Batch 22/6900 loss 10.282719 loss_att 11.388195 loss_ctc 15.147960 loss_rnnt 9.153233 hw_loss 0.486923 lr 0.00036241 rank 4
2023-02-22 18:22:14,872 DEBUG TRAIN Batch 22/7000 loss 8.884780 loss_att 11.195093 loss_ctc 13.769839 loss_rnnt 7.559392 hw_loss 0.397469 lr 0.00036222 rank 2
2023-02-22 18:22:14,873 DEBUG TRAIN Batch 22/7000 loss 12.686520 loss_att 12.418152 loss_ctc 15.751414 loss_rnnt 12.047915 hw_loss 0.531797 lr 0.00036229 rank 3
2023-02-22 18:22:14,876 DEBUG TRAIN Batch 22/7000 loss 7.930139 loss_att 9.198361 loss_ctc 11.074205 loss_rnnt 7.108403 hw_loss 0.279153 lr 0.00036231 rank 4
2023-02-22 18:22:14,877 DEBUG TRAIN Batch 22/7000 loss 10.030015 loss_att 9.946826 loss_ctc 12.774776 loss_rnnt 9.319421 hw_loss 0.677369 lr 0.00036220 rank 6
2023-02-22 18:22:14,882 DEBUG TRAIN Batch 22/7000 loss 2.242983 loss_att 4.035772 loss_ctc 1.529341 loss_rnnt 1.848825 hw_loss 0.245159 lr 0.00036221 rank 7
2023-02-22 18:22:14,882 DEBUG TRAIN Batch 22/7000 loss 5.307042 loss_att 6.173305 loss_ctc 9.983598 loss_rnnt 4.383084 hw_loss 0.238434 lr 0.00036225 rank 1
2023-02-22 18:22:14,886 DEBUG TRAIN Batch 22/7000 loss 4.049015 loss_att 7.413486 loss_ctc 6.312143 loss_rnnt 2.883101 hw_loss 0.358629 lr 0.00036232 rank 0
2023-02-22 18:22:14,888 DEBUG TRAIN Batch 22/7000 loss 6.012742 loss_att 10.530956 loss_ctc 9.809660 loss_rnnt 4.500382 hw_loss 0.192115 lr 0.00036225 rank 5
2023-02-22 18:23:30,204 DEBUG TRAIN Batch 22/7100 loss 9.782142 loss_att 11.828382 loss_ctc 14.632782 loss_rnnt 8.520065 hw_loss 0.386394 lr 0.00036222 rank 4
2023-02-22 18:23:30,216 DEBUG TRAIN Batch 22/7100 loss 8.150624 loss_att 12.070036 loss_ctc 13.105433 loss_rnnt 6.503398 hw_loss 0.380068 lr 0.00036212 rank 7
2023-02-22 18:23:30,218 DEBUG TRAIN Batch 22/7100 loss 4.512583 loss_att 6.943811 loss_ctc 6.142675 loss_rnnt 3.627144 hw_loss 0.340965 lr 0.00036216 rank 5
2023-02-22 18:23:30,221 DEBUG TRAIN Batch 22/7100 loss 10.233643 loss_att 12.676408 loss_ctc 15.544016 loss_rnnt 8.871741 hw_loss 0.309934 lr 0.00036219 rank 3
2023-02-22 18:23:30,221 DEBUG TRAIN Batch 22/7100 loss 6.280718 loss_att 10.242459 loss_ctc 9.915590 loss_rnnt 4.871214 hw_loss 0.248448 lr 0.00036211 rank 6
2023-02-22 18:23:30,222 DEBUG TRAIN Batch 22/7100 loss 13.494736 loss_att 18.544344 loss_ctc 18.417570 loss_rnnt 11.744781 hw_loss 0.156853 lr 0.00036222 rank 0
2023-02-22 18:23:30,225 DEBUG TRAIN Batch 22/7100 loss 9.238708 loss_att 9.989913 loss_ctc 12.359488 loss_rnnt 8.440054 hw_loss 0.435578 lr 0.00036213 rank 2
2023-02-22 18:23:30,285 DEBUG TRAIN Batch 22/7100 loss 13.912008 loss_att 15.136801 loss_ctc 21.857700 loss_rnnt 12.474891 hw_loss 0.248875 lr 0.00036216 rank 1
2023-02-22 18:24:43,841 DEBUG TRAIN Batch 22/7200 loss 9.579849 loss_att 11.788013 loss_ctc 14.490246 loss_rnnt 8.393004 hw_loss 0.169672 lr 0.00036203 rank 2
2023-02-22 18:24:43,850 DEBUG TRAIN Batch 22/7200 loss 8.321323 loss_att 10.093605 loss_ctc 12.556634 loss_rnnt 7.266469 hw_loss 0.254419 lr 0.00036212 rank 4
2023-02-22 18:24:43,851 DEBUG TRAIN Batch 22/7200 loss 6.114886 loss_att 10.722626 loss_ctc 11.398997 loss_rnnt 4.296122 hw_loss 0.361253 lr 0.00036201 rank 6
2023-02-22 18:24:43,852 DEBUG TRAIN Batch 22/7200 loss 7.385682 loss_att 6.967108 loss_ctc 6.806411 loss_rnnt 7.438463 hw_loss 0.202818 lr 0.00036210 rank 3
2023-02-22 18:24:43,853 DEBUG TRAIN Batch 22/7200 loss 5.294801 loss_att 7.590452 loss_ctc 6.750793 loss_rnnt 4.472177 hw_loss 0.317553 lr 0.00036206 rank 5
2023-02-22 18:24:43,854 DEBUG TRAIN Batch 22/7200 loss 8.037774 loss_att 10.730097 loss_ctc 8.567382 loss_rnnt 7.267629 hw_loss 0.301999 lr 0.00036213 rank 0
2023-02-22 18:24:43,858 DEBUG TRAIN Batch 22/7200 loss 6.547691 loss_att 9.254820 loss_ctc 14.223112 loss_rnnt 4.840164 hw_loss 0.267584 lr 0.00036206 rank 1
2023-02-22 18:24:43,860 DEBUG TRAIN Batch 22/7200 loss 8.589841 loss_att 11.888588 loss_ctc 11.889985 loss_rnnt 7.374485 hw_loss 0.216724 lr 0.00036202 rank 7
2023-02-22 18:25:55,786 DEBUG TRAIN Batch 22/7300 loss 3.927349 loss_att 6.522799 loss_ctc 5.681649 loss_rnnt 3.012313 hw_loss 0.303825 lr 0.00036192 rank 6
2023-02-22 18:25:55,788 DEBUG TRAIN Batch 22/7300 loss 13.716302 loss_att 15.753950 loss_ctc 17.807728 loss_rnnt 12.651441 hw_loss 0.209638 lr 0.00036200 rank 3
2023-02-22 18:25:55,793 DEBUG TRAIN Batch 22/7300 loss 11.891994 loss_att 14.731331 loss_ctc 18.557789 loss_rnnt 10.359102 hw_loss 0.142974 lr 0.00036203 rank 0
2023-02-22 18:25:55,793 DEBUG TRAIN Batch 22/7300 loss 25.848413 loss_att 26.191216 loss_ctc 38.302151 loss_rnnt 24.027128 hw_loss 0.172924 lr 0.00036194 rank 2
2023-02-22 18:25:55,793 DEBUG TRAIN Batch 22/7300 loss 10.607667 loss_att 10.396454 loss_ctc 12.189693 loss_rnnt 10.304770 hw_loss 0.251629 lr 0.00036197 rank 5
2023-02-22 18:25:55,795 DEBUG TRAIN Batch 22/7300 loss 16.931995 loss_att 21.099054 loss_ctc 19.868183 loss_rnnt 15.491961 hw_loss 0.403369 lr 0.00036197 rank 1
2023-02-22 18:25:55,796 DEBUG TRAIN Batch 22/7300 loss 6.077828 loss_att 8.142607 loss_ctc 6.133366 loss_rnnt 5.526693 hw_loss 0.245202 lr 0.00036193 rank 7
2023-02-22 18:25:55,797 DEBUG TRAIN Batch 22/7300 loss 16.120258 loss_att 19.654776 loss_ctc 24.994280 loss_rnnt 14.075654 hw_loss 0.289683 lr 0.00036203 rank 4
2023-02-22 18:27:08,559 DEBUG TRAIN Batch 22/7400 loss 21.299675 loss_att 20.971819 loss_ctc 27.412048 loss_rnnt 20.409779 hw_loss 0.263407 lr 0.00036184 rank 2
2023-02-22 18:27:08,561 DEBUG TRAIN Batch 22/7400 loss 7.565179 loss_att 10.857634 loss_ctc 14.532096 loss_rnnt 5.882080 hw_loss 0.179410 lr 0.00036193 rank 4
2023-02-22 18:27:08,562 DEBUG TRAIN Batch 22/7400 loss 8.925812 loss_att 12.045186 loss_ctc 14.291073 loss_rnnt 7.390971 hw_loss 0.366745 lr 0.00036191 rank 3
2023-02-22 18:27:08,562 DEBUG TRAIN Batch 22/7400 loss 11.042911 loss_att 14.194793 loss_ctc 17.102905 loss_rnnt 9.422486 hw_loss 0.341340 lr 0.00036182 rank 6
2023-02-22 18:27:08,563 DEBUG TRAIN Batch 22/7400 loss 6.006217 loss_att 8.039584 loss_ctc 9.441744 loss_rnnt 5.027062 hw_loss 0.214521 lr 0.00036194 rank 0
2023-02-22 18:27:08,564 DEBUG TRAIN Batch 22/7400 loss 4.874554 loss_att 7.600362 loss_ctc 8.792610 loss_rnnt 3.715118 hw_loss 0.172251 lr 0.00036187 rank 5
2023-02-22 18:27:08,569 DEBUG TRAIN Batch 22/7400 loss 8.580941 loss_att 8.442801 loss_ctc 10.519347 loss_rnnt 8.211006 hw_loss 0.260829 lr 0.00036183 rank 7
2023-02-22 18:27:08,586 DEBUG TRAIN Batch 22/7400 loss 6.945067 loss_att 11.576498 loss_ctc 12.634651 loss_rnnt 5.096748 hw_loss 0.306414 lr 0.00036187 rank 1
2023-02-22 18:28:23,322 DEBUG TRAIN Batch 22/7500 loss 15.313978 loss_att 17.991896 loss_ctc 18.784002 loss_rnnt 14.063803 hw_loss 0.472355 lr 0.00036174 rank 7
2023-02-22 18:28:23,327 DEBUG TRAIN Batch 22/7500 loss 6.087985 loss_att 7.536619 loss_ctc 7.990822 loss_rnnt 5.389250 hw_loss 0.291179 lr 0.00036181 rank 3
2023-02-22 18:28:23,328 DEBUG TRAIN Batch 22/7500 loss 6.141735 loss_att 8.742805 loss_ctc 9.461750 loss_rnnt 4.994581 hw_loss 0.345509 lr 0.00036175 rank 2
2023-02-22 18:28:23,328 DEBUG TRAIN Batch 22/7500 loss 12.699980 loss_att 13.808308 loss_ctc 17.227062 loss_rnnt 11.706861 hw_loss 0.314706 lr 0.00036178 rank 1
2023-02-22 18:28:23,330 DEBUG TRAIN Batch 22/7500 loss 13.622763 loss_att 14.808513 loss_ctc 19.159576 loss_rnnt 12.450853 hw_loss 0.368468 lr 0.00036184 rank 4
2023-02-22 18:28:23,331 DEBUG TRAIN Batch 22/7500 loss 15.243082 loss_att 15.696848 loss_ctc 21.132469 loss_rnnt 14.258072 hw_loss 0.204384 lr 0.00036173 rank 6
2023-02-22 18:28:23,335 DEBUG TRAIN Batch 22/7500 loss 14.224975 loss_att 14.307301 loss_ctc 17.431068 loss_rnnt 13.543780 hw_loss 0.444844 lr 0.00036178 rank 5
2023-02-22 18:28:23,335 DEBUG TRAIN Batch 22/7500 loss 5.066039 loss_att 6.404799 loss_ctc 6.578847 loss_rnnt 4.458702 hw_loss 0.258520 lr 0.00036184 rank 0
2023-02-22 18:29:35,922 DEBUG TRAIN Batch 22/7600 loss 8.406589 loss_att 11.365006 loss_ctc 10.760989 loss_rnnt 7.304150 hw_loss 0.369066 lr 0.00036172 rank 3
2023-02-22 18:29:35,923 DEBUG TRAIN Batch 22/7600 loss 9.036573 loss_att 12.838219 loss_ctc 11.284675 loss_rnnt 7.875118 hw_loss 0.190086 lr 0.00036165 rank 7
2023-02-22 18:29:35,925 DEBUG TRAIN Batch 22/7600 loss 7.703971 loss_att 8.710762 loss_ctc 10.291030 loss_rnnt 6.868792 hw_loss 0.541649 lr 0.00036168 rank 1
2023-02-22 18:29:35,923 DEBUG TRAIN Batch 22/7600 loss 10.606958 loss_att 11.665818 loss_ctc 14.051292 loss_rnnt 9.739014 hw_loss 0.369239 lr 0.00036163 rank 6
2023-02-22 18:29:35,925 DEBUG TRAIN Batch 22/7600 loss 6.748442 loss_att 9.008078 loss_ctc 8.457727 loss_rnnt 5.896334 hw_loss 0.323019 lr 0.00036165 rank 2
2023-02-22 18:29:35,926 DEBUG TRAIN Batch 22/7600 loss 24.089338 loss_att 23.455883 loss_ctc 31.592770 loss_rnnt 23.019154 hw_loss 0.368282 lr 0.00036175 rank 0
2023-02-22 18:29:35,930 DEBUG TRAIN Batch 22/7600 loss 3.329998 loss_att 7.073449 loss_ctc 7.104644 loss_rnnt 1.862909 hw_loss 0.403336 lr 0.00036174 rank 4
2023-02-22 18:29:35,931 DEBUG TRAIN Batch 22/7600 loss 7.171642 loss_att 10.340348 loss_ctc 7.068223 loss_rnnt 6.453120 hw_loss 0.184819 lr 0.00036168 rank 5
2023-02-22 18:30:49,005 DEBUG TRAIN Batch 22/7700 loss 13.023121 loss_att 15.182327 loss_ctc 16.998123 loss_rnnt 11.952505 hw_loss 0.203952 lr 0.00036165 rank 4
2023-02-22 18:30:49,005 DEBUG TRAIN Batch 22/7700 loss 13.848861 loss_att 14.421226 loss_ctc 16.972916 loss_rnnt 13.119379 hw_loss 0.372126 lr 0.00036156 rank 2
2023-02-22 18:30:49,006 DEBUG TRAIN Batch 22/7700 loss 6.581031 loss_att 8.189981 loss_ctc 6.481485 loss_rnnt 6.179276 hw_loss 0.174821 lr 0.00036155 rank 7
2023-02-22 18:30:49,008 DEBUG TRAIN Batch 22/7700 loss 5.396144 loss_att 6.193512 loss_ctc 7.547041 loss_rnnt 4.768696 hw_loss 0.339726 lr 0.00036159 rank 1
2023-02-22 18:30:49,008 DEBUG TRAIN Batch 22/7700 loss 10.705405 loss_att 15.949226 loss_ctc 15.039536 loss_rnnt 8.942177 hw_loss 0.256087 lr 0.00036162 rank 3
2023-02-22 18:30:49,009 DEBUG TRAIN Batch 22/7700 loss 7.123528 loss_att 13.164229 loss_ctc 7.634616 loss_rnnt 5.737221 hw_loss 0.206292 lr 0.00036165 rank 0
2023-02-22 18:30:49,012 DEBUG TRAIN Batch 22/7700 loss 8.551971 loss_att 12.136678 loss_ctc 13.327755 loss_rnnt 7.098052 hw_loss 0.187888 lr 0.00036154 rank 6
2023-02-22 18:30:49,058 DEBUG TRAIN Batch 22/7700 loss 6.096054 loss_att 9.694031 loss_ctc 10.679422 loss_rnnt 4.590170 hw_loss 0.328449 lr 0.00036159 rank 5
2023-02-22 18:32:03,418 DEBUG TRAIN Batch 22/7800 loss 7.133204 loss_att 10.092191 loss_ctc 7.614539 loss_rnnt 6.317534 hw_loss 0.299427 lr 0.00036156 rank 0
2023-02-22 18:32:03,419 DEBUG TRAIN Batch 22/7800 loss 14.354411 loss_att 19.413803 loss_ctc 18.856773 loss_rnnt 12.559019 hw_loss 0.343499 lr 0.00036155 rank 4
2023-02-22 18:32:03,430 DEBUG TRAIN Batch 22/7800 loss 11.103281 loss_att 13.967762 loss_ctc 16.680660 loss_rnnt 9.649890 hw_loss 0.256584 lr 0.00036153 rank 3
2023-02-22 18:32:03,433 DEBUG TRAIN Batch 22/7800 loss 8.081851 loss_att 9.209747 loss_ctc 7.375040 loss_rnnt 7.847635 hw_loss 0.192898 lr 0.00036146 rank 7
2023-02-22 18:32:03,434 DEBUG TRAIN Batch 22/7800 loss 19.865320 loss_att 25.631844 loss_ctc 23.507313 loss_rnnt 18.122805 hw_loss 0.194274 lr 0.00036149 rank 5
2023-02-22 18:32:03,456 DEBUG TRAIN Batch 22/7800 loss 4.986940 loss_att 6.964234 loss_ctc 7.929379 loss_rnnt 4.102905 hw_loss 0.180469 lr 0.00036149 rank 1
2023-02-22 18:32:03,457 DEBUG TRAIN Batch 22/7800 loss 3.571307 loss_att 6.858326 loss_ctc 3.967727 loss_rnnt 2.704434 hw_loss 0.293650 lr 0.00036146 rank 2
2023-02-22 18:32:03,459 DEBUG TRAIN Batch 22/7800 loss 3.722197 loss_att 6.690812 loss_ctc 4.752092 loss_rnnt 2.879392 hw_loss 0.209554 lr 0.00036144 rank 6
2023-02-22 18:33:16,250 DEBUG TRAIN Batch 22/7900 loss 5.702181 loss_att 7.939197 loss_ctc 7.281257 loss_rnnt 4.905725 hw_loss 0.259704 lr 0.00036147 rank 0
2023-02-22 18:33:16,256 DEBUG TRAIN Batch 22/7900 loss 5.460001 loss_att 7.469353 loss_ctc 6.110733 loss_rnnt 4.860314 hw_loss 0.208225 lr 0.00036146 rank 4
2023-02-22 18:33:16,266 DEBUG TRAIN Batch 22/7900 loss 3.226257 loss_att 6.686663 loss_ctc 5.504739 loss_rnnt 2.102314 hw_loss 0.240120 lr 0.00036135 rank 6
2023-02-22 18:33:16,267 DEBUG TRAIN Batch 22/7900 loss 9.883642 loss_att 13.152014 loss_ctc 14.441502 loss_rnnt 8.450347 hw_loss 0.322325 lr 0.00036144 rank 3
2023-02-22 18:33:16,267 DEBUG TRAIN Batch 22/7900 loss 13.265133 loss_att 17.264889 loss_ctc 26.035366 loss_rnnt 10.661530 hw_loss 0.189288 lr 0.00036137 rank 2
2023-02-22 18:33:16,267 DEBUG TRAIN Batch 22/7900 loss 7.839056 loss_att 10.515125 loss_ctc 13.983699 loss_rnnt 6.246484 hw_loss 0.446386 lr 0.00036140 rank 1
2023-02-22 18:33:16,277 DEBUG TRAIN Batch 22/7900 loss 17.178444 loss_att 17.648550 loss_ctc 21.803307 loss_rnnt 16.353329 hw_loss 0.214585 lr 0.00036140 rank 5
2023-02-22 18:33:16,279 DEBUG TRAIN Batch 22/7900 loss 6.360781 loss_att 8.082981 loss_ctc 8.670390 loss_rnnt 5.613397 hw_loss 0.178117 lr 0.00036136 rank 7
2023-02-22 18:34:29,643 DEBUG TRAIN Batch 22/8000 loss 7.806238 loss_att 9.719092 loss_ctc 10.529941 loss_rnnt 6.955538 hw_loss 0.196817 lr 0.00036136 rank 4
2023-02-22 18:34:29,648 DEBUG TRAIN Batch 22/8000 loss 17.508245 loss_att 17.287889 loss_ctc 20.509464 loss_rnnt 16.981617 hw_loss 0.319759 lr 0.00036126 rank 6
2023-02-22 18:34:29,653 DEBUG TRAIN Batch 22/8000 loss 5.405012 loss_att 6.313992 loss_ctc 6.217962 loss_rnnt 5.002309 hw_loss 0.210963 lr 0.00036128 rank 2
2023-02-22 18:34:29,655 DEBUG TRAIN Batch 22/8000 loss 5.049004 loss_att 7.355422 loss_ctc 5.026732 loss_rnnt 4.497580 hw_loss 0.174580 lr 0.00036127 rank 7
2023-02-22 18:34:29,657 DEBUG TRAIN Batch 22/8000 loss 9.773810 loss_att 12.232643 loss_ctc 15.193275 loss_rnnt 8.483308 hw_loss 0.142763 lr 0.00036134 rank 3
2023-02-22 18:34:29,658 DEBUG TRAIN Batch 22/8000 loss 6.086205 loss_att 8.143907 loss_ctc 10.935216 loss_rnnt 4.953243 hw_loss 0.140412 lr 0.00036137 rank 0
2023-02-22 18:34:29,665 DEBUG TRAIN Batch 22/8000 loss 4.209029 loss_att 5.914270 loss_ctc 5.243122 loss_rnnt 3.644320 hw_loss 0.160841 lr 0.00036130 rank 1
2023-02-22 18:34:29,710 DEBUG TRAIN Batch 22/8000 loss 2.264577 loss_att 4.000272 loss_ctc 2.481579 loss_rnnt 1.720205 hw_loss 0.315563 lr 0.00036130 rank 5
2023-02-22 18:35:42,387 DEBUG TRAIN Batch 22/8100 loss 6.141193 loss_att 9.295554 loss_ctc 8.990670 loss_rnnt 4.975079 hw_loss 0.291210 lr 0.00036121 rank 1
2023-02-22 18:35:42,397 DEBUG TRAIN Batch 22/8100 loss 13.157520 loss_att 14.617622 loss_ctc 18.748795 loss_rnnt 11.904677 hw_loss 0.403723 lr 0.00036128 rank 0
2023-02-22 18:35:42,398 DEBUG TRAIN Batch 22/8100 loss 6.081354 loss_att 8.236019 loss_ctc 9.031115 loss_rnnt 5.053322 hw_loss 0.382121 lr 0.00036116 rank 6
2023-02-22 18:35:42,401 DEBUG TRAIN Batch 22/8100 loss 13.154732 loss_att 13.189840 loss_ctc 14.946100 loss_rnnt 12.795935 hw_loss 0.211738 lr 0.00036118 rank 2
2023-02-22 18:35:42,402 DEBUG TRAIN Batch 22/8100 loss 14.294781 loss_att 16.605862 loss_ctc 20.864792 loss_rnnt 12.829580 hw_loss 0.238094 lr 0.00036125 rank 3
2023-02-22 18:35:42,404 DEBUG TRAIN Batch 22/8100 loss 11.117976 loss_att 11.107010 loss_ctc 13.737444 loss_rnnt 10.601084 hw_loss 0.318417 lr 0.00036117 rank 7
2023-02-22 18:35:42,406 DEBUG TRAIN Batch 22/8100 loss 14.644517 loss_att 16.781427 loss_ctc 19.312012 loss_rnnt 13.469446 hw_loss 0.235041 lr 0.00036127 rank 4
2023-02-22 18:35:42,421 DEBUG TRAIN Batch 22/8100 loss 8.130890 loss_att 10.554439 loss_ctc 8.689353 loss_rnnt 7.427986 hw_loss 0.269498 lr 0.00036121 rank 5
2023-02-22 18:36:56,684 DEBUG TRAIN Batch 22/8200 loss 11.352603 loss_att 12.846064 loss_ctc 16.406605 loss_rnnt 10.180445 hw_loss 0.374249 lr 0.00036115 rank 3
2023-02-22 18:36:56,684 DEBUG TRAIN Batch 22/8200 loss 9.242627 loss_att 11.017176 loss_ctc 11.828750 loss_rnnt 8.385931 hw_loss 0.294317 lr 0.00036117 rank 4
2023-02-22 18:36:56,688 DEBUG TRAIN Batch 22/8200 loss 8.309067 loss_att 9.521964 loss_ctc 11.799056 loss_rnnt 7.391122 hw_loss 0.393810 lr 0.00036108 rank 7
2023-02-22 18:36:56,692 DEBUG TRAIN Batch 22/8200 loss 6.385815 loss_att 9.374767 loss_ctc 12.517687 loss_rnnt 4.796088 hw_loss 0.326912 lr 0.00036109 rank 2
2023-02-22 18:36:56,692 DEBUG TRAIN Batch 22/8200 loss 15.208384 loss_att 20.319016 loss_ctc 23.482597 loss_rnnt 12.966364 hw_loss 0.218744 lr 0.00036107 rank 6
2023-02-22 18:36:56,695 DEBUG TRAIN Batch 22/8200 loss 5.545567 loss_att 8.176214 loss_ctc 8.229365 loss_rnnt 4.590639 hw_loss 0.133047 lr 0.00036112 rank 5
2023-02-22 18:36:56,696 DEBUG TRAIN Batch 22/8200 loss 24.967880 loss_att 23.759016 loss_ctc 34.718903 loss_rnnt 23.781483 hw_loss 0.240062 lr 0.00036112 rank 1
2023-02-22 18:36:56,741 DEBUG TRAIN Batch 22/8200 loss 4.195951 loss_att 5.855925 loss_ctc 6.560442 loss_rnnt 3.367453 hw_loss 0.339819 lr 0.00036118 rank 0
2023-02-22 18:38:09,678 DEBUG TRAIN Batch 22/8300 loss 8.926545 loss_att 14.674295 loss_ctc 11.121603 loss_rnnt 7.185479 hw_loss 0.560326 lr 0.00036099 rank 2
2023-02-22 18:38:09,682 DEBUG TRAIN Batch 22/8300 loss 10.075800 loss_att 11.091295 loss_ctc 14.434969 loss_rnnt 9.100512 hw_loss 0.358063 lr 0.00036106 rank 3
2023-02-22 18:38:09,688 DEBUG TRAIN Batch 22/8300 loss 12.760633 loss_att 14.341688 loss_ctc 16.922392 loss_rnnt 11.665664 hw_loss 0.419734 lr 0.00036097 rank 6
2023-02-22 18:38:09,689 DEBUG TRAIN Batch 22/8300 loss 7.048297 loss_att 9.565983 loss_ctc 10.493387 loss_rnnt 5.931985 hw_loss 0.287680 lr 0.00036098 rank 7
2023-02-22 18:38:09,689 DEBUG TRAIN Batch 22/8300 loss 2.448977 loss_att 4.824007 loss_ctc 3.182591 loss_rnnt 1.720616 hw_loss 0.291635 lr 0.00036102 rank 5
2023-02-22 18:38:09,690 DEBUG TRAIN Batch 22/8300 loss 6.061988 loss_att 9.641644 loss_ctc 8.574656 loss_rnnt 4.863374 hw_loss 0.276864 lr 0.00036109 rank 0
2023-02-22 18:38:09,691 DEBUG TRAIN Batch 22/8300 loss 8.583032 loss_att 12.399562 loss_ctc 14.917434 loss_rnnt 6.876395 hw_loss 0.185143 lr 0.00036108 rank 4
2023-02-22 18:38:09,739 DEBUG TRAIN Batch 22/8300 loss 4.854564 loss_att 7.593684 loss_ctc 5.471591 loss_rnnt 4.150086 hw_loss 0.139468 lr 0.00036102 rank 1
2023-02-22 18:38:56,184 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 3
2023-02-22 18:38:56,185 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 1
2023-02-22 18:38:56,186 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 7
2023-02-22 18:38:56,188 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 2
2023-02-22 18:38:56,197 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 0
2023-02-22 18:38:56,202 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 4
2023-02-22 18:38:56,205 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 5
2023-02-22 18:38:56,209 DEBUG CV Batch 22/0 loss 2.388628 loss_att 2.517189 loss_ctc 3.732561 loss_rnnt 1.831408 hw_loss 0.660593 history loss 2.300160 rank 6
2023-02-22 18:39:07,323 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 4
2023-02-22 18:39:07,382 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 1
2023-02-22 18:39:07,382 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 0
2023-02-22 18:39:07,524 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 7
2023-02-22 18:39:07,563 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 5
2023-02-22 18:39:07,901 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 3
2023-02-22 18:39:08,040 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 2
2023-02-22 18:39:08,358 DEBUG CV Batch 22/100 loss 6.758367 loss_att 7.769701 loss_ctc 12.472023 loss_rnnt 5.643697 hw_loss 0.282341 history loss 3.500185 rank 6
2023-02-22 18:39:20,418 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 4
2023-02-22 18:39:20,724 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 0
2023-02-22 18:39:20,774 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 1
2023-02-22 18:39:20,808 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 7
2023-02-22 18:39:21,059 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 5
2023-02-22 18:39:21,894 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 3
2023-02-22 18:39:22,001 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 2
2023-02-22 18:39:22,518 DEBUG CV Batch 22/200 loss 6.669893 loss_att 13.968681 loss_ctc 6.566012 loss_rnnt 5.159864 hw_loss 0.120229 history loss 4.017550 rank 6
2023-02-22 18:39:32,137 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 4
2023-02-22 18:39:32,443 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 1
2023-02-22 18:39:32,571 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 7
2023-02-22 18:39:32,765 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 0
2023-02-22 18:39:33,133 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 5
2023-02-22 18:39:34,642 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 3
2023-02-22 18:39:34,785 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 2
2023-02-22 18:39:35,488 DEBUG CV Batch 22/300 loss 4.021563 loss_att 4.829933 loss_ctc 7.059605 loss_rnnt 3.324337 hw_loss 0.244648 history loss 4.181243 rank 6
2023-02-22 18:39:44,092 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 4
2023-02-22 18:39:44,438 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 7
2023-02-22 18:39:44,778 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 1
2023-02-22 18:39:45,045 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 0
2023-02-22 18:39:45,175 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 5
2023-02-22 18:39:47,138 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 3
2023-02-22 18:39:47,320 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 2
2023-02-22 18:39:48,005 DEBUG CV Batch 22/400 loss 18.305588 loss_att 88.945053 loss_ctc 6.826314 loss_rnnt 5.667411 hw_loss 0.076598 history loss 5.114660 rank 6
2023-02-22 18:39:54,654 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 7
2023-02-22 18:39:54,822 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 4
2023-02-22 18:39:55,183 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 1
2023-02-22 18:39:55,714 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 5
2023-02-22 18:39:55,786 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 0
2023-02-22 18:39:58,376 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 3
2023-02-22 18:39:58,756 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 2
2023-02-22 18:39:59,496 DEBUG CV Batch 22/500 loss 5.000973 loss_att 5.479278 loss_ctc 6.222557 loss_rnnt 4.521624 hw_loss 0.414017 history loss 5.833578 rank 6
2023-02-22 18:40:06,655 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 7
2023-02-22 18:40:06,869 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 4
2023-02-22 18:40:07,236 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 1
2023-02-22 18:40:07,858 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 5
2023-02-22 18:40:08,308 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 0
2023-02-22 18:40:10,992 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 3
2023-02-22 18:40:11,380 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 2
2023-02-22 18:40:12,273 DEBUG CV Batch 22/600 loss 6.554311 loss_att 6.694982 loss_ctc 9.164190 loss_rnnt 5.882402 hw_loss 0.554608 history loss 6.756070 rank 6
2023-02-22 18:40:17,739 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 7
2023-02-22 18:40:18,057 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 4
2023-02-22 18:40:18,246 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 1
2023-02-22 18:40:19,524 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 5
2023-02-22 18:40:19,763 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 0
2023-02-22 18:40:23,065 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 3
2023-02-22 18:40:23,585 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 2
2023-02-22 18:40:24,428 DEBUG CV Batch 22/700 loss 12.287251 loss_att 35.710987 loss_ctc 14.531980 loss_rnnt 7.161845 hw_loss 0.265050 history loss 7.407088 rank 6
2023-02-22 18:40:29,016 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 1
2023-02-22 18:40:29,198 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 7
2023-02-22 18:40:29,478 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 4
2023-02-22 18:40:30,876 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 5
2023-02-22 18:40:31,249 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 0
2023-02-22 18:40:35,003 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 3
2023-02-22 18:40:35,655 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 2
2023-02-22 18:40:36,478 DEBUG CV Batch 22/800 loss 11.427612 loss_att 11.730514 loss_ctc 20.133591 loss_rnnt 9.929464 hw_loss 0.518946 history loss 6.879388 rank 6
2023-02-22 18:40:42,001 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 1
2023-02-22 18:40:42,297 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 7
2023-02-22 18:40:43,105 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 4
2023-02-22 18:40:44,034 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 5
2023-02-22 18:40:44,783 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 0
2023-02-22 18:40:48,836 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 3
2023-02-22 18:40:49,768 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 2
2023-02-22 18:40:50,372 DEBUG CV Batch 22/900 loss 12.766053 loss_att 20.390623 loss_ctc 23.663437 loss_rnnt 9.693623 hw_loss 0.177248 history loss 6.678735 rank 6
2023-02-22 18:40:54,054 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 1
2023-02-22 18:40:54,295 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 7
2023-02-22 18:40:55,196 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 4
2023-02-22 18:40:56,384 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 5
2023-02-22 18:40:57,395 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 0
2023-02-22 18:41:01,607 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 3
2023-02-22 18:41:02,853 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 2
2023-02-22 18:41:03,316 DEBUG CV Batch 22/1000 loss 5.516103 loss_att 5.447436 loss_ctc 6.736038 loss_rnnt 5.212039 hw_loss 0.290886 history loss 6.454788 rank 6
2023-02-22 18:41:05,697 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 1
2023-02-22 18:41:06,236 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 7
2023-02-22 18:41:06,846 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 4
2023-02-22 18:41:08,220 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 5
2023-02-22 18:41:09,436 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 0
2023-02-22 18:41:14,194 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 3
2023-02-22 18:41:15,466 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 2
2023-02-22 18:41:16,137 DEBUG CV Batch 22/1100 loss 6.377926 loss_att 5.734181 loss_ctc 9.185310 loss_rnnt 5.786891 hw_loss 0.647750 history loss 6.439308 rank 6
2023-02-22 18:41:16,471 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 1
2023-02-22 18:41:16,865 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 7
2023-02-22 18:41:17,268 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 4
2023-02-22 18:41:18,962 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 5
2023-02-22 18:41:20,322 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 0
2023-02-22 18:41:25,586 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 3
2023-02-22 18:41:26,963 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 2
2023-02-22 18:41:27,722 DEBUG CV Batch 22/1200 loss 5.943507 loss_att 7.152439 loss_ctc 6.433660 loss_rnnt 5.463546 hw_loss 0.324039 history loss 6.749357 rank 6
2023-02-22 18:41:28,500 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 1
2023-02-22 18:41:29,071 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 7
2023-02-22 18:41:29,089 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 4
2023-02-22 18:41:31,023 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 5
2023-02-22 18:41:32,463 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 0
2023-02-22 18:41:38,337 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 3
2023-02-22 18:41:39,790 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 2
2023-02-22 18:41:39,970 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 1
2023-02-22 18:41:40,066 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 4
2023-02-22 18:41:40,248 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 7
2023-02-22 18:41:40,580 DEBUG CV Batch 22/1300 loss 4.630914 loss_att 4.866497 loss_ctc 7.138529 loss_rnnt 3.982372 hw_loss 0.500768 history loss 7.053612 rank 6
2023-02-22 18:41:42,196 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 5
2023-02-22 18:41:43,805 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 0
2023-02-22 18:41:50,192 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 3
2023-02-22 18:41:51,211 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 1
2023-02-22 18:41:51,321 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 4
2023-02-22 18:41:51,781 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 2
2023-02-22 18:41:52,242 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 7
2023-02-22 18:41:52,588 DEBUG CV Batch 22/1400 loss 9.433466 loss_att 19.321590 loss_ctc 8.962598 loss_rnnt 7.444445 hw_loss 0.139083 history loss 7.370025 rank 6
2023-02-22 18:41:53,577 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 5
2023-02-22 18:41:55,347 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 0
2023-02-22 18:42:02,367 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 3
2023-02-22 18:42:03,951 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 1
2023-02-22 18:42:03,967 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 2
2023-02-22 18:42:04,054 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 4
2023-02-22 18:42:04,845 DEBUG CV Batch 22/1500 loss 5.856650 loss_att 7.228872 loss_ctc 5.504745 loss_rnnt 5.491138 hw_loss 0.258727 history loss 7.211684 rank 6
2023-02-22 18:42:05,301 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 7
2023-02-22 18:42:07,079 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 5
2023-02-22 18:42:08,495 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 0
2023-02-22 18:42:15,917 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 3
2023-02-22 18:42:16,367 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 4
2023-02-22 18:42:16,566 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 1
2023-02-22 18:42:17,564 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 2
2023-02-22 18:42:17,803 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 7
2023-02-22 18:42:18,454 DEBUG CV Batch 22/1600 loss 9.351753 loss_att 11.957374 loss_ctc 10.258245 loss_rnnt 8.601427 hw_loss 0.203130 history loss 7.150928 rank 6
2023-02-22 18:42:19,496 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 5
2023-02-22 18:42:20,998 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 0
2023-02-22 18:42:25,450 INFO Epoch 22 CV info cv_loss 7.041073408485544
2023-02-22 18:42:25,451 INFO Epoch 23 TRAIN info lr 0.00036103482827641467
2023-02-22 18:42:25,455 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:42:25,593 INFO Epoch 22 CV info cv_loss 7.041073409355622
2023-02-22 18:42:25,594 INFO Epoch 23 TRAIN info lr 0.0003609971865649499
2023-02-22 18:42:25,598 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:42:27,004 INFO Epoch 22 CV info cv_loss 7.041073409726051
2023-02-22 18:42:27,004 INFO Epoch 23 TRAIN info lr 0.00036093792473677265
2023-02-22 18:42:27,006 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:42:28,354 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 3
2023-02-22 18:42:29,220 INFO Epoch 22 CV info cv_loss 7.041073410105096
2023-02-22 18:42:29,220 INFO Epoch 23 TRAIN info lr 0.00036096990368516115
2023-02-22 18:42:29,225 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:42:29,842 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 2
2023-02-22 18:42:30,422 INFO Epoch 22 CV info cv_loss 7.041073409838042
2023-02-22 18:42:30,423 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/22.pt
2023-02-22 18:42:30,940 DEBUG CV Batch 22/1700 loss 11.143621 loss_att 9.983747 loss_ctc 16.665083 loss_rnnt 10.410558 hw_loss 0.429080 history loss 7.061738 rank 6
2023-02-22 18:42:31,060 INFO Epoch 23 TRAIN info lr 0.00036103859309521286
2023-02-22 18:42:31,064 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:42:37,679 INFO Epoch 22 CV info cv_loss 7.04107341053152
2023-02-22 18:42:37,680 INFO Epoch 23 TRAIN info lr 0.0003610235345266353
2023-02-22 18:42:37,685 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:42:39,155 INFO Epoch 22 CV info cv_loss 7.041073410897641
2023-02-22 18:42:39,155 INFO Epoch 23 TRAIN info lr 0.0003609764886415058
2023-02-22 18:42:39,157 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:42:40,315 INFO Epoch 22 CV info cv_loss 7.0410734099284955
2023-02-22 18:42:40,315 INFO Epoch 23 TRAIN info lr 0.0003609426269902658
2023-02-22 18:42:40,317 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 18:43:38,512 DEBUG TRAIN Batch 23/0 loss 8.926333 loss_att 8.221388 loss_ctc 10.272080 loss_rnnt 8.563175 hw_loss 0.608837 lr 0.00036103 rank 4
2023-02-22 18:43:38,512 DEBUG TRAIN Batch 23/0 loss 9.252813 loss_att 9.046078 loss_ctc 11.992806 loss_rnnt 8.633083 hw_loss 0.554521 lr 0.00036102 rank 3
2023-02-22 18:43:38,515 DEBUG TRAIN Batch 23/0 loss 10.833076 loss_att 10.806328 loss_ctc 13.881415 loss_rnnt 10.133101 hw_loss 0.560398 lr 0.00036104 rank 0
2023-02-22 18:43:38,515 DEBUG TRAIN Batch 23/0 loss 7.189929 loss_att 7.184348 loss_ctc 9.412050 loss_rnnt 6.503259 hw_loss 0.734069 lr 0.00036097 rank 5
2023-02-22 18:43:38,518 DEBUG TRAIN Batch 23/0 loss 7.448749 loss_att 6.785245 loss_ctc 9.235023 loss_rnnt 6.982767 hw_loss 0.675961 lr 0.00036094 rank 7
2023-02-22 18:43:38,535 DEBUG TRAIN Batch 23/0 loss 10.758640 loss_att 11.217469 loss_ctc 14.361950 loss_rnnt 9.839796 hw_loss 0.649947 lr 0.00036098 rank 2
2023-02-22 18:43:38,564 DEBUG TRAIN Batch 23/0 loss 8.861269 loss_att 8.691836 loss_ctc 11.338701 loss_rnnt 8.206407 hw_loss 0.672044 lr 0.00036094 rank 6
2023-02-22 18:43:38,572 DEBUG TRAIN Batch 23/0 loss 9.706336 loss_att 9.790888 loss_ctc 11.866359 loss_rnnt 9.090636 hw_loss 0.582727 lr 0.00036100 rank 1
2023-02-22 18:44:51,333 DEBUG TRAIN Batch 23/100 loss 7.316873 loss_att 9.408113 loss_ctc 10.883673 loss_rnnt 6.200980 hw_loss 0.416384 lr 0.00036088 rank 2
2023-02-22 18:44:51,336 DEBUG TRAIN Batch 23/100 loss 7.328440 loss_att 10.858488 loss_ctc 12.703539 loss_rnnt 5.785500 hw_loss 0.225470 lr 0.00036087 rank 5
2023-02-22 18:44:51,337 DEBUG TRAIN Batch 23/100 loss 8.589000 loss_att 12.218829 loss_ctc 11.830202 loss_rnnt 7.303918 hw_loss 0.238042 lr 0.00036093 rank 3
2023-02-22 18:44:51,337 DEBUG TRAIN Batch 23/100 loss 7.327916 loss_att 12.000952 loss_ctc 11.851385 loss_rnnt 5.631589 hw_loss 0.297357 lr 0.00036094 rank 4
2023-02-22 18:44:51,341 DEBUG TRAIN Batch 23/100 loss 4.239200 loss_att 6.362171 loss_ctc 7.511374 loss_rnnt 3.202363 hw_loss 0.329913 lr 0.00036085 rank 6
2023-02-22 18:44:51,341 DEBUG TRAIN Batch 23/100 loss 5.020586 loss_att 8.423338 loss_ctc 6.246299 loss_rnnt 4.000813 hw_loss 0.329615 lr 0.00036084 rank 7
2023-02-22 18:44:51,343 DEBUG TRAIN Batch 23/100 loss 12.583179 loss_att 16.252277 loss_ctc 20.811623 loss_rnnt 10.566366 hw_loss 0.348503 lr 0.00036090 rank 1
2023-02-22 18:44:51,343 DEBUG TRAIN Batch 23/100 loss 9.360102 loss_att 11.214049 loss_ctc 15.026890 loss_rnnt 8.088489 hw_loss 0.272347 lr 0.00036094 rank 0
2023-02-22 18:46:04,330 DEBUG TRAIN Batch 23/200 loss 9.853726 loss_att 12.920126 loss_ctc 9.584186 loss_rnnt 9.177761 hw_loss 0.184920 lr 0.00036083 rank 3
2023-02-22 18:46:04,334 DEBUG TRAIN Batch 23/200 loss 5.209773 loss_att 8.211384 loss_ctc 5.624012 loss_rnnt 4.326064 hw_loss 0.427791 lr 0.00036079 rank 2
2023-02-22 18:46:04,334 DEBUG TRAIN Batch 23/200 loss 11.198905 loss_att 13.662062 loss_ctc 12.003613 loss_rnnt 10.414867 hw_loss 0.345209 lr 0.00036075 rank 6
2023-02-22 18:46:04,339 DEBUG TRAIN Batch 23/200 loss 5.415922 loss_att 5.289107 loss_ctc 4.782075 loss_rnnt 5.317228 hw_loss 0.391067 lr 0.00036081 rank 1
2023-02-22 18:46:04,340 DEBUG TRAIN Batch 23/200 loss 11.914211 loss_att 11.434905 loss_ctc 16.316864 loss_rnnt 11.300545 hw_loss 0.229703 lr 0.00036075 rank 7
2023-02-22 18:46:04,340 DEBUG TRAIN Batch 23/200 loss 9.562814 loss_att 9.429716 loss_ctc 11.522956 loss_rnnt 9.208723 hw_loss 0.223797 lr 0.00036078 rank 5
2023-02-22 18:46:04,346 DEBUG TRAIN Batch 23/200 loss 9.110501 loss_att 11.328447 loss_ctc 12.170738 loss_rnnt 8.173397 hw_loss 0.160281 lr 0.00036085 rank 0
2023-02-22 18:46:04,385 DEBUG TRAIN Batch 23/200 loss 3.237980 loss_att 5.018833 loss_ctc 3.792727 loss_rnnt 2.691350 hw_loss 0.218424 lr 0.00036085 rank 4
2023-02-22 18:47:18,136 DEBUG TRAIN Batch 23/300 loss 3.793184 loss_att 5.267519 loss_ctc 5.329751 loss_rnnt 3.152815 hw_loss 0.263674 lr 0.00036066 rank 7
2023-02-22 18:47:18,139 DEBUG TRAIN Batch 23/300 loss 4.566089 loss_att 7.105104 loss_ctc 11.152139 loss_rnnt 3.037403 hw_loss 0.267642 lr 0.00036069 rank 5
2023-02-22 18:47:18,148 DEBUG TRAIN Batch 23/300 loss 10.046195 loss_att 12.410624 loss_ctc 12.044310 loss_rnnt 9.155854 hw_loss 0.283201 lr 0.00036069 rank 2
2023-02-22 18:47:18,152 DEBUG TRAIN Batch 23/300 loss 5.135674 loss_att 8.244089 loss_ctc 9.123350 loss_rnnt 3.796006 hw_loss 0.349302 lr 0.00036074 rank 3
2023-02-22 18:47:18,152 DEBUG TRAIN Batch 23/300 loss 9.811509 loss_att 11.929579 loss_ctc 12.848387 loss_rnnt 8.893423 hw_loss 0.167916 lr 0.00036066 rank 6
2023-02-22 18:47:18,154 DEBUG TRAIN Batch 23/300 loss 12.597002 loss_att 14.870832 loss_ctc 17.468504 loss_rnnt 11.396763 hw_loss 0.179887 lr 0.00036071 rank 1
2023-02-22 18:47:18,171 DEBUG TRAIN Batch 23/300 loss 7.518794 loss_att 12.999743 loss_ctc 11.422560 loss_rnnt 5.708656 hw_loss 0.362711 lr 0.00036076 rank 0
2023-02-22 18:47:18,198 DEBUG TRAIN Batch 23/300 loss 6.335929 loss_att 9.211660 loss_ctc 8.118966 loss_rnnt 5.330159 hw_loss 0.361660 lr 0.00036075 rank 4
2023-02-22 18:48:31,659 DEBUG TRAIN Batch 23/400 loss 5.069111 loss_att 9.032533 loss_ctc 7.296847 loss_rnnt 3.888769 hw_loss 0.169925 lr 0.00036059 rank 5
2023-02-22 18:48:31,658 DEBUG TRAIN Batch 23/400 loss 12.416518 loss_att 12.909781 loss_ctc 15.510225 loss_rnnt 11.767361 hw_loss 0.258770 lr 0.00036066 rank 0
2023-02-22 18:48:31,659 DEBUG TRAIN Batch 23/400 loss 7.346920 loss_att 10.341904 loss_ctc 10.303949 loss_rnnt 6.282673 hw_loss 0.133085 lr 0.00036066 rank 4
2023-02-22 18:48:31,659 DEBUG TRAIN Batch 23/400 loss 15.887303 loss_att 20.029446 loss_ctc 21.747417 loss_rnnt 14.142154 hw_loss 0.253823 lr 0.00036057 rank 6
2023-02-22 18:48:31,659 DEBUG TRAIN Batch 23/400 loss 6.587944 loss_att 12.591635 loss_ctc 11.661960 loss_rnnt 4.597997 hw_loss 0.211262 lr 0.00036060 rank 2
2023-02-22 18:48:31,662 DEBUG TRAIN Batch 23/400 loss 14.779997 loss_att 17.125431 loss_ctc 22.583721 loss_rnnt 13.142193 hw_loss 0.240411 lr 0.00036062 rank 1
2023-02-22 18:48:31,663 DEBUG TRAIN Batch 23/400 loss 5.333603 loss_att 9.709443 loss_ctc 10.469440 loss_rnnt 3.577471 hw_loss 0.367851 lr 0.00036065 rank 3
2023-02-22 18:48:31,665 DEBUG TRAIN Batch 23/400 loss 8.354887 loss_att 8.904332 loss_ctc 9.538036 loss_rnnt 7.878351 hw_loss 0.391677 lr 0.00036056 rank 7
2023-02-22 18:49:43,810 DEBUG TRAIN Batch 23/500 loss 5.455423 loss_att 8.852451 loss_ctc 8.480822 loss_rnnt 4.203768 hw_loss 0.316618 lr 0.00036053 rank 1
2023-02-22 18:49:43,810 DEBUG TRAIN Batch 23/500 loss 11.404321 loss_att 14.195059 loss_ctc 17.073225 loss_rnnt 9.925005 hw_loss 0.309964 lr 0.00036047 rank 7
2023-02-22 18:49:43,810 DEBUG TRAIN Batch 23/500 loss 5.267404 loss_att 6.745626 loss_ctc 6.463645 loss_rnnt 4.659112 hw_loss 0.287154 lr 0.00036057 rank 0
2023-02-22 18:49:43,811 DEBUG TRAIN Batch 23/500 loss 7.070488 loss_att 10.177823 loss_ctc 10.251781 loss_rnnt 5.888443 hw_loss 0.255759 lr 0.00036051 rank 2
2023-02-22 18:49:43,812 DEBUG TRAIN Batch 23/500 loss 6.083695 loss_att 8.415443 loss_ctc 7.048294 loss_rnnt 5.311210 hw_loss 0.332855 lr 0.00036050 rank 5
2023-02-22 18:49:43,812 DEBUG TRAIN Batch 23/500 loss 5.253757 loss_att 7.303006 loss_ctc 6.523908 loss_rnnt 4.556632 hw_loss 0.221104 lr 0.00036055 rank 3
2023-02-22 18:49:43,813 DEBUG TRAIN Batch 23/500 loss 7.636356 loss_att 9.298325 loss_ctc 10.678678 loss_rnnt 6.730855 hw_loss 0.313995 lr 0.00036047 rank 6
2023-02-22 18:49:43,820 DEBUG TRAIN Batch 23/500 loss 5.440486 loss_att 7.376163 loss_ctc 9.620903 loss_rnnt 4.391835 hw_loss 0.195239 lr 0.00036056 rank 4
2023-02-22 18:50:56,900 DEBUG TRAIN Batch 23/600 loss 9.930756 loss_att 9.755212 loss_ctc 13.532590 loss_rnnt 9.154405 hw_loss 0.621029 lr 0.00036047 rank 4
2023-02-22 18:50:56,901 DEBUG TRAIN Batch 23/600 loss 8.930367 loss_att 10.083641 loss_ctc 11.676365 loss_rnnt 8.091262 hw_loss 0.454345 lr 0.00036041 rank 2
2023-02-22 18:50:56,902 DEBUG TRAIN Batch 23/600 loss 12.062125 loss_att 11.108226 loss_ctc 13.374676 loss_rnnt 11.817392 hw_loss 0.488448 lr 0.00036043 rank 1
2023-02-22 18:50:56,904 DEBUG TRAIN Batch 23/600 loss 6.006040 loss_att 9.089227 loss_ctc 7.951751 loss_rnnt 5.016295 hw_loss 0.213150 lr 0.00036038 rank 6
2023-02-22 18:50:56,907 DEBUG TRAIN Batch 23/600 loss 13.747635 loss_att 13.365211 loss_ctc 19.379383 loss_rnnt 12.938839 hw_loss 0.251963 lr 0.00036046 rank 3
2023-02-22 18:50:56,906 DEBUG TRAIN Batch 23/600 loss 7.294617 loss_att 8.271087 loss_ctc 9.274823 loss_rnnt 6.700845 hw_loss 0.252095 lr 0.00036037 rank 7
2023-02-22 18:50:56,917 DEBUG TRAIN Batch 23/600 loss 11.364736 loss_att 12.246857 loss_ctc 16.210068 loss_rnnt 10.354119 hw_loss 0.352775 lr 0.00036041 rank 5
2023-02-22 18:50:56,955 DEBUG TRAIN Batch 23/600 loss 8.367826 loss_att 8.059459 loss_ctc 10.530165 loss_rnnt 7.826309 hw_loss 0.590396 lr 0.00036047 rank 0
2023-02-22 18:52:12,009 DEBUG TRAIN Batch 23/700 loss 9.952344 loss_att 15.163083 loss_ctc 16.293741 loss_rnnt 7.920885 hw_loss 0.269612 lr 0.00036028 rank 7
2023-02-22 18:52:12,017 DEBUG TRAIN Batch 23/700 loss 13.915613 loss_att 19.581215 loss_ctc 29.031103 loss_rnnt 10.632565 hw_loss 0.252241 lr 0.00036029 rank 6
2023-02-22 18:52:12,017 DEBUG TRAIN Batch 23/700 loss 3.616708 loss_att 6.771462 loss_ctc 5.899042 loss_rnnt 2.545465 hw_loss 0.254964 lr 0.00036038 rank 0
2023-02-22 18:52:12,023 DEBUG TRAIN Batch 23/700 loss 5.713027 loss_att 8.442249 loss_ctc 8.191370 loss_rnnt 4.560975 hw_loss 0.517052 lr 0.00036034 rank 1
2023-02-22 18:52:12,028 DEBUG TRAIN Batch 23/700 loss 9.964158 loss_att 12.653446 loss_ctc 12.709331 loss_rnnt 8.876084 hw_loss 0.345361 lr 0.00036037 rank 3
2023-02-22 18:52:12,035 DEBUG TRAIN Batch 23/700 loss 11.044009 loss_att 10.092705 loss_ctc 20.445141 loss_rnnt 9.819236 hw_loss 0.302905 lr 0.00036032 rank 2
2023-02-22 18:52:12,038 DEBUG TRAIN Batch 23/700 loss 3.608352 loss_att 5.966432 loss_ctc 6.139801 loss_rnnt 2.578466 hw_loss 0.413896 lr 0.00036038 rank 4
2023-02-22 18:52:12,046 DEBUG TRAIN Batch 23/700 loss 9.927797 loss_att 14.006020 loss_ctc 16.576853 loss_rnnt 8.121084 hw_loss 0.195989 lr 0.00036031 rank 5
2023-02-22 18:53:24,283 DEBUG TRAIN Batch 23/800 loss 8.593968 loss_att 12.995575 loss_ctc 11.976425 loss_rnnt 7.095212 hw_loss 0.313951 lr 0.00036023 rank 2
2023-02-22 18:53:24,284 DEBUG TRAIN Batch 23/800 loss 9.328509 loss_att 12.368397 loss_ctc 12.097038 loss_rnnt 8.221537 hw_loss 0.243483 lr 0.00036027 rank 3
2023-02-22 18:53:24,291 DEBUG TRAIN Batch 23/800 loss 3.277153 loss_att 6.114865 loss_ctc 4.330775 loss_rnnt 2.346624 hw_loss 0.417194 lr 0.00036025 rank 1
2023-02-22 18:53:24,292 DEBUG TRAIN Batch 23/800 loss 5.010607 loss_att 6.536201 loss_ctc 7.079112 loss_rnnt 4.272787 hw_loss 0.294187 lr 0.00036022 rank 5
2023-02-22 18:53:24,293 DEBUG TRAIN Batch 23/800 loss 6.828108 loss_att 9.116428 loss_ctc 10.552024 loss_rnnt 5.611549 hw_loss 0.491948 lr 0.00036019 rank 6
2023-02-22 18:53:24,296 DEBUG TRAIN Batch 23/800 loss 4.892258 loss_att 7.917201 loss_ctc 8.633183 loss_rnnt 3.623933 hw_loss 0.308526 lr 0.00036029 rank 0
2023-02-22 18:53:24,299 DEBUG TRAIN Batch 23/800 loss 7.265802 loss_att 10.397038 loss_ctc 10.950510 loss_rnnt 5.998486 hw_loss 0.280828 lr 0.00036019 rank 7
2023-02-22 18:53:24,343 DEBUG TRAIN Batch 23/800 loss 10.076239 loss_att 11.260472 loss_ctc 11.767314 loss_rnnt 9.460793 hw_loss 0.287106 lr 0.00036028 rank 4
2023-02-22 18:54:37,115 DEBUG TRAIN Batch 23/900 loss 10.303080 loss_att 12.657694 loss_ctc 16.022127 loss_rnnt 8.904437 hw_loss 0.309712 lr 0.00036013 rank 2
2023-02-22 18:54:37,118 DEBUG TRAIN Batch 23/900 loss 5.273349 loss_att 8.892765 loss_ctc 6.071016 loss_rnnt 4.264297 hw_loss 0.335276 lr 0.00036010 rank 6
2023-02-22 18:54:37,119 DEBUG TRAIN Batch 23/900 loss 3.494715 loss_att 5.588835 loss_ctc 3.378327 loss_rnnt 2.981721 hw_loss 0.205666 lr 0.00036018 rank 3
2023-02-22 18:54:37,119 DEBUG TRAIN Batch 23/900 loss 2.566016 loss_att 4.673553 loss_ctc 3.493594 loss_rnnt 1.866040 hw_loss 0.290236 lr 0.00036015 rank 1
2023-02-22 18:54:37,119 DEBUG TRAIN Batch 23/900 loss 4.668048 loss_att 7.041795 loss_ctc 6.266586 loss_rnnt 3.781990 hw_loss 0.371568 lr 0.00036019 rank 4
2023-02-22 18:54:37,121 DEBUG TRAIN Batch 23/900 loss 5.497334 loss_att 8.538103 loss_ctc 9.619039 loss_rnnt 4.192623 hw_loss 0.275621 lr 0.00036019 rank 0
2023-02-22 18:54:37,121 DEBUG TRAIN Batch 23/900 loss 10.642880 loss_att 8.994328 loss_ctc 14.804682 loss_rnnt 10.313034 hw_loss 0.196218 lr 0.00036013 rank 5
2023-02-22 18:54:37,165 DEBUG TRAIN Batch 23/900 loss 7.164648 loss_att 10.074740 loss_ctc 11.652441 loss_rnnt 5.839563 hw_loss 0.271301 lr 0.00036009 rank 7
2023-02-22 18:55:50,501 DEBUG TRAIN Batch 23/1000 loss 6.895379 loss_att 10.871975 loss_ctc 9.752188 loss_rnnt 5.524312 hw_loss 0.365326 lr 0.00036009 rank 3
2023-02-22 18:55:50,505 DEBUG TRAIN Batch 23/1000 loss 8.759907 loss_att 11.924425 loss_ctc 12.122430 loss_rnnt 7.494113 hw_loss 0.346037 lr 0.00036004 rank 2
2023-02-22 18:55:50,506 DEBUG TRAIN Batch 23/1000 loss 19.372503 loss_att 21.836649 loss_ctc 27.304792 loss_rnnt 17.714891 hw_loss 0.200897 lr 0.00036000 rank 6
2023-02-22 18:55:50,509 DEBUG TRAIN Batch 23/1000 loss 5.484512 loss_att 8.816400 loss_ctc 9.216184 loss_rnnt 4.224036 hw_loss 0.181017 lr 0.00036003 rank 5
2023-02-22 18:55:50,511 DEBUG TRAIN Batch 23/1000 loss 5.538269 loss_att 8.472353 loss_ctc 10.571179 loss_rnnt 4.112727 hw_loss 0.314382 lr 0.00036010 rank 0
2023-02-22 18:55:50,524 DEBUG TRAIN Batch 23/1000 loss 12.748621 loss_att 15.473802 loss_ctc 19.495682 loss_rnnt 11.158335 hw_loss 0.273077 lr 0.00036000 rank 7
2023-02-22 18:55:50,539 DEBUG TRAIN Batch 23/1000 loss 8.821198 loss_att 12.495625 loss_ctc 12.397264 loss_rnnt 7.485553 hw_loss 0.232405 lr 0.00036006 rank 1
2023-02-22 18:55:50,544 DEBUG TRAIN Batch 23/1000 loss 11.780185 loss_att 13.209344 loss_ctc 15.532877 loss_rnnt 10.852222 hw_loss 0.265823 lr 0.00036010 rank 4
2023-02-22 18:57:04,411 DEBUG TRAIN Batch 23/1100 loss 4.830086 loss_att 7.830282 loss_ctc 12.525372 loss_rnnt 3.013084 hw_loss 0.357985 lr 0.00035995 rank 2
2023-02-22 18:57:04,416 DEBUG TRAIN Batch 23/1100 loss 8.080896 loss_att 10.710002 loss_ctc 10.659653 loss_rnnt 7.032580 hw_loss 0.334990 lr 0.00035999 rank 3
2023-02-22 18:57:04,419 DEBUG TRAIN Batch 23/1100 loss 11.462504 loss_att 11.538146 loss_ctc 15.432861 loss_rnnt 10.761364 hw_loss 0.293680 lr 0.00035997 rank 1
2023-02-22 18:57:04,419 DEBUG TRAIN Batch 23/1100 loss 4.713292 loss_att 7.520942 loss_ctc 7.984516 loss_rnnt 3.566377 hw_loss 0.279792 lr 0.00036001 rank 0
2023-02-22 18:57:04,424 DEBUG TRAIN Batch 23/1100 loss 8.347562 loss_att 10.182560 loss_ctc 9.698151 loss_rnnt 7.635167 hw_loss 0.309968 lr 0.00035991 rank 6
2023-02-22 18:57:04,424 DEBUG TRAIN Batch 23/1100 loss 11.523952 loss_att 15.680418 loss_ctc 17.369209 loss_rnnt 9.722031 hw_loss 0.358616 lr 0.00035994 rank 5
2023-02-22 18:57:04,426 DEBUG TRAIN Batch 23/1100 loss 14.257883 loss_att 18.340549 loss_ctc 22.726656 loss_rnnt 12.155132 hw_loss 0.294465 lr 0.00036000 rank 4
2023-02-22 18:57:04,470 DEBUG TRAIN Batch 23/1100 loss 9.069933 loss_att 11.237442 loss_ctc 11.609282 loss_rnnt 8.153790 hw_loss 0.270115 lr 0.00035991 rank 7
2023-02-22 18:58:16,044 DEBUG TRAIN Batch 23/1200 loss 4.132082 loss_att 6.228232 loss_ctc 7.345442 loss_rnnt 3.085246 hw_loss 0.373420 lr 0.00035985 rank 2
2023-02-22 18:58:16,047 DEBUG TRAIN Batch 23/1200 loss 13.102940 loss_att 14.512777 loss_ctc 18.628048 loss_rnnt 11.947864 hw_loss 0.255804 lr 0.00035987 rank 1
2023-02-22 18:58:16,046 DEBUG TRAIN Batch 23/1200 loss 6.743742 loss_att 9.437876 loss_ctc 9.489623 loss_rnnt 5.609940 hw_loss 0.429109 lr 0.00035982 rank 6
2023-02-22 18:58:16,049 DEBUG TRAIN Batch 23/1200 loss 8.177898 loss_att 10.399873 loss_ctc 12.883948 loss_rnnt 6.934405 hw_loss 0.321797 lr 0.00035991 rank 0
2023-02-22 18:58:16,051 DEBUG TRAIN Batch 23/1200 loss 11.699459 loss_att 13.101933 loss_ctc 14.651725 loss_rnnt 10.888562 hw_loss 0.256436 lr 0.00035981 rank 7
2023-02-22 18:58:16,054 DEBUG TRAIN Batch 23/1200 loss 9.309896 loss_att 12.268246 loss_ctc 11.774005 loss_rnnt 8.268104 hw_loss 0.227955 lr 0.00035985 rank 5
2023-02-22 18:58:16,053 DEBUG TRAIN Batch 23/1200 loss 7.917304 loss_att 10.043774 loss_ctc 11.643139 loss_rnnt 6.907957 hw_loss 0.163643 lr 0.00035990 rank 3
2023-02-22 18:58:16,054 DEBUG TRAIN Batch 23/1200 loss 8.453356 loss_att 11.338923 loss_ctc 17.885351 loss_rnnt 6.476273 hw_loss 0.266942 lr 0.00035991 rank 4
2023-02-22 18:59:28,447 DEBUG TRAIN Batch 23/1300 loss 7.940991 loss_att 13.055772 loss_ctc 13.161364 loss_rnnt 6.035676 hw_loss 0.349330 lr 0.00035982 rank 0
2023-02-22 18:59:28,458 DEBUG TRAIN Batch 23/1300 loss 14.849617 loss_att 18.291269 loss_ctc 20.895853 loss_rnnt 13.234038 hw_loss 0.227032 lr 0.00035976 rank 2
2023-02-22 18:59:28,460 DEBUG TRAIN Batch 23/1300 loss 10.362883 loss_att 10.765065 loss_ctc 12.673837 loss_rnnt 9.790749 hw_loss 0.344196 lr 0.00035981 rank 3
2023-02-22 18:59:28,465 DEBUG TRAIN Batch 23/1300 loss 11.543302 loss_att 10.958329 loss_ctc 15.157721 loss_rnnt 10.854844 hw_loss 0.606618 lr 0.00035973 rank 6
2023-02-22 18:59:28,467 DEBUG TRAIN Batch 23/1300 loss 5.997111 loss_att 9.199488 loss_ctc 9.201263 loss_rnnt 4.822955 hw_loss 0.199614 lr 0.00035982 rank 4
2023-02-22 18:59:28,467 DEBUG TRAIN Batch 23/1300 loss 6.094522 loss_att 8.409643 loss_ctc 7.091796 loss_rnnt 5.459311 hw_loss 0.073529 lr 0.00035972 rank 7
2023-02-22 18:59:28,469 DEBUG TRAIN Batch 23/1300 loss 9.861239 loss_att 9.765656 loss_ctc 12.593794 loss_rnnt 9.395099 hw_loss 0.226719 lr 0.00035975 rank 5
2023-02-22 18:59:28,518 DEBUG TRAIN Batch 23/1300 loss 7.709635 loss_att 12.023561 loss_ctc 16.561798 loss_rnnt 5.465129 hw_loss 0.377684 lr 0.00035978 rank 1
2023-02-22 19:00:42,699 DEBUG TRAIN Batch 23/1400 loss 11.847519 loss_att 14.472094 loss_ctc 14.762393 loss_rnnt 10.860802 hw_loss 0.137162 lr 0.00035967 rank 2
2023-02-22 19:00:42,703 DEBUG TRAIN Batch 23/1400 loss 11.588160 loss_att 18.821667 loss_ctc 18.582195 loss_rnnt 9.066280 hw_loss 0.267450 lr 0.00035963 rank 6
2023-02-22 19:00:42,714 DEBUG TRAIN Batch 23/1400 loss 10.567081 loss_att 16.525587 loss_ctc 17.366009 loss_rnnt 8.387532 hw_loss 0.152482 lr 0.00035969 rank 1
2023-02-22 19:00:42,715 DEBUG TRAIN Batch 23/1400 loss 5.298104 loss_att 6.592868 loss_ctc 6.583555 loss_rnnt 4.714166 hw_loss 0.287985 lr 0.00035972 rank 4
2023-02-22 19:00:42,716 DEBUG TRAIN Batch 23/1400 loss 2.923535 loss_att 6.500124 loss_ctc 6.074306 loss_rnnt 1.660365 hw_loss 0.239530 lr 0.00035963 rank 7
2023-02-22 19:00:42,718 DEBUG TRAIN Batch 23/1400 loss 6.152708 loss_att 8.005249 loss_ctc 7.792437 loss_rnnt 5.358783 hw_loss 0.383974 lr 0.00035966 rank 5
2023-02-22 19:00:42,719 DEBUG TRAIN Batch 23/1400 loss 6.877858 loss_att 9.909615 loss_ctc 11.733760 loss_rnnt 5.459358 hw_loss 0.308802 lr 0.00035973 rank 0
2023-02-22 19:00:42,721 DEBUG TRAIN Batch 23/1400 loss 6.505224 loss_att 8.481952 loss_ctc 7.147877 loss_rnnt 5.907144 hw_loss 0.219464 lr 0.00035971 rank 3
2023-02-22 19:01:56,060 DEBUG TRAIN Batch 23/1500 loss 6.542809 loss_att 9.858291 loss_ctc 8.359715 loss_rnnt 5.494855 hw_loss 0.267383 lr 0.00035963 rank 0
2023-02-22 19:01:56,062 DEBUG TRAIN Batch 23/1500 loss 5.433161 loss_att 7.353160 loss_ctc 8.129539 loss_rnnt 4.379959 hw_loss 0.580660 lr 0.00035957 rank 5
2023-02-22 19:01:56,071 DEBUG TRAIN Batch 23/1500 loss 9.333206 loss_att 13.121624 loss_ctc 16.089630 loss_rnnt 7.521499 hw_loss 0.287189 lr 0.00035953 rank 7
2023-02-22 19:01:56,073 DEBUG TRAIN Batch 23/1500 loss 11.468609 loss_att 12.094113 loss_ctc 13.441021 loss_rnnt 10.943110 hw_loss 0.257641 lr 0.00035957 rank 2
2023-02-22 19:01:56,076 DEBUG TRAIN Batch 23/1500 loss 5.528053 loss_att 7.711353 loss_ctc 7.504940 loss_rnnt 4.704702 hw_loss 0.230823 lr 0.00035954 rank 6
2023-02-22 19:01:56,081 DEBUG TRAIN Batch 23/1500 loss 7.699405 loss_att 10.876744 loss_ctc 8.259901 loss_rnnt 6.892078 hw_loss 0.182111 lr 0.00035962 rank 3
2023-02-22 19:01:56,081 DEBUG TRAIN Batch 23/1500 loss 16.359095 loss_att 19.229006 loss_ctc 22.169752 loss_rnnt 14.968121 hw_loss 0.079194 lr 0.00035963 rank 4
2023-02-22 19:01:56,129 DEBUG TRAIN Batch 23/1500 loss 5.684349 loss_att 8.053483 loss_ctc 10.915905 loss_rnnt 4.347299 hw_loss 0.310655 lr 0.00035959 rank 1
2023-02-22 19:03:08,629 DEBUG TRAIN Batch 23/1600 loss 7.057689 loss_att 8.708485 loss_ctc 8.025229 loss_rnnt 6.508315 hw_loss 0.169144 lr 0.00035948 rank 2
2023-02-22 19:03:08,633 DEBUG TRAIN Batch 23/1600 loss 6.589769 loss_att 9.336388 loss_ctc 8.630994 loss_rnnt 5.557158 hw_loss 0.395857 lr 0.00035953 rank 3
2023-02-22 19:03:08,635 DEBUG TRAIN Batch 23/1600 loss 5.038690 loss_att 8.002566 loss_ctc 5.558446 loss_rnnt 4.178393 hw_loss 0.371665 lr 0.00035945 rank 6
2023-02-22 19:03:08,638 DEBUG TRAIN Batch 23/1600 loss 10.178399 loss_att 13.146514 loss_ctc 16.729351 loss_rnnt 8.638882 hw_loss 0.135812 lr 0.00035947 rank 5
2023-02-22 19:03:08,640 DEBUG TRAIN Batch 23/1600 loss 8.873021 loss_att 10.412832 loss_ctc 11.438643 loss_rnnt 8.091200 hw_loss 0.247080 lr 0.00035954 rank 0
2023-02-22 19:03:08,640 DEBUG TRAIN Batch 23/1600 loss 11.843210 loss_att 13.858999 loss_ctc 16.506704 loss_rnnt 10.606823 hw_loss 0.396433 lr 0.00035954 rank 4
2023-02-22 19:03:08,640 DEBUG TRAIN Batch 23/1600 loss 5.544363 loss_att 8.101036 loss_ctc 8.238654 loss_rnnt 4.591225 hw_loss 0.154810 lr 0.00035950 rank 1
2023-02-22 19:03:08,646 DEBUG TRAIN Batch 23/1600 loss 13.539285 loss_att 16.501698 loss_ctc 20.282501 loss_rnnt 11.864464 hw_loss 0.343580 lr 0.00035944 rank 7
2023-02-22 19:04:20,789 DEBUG TRAIN Batch 23/1700 loss 7.975214 loss_att 12.198133 loss_ctc 11.756078 loss_rnnt 6.488883 hw_loss 0.258061 lr 0.00035944 rank 4
2023-02-22 19:04:20,800 DEBUG TRAIN Batch 23/1700 loss 10.066808 loss_att 11.997371 loss_ctc 13.637708 loss_rnnt 9.122407 hw_loss 0.154065 lr 0.00035939 rank 2
2023-02-22 19:04:20,801 DEBUG TRAIN Batch 23/1700 loss 8.639681 loss_att 11.152944 loss_ctc 10.461840 loss_rnnt 7.785917 hw_loss 0.202795 lr 0.00035935 rank 6
2023-02-22 19:04:20,804 DEBUG TRAIN Batch 23/1700 loss 17.939199 loss_att 19.036736 loss_ctc 27.332634 loss_rnnt 16.322067 hw_loss 0.272190 lr 0.00035945 rank 0
2023-02-22 19:04:20,806 DEBUG TRAIN Batch 23/1700 loss 11.090712 loss_att 13.890697 loss_ctc 18.717199 loss_rnnt 9.431900 hw_loss 0.153653 lr 0.00035943 rank 3
2023-02-22 19:04:20,806 DEBUG TRAIN Batch 23/1700 loss 5.452809 loss_att 8.554663 loss_ctc 9.626552 loss_rnnt 4.110319 hw_loss 0.310539 lr 0.00035935 rank 7
2023-02-22 19:04:20,808 DEBUG TRAIN Batch 23/1700 loss 4.397753 loss_att 7.028365 loss_ctc 4.140718 loss_rnnt 3.804689 hw_loss 0.189773 lr 0.00035938 rank 5
2023-02-22 19:04:20,857 DEBUG TRAIN Batch 23/1700 loss 15.219619 loss_att 17.502943 loss_ctc 19.656538 loss_rnnt 13.984800 hw_loss 0.349810 lr 0.00035941 rank 1
2023-02-22 19:05:35,926 DEBUG TRAIN Batch 23/1800 loss 11.050111 loss_att 10.240399 loss_ctc 12.633142 loss_rnnt 10.876758 hw_loss 0.232920 lr 0.00035929 rank 2
2023-02-22 19:05:35,929 DEBUG TRAIN Batch 23/1800 loss 8.384086 loss_att 10.674903 loss_ctc 12.432974 loss_rnnt 7.295120 hw_loss 0.170532 lr 0.00035934 rank 3
2023-02-22 19:05:35,933 DEBUG TRAIN Batch 23/1800 loss 6.386106 loss_att 8.396931 loss_ctc 8.499053 loss_rnnt 5.620389 hw_loss 0.153423 lr 0.00035936 rank 0
2023-02-22 19:05:35,934 DEBUG TRAIN Batch 23/1800 loss 16.983561 loss_att 17.236893 loss_ctc 19.060415 loss_rnnt 16.471754 hw_loss 0.345425 lr 0.00035931 rank 1
2023-02-22 19:05:35,937 DEBUG TRAIN Batch 23/1800 loss 8.917146 loss_att 11.097965 loss_ctc 11.384487 loss_rnnt 8.092800 hw_loss 0.111005 lr 0.00035926 rank 6
2023-02-22 19:05:35,937 DEBUG TRAIN Batch 23/1800 loss 6.778417 loss_att 8.769231 loss_ctc 8.597341 loss_rnnt 5.958875 hw_loss 0.335355 lr 0.00035926 rank 7
2023-02-22 19:05:35,945 DEBUG TRAIN Batch 23/1800 loss 5.597076 loss_att 8.296674 loss_ctc 6.538974 loss_rnnt 4.787677 hw_loss 0.269799 lr 0.00035929 rank 5
2023-02-22 19:05:35,985 DEBUG TRAIN Batch 23/1800 loss 9.387656 loss_att 13.817027 loss_ctc 12.219921 loss_rnnt 7.973589 hw_loss 0.282295 lr 0.00035935 rank 4
2023-02-22 19:06:48,848 DEBUG TRAIN Batch 23/1900 loss 15.128836 loss_att 17.087479 loss_ctc 21.656378 loss_rnnt 13.618954 hw_loss 0.464652 lr 0.00035920 rank 2
2023-02-22 19:06:48,850 DEBUG TRAIN Batch 23/1900 loss 13.914188 loss_att 15.412031 loss_ctc 17.815802 loss_rnnt 12.985382 hw_loss 0.204417 lr 0.00035925 rank 3
2023-02-22 19:06:48,853 DEBUG TRAIN Batch 23/1900 loss 10.099114 loss_att 9.940781 loss_ctc 11.596482 loss_rnnt 9.725621 hw_loss 0.385333 lr 0.00035922 rank 1
2023-02-22 19:06:48,856 DEBUG TRAIN Batch 23/1900 loss 10.271921 loss_att 9.541862 loss_ctc 12.833284 loss_rnnt 9.820742 hw_loss 0.479394 lr 0.00035917 rank 6
2023-02-22 19:06:48,855 DEBUG TRAIN Batch 23/1900 loss 6.455614 loss_att 6.886609 loss_ctc 9.241086 loss_rnnt 5.764032 hw_loss 0.438725 lr 0.00035919 rank 5
2023-02-22 19:06:48,856 DEBUG TRAIN Batch 23/1900 loss 5.254365 loss_att 7.652424 loss_ctc 6.162930 loss_rnnt 4.469087 hw_loss 0.345985 lr 0.00035916 rank 7
2023-02-22 19:06:48,856 DEBUG TRAIN Batch 23/1900 loss 13.406214 loss_att 14.264398 loss_ctc 18.542860 loss_rnnt 12.241842 hw_loss 0.577216 lr 0.00035926 rank 4
2023-02-22 19:06:48,858 DEBUG TRAIN Batch 23/1900 loss 8.359613 loss_att 8.582583 loss_ctc 10.774007 loss_rnnt 7.794080 hw_loss 0.373164 lr 0.00035926 rank 0
2023-02-22 19:08:00,996 DEBUG TRAIN Batch 23/2000 loss 6.160066 loss_att 9.138098 loss_ctc 7.208410 loss_rnnt 5.324429 hw_loss 0.187971 lr 0.00035907 rank 7
2023-02-22 19:08:00,999 DEBUG TRAIN Batch 23/2000 loss 6.963908 loss_att 10.189043 loss_ctc 10.727775 loss_rnnt 5.644525 hw_loss 0.323450 lr 0.00035911 rank 2
2023-02-22 19:08:00,999 DEBUG TRAIN Batch 23/2000 loss 6.066044 loss_att 10.048445 loss_ctc 8.942961 loss_rnnt 4.685297 hw_loss 0.376273 lr 0.00035908 rank 6
2023-02-22 19:08:00,999 DEBUG TRAIN Batch 23/2000 loss 8.058940 loss_att 13.137386 loss_ctc 10.470665 loss_rnnt 6.583927 hw_loss 0.258301 lr 0.00035915 rank 3
2023-02-22 19:08:01,000 DEBUG TRAIN Batch 23/2000 loss 6.657357 loss_att 6.544983 loss_ctc 4.060750 loss_rnnt 6.755800 hw_loss 0.506710 lr 0.00035917 rank 4
2023-02-22 19:08:01,004 DEBUG TRAIN Batch 23/2000 loss 6.451325 loss_att 9.084423 loss_ctc 7.820461 loss_rnnt 5.667098 hw_loss 0.140730 lr 0.00035917 rank 0
2023-02-22 19:08:01,004 DEBUG TRAIN Batch 23/2000 loss 9.639064 loss_att 11.225817 loss_ctc 12.484404 loss_rnnt 8.788633 hw_loss 0.288190 lr 0.00035913 rank 1
2023-02-22 19:08:01,009 DEBUG TRAIN Batch 23/2000 loss 4.172214 loss_att 6.759666 loss_ctc 4.897525 loss_rnnt 3.520236 hw_loss 0.070837 lr 0.00035910 rank 5
2023-02-22 19:09:14,566 DEBUG TRAIN Batch 23/2100 loss 11.328695 loss_att 13.456390 loss_ctc 12.778793 loss_rnnt 10.573546 hw_loss 0.255495 lr 0.00035898 rank 6
2023-02-22 19:09:14,573 DEBUG TRAIN Batch 23/2100 loss 7.869585 loss_att 11.950893 loss_ctc 15.887094 loss_rnnt 5.856312 hw_loss 0.240019 lr 0.00035901 rank 5
2023-02-22 19:09:14,574 DEBUG TRAIN Batch 23/2100 loss 5.771571 loss_att 7.700109 loss_ctc 7.421953 loss_rnnt 5.036489 hw_loss 0.242483 lr 0.00035902 rank 2
2023-02-22 19:09:14,578 DEBUG TRAIN Batch 23/2100 loss 10.324717 loss_att 13.127956 loss_ctc 18.021557 loss_rnnt 8.646246 hw_loss 0.171706 lr 0.00035904 rank 1
2023-02-22 19:09:14,583 DEBUG TRAIN Batch 23/2100 loss 7.067606 loss_att 10.018557 loss_ctc 11.683121 loss_rnnt 5.743047 hw_loss 0.223063 lr 0.00035906 rank 3
2023-02-22 19:09:14,584 DEBUG TRAIN Batch 23/2100 loss 7.557718 loss_att 9.455693 loss_ctc 7.869910 loss_rnnt 6.989188 hw_loss 0.276204 lr 0.00035898 rank 7
2023-02-22 19:09:14,584 DEBUG TRAIN Batch 23/2100 loss 4.202187 loss_att 6.194249 loss_ctc 4.236982 loss_rnnt 3.679631 hw_loss 0.224071 lr 0.00035907 rank 4
2023-02-22 19:09:14,590 DEBUG TRAIN Batch 23/2100 loss 7.718607 loss_att 10.823601 loss_ctc 16.860130 loss_rnnt 5.779466 hw_loss 0.186137 lr 0.00035908 rank 0
2023-02-22 19:10:27,310 DEBUG TRAIN Batch 23/2200 loss 9.921288 loss_att 12.198681 loss_ctc 18.199532 loss_rnnt 8.166623 hw_loss 0.366412 lr 0.00035889 rank 7
2023-02-22 19:10:27,327 DEBUG TRAIN Batch 23/2200 loss 5.637150 loss_att 9.391509 loss_ctc 5.895978 loss_rnnt 4.670230 hw_loss 0.340383 lr 0.00035897 rank 3
2023-02-22 19:10:27,327 DEBUG TRAIN Batch 23/2200 loss 9.030241 loss_att 11.424509 loss_ctc 15.276133 loss_rnnt 7.546555 hw_loss 0.322589 lr 0.00035892 rank 2
2023-02-22 19:10:27,327 DEBUG TRAIN Batch 23/2200 loss 7.384137 loss_att 11.000747 loss_ctc 10.828430 loss_rnnt 6.052434 hw_loss 0.279642 lr 0.00035898 rank 0
2023-02-22 19:10:27,328 DEBUG TRAIN Batch 23/2200 loss 4.123503 loss_att 7.481474 loss_ctc 5.625937 loss_rnnt 3.179601 hw_loss 0.134968 lr 0.00035898 rank 4
2023-02-22 19:10:27,332 DEBUG TRAIN Batch 23/2200 loss 4.935388 loss_att 8.892750 loss_ctc 8.041038 loss_rnnt 3.584385 hw_loss 0.272706 lr 0.00035889 rank 6
2023-02-22 19:10:27,336 DEBUG TRAIN Batch 23/2200 loss 7.672144 loss_att 10.452814 loss_ctc 8.926916 loss_rnnt 6.732003 hw_loss 0.406319 lr 0.00035892 rank 5
2023-02-22 19:10:27,377 DEBUG TRAIN Batch 23/2200 loss 10.997747 loss_att 14.295508 loss_ctc 18.319336 loss_rnnt 9.176722 hw_loss 0.347367 lr 0.00035894 rank 1
2023-02-22 19:11:38,903 DEBUG TRAIN Batch 23/2300 loss 10.328173 loss_att 12.798252 loss_ctc 13.349487 loss_rnnt 9.271219 hw_loss 0.300179 lr 0.00035883 rank 2
2023-02-22 19:11:38,903 DEBUG TRAIN Batch 23/2300 loss 4.999180 loss_att 10.536501 loss_ctc 11.776074 loss_rnnt 2.864128 hw_loss 0.232505 lr 0.00035889 rank 4
2023-02-22 19:11:38,904 DEBUG TRAIN Batch 23/2300 loss 14.864766 loss_att 17.870083 loss_ctc 19.659903 loss_rnnt 13.532991 hw_loss 0.171299 lr 0.00035885 rank 1
2023-02-22 19:11:38,906 DEBUG TRAIN Batch 23/2300 loss 8.183180 loss_att 10.270648 loss_ctc 14.683902 loss_rnnt 6.742083 hw_loss 0.294077 lr 0.00035888 rank 3
2023-02-22 19:11:38,907 DEBUG TRAIN Batch 23/2300 loss 6.032368 loss_att 8.863562 loss_ctc 7.409453 loss_rnnt 5.164632 hw_loss 0.221037 lr 0.00035880 rank 6
2023-02-22 19:11:38,910 DEBUG TRAIN Batch 23/2300 loss 10.311750 loss_att 12.306999 loss_ctc 13.472364 loss_rnnt 9.347126 hw_loss 0.270298 lr 0.00035889 rank 0
2023-02-22 19:11:38,911 DEBUG TRAIN Batch 23/2300 loss 7.258533 loss_att 13.121386 loss_ctc 10.720699 loss_rnnt 5.473103 hw_loss 0.283569 lr 0.00035882 rank 5
2023-02-22 19:11:38,960 DEBUG TRAIN Batch 23/2300 loss 12.025806 loss_att 15.251547 loss_ctc 15.593505 loss_rnnt 10.778051 hw_loss 0.237962 lr 0.00035879 rank 7
2023-02-22 19:12:51,107 DEBUG TRAIN Batch 23/2400 loss 5.920887 loss_att 8.713522 loss_ctc 6.647047 loss_rnnt 5.098090 hw_loss 0.313965 lr 0.00035874 rank 2
2023-02-22 19:12:51,111 DEBUG TRAIN Batch 23/2400 loss 9.040344 loss_att 9.145174 loss_ctc 9.685713 loss_rnnt 8.729093 hw_loss 0.382942 lr 0.00035880 rank 4
2023-02-22 19:12:51,113 DEBUG TRAIN Batch 23/2400 loss 12.578290 loss_att 13.825876 loss_ctc 22.094025 loss_rnnt 10.949494 hw_loss 0.207213 lr 0.00035878 rank 3
2023-02-22 19:12:51,113 DEBUG TRAIN Batch 23/2400 loss 8.993120 loss_att 11.091030 loss_ctc 12.449875 loss_rnnt 8.032429 hw_loss 0.150393 lr 0.00035873 rank 5
2023-02-22 19:12:51,115 DEBUG TRAIN Batch 23/2400 loss 5.339652 loss_att 10.175612 loss_ctc 6.989831 loss_rnnt 3.956860 hw_loss 0.366705 lr 0.00035871 rank 6
2023-02-22 19:12:51,116 DEBUG TRAIN Batch 23/2400 loss 8.322390 loss_att 12.014170 loss_ctc 13.576489 loss_rnnt 6.754333 hw_loss 0.242161 lr 0.00035880 rank 0
2023-02-22 19:12:51,117 DEBUG TRAIN Batch 23/2400 loss 5.536905 loss_att 7.823226 loss_ctc 8.561842 loss_rnnt 4.533626 hw_loss 0.267546 lr 0.00035876 rank 1
2023-02-22 19:12:51,119 DEBUG TRAIN Batch 23/2400 loss 10.405107 loss_att 15.581143 loss_ctc 17.241684 loss_rnnt 8.368922 hw_loss 0.167686 lr 0.00035870 rank 7
2023-02-22 19:14:05,948 DEBUG TRAIN Batch 23/2500 loss 5.494548 loss_att 7.386058 loss_ctc 9.152487 loss_rnnt 4.356121 hw_loss 0.510750 lr 0.00035865 rank 2
2023-02-22 19:14:05,959 DEBUG TRAIN Batch 23/2500 loss 9.729568 loss_att 10.533077 loss_ctc 13.061815 loss_rnnt 9.044955 hw_loss 0.149271 lr 0.00035869 rank 3
2023-02-22 19:14:05,960 DEBUG TRAIN Batch 23/2500 loss 9.017831 loss_att 10.029346 loss_ctc 11.696349 loss_rnnt 8.227695 hw_loss 0.432555 lr 0.00035870 rank 4
2023-02-22 19:14:05,959 DEBUG TRAIN Batch 23/2500 loss 9.401902 loss_att 10.313242 loss_ctc 14.530042 loss_rnnt 8.295581 hw_loss 0.450565 lr 0.00035864 rank 5
2023-02-22 19:14:05,960 DEBUG TRAIN Batch 23/2500 loss 6.507041 loss_att 8.661798 loss_ctc 9.592463 loss_rnnt 5.471254 hw_loss 0.362712 lr 0.00035861 rank 6
2023-02-22 19:14:05,963 DEBUG TRAIN Batch 23/2500 loss 6.266902 loss_att 6.400724 loss_ctc 8.129058 loss_rnnt 5.883729 hw_loss 0.202729 lr 0.00035867 rank 1
2023-02-22 19:14:05,989 DEBUG TRAIN Batch 23/2500 loss 5.886013 loss_att 7.926463 loss_ctc 8.554404 loss_rnnt 4.901032 hw_loss 0.414572 lr 0.00035861 rank 7
2023-02-22 19:14:05,997 DEBUG TRAIN Batch 23/2500 loss 6.857495 loss_att 8.283634 loss_ctc 8.166845 loss_rnnt 6.198399 hw_loss 0.373664 lr 0.00035871 rank 0
2023-02-22 19:15:17,942 DEBUG TRAIN Batch 23/2600 loss 9.576588 loss_att 14.354275 loss_ctc 15.140220 loss_rnnt 7.761333 hw_loss 0.221064 lr 0.00035852 rank 7
2023-02-22 19:15:17,960 DEBUG TRAIN Batch 23/2600 loss 6.260771 loss_att 7.748538 loss_ctc 8.948828 loss_rnnt 5.509807 hw_loss 0.178131 lr 0.00035855 rank 2
2023-02-22 19:15:17,963 DEBUG TRAIN Batch 23/2600 loss 11.850596 loss_att 17.326969 loss_ctc 18.906155 loss_rnnt 9.741955 hw_loss 0.136173 lr 0.00035860 rank 3
2023-02-22 19:15:17,965 DEBUG TRAIN Batch 23/2600 loss 12.146099 loss_att 15.198378 loss_ctc 24.309879 loss_rnnt 9.866290 hw_loss 0.089091 lr 0.00035852 rank 6
2023-02-22 19:15:17,967 DEBUG TRAIN Batch 23/2600 loss 7.188517 loss_att 10.271807 loss_ctc 7.542413 loss_rnnt 6.283125 hw_loss 0.452902 lr 0.00035862 rank 0
2023-02-22 19:15:17,968 DEBUG TRAIN Batch 23/2600 loss 12.735872 loss_att 11.965670 loss_ctc 16.242651 loss_rnnt 12.208138 hw_loss 0.401636 lr 0.00035857 rank 1
2023-02-22 19:15:17,969 DEBUG TRAIN Batch 23/2600 loss 8.725394 loss_att 12.657843 loss_ctc 14.538975 loss_rnnt 7.051826 hw_loss 0.209876 lr 0.00035855 rank 5
2023-02-22 19:15:17,969 DEBUG TRAIN Batch 23/2600 loss 16.983843 loss_att 18.462929 loss_ctc 26.736889 loss_rnnt 15.198531 hw_loss 0.354544 lr 0.00035861 rank 4
2023-02-22 19:16:29,400 DEBUG TRAIN Batch 23/2700 loss 7.656638 loss_att 12.285345 loss_ctc 11.647132 loss_rnnt 6.054876 hw_loss 0.269915 lr 0.00035852 rank 4
2023-02-22 19:16:29,403 DEBUG TRAIN Batch 23/2700 loss 9.176069 loss_att 12.264185 loss_ctc 12.834125 loss_rnnt 7.935146 hw_loss 0.254173 lr 0.00035852 rank 0
2023-02-22 19:16:29,403 DEBUG TRAIN Batch 23/2700 loss 9.219637 loss_att 13.317028 loss_ctc 16.918907 loss_rnnt 7.288401 hw_loss 0.159729 lr 0.00035846 rank 2
2023-02-22 19:16:29,404 DEBUG TRAIN Batch 23/2700 loss 7.831393 loss_att 11.207995 loss_ctc 13.212425 loss_rnnt 6.333461 hw_loss 0.197139 lr 0.00035846 rank 5
2023-02-22 19:16:29,405 DEBUG TRAIN Batch 23/2700 loss 12.070532 loss_att 16.302677 loss_ctc 23.699705 loss_rnnt 9.539803 hw_loss 0.250769 lr 0.00035851 rank 3
2023-02-22 19:16:29,406 DEBUG TRAIN Batch 23/2700 loss 8.401724 loss_att 12.849053 loss_ctc 12.744703 loss_rnnt 6.825397 hw_loss 0.202119 lr 0.00035848 rank 1
2023-02-22 19:16:29,407 DEBUG TRAIN Batch 23/2700 loss 5.536836 loss_att 7.658237 loss_ctc 9.290369 loss_rnnt 4.416510 hw_loss 0.366703 lr 0.00035843 rank 6
2023-02-22 19:16:29,408 DEBUG TRAIN Batch 23/2700 loss 7.224444 loss_att 12.765738 loss_ctc 11.608894 loss_rnnt 5.338329 hw_loss 0.362368 lr 0.00035842 rank 7
2023-02-22 19:17:43,377 DEBUG TRAIN Batch 23/2800 loss 15.846836 loss_att 17.617294 loss_ctc 19.778816 loss_rnnt 14.922885 hw_loss 0.085492 lr 0.00035843 rank 0
2023-02-22 19:17:43,386 DEBUG TRAIN Batch 23/2800 loss 4.232436 loss_att 7.689817 loss_ctc 10.843407 loss_rnnt 2.481759 hw_loss 0.333259 lr 0.00035833 rank 7
2023-02-22 19:17:43,387 DEBUG TRAIN Batch 23/2800 loss 14.354361 loss_att 15.619900 loss_ctc 19.093634 loss_rnnt 13.293643 hw_loss 0.329448 lr 0.00035837 rank 2
2023-02-22 19:17:43,388 DEBUG TRAIN Batch 23/2800 loss 6.564951 loss_att 10.975516 loss_ctc 11.977327 loss_rnnt 4.801950 hw_loss 0.298570 lr 0.00035842 rank 3
2023-02-22 19:17:43,388 DEBUG TRAIN Batch 23/2800 loss 10.160928 loss_att 12.740230 loss_ctc 14.346060 loss_rnnt 8.979920 hw_loss 0.200867 lr 0.00035834 rank 6
2023-02-22 19:17:43,389 DEBUG TRAIN Batch 23/2800 loss 6.366183 loss_att 8.679085 loss_ctc 8.462005 loss_rnnt 5.498010 hw_loss 0.236531 lr 0.00035843 rank 4
2023-02-22 19:17:43,389 DEBUG TRAIN Batch 23/2800 loss 6.407079 loss_att 6.395548 loss_ctc 10.313552 loss_rnnt 5.739365 hw_loss 0.279670 lr 0.00035836 rank 5
2023-02-22 19:17:43,391 DEBUG TRAIN Batch 23/2800 loss 4.173750 loss_att 7.715845 loss_ctc 4.846920 loss_rnnt 3.286309 hw_loss 0.167375 lr 0.00035839 rank 1
2023-02-22 19:18:57,236 DEBUG TRAIN Batch 23/2900 loss 8.039019 loss_att 8.108033 loss_ctc 8.082006 loss_rnnt 7.848768 hw_loss 0.320093 lr 0.00035832 rank 3
2023-02-22 19:18:57,237 DEBUG TRAIN Batch 23/2900 loss 8.331063 loss_att 12.198341 loss_ctc 11.827893 loss_rnnt 6.922782 hw_loss 0.316091 lr 0.00035828 rank 2
2023-02-22 19:18:57,246 DEBUG TRAIN Batch 23/2900 loss 10.674997 loss_att 12.589888 loss_ctc 13.007213 loss_rnnt 9.850363 hw_loss 0.245050 lr 0.00035834 rank 0
2023-02-22 19:18:57,247 DEBUG TRAIN Batch 23/2900 loss 16.210194 loss_att 19.395767 loss_ctc 24.690783 loss_rnnt 14.276058 hw_loss 0.311766 lr 0.00035824 rank 6
2023-02-22 19:18:57,248 DEBUG TRAIN Batch 23/2900 loss 7.168972 loss_att 11.434361 loss_ctc 12.135812 loss_rnnt 5.540070 hw_loss 0.212960 lr 0.00035830 rank 1
2023-02-22 19:18:57,250 DEBUG TRAIN Batch 23/2900 loss 8.117489 loss_att 11.640387 loss_ctc 13.946125 loss_rnnt 6.513704 hw_loss 0.228851 lr 0.00035834 rank 4
2023-02-22 19:18:57,249 DEBUG TRAIN Batch 23/2900 loss 10.505559 loss_att 13.309679 loss_ctc 15.732294 loss_rnnt 9.098310 hw_loss 0.280362 lr 0.00035827 rank 5
2023-02-22 19:18:57,251 DEBUG TRAIN Batch 23/2900 loss 4.830281 loss_att 7.489192 loss_ctc 6.399095 loss_rnnt 4.012480 hw_loss 0.144082 lr 0.00035824 rank 7
2023-02-22 19:20:09,498 DEBUG TRAIN Batch 23/3000 loss 4.148210 loss_att 5.242555 loss_ctc 7.438676 loss_rnnt 3.328135 hw_loss 0.304644 lr 0.00035819 rank 2
2023-02-22 19:20:09,500 DEBUG TRAIN Batch 23/3000 loss 8.445792 loss_att 8.702950 loss_ctc 7.641230 loss_rnnt 8.339613 hw_loss 0.303794 lr 0.00035825 rank 0
2023-02-22 19:20:09,501 DEBUG TRAIN Batch 23/3000 loss 6.446759 loss_att 10.087098 loss_ctc 8.930750 loss_rnnt 5.212581 hw_loss 0.327960 lr 0.00035821 rank 1
2023-02-22 19:20:09,504 DEBUG TRAIN Batch 23/3000 loss 4.311493 loss_att 7.897795 loss_ctc 9.003500 loss_rnnt 2.817315 hw_loss 0.283719 lr 0.00035815 rank 6
2023-02-22 19:20:09,505 DEBUG TRAIN Batch 23/3000 loss 10.134881 loss_att 14.031809 loss_ctc 12.424838 loss_rnnt 8.859963 hw_loss 0.356631 lr 0.00035823 rank 3
2023-02-22 19:20:09,504 DEBUG TRAIN Batch 23/3000 loss 8.873233 loss_att 11.747356 loss_ctc 12.738406 loss_rnnt 7.645691 hw_loss 0.257551 lr 0.00035818 rank 5
2023-02-22 19:20:09,505 DEBUG TRAIN Batch 23/3000 loss 6.340501 loss_att 8.268490 loss_ctc 7.904715 loss_rnnt 5.697421 hw_loss 0.091726 lr 0.00035815 rank 7
2023-02-22 19:20:09,550 DEBUG TRAIN Batch 23/3000 loss 13.540498 loss_att 14.429863 loss_ctc 17.295780 loss_rnnt 12.627646 hw_loss 0.439265 lr 0.00035824 rank 4
2023-02-22 19:21:21,504 DEBUG TRAIN Batch 23/3100 loss 10.578848 loss_att 13.878480 loss_ctc 16.332367 loss_rnnt 9.021861 hw_loss 0.243610 lr 0.00035815 rank 4
2023-02-22 19:21:21,515 DEBUG TRAIN Batch 23/3100 loss 9.687300 loss_att 9.638396 loss_ctc 13.702291 loss_rnnt 8.962166 hw_loss 0.374216 lr 0.00035809 rank 2
2023-02-22 19:21:21,515 DEBUG TRAIN Batch 23/3100 loss 10.058440 loss_att 13.219386 loss_ctc 9.878631 loss_rnnt 9.332259 hw_loss 0.221188 lr 0.00035814 rank 3
2023-02-22 19:21:21,515 DEBUG TRAIN Batch 23/3100 loss 7.589888 loss_att 10.564233 loss_ctc 10.390845 loss_rnnt 6.555093 hw_loss 0.124621 lr 0.00035806 rank 7
2023-02-22 19:21:21,516 DEBUG TRAIN Batch 23/3100 loss 9.801416 loss_att 11.694150 loss_ctc 13.945328 loss_rnnt 8.699737 hw_loss 0.319898 lr 0.00035806 rank 6
2023-02-22 19:21:21,519 DEBUG TRAIN Batch 23/3100 loss 9.747812 loss_att 10.707633 loss_ctc 17.047874 loss_rnnt 8.459464 hw_loss 0.230706 lr 0.00035811 rank 1
2023-02-22 19:21:21,533 DEBUG TRAIN Batch 23/3100 loss 4.245573 loss_att 6.646523 loss_ctc 6.205344 loss_rnnt 3.292749 hw_loss 0.396245 lr 0.00035815 rank 0
2023-02-22 19:21:21,571 DEBUG TRAIN Batch 23/3100 loss 15.622260 loss_att 16.946287 loss_ctc 17.541540 loss_rnnt 15.004276 hw_loss 0.182388 lr 0.00035809 rank 5
2023-02-22 19:22:37,287 DEBUG TRAIN Batch 23/3200 loss 14.554008 loss_att 22.500366 loss_ctc 22.873562 loss_rnnt 11.684962 hw_loss 0.319688 lr 0.00035800 rank 2
2023-02-22 19:22:37,290 DEBUG TRAIN Batch 23/3200 loss 11.963254 loss_att 12.249177 loss_ctc 16.778347 loss_rnnt 11.058993 hw_loss 0.384495 lr 0.00035805 rank 3
2023-02-22 19:22:37,292 DEBUG TRAIN Batch 23/3200 loss 12.710175 loss_att 14.172951 loss_ctc 14.605644 loss_rnnt 12.084273 hw_loss 0.151156 lr 0.00035797 rank 6
2023-02-22 19:22:37,295 DEBUG TRAIN Batch 23/3200 loss 5.294955 loss_att 6.681203 loss_ctc 10.057125 loss_rnnt 4.200552 hw_loss 0.341620 lr 0.00035796 rank 7
2023-02-22 19:22:37,295 DEBUG TRAIN Batch 23/3200 loss 7.459188 loss_att 10.159969 loss_ctc 8.667293 loss_rnnt 6.485359 hw_loss 0.511109 lr 0.00035802 rank 1
2023-02-22 19:22:37,298 DEBUG TRAIN Batch 23/3200 loss 8.172135 loss_att 9.839117 loss_ctc 11.022081 loss_rnnt 7.366347 hw_loss 0.173250 lr 0.00035800 rank 5
2023-02-22 19:22:37,302 DEBUG TRAIN Batch 23/3200 loss 1.960662 loss_att 6.539384 loss_ctc 3.469920 loss_rnnt 0.712974 hw_loss 0.245081 lr 0.00035806 rank 4
2023-02-22 19:22:37,340 DEBUG TRAIN Batch 23/3200 loss 4.873105 loss_att 7.789201 loss_ctc 8.358520 loss_rnnt 3.722835 hw_loss 0.191865 lr 0.00035806 rank 0
2023-02-22 19:23:49,668 DEBUG TRAIN Batch 23/3300 loss 8.143542 loss_att 10.385859 loss_ctc 11.792532 loss_rnnt 7.040763 hw_loss 0.314596 lr 0.00035791 rank 2
2023-02-22 19:23:49,670 DEBUG TRAIN Batch 23/3300 loss 5.401263 loss_att 9.071311 loss_ctc 8.923075 loss_rnnt 4.088042 hw_loss 0.205568 lr 0.00035788 rank 6
2023-02-22 19:23:49,670 DEBUG TRAIN Batch 23/3300 loss 4.922961 loss_att 7.894388 loss_ctc 8.726788 loss_rnnt 3.687836 hw_loss 0.250617 lr 0.00035793 rank 1
2023-02-22 19:23:49,672 DEBUG TRAIN Batch 23/3300 loss 10.744251 loss_att 17.757324 loss_ctc 18.646353 loss_rnnt 8.197508 hw_loss 0.169715 lr 0.00035797 rank 0
2023-02-22 19:23:49,672 DEBUG TRAIN Batch 23/3300 loss 1.367388 loss_att 3.346485 loss_ctc 2.200684 loss_rnnt 0.759425 hw_loss 0.189445 lr 0.00035796 rank 3
2023-02-22 19:23:49,673 DEBUG TRAIN Batch 23/3300 loss 10.420439 loss_att 14.081165 loss_ctc 12.874319 loss_rnnt 9.246231 hw_loss 0.215397 lr 0.00035787 rank 7
2023-02-22 19:23:49,677 DEBUG TRAIN Batch 23/3300 loss 4.115985 loss_att 6.391933 loss_ctc 4.622397 loss_rnnt 3.417853 hw_loss 0.328913 lr 0.00035790 rank 5
2023-02-22 19:23:49,683 DEBUG TRAIN Batch 23/3300 loss 8.820647 loss_att 10.735998 loss_ctc 11.565058 loss_rnnt 7.926401 hw_loss 0.272353 lr 0.00035797 rank 4
2023-02-22 19:25:02,403 DEBUG TRAIN Batch 23/3400 loss 4.611474 loss_att 7.846352 loss_ctc 5.959346 loss_rnnt 3.615306 hw_loss 0.317766 lr 0.00035781 rank 5
2023-02-22 19:25:02,408 DEBUG TRAIN Batch 23/3400 loss 4.245588 loss_att 7.241249 loss_ctc 10.472501 loss_rnnt 2.733466 hw_loss 0.155127 lr 0.00035786 rank 3
2023-02-22 19:25:02,416 DEBUG TRAIN Batch 23/3400 loss 6.652810 loss_att 11.446205 loss_ctc 14.731178 loss_rnnt 4.394604 hw_loss 0.417020 lr 0.00035778 rank 7
2023-02-22 19:25:02,417 DEBUG TRAIN Batch 23/3400 loss 14.064976 loss_att 14.172284 loss_ctc 18.363001 loss_rnnt 13.329616 hw_loss 0.264054 lr 0.00035784 rank 1
2023-02-22 19:25:02,417 DEBUG TRAIN Batch 23/3400 loss 6.204833 loss_att 10.038887 loss_ctc 10.616981 loss_rnnt 4.747303 hw_loss 0.192063 lr 0.00035782 rank 2
2023-02-22 19:25:02,419 DEBUG TRAIN Batch 23/3400 loss 12.822934 loss_att 18.528793 loss_ctc 17.181711 loss_rnnt 10.989914 hw_loss 0.207521 lr 0.00035779 rank 6
2023-02-22 19:25:02,420 DEBUG TRAIN Batch 23/3400 loss 4.618701 loss_att 7.048360 loss_ctc 6.916106 loss_rnnt 3.713766 hw_loss 0.211280 lr 0.00035788 rank 0
2023-02-22 19:25:02,461 DEBUG TRAIN Batch 23/3400 loss 10.190997 loss_att 13.530727 loss_ctc 13.194903 loss_rnnt 9.043864 hw_loss 0.147498 lr 0.00035788 rank 4
2023-02-22 19:26:16,738 DEBUG TRAIN Batch 23/3500 loss 8.531977 loss_att 12.850787 loss_ctc 13.380139 loss_rnnt 6.858942 hw_loss 0.305346 lr 0.00035772 rank 5
2023-02-22 19:26:16,742 DEBUG TRAIN Batch 23/3500 loss 6.639902 loss_att 8.583897 loss_ctc 8.242167 loss_rnnt 5.921898 hw_loss 0.216692 lr 0.00035769 rank 7
2023-02-22 19:26:16,742 DEBUG TRAIN Batch 23/3500 loss 14.062947 loss_att 16.099335 loss_ctc 19.492659 loss_rnnt 12.732542 hw_loss 0.373438 lr 0.00035773 rank 2
2023-02-22 19:26:16,743 DEBUG TRAIN Batch 23/3500 loss 6.368822 loss_att 9.787285 loss_ctc 10.663151 loss_rnnt 4.930012 hw_loss 0.342263 lr 0.00035775 rank 1
2023-02-22 19:26:16,744 DEBUG TRAIN Batch 23/3500 loss 2.251359 loss_att 6.010706 loss_ctc 2.566863 loss_rnnt 1.285460 hw_loss 0.322430 lr 0.00035777 rank 3
2023-02-22 19:26:16,746 DEBUG TRAIN Batch 23/3500 loss 7.965385 loss_att 12.267998 loss_ctc 13.046297 loss_rnnt 6.228677 hw_loss 0.372620 lr 0.00035779 rank 0
2023-02-22 19:26:16,746 DEBUG TRAIN Batch 23/3500 loss 2.022771 loss_att 5.618042 loss_ctc 3.543293 loss_rnnt 1.012787 hw_loss 0.165362 lr 0.00035769 rank 6
2023-02-22 19:26:16,749 DEBUG TRAIN Batch 23/3500 loss 7.941760 loss_att 8.673362 loss_ctc 10.413037 loss_rnnt 7.352385 hw_loss 0.212908 lr 0.00035778 rank 4
2023-02-22 19:27:30,685 DEBUG TRAIN Batch 23/3600 loss 15.358406 loss_att 20.558132 loss_ctc 20.409718 loss_rnnt 13.505318 hw_loss 0.261816 lr 0.00035768 rank 3
2023-02-22 19:27:30,685 DEBUG TRAIN Batch 23/3600 loss 7.327257 loss_att 10.756594 loss_ctc 11.511997 loss_rnnt 5.915822 hw_loss 0.314252 lr 0.00035760 rank 6
2023-02-22 19:27:30,687 DEBUG TRAIN Batch 23/3600 loss 6.705715 loss_att 8.997515 loss_ctc 8.061560 loss_rnnt 5.915762 hw_loss 0.282775 lr 0.00035764 rank 2
2023-02-22 19:27:30,691 DEBUG TRAIN Batch 23/3600 loss 4.078674 loss_att 7.619642 loss_ctc 7.638824 loss_rnnt 2.679302 hw_loss 0.405923 lr 0.00035770 rank 0
2023-02-22 19:27:30,694 DEBUG TRAIN Batch 23/3600 loss 15.893705 loss_att 19.437168 loss_ctc 23.886005 loss_rnnt 14.016354 hw_loss 0.193163 lr 0.00035769 rank 4
2023-02-22 19:27:30,695 DEBUG TRAIN Batch 23/3600 loss 10.395207 loss_att 13.885035 loss_ctc 13.569228 loss_rnnt 9.061896 hw_loss 0.397769 lr 0.00035766 rank 1
2023-02-22 19:27:30,696 DEBUG TRAIN Batch 23/3600 loss 12.406496 loss_att 15.065923 loss_ctc 16.968248 loss_rnnt 11.129166 hw_loss 0.257270 lr 0.00035763 rank 5
2023-02-22 19:27:30,738 DEBUG TRAIN Batch 23/3600 loss 5.815200 loss_att 7.229795 loss_ctc 8.159057 loss_rnnt 5.082579 hw_loss 0.257227 lr 0.00035760 rank 7
2023-02-22 19:28:43,155 DEBUG TRAIN Batch 23/3700 loss 16.173847 loss_att 18.976618 loss_ctc 22.121452 loss_rnnt 14.677881 hw_loss 0.266994 lr 0.00035754 rank 2
2023-02-22 19:28:43,158 DEBUG TRAIN Batch 23/3700 loss 8.368879 loss_att 13.449621 loss_ctc 16.423159 loss_rnnt 6.134162 hw_loss 0.271248 lr 0.00035760 rank 4
2023-02-22 19:28:43,160 DEBUG TRAIN Batch 23/3700 loss 9.616338 loss_att 13.548656 loss_ctc 13.750674 loss_rnnt 8.177515 hw_loss 0.189589 lr 0.00035754 rank 5
2023-02-22 19:28:43,161 DEBUG TRAIN Batch 23/3700 loss 5.885332 loss_att 7.344872 loss_ctc 8.102879 loss_rnnt 5.072610 hw_loss 0.422140 lr 0.00035751 rank 7
2023-02-22 19:28:43,161 DEBUG TRAIN Batch 23/3700 loss 14.223876 loss_att 13.199068 loss_ctc 19.946455 loss_rnnt 13.554733 hw_loss 0.208302 lr 0.00035751 rank 6
2023-02-22 19:28:43,164 DEBUG TRAIN Batch 23/3700 loss 7.633616 loss_att 10.097717 loss_ctc 9.764462 loss_rnnt 6.670767 hw_loss 0.348593 lr 0.00035760 rank 0
2023-02-22 19:28:43,167 DEBUG TRAIN Batch 23/3700 loss 16.052174 loss_att 16.512257 loss_ctc 19.650421 loss_rnnt 15.429547 hw_loss 0.095331 lr 0.00035759 rank 3
2023-02-22 19:28:43,212 DEBUG TRAIN Batch 23/3700 loss 8.940590 loss_att 13.071426 loss_ctc 13.287825 loss_rnnt 7.385692 hw_loss 0.279563 lr 0.00035756 rank 1
2023-02-22 19:29:56,750 DEBUG TRAIN Batch 23/3800 loss 9.596308 loss_att 9.837448 loss_ctc 12.907457 loss_rnnt 8.609268 hw_loss 0.932485 lr 0.00035745 rank 2
2023-02-22 19:29:56,751 DEBUG TRAIN Batch 23/3800 loss 8.645880 loss_att 13.486614 loss_ctc 13.282421 loss_rnnt 6.979263 hw_loss 0.150495 lr 0.00035742 rank 6
2023-02-22 19:29:56,754 DEBUG TRAIN Batch 23/3800 loss 10.950897 loss_att 11.441036 loss_ctc 14.081782 loss_rnnt 10.245532 hw_loss 0.356034 lr 0.00035751 rank 4
2023-02-22 19:29:56,756 DEBUG TRAIN Batch 23/3800 loss 7.465739 loss_att 9.327915 loss_ctc 9.241490 loss_rnnt 6.691159 hw_loss 0.310083 lr 0.00035742 rank 7
2023-02-22 19:29:56,758 DEBUG TRAIN Batch 23/3800 loss 15.255939 loss_att 17.992323 loss_ctc 20.711233 loss_rnnt 13.868606 hw_loss 0.211281 lr 0.00035750 rank 3
2023-02-22 19:29:56,759 DEBUG TRAIN Batch 23/3800 loss 6.113419 loss_att 6.467535 loss_ctc 9.259067 loss_rnnt 5.313925 hw_loss 0.579844 lr 0.00035745 rank 5
2023-02-22 19:29:56,759 DEBUG TRAIN Batch 23/3800 loss 4.100275 loss_att 6.982574 loss_ctc 4.392045 loss_rnnt 3.320014 hw_loss 0.309185 lr 0.00035747 rank 1
2023-02-22 19:29:56,761 DEBUG TRAIN Batch 23/3800 loss 3.630557 loss_att 6.476328 loss_ctc 6.762004 loss_rnnt 2.490340 hw_loss 0.287881 lr 0.00035751 rank 0
2023-02-22 19:31:11,574 DEBUG TRAIN Batch 23/3900 loss 4.945651 loss_att 6.566518 loss_ctc 6.815794 loss_rnnt 4.234136 hw_loss 0.258730 lr 0.00035736 rank 2
2023-02-22 19:31:11,583 DEBUG TRAIN Batch 23/3900 loss 8.994739 loss_att 9.641108 loss_ctc 10.402492 loss_rnnt 8.581507 hw_loss 0.180483 lr 0.00035733 rank 6
2023-02-22 19:31:11,585 DEBUG TRAIN Batch 23/3900 loss 7.087759 loss_att 8.818192 loss_ctc 12.067424 loss_rnnt 5.911903 hw_loss 0.310903 lr 0.00035741 rank 3
2023-02-22 19:31:11,585 DEBUG TRAIN Batch 23/3900 loss 3.340552 loss_att 5.095720 loss_ctc 3.433384 loss_rnnt 2.819464 hw_loss 0.295644 lr 0.00035742 rank 4
2023-02-22 19:31:11,586 DEBUG TRAIN Batch 23/3900 loss 2.995046 loss_att 4.836094 loss_ctc 5.236682 loss_rnnt 2.261908 hw_loss 0.123832 lr 0.00035742 rank 0
2023-02-22 19:31:11,589 DEBUG TRAIN Batch 23/3900 loss 7.634817 loss_att 11.107660 loss_ctc 8.911880 loss_rnnt 6.603696 hw_loss 0.311768 lr 0.00035736 rank 5
2023-02-22 19:31:11,599 DEBUG TRAIN Batch 23/3900 loss 8.983068 loss_att 8.251027 loss_ctc 11.416954 loss_rnnt 8.625587 hw_loss 0.336323 lr 0.00035738 rank 1
2023-02-22 19:31:11,615 DEBUG TRAIN Batch 23/3900 loss 16.367178 loss_att 20.122993 loss_ctc 28.739025 loss_rnnt 13.867485 hw_loss 0.185532 lr 0.00035732 rank 7
2023-02-22 19:32:23,501 DEBUG TRAIN Batch 23/4000 loss 11.409595 loss_att 12.658424 loss_ctc 14.367393 loss_rnnt 10.632950 hw_loss 0.248449 lr 0.00035724 rank 6
2023-02-22 19:32:23,510 DEBUG TRAIN Batch 23/4000 loss 5.114211 loss_att 7.203521 loss_ctc 4.903378 loss_rnnt 4.545106 hw_loss 0.336289 lr 0.00035732 rank 3
2023-02-22 19:32:23,511 DEBUG TRAIN Batch 23/4000 loss 17.237852 loss_att 18.815880 loss_ctc 27.096668 loss_rnnt 15.430609 hw_loss 0.332119 lr 0.00035726 rank 5
2023-02-22 19:32:23,511 DEBUG TRAIN Batch 23/4000 loss 1.399090 loss_att 3.769856 loss_ctc 1.993472 loss_rnnt 0.641614 hw_loss 0.382635 lr 0.00035733 rank 4
2023-02-22 19:32:23,511 DEBUG TRAIN Batch 23/4000 loss 15.074908 loss_att 17.441505 loss_ctc 20.210514 loss_rnnt 13.767727 hw_loss 0.279589 lr 0.00035733 rank 0
2023-02-22 19:32:23,512 DEBUG TRAIN Batch 23/4000 loss 7.968205 loss_att 8.757732 loss_ctc 9.628257 loss_rnnt 7.459517 hw_loss 0.242706 lr 0.00035729 rank 1
2023-02-22 19:32:23,513 DEBUG TRAIN Batch 23/4000 loss 5.359685 loss_att 6.483597 loss_ctc 7.671010 loss_rnnt 4.748717 hw_loss 0.146268 lr 0.00035727 rank 2
2023-02-22 19:32:23,516 DEBUG TRAIN Batch 23/4000 loss 17.041874 loss_att 21.318048 loss_ctc 24.011585 loss_rnnt 15.112082 hw_loss 0.272369 lr 0.00035723 rank 7
2023-02-22 19:33:35,781 DEBUG TRAIN Batch 23/4100 loss 6.636644 loss_att 8.394604 loss_ctc 7.881228 loss_rnnt 6.011388 hw_loss 0.201975 lr 0.00035722 rank 3
2023-02-22 19:33:35,788 DEBUG TRAIN Batch 23/4100 loss 14.021172 loss_att 16.662430 loss_ctc 17.846771 loss_rnnt 12.861590 hw_loss 0.227343 lr 0.00035718 rank 2
2023-02-22 19:33:35,790 DEBUG TRAIN Batch 23/4100 loss 5.405418 loss_att 9.802942 loss_ctc 6.491932 loss_rnnt 4.215859 hw_loss 0.309723 lr 0.00035724 rank 4
2023-02-22 19:33:35,793 DEBUG TRAIN Batch 23/4100 loss 6.736415 loss_att 10.708508 loss_ctc 11.910471 loss_rnnt 5.119297 hw_loss 0.249046 lr 0.00035715 rank 6
2023-02-22 19:33:35,796 DEBUG TRAIN Batch 23/4100 loss 10.943558 loss_att 16.851542 loss_ctc 20.019222 loss_rnnt 8.385178 hw_loss 0.312552 lr 0.00035714 rank 7
2023-02-22 19:33:35,797 DEBUG TRAIN Batch 23/4100 loss 8.530054 loss_att 11.019350 loss_ctc 9.553028 loss_rnnt 7.781710 hw_loss 0.213917 lr 0.00035720 rank 1
2023-02-22 19:33:35,801 DEBUG TRAIN Batch 23/4100 loss 10.994266 loss_att 14.076178 loss_ctc 17.257219 loss_rnnt 9.448121 hw_loss 0.177562 lr 0.00035717 rank 5
2023-02-22 19:33:35,800 DEBUG TRAIN Batch 23/4100 loss 6.272400 loss_att 10.412074 loss_ctc 10.714708 loss_rnnt 4.688177 hw_loss 0.307464 lr 0.00035724 rank 0
2023-02-22 19:34:49,093 DEBUG TRAIN Batch 23/4200 loss 12.739862 loss_att 19.398228 loss_ctc 21.290852 loss_rnnt 10.116757 hw_loss 0.283686 lr 0.00035711 rank 1
2023-02-22 19:34:49,098 DEBUG TRAIN Batch 23/4200 loss 8.407791 loss_att 11.341436 loss_ctc 14.177739 loss_rnnt 6.909864 hw_loss 0.266009 lr 0.00035708 rank 5
2023-02-22 19:34:49,105 DEBUG TRAIN Batch 23/4200 loss 5.435392 loss_att 8.286020 loss_ctc 8.203336 loss_rnnt 4.350787 hw_loss 0.272661 lr 0.00035709 rank 2
2023-02-22 19:34:49,109 DEBUG TRAIN Batch 23/4200 loss 6.864616 loss_att 10.396104 loss_ctc 7.565400 loss_rnnt 5.924519 hw_loss 0.263180 lr 0.00035706 rank 6
2023-02-22 19:34:49,109 DEBUG TRAIN Batch 23/4200 loss 12.717445 loss_att 15.740532 loss_ctc 15.936773 loss_rnnt 11.571945 hw_loss 0.209322 lr 0.00035714 rank 4
2023-02-22 19:34:49,109 DEBUG TRAIN Batch 23/4200 loss 9.317163 loss_att 11.425422 loss_ctc 11.223938 loss_rnnt 8.523212 hw_loss 0.221364 lr 0.00035713 rank 3
2023-02-22 19:34:49,113 DEBUG TRAIN Batch 23/4200 loss 11.142031 loss_att 13.651018 loss_ctc 12.992537 loss_rnnt 10.269878 hw_loss 0.231791 lr 0.00035705 rank 7
2023-02-22 19:34:49,142 DEBUG TRAIN Batch 23/4200 loss 5.468442 loss_att 8.429036 loss_ctc 7.350468 loss_rnnt 4.452424 hw_loss 0.324305 lr 0.00035715 rank 0
2023-02-22 19:36:03,259 DEBUG TRAIN Batch 23/4300 loss 1.735304 loss_att 4.014653 loss_ctc 4.366978 loss_rnnt 0.811218 hw_loss 0.219987 lr 0.00035700 rank 2
2023-02-22 19:36:03,262 DEBUG TRAIN Batch 23/4300 loss 11.136724 loss_att 13.774370 loss_ctc 18.304358 loss_rnnt 9.462130 hw_loss 0.358842 lr 0.00035706 rank 0
2023-02-22 19:36:03,261 DEBUG TRAIN Batch 23/4300 loss 9.080972 loss_att 11.879985 loss_ctc 14.930607 loss_rnnt 7.524793 hw_loss 0.405795 lr 0.00035696 rank 7
2023-02-22 19:36:03,263 DEBUG TRAIN Batch 23/4300 loss 20.721554 loss_att 22.527718 loss_ctc 30.386179 loss_rnnt 18.916775 hw_loss 0.290496 lr 0.00035696 rank 6
2023-02-22 19:36:03,265 DEBUG TRAIN Batch 23/4300 loss 9.172795 loss_att 12.037004 loss_ctc 11.191301 loss_rnnt 8.203455 hw_loss 0.238807 lr 0.00035705 rank 4
2023-02-22 19:36:03,265 DEBUG TRAIN Batch 23/4300 loss 11.096437 loss_att 15.356634 loss_ctc 16.004438 loss_rnnt 9.460068 hw_loss 0.243618 lr 0.00035702 rank 1
2023-02-22 19:36:03,266 DEBUG TRAIN Batch 23/4300 loss 12.721663 loss_att 14.981861 loss_ctc 16.902397 loss_rnnt 11.602962 hw_loss 0.204807 lr 0.00035704 rank 3
2023-02-22 19:36:03,268 DEBUG TRAIN Batch 23/4300 loss 5.664185 loss_att 9.509846 loss_ctc 9.651628 loss_rnnt 4.190874 hw_loss 0.323474 lr 0.00035699 rank 5
2023-02-22 19:37:16,003 DEBUG TRAIN Batch 23/4400 loss 7.864822 loss_att 8.090159 loss_ctc 10.840699 loss_rnnt 7.208160 hw_loss 0.402769 lr 0.00035690 rank 5
2023-02-22 19:37:16,003 DEBUG TRAIN Batch 23/4400 loss 15.381379 loss_att 15.714788 loss_ctc 20.656561 loss_rnnt 14.465850 hw_loss 0.272796 lr 0.00035696 rank 4
2023-02-22 19:37:16,008 DEBUG TRAIN Batch 23/4400 loss 4.802691 loss_att 7.671416 loss_ctc 6.984218 loss_rnnt 3.763402 hw_loss 0.327511 lr 0.00035687 rank 7
2023-02-22 19:37:16,020 DEBUG TRAIN Batch 23/4400 loss 15.342163 loss_att 16.680370 loss_ctc 23.828377 loss_rnnt 13.713285 hw_loss 0.430764 lr 0.00035695 rank 3
2023-02-22 19:37:16,020 DEBUG TRAIN Batch 23/4400 loss 7.070913 loss_att 8.389418 loss_ctc 10.549118 loss_rnnt 6.237807 hw_loss 0.198083 lr 0.00035691 rank 2
2023-02-22 19:37:16,027 DEBUG TRAIN Batch 23/4400 loss 7.708695 loss_att 8.507985 loss_ctc 11.588675 loss_rnnt 6.771125 hw_loss 0.488216 lr 0.00035687 rank 6
2023-02-22 19:37:16,034 DEBUG TRAIN Batch 23/4400 loss 9.725768 loss_att 10.962365 loss_ctc 10.532534 loss_rnnt 9.250896 hw_loss 0.224971 lr 0.00035693 rank 1
2023-02-22 19:37:16,035 DEBUG TRAIN Batch 23/4400 loss 8.444832 loss_att 8.828137 loss_ctc 12.289334 loss_rnnt 7.608556 hw_loss 0.463151 lr 0.00035697 rank 0
2023-02-22 19:38:28,715 DEBUG TRAIN Batch 23/4500 loss 5.868118 loss_att 8.043372 loss_ctc 11.311747 loss_rnnt 4.483221 hw_loss 0.420057 lr 0.00035684 rank 1
2023-02-22 19:38:28,726 DEBUG TRAIN Batch 23/4500 loss 16.226795 loss_att 21.000519 loss_ctc 30.581549 loss_rnnt 13.276141 hw_loss 0.153641 lr 0.00035682 rank 2
2023-02-22 19:38:28,725 DEBUG TRAIN Batch 23/4500 loss 2.814025 loss_att 5.849831 loss_ctc 4.501541 loss_rnnt 1.872882 hw_loss 0.204336 lr 0.00035688 rank 0
2023-02-22 19:38:28,728 DEBUG TRAIN Batch 23/4500 loss 5.671509 loss_att 8.902660 loss_ctc 8.719301 loss_rnnt 4.501066 hw_loss 0.220951 lr 0.00035686 rank 3
2023-02-22 19:38:28,730 DEBUG TRAIN Batch 23/4500 loss 9.093217 loss_att 11.239235 loss_ctc 12.491508 loss_rnnt 8.059916 hw_loss 0.283111 lr 0.00035678 rank 6
2023-02-22 19:38:28,732 DEBUG TRAIN Batch 23/4500 loss 12.432071 loss_att 15.981774 loss_ctc 19.559856 loss_rnnt 10.616894 hw_loss 0.290369 lr 0.00035678 rank 7
2023-02-22 19:38:28,736 DEBUG TRAIN Batch 23/4500 loss 7.030569 loss_att 10.311611 loss_ctc 10.862000 loss_rnnt 5.723463 hw_loss 0.262576 lr 0.00035681 rank 5
2023-02-22 19:38:28,787 DEBUG TRAIN Batch 23/4500 loss 4.753073 loss_att 7.070459 loss_ctc 7.837821 loss_rnnt 3.777610 hw_loss 0.188786 lr 0.00035687 rank 4
2023-02-22 19:39:43,196 DEBUG TRAIN Batch 23/4600 loss 9.656057 loss_att 13.273416 loss_ctc 17.353559 loss_rnnt 7.798999 hw_loss 0.201102 lr 0.00035672 rank 2
2023-02-22 19:39:43,203 DEBUG TRAIN Batch 23/4600 loss 3.738007 loss_att 8.407412 loss_ctc 7.583858 loss_rnnt 2.099648 hw_loss 0.359434 lr 0.00035677 rank 3
2023-02-22 19:39:43,203 DEBUG TRAIN Batch 23/4600 loss 10.186277 loss_att 14.236463 loss_ctc 15.241159 loss_rnnt 8.529532 hw_loss 0.323858 lr 0.00035678 rank 4
2023-02-22 19:39:43,218 DEBUG TRAIN Batch 23/4600 loss 10.792954 loss_att 15.658594 loss_ctc 13.909231 loss_rnnt 9.302920 hw_loss 0.190128 lr 0.00035669 rank 6
2023-02-22 19:39:43,223 DEBUG TRAIN Batch 23/4600 loss 15.610390 loss_att 19.989092 loss_ctc 21.199535 loss_rnnt 13.803966 hw_loss 0.347748 lr 0.00035672 rank 5
2023-02-22 19:39:43,224 DEBUG TRAIN Batch 23/4600 loss 2.876344 loss_att 5.966259 loss_ctc 4.240331 loss_rnnt 1.983945 hw_loss 0.173533 lr 0.00035669 rank 7
2023-02-22 19:39:43,229 DEBUG TRAIN Batch 23/4600 loss 9.331075 loss_att 9.674258 loss_ctc 11.659965 loss_rnnt 8.703490 hw_loss 0.465805 lr 0.00035674 rank 1
2023-02-22 19:39:43,248 DEBUG TRAIN Batch 23/4600 loss 5.707259 loss_att 8.968557 loss_ctc 11.800799 loss_rnnt 4.157610 hw_loss 0.159220 lr 0.00035678 rank 0
2023-02-22 19:40:56,288 DEBUG TRAIN Batch 23/4700 loss 9.242085 loss_att 10.653403 loss_ctc 12.277224 loss_rnnt 8.451277 hw_loss 0.194737 lr 0.00035669 rank 4
2023-02-22 19:40:56,293 DEBUG TRAIN Batch 23/4700 loss 7.903443 loss_att 11.143282 loss_ctc 10.186472 loss_rnnt 6.890268 hw_loss 0.114007 lr 0.00035665 rank 1
2023-02-22 19:40:56,296 DEBUG TRAIN Batch 23/4700 loss 11.474725 loss_att 13.739797 loss_ctc 14.291228 loss_rnnt 10.557011 hw_loss 0.167186 lr 0.00035663 rank 5
2023-02-22 19:40:56,298 DEBUG TRAIN Batch 23/4700 loss 4.003673 loss_att 6.007438 loss_ctc 6.607747 loss_rnnt 3.069158 hw_loss 0.349785 lr 0.00035663 rank 2
2023-02-22 19:40:56,300 DEBUG TRAIN Batch 23/4700 loss 6.044473 loss_att 9.206035 loss_ctc 7.376666 loss_rnnt 5.102043 hw_loss 0.248423 lr 0.00035669 rank 0
2023-02-22 19:40:56,302 DEBUG TRAIN Batch 23/4700 loss 8.906885 loss_att 13.686086 loss_ctc 13.861074 loss_rnnt 7.122631 hw_loss 0.314730 lr 0.00035660 rank 6
2023-02-22 19:40:56,304 DEBUG TRAIN Batch 23/4700 loss 8.790393 loss_att 12.954592 loss_ctc 14.421963 loss_rnnt 7.055429 hw_loss 0.283589 lr 0.00035668 rank 3
2023-02-22 19:40:56,346 DEBUG TRAIN Batch 23/4700 loss 5.322670 loss_att 8.263283 loss_ctc 7.770252 loss_rnnt 4.340003 hw_loss 0.127875 lr 0.00035660 rank 7
2023-02-22 19:42:08,539 DEBUG TRAIN Batch 23/4800 loss 9.824995 loss_att 13.017159 loss_ctc 13.839095 loss_rnnt 8.524479 hw_loss 0.237881 lr 0.00035659 rank 3
2023-02-22 19:42:08,540 DEBUG TRAIN Batch 23/4800 loss 9.803815 loss_att 12.155033 loss_ctc 17.121498 loss_rnnt 8.214067 hw_loss 0.269649 lr 0.00035654 rank 2
2023-02-22 19:42:08,542 DEBUG TRAIN Batch 23/4800 loss 9.634791 loss_att 12.698169 loss_ctc 13.380095 loss_rnnt 8.442495 hw_loss 0.150463 lr 0.00035660 rank 0
2023-02-22 19:42:08,541 DEBUG TRAIN Batch 23/4800 loss 4.545454 loss_att 7.395263 loss_ctc 10.565192 loss_rnnt 3.038599 hw_loss 0.251741 lr 0.00035656 rank 1
2023-02-22 19:42:08,541 DEBUG TRAIN Batch 23/4800 loss 8.391455 loss_att 12.333889 loss_ctc 13.054932 loss_rnnt 6.839070 hw_loss 0.266437 lr 0.00035651 rank 7
2023-02-22 19:42:08,543 DEBUG TRAIN Batch 23/4800 loss 12.154124 loss_att 13.791079 loss_ctc 20.872940 loss_rnnt 10.543249 hw_loss 0.226828 lr 0.00035651 rank 6
2023-02-22 19:42:08,546 DEBUG TRAIN Batch 23/4800 loss 7.260207 loss_att 10.560692 loss_ctc 10.232396 loss_rnnt 6.083077 hw_loss 0.226390 lr 0.00035660 rank 4
2023-02-22 19:42:08,549 DEBUG TRAIN Batch 23/4800 loss 7.558512 loss_att 10.126778 loss_ctc 8.159750 loss_rnnt 6.833913 hw_loss 0.245214 lr 0.00035654 rank 5
2023-02-22 19:43:21,269 DEBUG TRAIN Batch 23/4900 loss 14.999970 loss_att 15.799283 loss_ctc 21.448360 loss_rnnt 13.834215 hw_loss 0.273950 lr 0.00035645 rank 5
2023-02-22 19:43:21,273 DEBUG TRAIN Batch 23/4900 loss 13.321749 loss_att 14.751514 loss_ctc 18.067062 loss_rnnt 12.296523 hw_loss 0.199807 lr 0.00035642 rank 7
2023-02-22 19:43:21,274 DEBUG TRAIN Batch 23/4900 loss 13.542127 loss_att 16.708498 loss_ctc 19.804989 loss_rnnt 11.903972 hw_loss 0.318435 lr 0.00035650 rank 3
2023-02-22 19:43:21,278 DEBUG TRAIN Batch 23/4900 loss 5.169661 loss_att 7.763697 loss_ctc 8.790821 loss_rnnt 4.055359 hw_loss 0.211260 lr 0.00035647 rank 1
2023-02-22 19:43:21,279 DEBUG TRAIN Batch 23/4900 loss 14.279801 loss_att 15.461359 loss_ctc 16.293348 loss_rnnt 13.583231 hw_loss 0.359599 lr 0.00035645 rank 2
2023-02-22 19:43:21,280 DEBUG TRAIN Batch 23/4900 loss 9.643621 loss_att 10.632083 loss_ctc 14.133765 loss_rnnt 8.715415 hw_loss 0.247178 lr 0.00035651 rank 0
2023-02-22 19:43:21,282 DEBUG TRAIN Batch 23/4900 loss 20.944265 loss_att 24.630217 loss_ctc 26.860023 loss_rnnt 19.280407 hw_loss 0.258563 lr 0.00035642 rank 6
2023-02-22 19:43:21,318 DEBUG TRAIN Batch 23/4900 loss 5.774243 loss_att 8.637780 loss_ctc 6.337470 loss_rnnt 5.006784 hw_loss 0.224352 lr 0.00035651 rank 4
2023-02-22 19:44:37,158 DEBUG TRAIN Batch 23/5000 loss 6.168305 loss_att 9.876737 loss_ctc 7.774478 loss_rnnt 4.957672 hw_loss 0.477733 lr 0.00035636 rank 2
2023-02-22 19:44:37,159 DEBUG TRAIN Batch 23/5000 loss 15.044765 loss_att 16.911186 loss_ctc 19.186584 loss_rnnt 13.995606 hw_loss 0.231807 lr 0.00035638 rank 1
2023-02-22 19:44:37,161 DEBUG TRAIN Batch 23/5000 loss 6.972085 loss_att 8.044716 loss_ctc 10.150587 loss_rnnt 6.232521 hw_loss 0.189822 lr 0.00035641 rank 3
2023-02-22 19:44:37,161 DEBUG TRAIN Batch 23/5000 loss 12.627848 loss_att 12.455400 loss_ctc 14.751474 loss_rnnt 12.193452 hw_loss 0.348253 lr 0.00035642 rank 0
2023-02-22 19:44:37,163 DEBUG TRAIN Batch 23/5000 loss 5.668138 loss_att 8.505120 loss_ctc 8.778737 loss_rnnt 4.516134 hw_loss 0.318489 lr 0.00035632 rank 7
2023-02-22 19:44:37,165 DEBUG TRAIN Batch 23/5000 loss 9.982209 loss_att 9.838424 loss_ctc 15.303601 loss_rnnt 9.186662 hw_loss 0.215224 lr 0.00035636 rank 5
2023-02-22 19:44:37,166 DEBUG TRAIN Batch 23/5000 loss 11.063837 loss_att 13.573681 loss_ctc 16.799749 loss_rnnt 9.676540 hw_loss 0.226010 lr 0.00035642 rank 4
2023-02-22 19:44:37,168 DEBUG TRAIN Batch 23/5000 loss 9.948442 loss_att 12.128643 loss_ctc 13.753466 loss_rnnt 8.868060 hw_loss 0.256883 lr 0.00035633 rank 6
2023-02-22 19:45:49,477 DEBUG TRAIN Batch 23/5100 loss 19.849276 loss_att 24.051746 loss_ctc 33.742855 loss_rnnt 17.079571 hw_loss 0.143875 lr 0.00035623 rank 7
2023-02-22 19:45:49,478 DEBUG TRAIN Batch 23/5100 loss 7.323839 loss_att 7.782484 loss_ctc 10.430807 loss_rnnt 6.600384 hw_loss 0.407743 lr 0.00035633 rank 4
2023-02-22 19:45:49,479 DEBUG TRAIN Batch 23/5100 loss 2.755868 loss_att 5.024839 loss_ctc 3.512235 loss_rnnt 2.104048 hw_loss 0.182208 lr 0.00035624 rank 6
2023-02-22 19:45:49,480 DEBUG TRAIN Batch 23/5100 loss 6.101118 loss_att 8.993564 loss_ctc 12.577600 loss_rnnt 4.496281 hw_loss 0.305281 lr 0.00035632 rank 3
2023-02-22 19:45:49,480 DEBUG TRAIN Batch 23/5100 loss 6.986310 loss_att 11.925406 loss_ctc 12.284620 loss_rnnt 5.159879 hw_loss 0.247817 lr 0.00035627 rank 2
2023-02-22 19:45:49,483 DEBUG TRAIN Batch 23/5100 loss 9.254136 loss_att 9.802530 loss_ctc 10.090260 loss_rnnt 8.922544 hw_loss 0.207055 lr 0.00035633 rank 0
2023-02-22 19:45:49,483 DEBUG TRAIN Batch 23/5100 loss 4.101093 loss_att 9.834840 loss_ctc 8.913046 loss_rnnt 2.187205 hw_loss 0.235396 lr 0.00035627 rank 5
2023-02-22 19:45:49,487 DEBUG TRAIN Batch 23/5100 loss 5.831982 loss_att 6.465173 loss_ctc 7.833333 loss_rnnt 5.236450 hw_loss 0.378838 lr 0.00035629 rank 1
2023-02-22 19:47:01,292 DEBUG TRAIN Batch 23/5200 loss 5.714874 loss_att 10.231415 loss_ctc 7.582514 loss_rnnt 4.455451 hw_loss 0.200806 lr 0.00035617 rank 5
2023-02-22 19:47:01,295 DEBUG TRAIN Batch 23/5200 loss 5.004956 loss_att 6.209222 loss_ctc 6.418615 loss_rnnt 4.336099 hw_loss 0.449094 lr 0.00035620 rank 1
2023-02-22 19:47:01,302 DEBUG TRAIN Batch 23/5200 loss 10.853192 loss_att 13.472238 loss_ctc 19.207441 loss_rnnt 9.018500 hw_loss 0.369344 lr 0.00035614 rank 7
2023-02-22 19:47:01,307 DEBUG TRAIN Batch 23/5200 loss 11.629808 loss_att 12.767665 loss_ctc 13.954750 loss_rnnt 10.939032 hw_loss 0.287276 lr 0.00035615 rank 6
2023-02-22 19:47:01,310 DEBUG TRAIN Batch 23/5200 loss 6.992898 loss_att 11.917461 loss_ctc 8.503786 loss_rnnt 5.650725 hw_loss 0.292140 lr 0.00035623 rank 3
2023-02-22 19:47:01,310 DEBUG TRAIN Batch 23/5200 loss 1.326781 loss_att 3.203308 loss_ctc 2.256504 loss_rnnt 0.578369 hw_loss 0.467143 lr 0.00035624 rank 0
2023-02-22 19:47:01,312 DEBUG TRAIN Batch 23/5200 loss 5.422011 loss_att 8.438896 loss_ctc 4.695607 loss_rnnt 4.839673 hw_loss 0.142154 lr 0.00035618 rank 2
2023-02-22 19:47:01,314 DEBUG TRAIN Batch 23/5200 loss 2.335910 loss_att 5.003832 loss_ctc 4.659555 loss_rnnt 1.294235 hw_loss 0.371757 lr 0.00035624 rank 4
2023-02-22 19:48:15,341 DEBUG TRAIN Batch 23/5300 loss 3.265147 loss_att 5.695417 loss_ctc 3.732872 loss_rnnt 2.643528 hw_loss 0.137254 lr 0.00035615 rank 4
2023-02-22 19:48:15,342 DEBUG TRAIN Batch 23/5300 loss 9.008081 loss_att 12.083479 loss_ctc 11.238163 loss_rnnt 7.957313 hw_loss 0.259395 lr 0.00035609 rank 2
2023-02-22 19:48:15,343 DEBUG TRAIN Batch 23/5300 loss 5.261390 loss_att 7.882826 loss_ctc 8.037773 loss_rnnt 4.283457 hw_loss 0.156489 lr 0.00035614 rank 3
2023-02-22 19:48:15,346 DEBUG TRAIN Batch 23/5300 loss 4.174905 loss_att 6.271159 loss_ctc 6.114992 loss_rnnt 3.373435 hw_loss 0.231641 lr 0.00035606 rank 6
2023-02-22 19:48:15,349 DEBUG TRAIN Batch 23/5300 loss 8.223430 loss_att 12.842068 loss_ctc 13.060844 loss_rnnt 6.535758 hw_loss 0.223040 lr 0.00035615 rank 0
2023-02-22 19:48:15,354 DEBUG TRAIN Batch 23/5300 loss 8.156533 loss_att 9.349567 loss_ctc 10.279639 loss_rnnt 7.479232 hw_loss 0.291774 lr 0.00035605 rank 7
2023-02-22 19:48:15,357 DEBUG TRAIN Batch 23/5300 loss 9.286018 loss_att 13.895559 loss_ctc 14.360599 loss_rnnt 7.586816 hw_loss 0.188781 lr 0.00035608 rank 5
2023-02-22 19:48:15,398 DEBUG TRAIN Batch 23/5300 loss 11.451610 loss_att 14.754555 loss_ctc 19.491171 loss_rnnt 9.625087 hw_loss 0.176236 lr 0.00035611 rank 1
2023-02-22 19:49:29,052 DEBUG TRAIN Batch 23/5400 loss 3.369585 loss_att 7.246449 loss_ctc 5.313661 loss_rnnt 2.119786 hw_loss 0.403530 lr 0.00035596 rank 7
2023-02-22 19:49:29,055 DEBUG TRAIN Batch 23/5400 loss 8.931303 loss_att 12.503206 loss_ctc 10.714155 loss_rnnt 7.797397 hw_loss 0.340898 lr 0.00035597 rank 6
2023-02-22 19:49:29,055 DEBUG TRAIN Batch 23/5400 loss 11.765549 loss_att 16.935196 loss_ctc 16.668018 loss_rnnt 9.910208 hw_loss 0.314529 lr 0.00035606 rank 0
2023-02-22 19:49:29,056 DEBUG TRAIN Batch 23/5400 loss 8.785594 loss_att 11.190309 loss_ctc 14.154257 loss_rnnt 7.509906 hw_loss 0.147981 lr 0.00035602 rank 1
2023-02-22 19:49:29,058 DEBUG TRAIN Batch 23/5400 loss 5.467972 loss_att 8.852966 loss_ctc 8.692274 loss_rnnt 4.268298 hw_loss 0.173941 lr 0.00035600 rank 2
2023-02-22 19:49:29,062 DEBUG TRAIN Batch 23/5400 loss 10.161424 loss_att 13.166068 loss_ctc 17.719238 loss_rnnt 8.372627 hw_loss 0.337798 lr 0.00035605 rank 3
2023-02-22 19:49:29,061 DEBUG TRAIN Batch 23/5400 loss 12.163551 loss_att 16.199623 loss_ctc 20.314579 loss_rnnt 10.067890 hw_loss 0.378080 lr 0.00035606 rank 4
2023-02-22 19:49:29,072 DEBUG TRAIN Batch 23/5400 loss 8.573810 loss_att 11.976000 loss_ctc 14.628167 loss_rnnt 6.936446 hw_loss 0.280645 lr 0.00035599 rank 5
2023-02-22 19:50:41,585 DEBUG TRAIN Batch 23/5500 loss 10.065302 loss_att 12.851217 loss_ctc 19.090023 loss_rnnt 8.140877 hw_loss 0.307399 lr 0.00035591 rank 2
2023-02-22 19:50:41,588 DEBUG TRAIN Batch 23/5500 loss 6.777806 loss_att 8.107531 loss_ctc 8.294039 loss_rnnt 6.115404 hw_loss 0.364299 lr 0.00035596 rank 3
2023-02-22 19:50:41,589 DEBUG TRAIN Batch 23/5500 loss 3.394894 loss_att 6.920205 loss_ctc 4.880690 loss_rnnt 2.305417 hw_loss 0.349330 lr 0.00035597 rank 0
2023-02-22 19:50:41,589 DEBUG TRAIN Batch 23/5500 loss 14.886782 loss_att 16.499773 loss_ctc 18.154678 loss_rnnt 13.960644 hw_loss 0.314663 lr 0.00035588 rank 6
2023-02-22 19:50:41,590 DEBUG TRAIN Batch 23/5500 loss 4.780243 loss_att 7.409946 loss_ctc 6.338212 loss_rnnt 3.865414 hw_loss 0.339674 lr 0.00035593 rank 1
2023-02-22 19:50:41,592 DEBUG TRAIN Batch 23/5500 loss 12.486991 loss_att 14.507693 loss_ctc 17.264221 loss_rnnt 11.292826 hw_loss 0.286988 lr 0.00035587 rank 7
2023-02-22 19:50:41,593 DEBUG TRAIN Batch 23/5500 loss 4.475022 loss_att 6.096298 loss_ctc 8.151621 loss_rnnt 3.401185 hw_loss 0.486317 lr 0.00035597 rank 4
2023-02-22 19:50:41,597 DEBUG TRAIN Batch 23/5500 loss 2.731621 loss_att 5.068666 loss_ctc 4.573254 loss_rnnt 1.840161 hw_loss 0.334688 lr 0.00035590 rank 5
2023-02-22 19:51:54,010 DEBUG TRAIN Batch 23/5600 loss 7.943252 loss_att 9.054735 loss_ctc 11.182335 loss_rnnt 7.150781 hw_loss 0.259304 lr 0.00035587 rank 3
2023-02-22 19:51:54,023 DEBUG TRAIN Batch 23/5600 loss 12.975674 loss_att 14.038940 loss_ctc 16.988493 loss_rnnt 12.087406 hw_loss 0.263571 lr 0.00035582 rank 2
2023-02-22 19:51:54,024 DEBUG TRAIN Batch 23/5600 loss 4.730947 loss_att 7.869833 loss_ctc 6.939385 loss_rnnt 3.600677 hw_loss 0.390062 lr 0.00035578 rank 7
2023-02-22 19:51:54,029 DEBUG TRAIN Batch 23/5600 loss 3.842336 loss_att 6.636492 loss_ctc 5.157949 loss_rnnt 3.005311 hw_loss 0.192708 lr 0.00035588 rank 0
2023-02-22 19:51:54,029 DEBUG TRAIN Batch 23/5600 loss 5.687366 loss_att 7.267905 loss_ctc 13.731473 loss_rnnt 4.243448 hw_loss 0.103616 lr 0.00035579 rank 6
2023-02-22 19:51:54,030 DEBUG TRAIN Batch 23/5600 loss 8.938105 loss_att 10.827699 loss_ctc 10.483911 loss_rnnt 8.205620 hw_loss 0.278357 lr 0.00035588 rank 4
2023-02-22 19:51:54,031 DEBUG TRAIN Batch 23/5600 loss 6.877929 loss_att 9.779466 loss_ctc 9.114120 loss_rnnt 5.842402 hw_loss 0.294488 lr 0.00035581 rank 5
2023-02-22 19:51:54,032 DEBUG TRAIN Batch 23/5600 loss 6.611452 loss_att 8.479818 loss_ctc 10.235200 loss_rnnt 5.588470 hw_loss 0.311518 lr 0.00035584 rank 1
2023-02-22 19:53:09,676 DEBUG TRAIN Batch 23/5700 loss 10.354286 loss_att 10.824554 loss_ctc 14.016094 loss_rnnt 9.457314 hw_loss 0.590019 lr 0.00035573 rank 2
2023-02-22 19:53:09,677 DEBUG TRAIN Batch 23/5700 loss 9.122231 loss_att 10.833632 loss_ctc 12.465044 loss_rnnt 8.083226 hw_loss 0.470654 lr 0.00035578 rank 3
2023-02-22 19:53:09,681 DEBUG TRAIN Batch 23/5700 loss 10.890420 loss_att 10.774405 loss_ctc 13.868854 loss_rnnt 10.336724 hw_loss 0.337075 lr 0.00035570 rank 6
2023-02-22 19:53:09,686 DEBUG TRAIN Batch 23/5700 loss 9.909600 loss_att 11.478113 loss_ctc 14.299457 loss_rnnt 8.830001 hw_loss 0.338592 lr 0.00035579 rank 4
2023-02-22 19:53:09,688 DEBUG TRAIN Batch 23/5700 loss 5.467278 loss_att 7.984269 loss_ctc 10.671309 loss_rnnt 4.106044 hw_loss 0.307435 lr 0.00035572 rank 5
2023-02-22 19:53:09,688 DEBUG TRAIN Batch 23/5700 loss 5.045956 loss_att 6.172204 loss_ctc 5.219819 loss_rnnt 4.536773 hw_loss 0.488910 lr 0.00035575 rank 1
2023-02-22 19:53:09,698 DEBUG TRAIN Batch 23/5700 loss 6.484792 loss_att 6.290691 loss_ctc 8.894569 loss_rnnt 5.934420 hw_loss 0.502290 lr 0.00035569 rank 7
2023-02-22 19:53:09,734 DEBUG TRAIN Batch 23/5700 loss 7.214252 loss_att 9.300161 loss_ctc 11.476230 loss_rnnt 6.182270 hw_loss 0.087255 lr 0.00035579 rank 0
2023-02-22 19:54:22,437 DEBUG TRAIN Batch 23/5800 loss 2.061493 loss_att 4.934288 loss_ctc 4.238031 loss_rnnt 1.091075 hw_loss 0.198103 lr 0.00035568 rank 3
2023-02-22 19:54:22,443 DEBUG TRAIN Batch 23/5800 loss 14.948966 loss_att 18.522852 loss_ctc 18.448662 loss_rnnt 13.660780 hw_loss 0.200218 lr 0.00035564 rank 2
2023-02-22 19:54:22,445 DEBUG TRAIN Batch 23/5800 loss 7.926183 loss_att 13.418847 loss_ctc 11.450840 loss_rnnt 6.226800 hw_loss 0.245428 lr 0.00035570 rank 4
2023-02-22 19:54:22,450 DEBUG TRAIN Batch 23/5800 loss 6.751349 loss_att 8.937870 loss_ctc 8.815678 loss_rnnt 5.897218 hw_loss 0.265467 lr 0.00035561 rank 6
2023-02-22 19:54:22,453 DEBUG TRAIN Batch 23/5800 loss 6.352175 loss_att 9.114500 loss_ctc 8.646721 loss_rnnt 5.375831 hw_loss 0.221137 lr 0.00035566 rank 1
2023-02-22 19:54:22,454 DEBUG TRAIN Batch 23/5800 loss 2.750303 loss_att 5.051473 loss_ctc 4.812248 loss_rnnt 1.891670 hw_loss 0.231512 lr 0.00035563 rank 5
2023-02-22 19:54:22,484 DEBUG TRAIN Batch 23/5800 loss 5.995572 loss_att 8.456385 loss_ctc 11.587169 loss_rnnt 4.661514 hw_loss 0.180653 lr 0.00035570 rank 0
2023-02-22 19:54:22,494 DEBUG TRAIN Batch 23/5800 loss 4.167144 loss_att 7.479906 loss_ctc 4.929526 loss_rnnt 3.361389 hw_loss 0.077907 lr 0.00035560 rank 7
2023-02-22 19:55:35,022 DEBUG TRAIN Batch 23/5900 loss 11.316889 loss_att 15.246363 loss_ctc 18.093857 loss_rnnt 9.516579 hw_loss 0.207786 lr 0.00035560 rank 3
2023-02-22 19:55:35,022 DEBUG TRAIN Batch 23/5900 loss 7.951391 loss_att 9.986753 loss_ctc 12.909270 loss_rnnt 6.729795 hw_loss 0.287761 lr 0.00035557 rank 1
2023-02-22 19:55:35,024 DEBUG TRAIN Batch 23/5900 loss 12.547590 loss_att 14.185901 loss_ctc 19.321465 loss_rnnt 11.191126 hw_loss 0.235536 lr 0.00035555 rank 2
2023-02-22 19:55:35,025 DEBUG TRAIN Batch 23/5900 loss 6.153615 loss_att 7.670201 loss_ctc 7.713356 loss_rnnt 5.426935 hw_loss 0.403869 lr 0.00035551 rank 7
2023-02-22 19:55:35,025 DEBUG TRAIN Batch 23/5900 loss 6.500713 loss_att 10.057779 loss_ctc 9.274180 loss_rnnt 5.265856 hw_loss 0.288090 lr 0.00035561 rank 0
2023-02-22 19:55:35,028 DEBUG TRAIN Batch 23/5900 loss 6.266781 loss_att 11.230925 loss_ctc 7.505250 loss_rnnt 4.997947 hw_loss 0.207892 lr 0.00035561 rank 4
2023-02-22 19:55:35,034 DEBUG TRAIN Batch 23/5900 loss 7.062132 loss_att 10.705225 loss_ctc 18.659874 loss_rnnt 4.637870 hw_loss 0.279896 lr 0.00035552 rank 6
2023-02-22 19:55:35,079 DEBUG TRAIN Batch 23/5900 loss 5.146612 loss_att 6.685249 loss_ctc 4.815748 loss_rnnt 4.770047 hw_loss 0.211785 lr 0.00035554 rank 5
2023-02-22 19:56:49,197 DEBUG TRAIN Batch 23/6000 loss 7.916006 loss_att 12.643816 loss_ctc 11.617735 loss_rnnt 6.413585 hw_loss 0.118678 lr 0.00035552 rank 0
2023-02-22 19:56:49,199 DEBUG TRAIN Batch 23/6000 loss 14.992966 loss_att 18.820486 loss_ctc 24.585196 loss_rnnt 12.772206 hw_loss 0.330544 lr 0.00035552 rank 4
2023-02-22 19:56:49,207 DEBUG TRAIN Batch 23/6000 loss 14.506102 loss_att 17.519543 loss_ctc 17.109726 loss_rnnt 13.309933 hw_loss 0.461870 lr 0.00035546 rank 2
2023-02-22 19:56:49,207 DEBUG TRAIN Batch 23/6000 loss 9.073270 loss_att 12.435908 loss_ctc 13.325783 loss_rnnt 7.659786 hw_loss 0.326165 lr 0.00035551 rank 3
2023-02-22 19:56:49,208 DEBUG TRAIN Batch 23/6000 loss 8.212214 loss_att 10.864367 loss_ctc 10.921321 loss_rnnt 7.177441 hw_loss 0.268365 lr 0.00035548 rank 1
2023-02-22 19:56:49,214 DEBUG TRAIN Batch 23/6000 loss 11.733665 loss_att 13.345067 loss_ctc 16.812990 loss_rnnt 10.614055 hw_loss 0.225163 lr 0.00035542 rank 7
2023-02-22 19:56:49,215 DEBUG TRAIN Batch 23/6000 loss 7.148429 loss_att 10.058669 loss_ctc 10.484667 loss_rnnt 6.034719 hw_loss 0.162805 lr 0.00035543 rank 6
2023-02-22 19:56:49,223 DEBUG TRAIN Batch 23/6000 loss 7.817406 loss_att 12.371704 loss_ctc 9.792404 loss_rnnt 6.566502 hw_loss 0.143833 lr 0.00035545 rank 5
2023-02-22 19:58:03,091 DEBUG TRAIN Batch 23/6100 loss 11.208477 loss_att 13.739239 loss_ctc 15.975555 loss_rnnt 9.924137 hw_loss 0.267335 lr 0.00035537 rank 2
2023-02-22 19:58:03,097 DEBUG TRAIN Batch 23/6100 loss 7.435585 loss_att 11.750740 loss_ctc 10.271661 loss_rnnt 6.104291 hw_loss 0.168974 lr 0.00035542 rank 3
2023-02-22 19:58:03,098 DEBUG TRAIN Batch 23/6100 loss 6.554437 loss_att 7.367978 loss_ctc 10.071228 loss_rnnt 5.731219 hw_loss 0.359258 lr 0.00035534 rank 6
2023-02-22 19:58:03,101 DEBUG TRAIN Batch 23/6100 loss 14.275309 loss_att 19.761131 loss_ctc 30.394524 loss_rnnt 10.924191 hw_loss 0.196360 lr 0.00035539 rank 1
2023-02-22 19:58:03,106 DEBUG TRAIN Batch 23/6100 loss 9.009580 loss_att 12.880637 loss_ctc 15.176614 loss_rnnt 7.298761 hw_loss 0.214380 lr 0.00035543 rank 0
2023-02-22 19:58:03,111 DEBUG TRAIN Batch 23/6100 loss 10.887726 loss_att 12.683425 loss_ctc 16.562840 loss_rnnt 9.642944 hw_loss 0.241799 lr 0.00035543 rank 4
2023-02-22 19:58:03,115 DEBUG TRAIN Batch 23/6100 loss 6.591569 loss_att 8.266567 loss_ctc 10.066339 loss_rnnt 5.613409 hw_loss 0.337236 lr 0.00035536 rank 5
2023-02-22 19:58:03,150 DEBUG TRAIN Batch 23/6100 loss 13.798007 loss_att 17.349646 loss_ctc 17.901318 loss_rnnt 12.344978 hw_loss 0.366737 lr 0.00035533 rank 7
2023-02-22 19:59:15,337 DEBUG TRAIN Batch 23/6200 loss 5.191940 loss_att 5.852400 loss_ctc 6.129556 loss_rnnt 4.879603 hw_loss 0.103554 lr 0.00035528 rank 2
2023-02-22 19:59:15,343 DEBUG TRAIN Batch 23/6200 loss 13.627403 loss_att 15.960890 loss_ctc 18.020329 loss_rnnt 12.415524 hw_loss 0.298983 lr 0.00035525 rank 6
2023-02-22 19:59:15,344 DEBUG TRAIN Batch 23/6200 loss 8.998994 loss_att 11.750074 loss_ctc 15.691224 loss_rnnt 7.349968 hw_loss 0.387208 lr 0.00035534 rank 4
2023-02-22 19:59:15,347 DEBUG TRAIN Batch 23/6200 loss 9.755263 loss_att 12.597565 loss_ctc 13.809011 loss_rnnt 8.464445 hw_loss 0.340984 lr 0.00035533 rank 3
2023-02-22 19:59:15,350 DEBUG TRAIN Batch 23/6200 loss 3.241735 loss_att 7.363217 loss_ctc 4.913869 loss_rnnt 2.007784 hw_loss 0.350070 lr 0.00035524 rank 7
2023-02-22 19:59:15,350 DEBUG TRAIN Batch 23/6200 loss 13.565567 loss_att 14.789777 loss_ctc 17.105661 loss_rnnt 12.698377 hw_loss 0.281879 lr 0.00035534 rank 0
2023-02-22 19:59:15,350 DEBUG TRAIN Batch 23/6200 loss 15.743038 loss_att 17.361671 loss_ctc 20.275658 loss_rnnt 14.611994 hw_loss 0.380563 lr 0.00035530 rank 1
2023-02-22 19:59:15,357 DEBUG TRAIN Batch 23/6200 loss 8.484635 loss_att 11.217921 loss_ctc 13.242085 loss_rnnt 7.105546 hw_loss 0.371446 lr 0.00035527 rank 5
2023-02-22 20:00:28,042 DEBUG TRAIN Batch 23/6300 loss 10.217411 loss_att 12.241920 loss_ctc 15.060229 loss_rnnt 9.067894 hw_loss 0.185447 lr 0.00035524 rank 3
2023-02-22 20:00:28,042 DEBUG TRAIN Batch 23/6300 loss 14.422356 loss_att 14.182201 loss_ctc 20.158218 loss_rnnt 13.550545 hw_loss 0.290737 lr 0.00035519 rank 2
2023-02-22 20:00:28,043 DEBUG TRAIN Batch 23/6300 loss 12.109361 loss_att 14.740500 loss_ctc 15.686780 loss_rnnt 10.937764 hw_loss 0.315712 lr 0.00035521 rank 1
2023-02-22 20:00:28,044 DEBUG TRAIN Batch 23/6300 loss 9.328886 loss_att 9.176590 loss_ctc 12.825300 loss_rnnt 8.606502 hw_loss 0.537478 lr 0.00035525 rank 4
2023-02-22 20:00:28,044 DEBUG TRAIN Batch 23/6300 loss 5.115531 loss_att 7.517157 loss_ctc 7.780288 loss_rnnt 4.030468 hw_loss 0.467694 lr 0.00035516 rank 6
2023-02-22 20:00:28,068 DEBUG TRAIN Batch 23/6300 loss 6.085393 loss_att 5.943062 loss_ctc 8.632468 loss_rnnt 5.563860 hw_loss 0.394478 lr 0.00035515 rank 7
2023-02-22 20:00:28,075 DEBUG TRAIN Batch 23/6300 loss 10.213337 loss_att 10.425261 loss_ctc 14.045310 loss_rnnt 9.467283 hw_loss 0.361385 lr 0.00035525 rank 0
2023-02-22 20:00:28,098 DEBUG TRAIN Batch 23/6300 loss 10.340643 loss_att 14.030735 loss_ctc 16.807865 loss_rnnt 8.625954 hw_loss 0.214452 lr 0.00035518 rank 5
2023-02-22 20:01:42,474 DEBUG TRAIN Batch 23/6400 loss 6.839981 loss_att 6.807022 loss_ctc 8.889438 loss_rnnt 6.202358 hw_loss 0.695538 lr 0.00035515 rank 3
2023-02-22 20:01:42,475 DEBUG TRAIN Batch 23/6400 loss 8.203465 loss_att 7.984236 loss_ctc 11.373512 loss_rnnt 7.575080 hw_loss 0.467920 lr 0.00035510 rank 5
2023-02-22 20:01:42,480 DEBUG TRAIN Batch 23/6400 loss 9.835435 loss_att 10.527160 loss_ctc 11.511367 loss_rnnt 9.355009 hw_loss 0.222419 lr 0.00035507 rank 6
2023-02-22 20:01:42,480 DEBUG TRAIN Batch 23/6400 loss 5.507143 loss_att 9.833220 loss_ctc 10.503231 loss_rnnt 3.890033 hw_loss 0.160781 lr 0.00035510 rank 2
2023-02-22 20:01:42,481 DEBUG TRAIN Batch 23/6400 loss 11.856547 loss_att 13.325464 loss_ctc 18.514061 loss_rnnt 10.525654 hw_loss 0.280205 lr 0.00035506 rank 7
2023-02-22 20:01:42,483 DEBUG TRAIN Batch 23/6400 loss 10.546596 loss_att 14.059505 loss_ctc 17.008909 loss_rnnt 8.798812 hw_loss 0.344176 lr 0.00035512 rank 1
2023-02-22 20:01:42,485 DEBUG TRAIN Batch 23/6400 loss 13.446527 loss_att 16.531025 loss_ctc 20.127327 loss_rnnt 11.804522 hw_loss 0.251874 lr 0.00035516 rank 0
2023-02-22 20:01:42,486 DEBUG TRAIN Batch 23/6400 loss 5.424500 loss_att 7.645315 loss_ctc 4.688699 loss_rnnt 4.945780 hw_loss 0.248746 lr 0.00035516 rank 4
2023-02-22 20:02:55,687 DEBUG TRAIN Batch 23/6500 loss 5.639200 loss_att 8.062251 loss_ctc 8.561677 loss_rnnt 4.629643 hw_loss 0.253656 lr 0.00035507 rank 4
2023-02-22 20:02:55,688 DEBUG TRAIN Batch 23/6500 loss 3.168398 loss_att 6.080267 loss_ctc 4.870718 loss_rnnt 2.245905 hw_loss 0.212144 lr 0.00035506 rank 3
2023-02-22 20:02:55,689 DEBUG TRAIN Batch 23/6500 loss 7.903290 loss_att 10.853345 loss_ctc 11.899837 loss_rnnt 6.689768 hw_loss 0.169946 lr 0.00035498 rank 6
2023-02-22 20:02:55,692 DEBUG TRAIN Batch 23/6500 loss 1.617628 loss_att 4.381194 loss_ctc 2.201025 loss_rnnt 0.832393 hw_loss 0.290129 lr 0.00035501 rank 2
2023-02-22 20:02:55,692 DEBUG TRAIN Batch 23/6500 loss 10.858891 loss_att 15.688602 loss_ctc 16.565912 loss_rnnt 8.975084 hw_loss 0.294243 lr 0.00035507 rank 0
2023-02-22 20:02:55,696 DEBUG TRAIN Batch 23/6500 loss 9.087913 loss_att 13.916918 loss_ctc 11.794883 loss_rnnt 7.633869 hw_loss 0.238711 lr 0.00035503 rank 1
2023-02-22 20:02:55,698 DEBUG TRAIN Batch 23/6500 loss 7.330071 loss_att 11.742195 loss_ctc 11.660628 loss_rnnt 5.724965 hw_loss 0.272388 lr 0.00035501 rank 5
2023-02-22 20:02:55,740 DEBUG TRAIN Batch 23/6500 loss 9.952816 loss_att 16.451248 loss_ctc 15.510730 loss_rnnt 7.745330 hw_loss 0.312645 lr 0.00035498 rank 7
2023-02-22 20:04:08,464 DEBUG TRAIN Batch 23/6600 loss 7.366181 loss_att 9.351706 loss_ctc 9.648894 loss_rnnt 6.502967 hw_loss 0.303276 lr 0.00035494 rank 1
2023-02-22 20:04:08,480 DEBUG TRAIN Batch 23/6600 loss 7.902535 loss_att 10.374392 loss_ctc 9.325702 loss_rnnt 7.017625 hw_loss 0.376469 lr 0.00035492 rank 2
2023-02-22 20:04:08,480 DEBUG TRAIN Batch 23/6600 loss 8.090697 loss_att 9.810828 loss_ctc 9.025281 loss_rnnt 7.544271 hw_loss 0.145855 lr 0.00035489 rank 7
2023-02-22 20:04:08,483 DEBUG TRAIN Batch 23/6600 loss 4.821242 loss_att 6.757760 loss_ctc 9.211034 loss_rnnt 3.706944 hw_loss 0.265667 lr 0.00035489 rank 6
2023-02-22 20:04:08,484 DEBUG TRAIN Batch 23/6600 loss 16.259996 loss_att 16.482132 loss_ctc 22.727535 loss_rnnt 15.263662 hw_loss 0.167941 lr 0.00035497 rank 3
2023-02-22 20:04:08,487 DEBUG TRAIN Batch 23/6600 loss 6.027367 loss_att 12.227689 loss_ctc 10.762989 loss_rnnt 3.984725 hw_loss 0.320927 lr 0.00035492 rank 5
2023-02-22 20:04:08,489 DEBUG TRAIN Batch 23/6600 loss 20.648994 loss_att 24.396160 loss_ctc 29.921776 loss_rnnt 18.583868 hw_loss 0.148729 lr 0.00035498 rank 0
2023-02-22 20:04:08,490 DEBUG TRAIN Batch 23/6600 loss 4.324959 loss_att 6.733967 loss_ctc 5.831928 loss_rnnt 3.492723 hw_loss 0.280321 lr 0.00035498 rank 4
2023-02-22 20:05:21,401 DEBUG TRAIN Batch 23/6700 loss 11.664334 loss_att 12.696125 loss_ctc 16.690554 loss_rnnt 10.686826 hw_loss 0.189351 lr 0.00035480 rank 7
2023-02-22 20:05:21,406 DEBUG TRAIN Batch 23/6700 loss 13.356278 loss_att 15.236105 loss_ctc 15.647469 loss_rnnt 12.554106 hw_loss 0.226343 lr 0.00035483 rank 5
2023-02-22 20:05:21,412 DEBUG TRAIN Batch 23/6700 loss 6.116035 loss_att 7.948758 loss_ctc 8.056199 loss_rnnt 5.344758 hw_loss 0.273834 lr 0.00035480 rank 6
2023-02-22 20:05:21,419 DEBUG TRAIN Batch 23/6700 loss 4.613192 loss_att 7.177458 loss_ctc 8.769923 loss_rnnt 3.451937 hw_loss 0.176570 lr 0.00035489 rank 0
2023-02-22 20:05:21,420 DEBUG TRAIN Batch 23/6700 loss 14.365983 loss_att 16.909782 loss_ctc 19.309494 loss_rnnt 13.070667 hw_loss 0.238914 lr 0.00035489 rank 4
2023-02-22 20:05:21,422 DEBUG TRAIN Batch 23/6700 loss 15.618783 loss_att 17.679516 loss_ctc 21.141668 loss_rnnt 14.302578 hw_loss 0.314386 lr 0.00035483 rank 2
2023-02-22 20:05:21,435 DEBUG TRAIN Batch 23/6700 loss 8.861139 loss_att 10.785894 loss_ctc 9.815685 loss_rnnt 8.225407 hw_loss 0.231579 lr 0.00035488 rank 3
2023-02-22 20:05:21,465 DEBUG TRAIN Batch 23/6700 loss 7.845487 loss_att 10.841198 loss_ctc 13.118141 loss_rnnt 6.334872 hw_loss 0.390848 lr 0.00035485 rank 1
2023-02-22 20:06:35,380 DEBUG TRAIN Batch 23/6800 loss 5.087785 loss_att 9.423095 loss_ctc 8.651127 loss_rnnt 3.630486 hw_loss 0.215857 lr 0.00035479 rank 3
2023-02-22 20:06:35,383 DEBUG TRAIN Batch 23/6800 loss 3.491415 loss_att 5.342022 loss_ctc 6.495718 loss_rnnt 2.549317 hw_loss 0.321379 lr 0.00035480 rank 4
2023-02-22 20:06:35,383 DEBUG TRAIN Batch 23/6800 loss 9.495169 loss_att 9.896081 loss_ctc 14.860329 loss_rnnt 8.574472 hw_loss 0.234673 lr 0.00035471 rank 7
2023-02-22 20:06:35,386 DEBUG TRAIN Batch 23/6800 loss 10.525858 loss_att 13.267817 loss_ctc 12.426548 loss_rnnt 9.484718 hw_loss 0.448731 lr 0.00035474 rank 2
2023-02-22 20:06:35,388 DEBUG TRAIN Batch 23/6800 loss 6.346012 loss_att 11.845612 loss_ctc 10.003839 loss_rnnt 4.603518 hw_loss 0.290370 lr 0.00035476 rank 1
2023-02-22 20:06:35,388 DEBUG TRAIN Batch 23/6800 loss 7.143973 loss_att 9.433684 loss_ctc 10.970057 loss_rnnt 6.028501 hw_loss 0.276349 lr 0.00035471 rank 6
2023-02-22 20:06:35,392 DEBUG TRAIN Batch 23/6800 loss 8.424748 loss_att 11.477392 loss_ctc 11.541154 loss_rnnt 7.306517 hw_loss 0.172841 lr 0.00035474 rank 5
2023-02-22 20:06:35,394 DEBUG TRAIN Batch 23/6800 loss 5.136594 loss_att 6.918473 loss_ctc 8.796534 loss_rnnt 4.151009 hw_loss 0.264782 lr 0.00035480 rank 0
2023-02-22 20:07:48,348 DEBUG TRAIN Batch 23/6900 loss 16.827402 loss_att 17.948576 loss_ctc 25.549385 loss_rnnt 15.269848 hw_loss 0.319474 lr 0.00035470 rank 3
2023-02-22 20:07:48,349 DEBUG TRAIN Batch 23/6900 loss 5.164765 loss_att 6.838216 loss_ctc 8.434762 loss_rnnt 4.254633 hw_loss 0.261453 lr 0.00035465 rank 2
2023-02-22 20:07:48,349 DEBUG TRAIN Batch 23/6900 loss 10.798380 loss_att 10.329820 loss_ctc 14.644282 loss_rnnt 10.088135 hw_loss 0.545946 lr 0.00035462 rank 7
2023-02-22 20:07:48,350 DEBUG TRAIN Batch 23/6900 loss 14.844815 loss_att 16.288467 loss_ctc 19.930063 loss_rnnt 13.764084 hw_loss 0.213688 lr 0.00035462 rank 6
2023-02-22 20:07:48,355 DEBUG TRAIN Batch 23/6900 loss 14.792118 loss_att 16.139053 loss_ctc 20.232819 loss_rnnt 13.558812 hw_loss 0.447171 lr 0.00035471 rank 0
2023-02-22 20:07:48,357 DEBUG TRAIN Batch 23/6900 loss 5.849759 loss_att 6.806524 loss_ctc 6.995466 loss_rnnt 5.369836 hw_loss 0.254640 lr 0.00035465 rank 5
2023-02-22 20:07:48,376 DEBUG TRAIN Batch 23/6900 loss 8.541661 loss_att 11.979372 loss_ctc 14.808634 loss_rnnt 6.850866 hw_loss 0.314355 lr 0.00035471 rank 4
2023-02-22 20:07:48,385 DEBUG TRAIN Batch 23/6900 loss 7.100043 loss_att 8.439959 loss_ctc 12.023689 loss_rnnt 6.101043 hw_loss 0.139745 lr 0.00035467 rank 1
2023-02-22 20:09:01,097 DEBUG TRAIN Batch 23/7000 loss 10.636030 loss_att 13.105400 loss_ctc 13.065845 loss_rnnt 9.697640 hw_loss 0.226014 lr 0.00035462 rank 0
2023-02-22 20:09:01,097 DEBUG TRAIN Batch 23/7000 loss 10.671212 loss_att 12.287379 loss_ctc 12.752087 loss_rnnt 9.917253 hw_loss 0.287393 lr 0.00035458 rank 1
2023-02-22 20:09:01,098 DEBUG TRAIN Batch 23/7000 loss 9.455575 loss_att 8.012204 loss_ctc 12.728687 loss_rnnt 8.955472 hw_loss 0.660679 lr 0.00035457 rank 2
2023-02-22 20:09:01,098 DEBUG TRAIN Batch 23/7000 loss 8.696285 loss_att 9.543006 loss_ctc 10.525828 loss_rnnt 8.043621 hw_loss 0.448841 lr 0.00035461 rank 3
2023-02-22 20:09:01,100 DEBUG TRAIN Batch 23/7000 loss 9.768948 loss_att 9.632481 loss_ctc 12.853503 loss_rnnt 9.013381 hw_loss 0.696727 lr 0.00035453 rank 6
2023-02-22 20:09:01,100 DEBUG TRAIN Batch 23/7000 loss 4.012190 loss_att 7.206171 loss_ctc 6.984812 loss_rnnt 2.873234 hw_loss 0.194645 lr 0.00035453 rank 7
2023-02-22 20:09:01,104 DEBUG TRAIN Batch 23/7000 loss 6.043984 loss_att 8.611156 loss_ctc 9.682932 loss_rnnt 4.944744 hw_loss 0.188648 lr 0.00035462 rank 4
2023-02-22 20:09:01,106 DEBUG TRAIN Batch 23/7000 loss 7.483694 loss_att 8.642173 loss_ctc 10.337205 loss_rnnt 6.656038 hw_loss 0.404047 lr 0.00035456 rank 5
2023-02-22 20:10:15,950 DEBUG TRAIN Batch 23/7100 loss 9.014615 loss_att 9.704643 loss_ctc 11.502500 loss_rnnt 8.358946 hw_loss 0.348647 lr 0.00035450 rank 1
2023-02-22 20:10:15,957 DEBUG TRAIN Batch 23/7100 loss 18.133553 loss_att 19.754808 loss_ctc 23.169617 loss_rnnt 17.061802 hw_loss 0.142546 lr 0.00035448 rank 2
2023-02-22 20:10:15,958 DEBUG TRAIN Batch 23/7100 loss 8.131006 loss_att 11.496484 loss_ctc 11.962221 loss_rnnt 6.863459 hw_loss 0.156793 lr 0.00035444 rank 7
2023-02-22 20:10:15,960 DEBUG TRAIN Batch 23/7100 loss 9.304187 loss_att 13.012173 loss_ctc 13.279128 loss_rnnt 7.897075 hw_loss 0.254106 lr 0.00035453 rank 4
2023-02-22 20:10:15,961 DEBUG TRAIN Batch 23/7100 loss 7.525300 loss_att 10.763391 loss_ctc 10.737807 loss_rnnt 6.386718 hw_loss 0.117431 lr 0.00035444 rank 6
2023-02-22 20:10:15,967 DEBUG TRAIN Batch 23/7100 loss 7.371582 loss_att 9.822927 loss_ctc 7.465656 loss_rnnt 6.747926 hw_loss 0.226580 lr 0.00035452 rank 3
2023-02-22 20:10:15,982 DEBUG TRAIN Batch 23/7100 loss 23.994574 loss_att 25.585857 loss_ctc 32.462585 loss_rnnt 22.421612 hw_loss 0.235570 lr 0.00035454 rank 0
2023-02-22 20:10:16,028 DEBUG TRAIN Batch 23/7100 loss 8.359005 loss_att 10.537715 loss_ctc 14.160514 loss_rnnt 7.054919 hw_loss 0.177767 lr 0.00035447 rank 5
2023-02-22 20:11:28,896 DEBUG TRAIN Batch 23/7200 loss 6.432116 loss_att 8.902169 loss_ctc 9.876063 loss_rnnt 5.309098 hw_loss 0.318402 lr 0.00035436 rank 6
2023-02-22 20:11:28,908 DEBUG TRAIN Batch 23/7200 loss 8.792106 loss_att 10.814840 loss_ctc 11.315826 loss_rnnt 7.837647 hw_loss 0.400152 lr 0.00035444 rank 4
2023-02-22 20:11:28,911 DEBUG TRAIN Batch 23/7200 loss 2.426183 loss_att 5.070249 loss_ctc 3.564163 loss_rnnt 1.656813 hw_loss 0.166548 lr 0.00035441 rank 1
2023-02-22 20:11:28,911 DEBUG TRAIN Batch 23/7200 loss 14.175150 loss_att 18.276182 loss_ctc 19.078466 loss_rnnt 12.570044 hw_loss 0.245861 lr 0.00035443 rank 3
2023-02-22 20:11:28,912 DEBUG TRAIN Batch 23/7200 loss 2.950796 loss_att 5.745477 loss_ctc 4.547052 loss_rnnt 2.066692 hw_loss 0.210627 lr 0.00035445 rank 0
2023-02-22 20:11:28,912 DEBUG TRAIN Batch 23/7200 loss 8.905610 loss_att 8.930354 loss_ctc 11.562468 loss_rnnt 8.405514 hw_loss 0.264188 lr 0.00035439 rank 2
2023-02-22 20:11:28,912 DEBUG TRAIN Batch 23/7200 loss 10.039874 loss_att 11.037355 loss_ctc 18.734726 loss_rnnt 8.461641 hw_loss 0.411417 lr 0.00035438 rank 5
2023-02-22 20:11:28,914 DEBUG TRAIN Batch 23/7200 loss 9.830410 loss_att 12.527828 loss_ctc 20.643194 loss_rnnt 7.647368 hw_loss 0.378475 lr 0.00035435 rank 7
2023-02-22 20:12:41,794 DEBUG TRAIN Batch 23/7300 loss 21.902796 loss_att 24.825768 loss_ctc 25.893425 loss_rnnt 20.663742 hw_loss 0.229454 lr 0.00035435 rank 4
2023-02-22 20:12:41,794 DEBUG TRAIN Batch 23/7300 loss 6.668638 loss_att 8.484508 loss_ctc 8.944699 loss_rnnt 5.871645 hw_loss 0.244394 lr 0.00035430 rank 2
2023-02-22 20:12:41,796 DEBUG TRAIN Batch 23/7300 loss 13.635274 loss_att 14.508004 loss_ctc 22.118992 loss_rnnt 12.187010 hw_loss 0.267293 lr 0.00035434 rank 3
2023-02-22 20:12:41,800 DEBUG TRAIN Batch 23/7300 loss 9.018974 loss_att 12.432882 loss_ctc 12.455334 loss_rnnt 7.756063 hw_loss 0.228654 lr 0.00035426 rank 7
2023-02-22 20:12:41,800 DEBUG TRAIN Batch 23/7300 loss 18.950159 loss_att 21.713415 loss_ctc 25.320704 loss_rnnt 17.483337 hw_loss 0.121437 lr 0.00035427 rank 6
2023-02-22 20:12:41,801 DEBUG TRAIN Batch 23/7300 loss 6.469184 loss_att 9.498427 loss_ctc 8.598770 loss_rnnt 5.418115 hw_loss 0.302391 lr 0.00035432 rank 1
2023-02-22 20:12:41,804 DEBUG TRAIN Batch 23/7300 loss 10.637959 loss_att 10.215083 loss_ctc 13.532321 loss_rnnt 10.191094 hw_loss 0.272857 lr 0.00035436 rank 0
2023-02-22 20:12:41,805 DEBUG TRAIN Batch 23/7300 loss 6.355165 loss_att 8.419076 loss_ctc 11.854322 loss_rnnt 5.105109 hw_loss 0.195100 lr 0.00035429 rank 5
2023-02-22 20:13:54,039 DEBUG TRAIN Batch 23/7400 loss 14.132726 loss_att 17.014214 loss_ctc 19.675865 loss_rnnt 12.745958 hw_loss 0.133847 lr 0.00035426 rank 4
2023-02-22 20:13:54,040 DEBUG TRAIN Batch 23/7400 loss 6.123443 loss_att 8.384581 loss_ctc 7.521087 loss_rnnt 5.308349 hw_loss 0.330964 lr 0.00035420 rank 5
2023-02-22 20:13:54,048 DEBUG TRAIN Batch 23/7400 loss 13.962404 loss_att 17.105404 loss_ctc 18.393456 loss_rnnt 12.638641 hw_loss 0.195666 lr 0.00035421 rank 2
2023-02-22 20:13:54,049 DEBUG TRAIN Batch 23/7400 loss 8.492411 loss_att 9.666389 loss_ctc 11.543953 loss_rnnt 7.737556 hw_loss 0.212224 lr 0.00035427 rank 0
2023-02-22 20:13:54,049 DEBUG TRAIN Batch 23/7400 loss 18.773224 loss_att 19.379066 loss_ctc 25.827585 loss_rnnt 17.581995 hw_loss 0.242774 lr 0.00035423 rank 1
2023-02-22 20:13:54,049 DEBUG TRAIN Batch 23/7400 loss 10.285576 loss_att 11.544119 loss_ctc 12.168505 loss_rnnt 9.669823 hw_loss 0.211851 lr 0.00035417 rank 7
2023-02-22 20:13:54,050 DEBUG TRAIN Batch 23/7400 loss 9.449810 loss_att 12.045090 loss_ctc 13.303555 loss_rnnt 8.335260 hw_loss 0.153116 lr 0.00035425 rank 3
2023-02-22 20:13:54,053 DEBUG TRAIN Batch 23/7400 loss 21.088717 loss_att 21.844374 loss_ctc 28.923210 loss_rnnt 19.761614 hw_loss 0.246318 lr 0.00035418 rank 6
2023-02-22 20:15:08,765 DEBUG TRAIN Batch 23/7500 loss 4.422383 loss_att 7.248258 loss_ctc 8.287913 loss_rnnt 3.151761 hw_loss 0.356332 lr 0.00035409 rank 6
2023-02-22 20:15:08,772 DEBUG TRAIN Batch 23/7500 loss 9.757078 loss_att 11.578178 loss_ctc 13.443649 loss_rnnt 8.727364 hw_loss 0.326159 lr 0.00035418 rank 4
2023-02-22 20:15:08,774 DEBUG TRAIN Batch 23/7500 loss 5.632900 loss_att 8.919334 loss_ctc 8.937033 loss_rnnt 4.468481 hw_loss 0.124840 lr 0.00035412 rank 2
2023-02-22 20:15:08,775 DEBUG TRAIN Batch 23/7500 loss 8.647963 loss_att 10.785487 loss_ctc 12.701818 loss_rnnt 7.537626 hw_loss 0.266842 lr 0.00035414 rank 1
2023-02-22 20:15:08,785 DEBUG TRAIN Batch 23/7500 loss 19.828110 loss_att 23.114187 loss_ctc 26.332670 loss_rnnt 18.119055 hw_loss 0.346059 lr 0.00035411 rank 5
2023-02-22 20:15:08,786 DEBUG TRAIN Batch 23/7500 loss 8.372869 loss_att 9.921157 loss_ctc 11.139796 loss_rnnt 7.598882 hw_loss 0.178885 lr 0.00035418 rank 0
2023-02-22 20:15:08,791 DEBUG TRAIN Batch 23/7500 loss 8.431082 loss_att 12.760073 loss_ctc 12.052919 loss_rnnt 6.864442 hw_loss 0.408618 lr 0.00035416 rank 3
2023-02-22 20:15:08,833 DEBUG TRAIN Batch 23/7500 loss 5.348657 loss_att 6.318088 loss_ctc 8.418108 loss_rnnt 4.529717 hw_loss 0.404612 lr 0.00035408 rank 7
2023-02-22 20:16:21,946 DEBUG TRAIN Batch 23/7600 loss 16.642061 loss_att 19.058521 loss_ctc 24.874928 loss_rnnt 14.950832 hw_loss 0.206664 lr 0.00035403 rank 2
2023-02-22 20:16:21,947 DEBUG TRAIN Batch 23/7600 loss 5.793521 loss_att 6.034047 loss_ctc 6.904120 loss_rnnt 5.332167 hw_loss 0.497193 lr 0.00035400 rank 6
2023-02-22 20:16:21,948 DEBUG TRAIN Batch 23/7600 loss 11.367388 loss_att 12.712413 loss_ctc 17.974827 loss_rnnt 9.997633 hw_loss 0.412045 lr 0.00035409 rank 4
2023-02-22 20:16:21,950 DEBUG TRAIN Batch 23/7600 loss 11.345102 loss_att 12.543891 loss_ctc 13.968528 loss_rnnt 10.551206 hw_loss 0.383153 lr 0.00035409 rank 0
2023-02-22 20:16:21,952 DEBUG TRAIN Batch 23/7600 loss 13.392458 loss_att 15.877603 loss_ctc 20.281755 loss_rnnt 11.824280 hw_loss 0.286082 lr 0.00035408 rank 3
2023-02-22 20:16:21,951 DEBUG TRAIN Batch 23/7600 loss 6.268670 loss_att 7.926614 loss_ctc 11.562232 loss_rnnt 5.045612 hw_loss 0.348115 lr 0.00035403 rank 5
2023-02-22 20:16:21,955 DEBUG TRAIN Batch 23/7600 loss 6.229059 loss_att 9.777047 loss_ctc 8.946377 loss_rnnt 5.073387 hw_loss 0.157061 lr 0.00035405 rank 1
2023-02-22 20:16:22,000 DEBUG TRAIN Batch 23/7600 loss 5.986085 loss_att 10.451538 loss_ctc 10.926470 loss_rnnt 4.354086 hw_loss 0.150356 lr 0.00035400 rank 7
2023-02-22 20:17:34,342 DEBUG TRAIN Batch 23/7700 loss 4.279901 loss_att 8.761449 loss_ctc 10.455169 loss_rnnt 2.452618 hw_loss 0.201757 lr 0.00035394 rank 2
2023-02-22 20:17:34,343 DEBUG TRAIN Batch 23/7700 loss 4.933850 loss_att 7.843496 loss_ctc 7.742366 loss_rnnt 3.912677 hw_loss 0.121456 lr 0.00035399 rank 3
2023-02-22 20:17:34,346 DEBUG TRAIN Batch 23/7700 loss 15.256365 loss_att 16.007294 loss_ctc 16.162977 loss_rnnt 14.910889 hw_loss 0.139515 lr 0.00035391 rank 6
2023-02-22 20:17:34,347 DEBUG TRAIN Batch 23/7700 loss 18.906830 loss_att 18.572933 loss_ctc 24.883358 loss_rnnt 17.911467 hw_loss 0.497387 lr 0.00035396 rank 1
2023-02-22 20:17:34,349 DEBUG TRAIN Batch 23/7700 loss 6.128306 loss_att 9.063459 loss_ctc 11.713871 loss_rnnt 4.665339 hw_loss 0.245990 lr 0.00035394 rank 5
2023-02-22 20:17:34,352 DEBUG TRAIN Batch 23/7700 loss 3.413206 loss_att 5.515098 loss_ctc 3.781932 loss_rnnt 2.739143 hw_loss 0.383477 lr 0.00035400 rank 0
2023-02-22 20:17:34,357 DEBUG TRAIN Batch 23/7700 loss 7.990122 loss_att 10.437631 loss_ctc 10.869513 loss_rnnt 7.043948 hw_loss 0.136412 lr 0.00035400 rank 4
2023-02-22 20:17:34,396 DEBUG TRAIN Batch 23/7700 loss 3.333658 loss_att 5.660951 loss_ctc 7.974654 loss_rnnt 2.096335 hw_loss 0.286998 lr 0.00035391 rank 7
2023-02-22 20:18:49,491 DEBUG TRAIN Batch 23/7800 loss 13.471777 loss_att 17.739372 loss_ctc 15.889407 loss_rnnt 12.240482 hw_loss 0.103922 lr 0.00035391 rank 0
2023-02-22 20:18:49,494 DEBUG TRAIN Batch 23/7800 loss 3.220864 loss_att 6.717649 loss_ctc 6.295562 loss_rnnt 2.031897 hw_loss 0.149344 lr 0.00035385 rank 2
2023-02-22 20:18:49,494 DEBUG TRAIN Batch 23/7800 loss 6.556312 loss_att 8.488098 loss_ctc 8.068255 loss_rnnt 5.831008 hw_loss 0.257538 lr 0.00035382 rank 7
2023-02-22 20:18:49,495 DEBUG TRAIN Batch 23/7800 loss 5.272374 loss_att 7.474734 loss_ctc 8.193382 loss_rnnt 4.299698 hw_loss 0.267629 lr 0.00035382 rank 6
2023-02-22 20:18:49,495 DEBUG TRAIN Batch 23/7800 loss 3.681114 loss_att 6.891497 loss_ctc 5.381374 loss_rnnt 2.477872 hw_loss 0.627119 lr 0.00035391 rank 4
2023-02-22 20:18:49,498 DEBUG TRAIN Batch 23/7800 loss 8.873558 loss_att 12.338996 loss_ctc 11.009875 loss_rnnt 7.803426 hw_loss 0.172879 lr 0.00035390 rank 3
2023-02-22 20:18:49,498 DEBUG TRAIN Batch 23/7800 loss 4.485981 loss_att 6.344341 loss_ctc 6.180130 loss_rnnt 3.775663 hw_loss 0.211422 lr 0.00035387 rank 1
2023-02-22 20:18:49,514 DEBUG TRAIN Batch 23/7800 loss 4.762391 loss_att 9.154135 loss_ctc 9.043566 loss_rnnt 3.193366 hw_loss 0.224723 lr 0.00035385 rank 5
2023-02-22 20:20:03,770 DEBUG TRAIN Batch 23/7900 loss 8.696949 loss_att 9.485951 loss_ctc 14.328337 loss_rnnt 7.657507 hw_loss 0.245231 lr 0.00035381 rank 3
2023-02-22 20:20:03,776 DEBUG TRAIN Batch 23/7900 loss 8.169211 loss_att 10.268917 loss_ctc 10.402040 loss_rnnt 7.348693 hw_loss 0.192875 lr 0.00035382 rank 0
2023-02-22 20:20:03,775 DEBUG TRAIN Batch 23/7900 loss 7.178993 loss_att 10.355078 loss_ctc 8.630449 loss_rnnt 6.126579 hw_loss 0.419382 lr 0.00035373 rank 6
2023-02-22 20:20:03,779 DEBUG TRAIN Batch 23/7900 loss 12.136627 loss_att 16.088089 loss_ctc 19.321625 loss_rnnt 10.286581 hw_loss 0.190786 lr 0.00035373 rank 7
2023-02-22 20:20:03,781 DEBUG TRAIN Batch 23/7900 loss 9.339193 loss_att 11.620058 loss_ctc 11.540637 loss_rnnt 8.487901 hw_loss 0.190486 lr 0.00035377 rank 2
2023-02-22 20:20:03,780 DEBUG TRAIN Batch 23/7900 loss 9.129211 loss_att 10.316774 loss_ctc 12.289887 loss_rnnt 8.276348 hw_loss 0.363616 lr 0.00035382 rank 4
2023-02-22 20:20:03,782 DEBUG TRAIN Batch 23/7900 loss 2.755268 loss_att 3.900109 loss_ctc 4.182367 loss_rnnt 2.175584 hw_loss 0.300819 lr 0.00035376 rank 5
2023-02-22 20:20:03,783 DEBUG TRAIN Batch 23/7900 loss 14.760715 loss_att 16.676895 loss_ctc 23.828709 loss_rnnt 13.042271 hw_loss 0.236517 lr 0.00035379 rank 1
2023-02-22 20:21:16,033 DEBUG TRAIN Batch 23/8000 loss 9.107731 loss_att 12.042935 loss_ctc 8.735096 loss_rnnt 8.391010 hw_loss 0.336308 lr 0.00035370 rank 1
2023-02-22 20:21:16,050 DEBUG TRAIN Batch 23/8000 loss 6.239259 loss_att 8.408665 loss_ctc 6.103220 loss_rnnt 5.711473 hw_loss 0.210082 lr 0.00035368 rank 2
2023-02-22 20:21:16,051 DEBUG TRAIN Batch 23/8000 loss 7.489780 loss_att 10.861101 loss_ctc 12.632828 loss_rnnt 5.983785 hw_loss 0.273734 lr 0.00035373 rank 4
2023-02-22 20:21:16,052 DEBUG TRAIN Batch 23/8000 loss 8.251073 loss_att 12.800425 loss_ctc 12.782854 loss_rnnt 6.611470 hw_loss 0.235303 lr 0.00035372 rank 3
2023-02-22 20:21:16,053 DEBUG TRAIN Batch 23/8000 loss 8.505096 loss_att 10.989743 loss_ctc 14.147919 loss_rnnt 7.166784 hw_loss 0.166887 lr 0.00035374 rank 0
2023-02-22 20:21:16,052 DEBUG TRAIN Batch 23/8000 loss 9.101183 loss_att 12.404025 loss_ctc 14.468033 loss_rnnt 7.583282 hw_loss 0.265789 lr 0.00035365 rank 6
2023-02-22 20:21:16,058 DEBUG TRAIN Batch 23/8000 loss 9.667751 loss_att 13.910868 loss_ctc 13.725376 loss_rnnt 8.100080 hw_loss 0.333808 lr 0.00035364 rank 7
2023-02-22 20:21:16,110 DEBUG TRAIN Batch 23/8000 loss 8.590423 loss_att 10.201260 loss_ctc 11.667856 loss_rnnt 7.717038 hw_loss 0.264172 lr 0.00035367 rank 5
2023-02-22 20:22:28,980 DEBUG TRAIN Batch 23/8100 loss 3.910297 loss_att 6.291739 loss_ctc 5.891287 loss_rnnt 3.059159 hw_loss 0.207596 lr 0.00035361 rank 1
2023-02-22 20:22:28,984 DEBUG TRAIN Batch 23/8100 loss 12.938671 loss_att 15.827440 loss_ctc 20.416386 loss_rnnt 11.309853 hw_loss 0.101319 lr 0.00035358 rank 5
2023-02-22 20:22:28,986 DEBUG TRAIN Batch 23/8100 loss 10.223709 loss_att 11.879496 loss_ctc 13.872971 loss_rnnt 9.298652 hw_loss 0.201249 lr 0.00035355 rank 7
2023-02-22 20:22:28,991 DEBUG TRAIN Batch 23/8100 loss 11.229709 loss_att 14.365943 loss_ctc 17.631733 loss_rnnt 9.620022 hw_loss 0.241567 lr 0.00035364 rank 4
2023-02-22 20:22:28,994 DEBUG TRAIN Batch 23/8100 loss 17.141651 loss_att 22.820290 loss_ctc 24.951500 loss_rnnt 14.805157 hw_loss 0.298971 lr 0.00035359 rank 2
2023-02-22 20:22:28,996 DEBUG TRAIN Batch 23/8100 loss 8.480306 loss_att 14.210647 loss_ctc 15.513607 loss_rnnt 6.282378 hw_loss 0.213911 lr 0.00035356 rank 6
2023-02-22 20:22:28,996 DEBUG TRAIN Batch 23/8100 loss 14.613288 loss_att 16.565720 loss_ctc 17.581047 loss_rnnt 13.712372 hw_loss 0.215118 lr 0.00035363 rank 3
2023-02-22 20:22:29,040 DEBUG TRAIN Batch 23/8100 loss 7.453198 loss_att 9.913721 loss_ctc 10.558477 loss_rnnt 6.396034 hw_loss 0.283168 lr 0.00035365 rank 0
2023-02-22 20:23:41,998 DEBUG TRAIN Batch 23/8200 loss 10.479401 loss_att 11.987052 loss_ctc 16.411125 loss_rnnt 9.214256 hw_loss 0.323847 lr 0.00035347 rank 6
2023-02-22 20:23:42,003 DEBUG TRAIN Batch 23/8200 loss 5.414263 loss_att 6.163407 loss_ctc 6.554586 loss_rnnt 4.989020 hw_loss 0.231320 lr 0.00035356 rank 0
2023-02-22 20:23:42,004 DEBUG TRAIN Batch 23/8200 loss 4.781015 loss_att 5.616374 loss_ctc 5.623422 loss_rnnt 4.324916 hw_loss 0.331325 lr 0.00035350 rank 2
2023-02-22 20:23:42,003 DEBUG TRAIN Batch 23/8200 loss 4.658061 loss_att 7.884911 loss_ctc 5.480950 loss_rnnt 3.775880 hw_loss 0.238298 lr 0.00035352 rank 1
2023-02-22 20:23:42,004 DEBUG TRAIN Batch 23/8200 loss 8.078956 loss_att 14.260298 loss_ctc 16.076160 loss_rnnt 5.680973 hw_loss 0.178912 lr 0.00035346 rank 7
2023-02-22 20:23:42,003 DEBUG TRAIN Batch 23/8200 loss 11.808514 loss_att 11.365170 loss_ctc 16.450548 loss_rnnt 11.170686 hw_loss 0.201672 lr 0.00035354 rank 3
2023-02-22 20:23:42,006 DEBUG TRAIN Batch 23/8200 loss 7.553491 loss_att 8.480810 loss_ctc 9.928909 loss_rnnt 6.951697 hw_loss 0.186764 lr 0.00035356 rank 4
2023-02-22 20:23:42,010 DEBUG TRAIN Batch 23/8200 loss 5.312706 loss_att 8.423470 loss_ctc 8.364093 loss_rnnt 4.208474 hw_loss 0.141051 lr 0.00035349 rank 5
2023-02-22 20:24:54,535 DEBUG TRAIN Batch 23/8300 loss 3.658465 loss_att 7.186370 loss_ctc 5.101795 loss_rnnt 2.563928 hw_loss 0.368460 lr 0.00035341 rank 2
2023-02-22 20:24:54,537 DEBUG TRAIN Batch 23/8300 loss 10.767365 loss_att 13.197060 loss_ctc 17.646933 loss_rnnt 9.286470 hw_loss 0.145651 lr 0.00035347 rank 0
2023-02-22 20:24:54,540 DEBUG TRAIN Batch 23/8300 loss 10.064612 loss_att 11.519979 loss_ctc 16.768515 loss_rnnt 8.805110 hw_loss 0.139831 lr 0.00035343 rank 1
2023-02-22 20:24:54,542 DEBUG TRAIN Batch 23/8300 loss 2.372920 loss_att 5.143676 loss_ctc 3.566701 loss_rnnt 1.480979 hw_loss 0.334911 lr 0.00035338 rank 6
2023-02-22 20:24:54,543 DEBUG TRAIN Batch 23/8300 loss 4.939256 loss_att 7.582888 loss_ctc 7.581698 loss_rnnt 3.845285 hw_loss 0.399224 lr 0.00035346 rank 3
2023-02-22 20:24:54,544 DEBUG TRAIN Batch 23/8300 loss 2.002116 loss_att 4.753513 loss_ctc 2.606525 loss_rnnt 1.130468 hw_loss 0.451462 lr 0.00035338 rank 7
2023-02-22 20:24:54,546 DEBUG TRAIN Batch 23/8300 loss 10.673873 loss_att 12.868148 loss_ctc 17.825583 loss_rnnt 9.134686 hw_loss 0.275193 lr 0.00035341 rank 5
2023-02-22 20:24:54,550 DEBUG TRAIN Batch 23/8300 loss 9.222013 loss_att 13.748674 loss_ctc 15.524956 loss_rnnt 7.333816 hw_loss 0.267136 lr 0.00035347 rank 4
2023-02-22 20:25:41,585 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 1
2023-02-22 20:25:41,591 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 3
2023-02-22 20:25:41,594 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 2
2023-02-22 20:25:41,595 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 0
2023-02-22 20:25:41,596 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 6
2023-02-22 20:25:41,597 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 4
2023-02-22 20:25:41,605 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 7
2023-02-22 20:25:41,618 DEBUG CV Batch 23/0 loss 2.132153 loss_att 1.979306 loss_ctc 2.695740 loss_rnnt 1.681692 hw_loss 0.761037 history loss 2.053185 rank 5
2023-02-22 20:25:53,007 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 2
2023-02-22 20:25:53,042 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 7
2023-02-22 20:25:53,044 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 1
2023-02-22 20:25:53,096 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 4
2023-02-22 20:25:53,112 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 3
2023-02-22 20:25:53,181 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 6
2023-02-22 20:25:53,329 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 0
2023-02-22 20:25:53,502 DEBUG CV Batch 23/100 loss 6.066765 loss_att 7.816225 loss_ctc 10.163596 loss_rnnt 4.996360 hw_loss 0.326754 history loss 3.456155 rank 5
2023-02-22 20:26:06,414 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 2
2023-02-22 20:26:06,501 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 1
2023-02-22 20:26:06,546 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 7
2023-02-22 20:26:06,547 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 3
2023-02-22 20:26:06,654 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 4
2023-02-22 20:26:06,699 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 6
2023-02-22 20:26:06,998 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 0
2023-02-22 20:26:07,310 DEBUG CV Batch 23/200 loss 4.520235 loss_att 12.136030 loss_ctc 4.435359 loss_rnnt 2.955692 hw_loss 0.098813 history loss 4.084460 rank 5
2023-02-22 20:26:18,751 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 7
2023-02-22 20:26:18,765 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 2
2023-02-22 20:26:18,922 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 3
2023-02-22 20:26:18,933 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 1
2023-02-22 20:26:18,957 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 4
2023-02-22 20:26:19,030 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 6
2023-02-22 20:26:19,681 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 5
2023-02-22 20:26:20,009 DEBUG CV Batch 23/300 loss 4.029441 loss_att 4.928717 loss_ctc 6.354546 loss_rnnt 3.370686 hw_loss 0.316661 history loss 4.198390 rank 0
2023-02-22 20:26:30,790 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 2
2023-02-22 20:26:31,036 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 3
2023-02-22 20:26:31,142 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 6
2023-02-22 20:26:31,236 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 4
2023-02-22 20:26:31,249 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 1
2023-02-22 20:26:31,411 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 7
2023-02-22 20:26:32,340 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 5
2023-02-22 20:26:32,692 DEBUG CV Batch 23/400 loss 16.445374 loss_att 83.855064 loss_ctc 6.296220 loss_rnnt 4.215398 hw_loss 0.189858 history loss 5.175554 rank 0
2023-02-22 20:26:41,524 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 2
2023-02-22 20:26:41,750 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 3
2023-02-22 20:26:41,935 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 6
2023-02-22 20:26:42,063 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 4
2023-02-22 20:26:42,328 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 1
2023-02-22 20:26:42,399 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 7
2023-02-22 20:26:43,754 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 5
2023-02-22 20:26:43,846 DEBUG CV Batch 23/500 loss 5.202444 loss_att 5.305850 loss_ctc 6.538509 loss_rnnt 4.898100 hw_loss 0.197850 history loss 5.938994 rank 0
2023-02-22 20:26:53,759 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 2
2023-02-22 20:26:53,888 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 3
2023-02-22 20:26:54,127 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 6
2023-02-22 20:26:54,654 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 7
2023-02-22 20:26:54,665 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 1
2023-02-22 20:26:54,707 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 4
2023-02-22 20:26:56,638 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 5
2023-02-22 20:26:56,638 DEBUG CV Batch 23/600 loss 8.060194 loss_att 7.813058 loss_ctc 10.253958 loss_rnnt 7.555702 hw_loss 0.490158 history loss 6.875127 rank 0
2023-02-22 20:27:05,265 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 2
2023-02-22 20:27:05,347 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 3
2023-02-22 20:27:05,709 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 6
2023-02-22 20:27:06,116 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 1
2023-02-22 20:27:06,230 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 7
2023-02-22 20:27:06,309 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 4
2023-02-22 20:27:08,490 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 0
2023-02-22 20:27:08,567 DEBUG CV Batch 23/700 loss 11.359851 loss_att 41.351288 loss_ctc 13.302446 loss_rnnt 4.975927 hw_loss 0.237420 history loss 7.490653 rank 5
2023-02-22 20:27:16,758 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 2
2023-02-22 20:27:16,832 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 3
2023-02-22 20:27:17,227 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 6
2023-02-22 20:27:17,681 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 1
2023-02-22 20:27:17,872 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 4
2023-02-22 20:27:17,919 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 7
2023-02-22 20:27:20,207 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 0
2023-02-22 20:27:20,289 DEBUG CV Batch 23/800 loss 9.234749 loss_att 10.774552 loss_ctc 16.890621 loss_rnnt 7.720252 hw_loss 0.348286 history loss 6.948666 rank 5
2023-02-22 20:27:30,172 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 2
2023-02-22 20:27:30,190 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 3
2023-02-22 20:27:30,751 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 6
2023-02-22 20:27:31,039 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 1
2023-02-22 20:27:31,472 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 4
2023-02-22 20:27:31,692 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 7
2023-02-22 20:27:33,990 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 5
2023-02-22 20:27:34,057 DEBUG CV Batch 23/900 loss 14.580036 loss_att 18.880199 loss_ctc 26.793459 loss_rnnt 11.990877 hw_loss 0.188754 history loss 6.758683 rank 0
2023-02-22 20:27:42,463 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 2
2023-02-22 20:27:42,511 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 3
2023-02-22 20:27:43,089 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 6
2023-02-22 20:27:43,549 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 1
2023-02-22 20:27:43,985 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 4
2023-02-22 20:27:44,326 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 7
2023-02-22 20:27:46,740 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 5
2023-02-22 20:27:47,111 DEBUG CV Batch 23/1000 loss 4.817786 loss_att 5.297612 loss_ctc 4.971498 loss_rnnt 4.522472 hw_loss 0.335350 history loss 6.520931 rank 0
2023-02-22 20:27:54,485 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 2
2023-02-22 20:27:54,564 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 3
2023-02-22 20:27:55,252 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 6
2023-02-22 20:27:55,458 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 1
2023-02-22 20:27:56,034 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 4
2023-02-22 20:27:56,488 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 7
2023-02-22 20:27:59,015 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 5
2023-02-22 20:28:00,627 DEBUG CV Batch 23/1100 loss 6.214962 loss_att 5.712082 loss_ctc 8.227645 loss_rnnt 5.672306 hw_loss 0.702890 history loss 6.508334 rank 0
2023-02-22 20:28:05,321 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 2
2023-02-22 20:28:05,402 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 3
2023-02-22 20:28:06,095 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 6
2023-02-22 20:28:06,420 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 1
2023-02-22 20:28:06,996 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 4
2023-02-22 20:28:07,598 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 7
2023-02-22 20:28:10,358 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 5
2023-02-22 20:28:11,913 DEBUG CV Batch 23/1200 loss 8.457634 loss_att 7.661872 loss_ctc 8.378781 loss_rnnt 8.389947 hw_loss 0.445036 history loss 6.844521 rank 0
2023-02-22 20:28:17,492 DEBUG CV Batch 23/1300 loss 5.665464 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 2
2023-02-22 20:28:17,530 DEBUG CV Batch 23/1300 loss 5.665465 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 3
2023-02-22 20:28:18,297 DEBUG CV Batch 23/1300 loss 5.665464 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 6
2023-02-22 20:28:18,949 DEBUG CV Batch 23/1300 loss 5.665464 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 1
2023-02-22 20:28:19,122 DEBUG CV Batch 23/1300 loss 5.665464 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 4
2023-02-22 20:28:19,874 DEBUG CV Batch 23/1300 loss 5.665464 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 7
2023-02-22 20:28:22,830 DEBUG CV Batch 23/1300 loss 5.665464 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 5
2023-02-22 20:28:24,714 DEBUG CV Batch 23/1300 loss 5.665464 loss_att 5.595393 loss_ctc 7.834530 loss_rnnt 5.177243 hw_loss 0.399424 history loss 7.158974 rank 0
2023-02-22 20:28:28,896 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 2
2023-02-22 20:28:28,957 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 3
2023-02-22 20:28:29,822 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 6
2023-02-22 20:28:30,647 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 1
2023-02-22 20:28:31,159 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 4
2023-02-22 20:28:31,642 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 7
2023-02-22 20:28:34,428 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 5
2023-02-22 20:28:36,585 DEBUG CV Batch 23/1400 loss 3.670945 loss_att 10.537970 loss_ctc 3.979251 loss_rnnt 2.089182 hw_loss 0.313596 history loss 7.454089 rank 0
2023-02-22 20:28:40,681 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 2
2023-02-22 20:28:40,751 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 3
2023-02-22 20:28:41,534 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 6
2023-02-22 20:28:42,709 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 1
2023-02-22 20:28:42,937 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 4
2023-02-22 20:28:43,549 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 7
2023-02-22 20:28:46,196 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 5
2023-02-22 20:28:48,813 DEBUG CV Batch 23/1500 loss 5.531344 loss_att 6.892951 loss_ctc 4.636587 loss_rnnt 5.208100 hw_loss 0.319169 history loss 7.275612 rank 0
2023-02-22 20:28:53,952 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 2
2023-02-22 20:28:54,029 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 3
2023-02-22 20:28:54,759 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 6
2023-02-22 20:28:56,232 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 1
2023-02-22 20:28:56,379 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 4
2023-02-22 20:28:56,848 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 7
2023-02-22 20:28:59,768 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 5
2023-02-22 20:29:02,355 DEBUG CV Batch 23/1600 loss 6.743198 loss_att 11.100531 loss_ctc 8.215088 loss_rnnt 5.612530 hw_loss 0.118029 history loss 7.211250 rank 0
2023-02-22 20:29:06,401 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 2
2023-02-22 20:29:06,553 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 3
2023-02-22 20:29:07,331 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 6
2023-02-22 20:29:08,725 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 1
2023-02-22 20:29:09,063 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 4
2023-02-22 20:29:09,564 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 7
2023-02-22 20:29:12,377 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 5
2023-02-22 20:29:15,019 DEBUG CV Batch 23/1700 loss 8.664259 loss_att 8.925353 loss_ctc 14.243773 loss_rnnt 7.776149 hw_loss 0.172416 history loss 7.106904 rank 0
2023-02-22 20:29:15,511 INFO Epoch 23 CV info cv_loss 7.07822206850935
2023-02-22 20:29:15,511 INFO Epoch 24 TRAIN info lr 0.0003533758638141094
2023-02-22 20:29:15,516 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:29:15,661 INFO Epoch 23 CV info cv_loss 7.078222067131009
2023-02-22 20:29:15,661 INFO Epoch 24 TRAIN info lr 0.0003534279459349428
2023-02-22 20:29:15,663 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:29:16,487 INFO Epoch 23 CV info cv_loss 7.078222067818026
2023-02-22 20:29:16,487 INFO Epoch 24 TRAIN info lr 0.0003533414492870301
2023-02-22 20:29:16,489 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:29:17,944 INFO Epoch 23 CV info cv_loss 7.078222067150392
2023-02-22 20:29:17,945 INFO Epoch 24 TRAIN info lr 0.0003534129368605052
2023-02-22 20:29:17,951 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:29:18,154 INFO Epoch 23 CV info cv_loss 7.078222069465575
2023-02-22 20:29:18,155 INFO Epoch 24 TRAIN info lr 0.000353431477759784
2023-02-22 20:29:18,160 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:29:18,764 INFO Epoch 23 CV info cv_loss 7.078222068828092
2023-02-22 20:29:18,764 INFO Epoch 24 TRAIN info lr 0.00035332556905000464
2023-02-22 20:29:18,766 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:29:21,588 INFO Epoch 23 CV info cv_loss 7.078222067725419
2023-02-22 20:29:21,589 INFO Epoch 24 TRAIN info lr 0.0003533767463701098
2023-02-22 20:29:21,594 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:29:24,443 INFO Epoch 23 CV info cv_loss 7.078222069579718
2023-02-22 20:29:24,443 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/23.pt
2023-02-22 20:29:29,345 INFO Epoch 24 TRAIN info lr 0.0003534252971357947
2023-02-22 20:29:29,348 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 20:30:30,061 DEBUG TRAIN Batch 24/0 loss 9.761165 loss_att 10.257257 loss_ctc 11.457179 loss_rnnt 9.160391 hw_loss 0.516413 lr 0.00035334 rank 6
2023-02-22 20:30:30,063 DEBUG TRAIN Batch 24/0 loss 8.392951 loss_att 8.283501 loss_ctc 11.339415 loss_rnnt 7.645665 hw_loss 0.705587 lr 0.00035341 rank 1
2023-02-22 20:30:30,064 DEBUG TRAIN Batch 24/0 loss 13.413351 loss_att 12.458493 loss_ctc 17.238390 loss_rnnt 12.715594 hw_loss 0.710106 lr 0.00035343 rank 4
2023-02-22 20:30:30,065 DEBUG TRAIN Batch 24/0 loss 7.124760 loss_att 6.545434 loss_ctc 8.222013 loss_rnnt 6.768117 hw_loss 0.611638 lr 0.00035337 rank 2
2023-02-22 20:30:30,066 DEBUG TRAIN Batch 24/0 loss 8.818397 loss_att 8.232646 loss_ctc 11.347058 loss_rnnt 8.301730 hw_loss 0.556239 lr 0.00035343 rank 3
2023-02-22 20:30:30,102 DEBUG TRAIN Batch 24/0 loss 13.834255 loss_att 12.941228 loss_ctc 16.449568 loss_rnnt 13.335773 hw_loss 0.615713 lr 0.00035338 rank 5
2023-02-22 20:30:30,117 DEBUG TRAIN Batch 24/0 loss 12.196449 loss_att 13.073605 loss_ctc 16.339964 loss_rnnt 11.239672 hw_loss 0.429147 lr 0.00035342 rank 0
2023-02-22 20:30:30,136 DEBUG TRAIN Batch 24/0 loss 9.119991 loss_att 9.302296 loss_ctc 10.849543 loss_rnnt 8.541806 hw_loss 0.583343 lr 0.00035332 rank 7
2023-02-22 20:31:42,194 DEBUG TRAIN Batch 24/100 loss 12.851754 loss_att 18.396397 loss_ctc 22.612854 loss_rnnt 10.267220 hw_loss 0.326484 lr 0.00035329 rank 2
2023-02-22 20:31:42,195 DEBUG TRAIN Batch 24/100 loss 11.368382 loss_att 15.018963 loss_ctc 15.002089 loss_rnnt 10.005820 hw_loss 0.277410 lr 0.00035325 rank 6
2023-02-22 20:31:42,198 DEBUG TRAIN Batch 24/100 loss 9.293399 loss_att 12.355926 loss_ctc 14.872421 loss_rnnt 7.801065 hw_loss 0.254923 lr 0.00035332 rank 1
2023-02-22 20:31:42,199 DEBUG TRAIN Batch 24/100 loss 6.048789 loss_att 10.292838 loss_ctc 12.311871 loss_rnnt 4.178581 hw_loss 0.349351 lr 0.00035334 rank 0
2023-02-22 20:31:42,199 DEBUG TRAIN Batch 24/100 loss 5.537135 loss_att 7.107552 loss_ctc 7.423209 loss_rnnt 4.822762 hw_loss 0.279026 lr 0.00035334 rank 3
2023-02-22 20:31:42,202 DEBUG TRAIN Batch 24/100 loss 16.046570 loss_att 21.690384 loss_ctc 19.576372 loss_rnnt 14.275081 hw_loss 0.322663 lr 0.00035324 rank 7
2023-02-22 20:31:42,204 DEBUG TRAIN Batch 24/100 loss 4.775949 loss_att 6.651993 loss_ctc 5.440721 loss_rnnt 4.162403 hw_loss 0.280689 lr 0.00035334 rank 4
2023-02-22 20:31:42,211 DEBUG TRAIN Batch 24/100 loss 9.107933 loss_att 10.219299 loss_ctc 10.068830 loss_rnnt 8.630949 hw_loss 0.237357 lr 0.00035329 rank 5
2023-02-22 20:32:54,253 DEBUG TRAIN Batch 24/200 loss 8.316895 loss_att 9.508027 loss_ctc 9.236734 loss_rnnt 7.780975 hw_loss 0.328214 lr 0.00035325 rank 4
2023-02-22 20:32:54,267 DEBUG TRAIN Batch 24/200 loss 4.687666 loss_att 8.805132 loss_ctc 5.648889 loss_rnnt 3.634632 hw_loss 0.190083 lr 0.00035320 rank 2
2023-02-22 20:32:54,268 DEBUG TRAIN Batch 24/200 loss 9.176342 loss_att 13.879213 loss_ctc 14.655838 loss_rnnt 7.297984 hw_loss 0.388470 lr 0.00035315 rank 7
2023-02-22 20:32:54,270 DEBUG TRAIN Batch 24/200 loss 8.138740 loss_att 12.253545 loss_ctc 12.062973 loss_rnnt 6.710378 hw_loss 0.154068 lr 0.00035320 rank 5
2023-02-22 20:32:54,269 DEBUG TRAIN Batch 24/200 loss 8.060443 loss_att 10.201718 loss_ctc 10.852573 loss_rnnt 7.055737 hw_loss 0.382813 lr 0.00035325 rank 3
2023-02-22 20:32:54,270 DEBUG TRAIN Batch 24/200 loss 7.477891 loss_att 12.365461 loss_ctc 13.531334 loss_rnnt 5.427050 hw_loss 0.499128 lr 0.00035316 rank 6
2023-02-22 20:32:54,274 DEBUG TRAIN Batch 24/200 loss 4.559852 loss_att 6.694026 loss_ctc 4.638908 loss_rnnt 4.027830 hw_loss 0.177463 lr 0.00035325 rank 0
2023-02-22 20:32:54,323 DEBUG TRAIN Batch 24/200 loss 11.416331 loss_att 13.297891 loss_ctc 18.656223 loss_rnnt 9.940063 hw_loss 0.252444 lr 0.00035324 rank 1
2023-02-22 20:34:08,141 DEBUG TRAIN Batch 24/300 loss 7.423538 loss_att 11.009949 loss_ctc 11.687264 loss_rnnt 6.007854 hw_loss 0.243574 lr 0.00035311 rank 2
2023-02-22 20:34:08,143 DEBUG TRAIN Batch 24/300 loss 5.725410 loss_att 7.894649 loss_ctc 10.754875 loss_rnnt 4.447478 hw_loss 0.325291 lr 0.00035311 rank 5
2023-02-22 20:34:08,143 DEBUG TRAIN Batch 24/300 loss 14.653803 loss_att 17.814600 loss_ctc 22.257710 loss_rnnt 12.863517 hw_loss 0.270510 lr 0.00035316 rank 3
2023-02-22 20:34:08,145 DEBUG TRAIN Batch 24/300 loss 15.726850 loss_att 19.445414 loss_ctc 23.078880 loss_rnnt 13.935890 hw_loss 0.125580 lr 0.00035317 rank 4
2023-02-22 20:34:08,146 DEBUG TRAIN Batch 24/300 loss 6.514478 loss_att 8.134671 loss_ctc 12.014853 loss_rnnt 5.267951 hw_loss 0.354572 lr 0.00035308 rank 6
2023-02-22 20:34:08,147 DEBUG TRAIN Batch 24/300 loss 10.606214 loss_att 21.035913 loss_ctc 17.654884 loss_rnnt 7.493842 hw_loss 0.162391 lr 0.00035306 rank 7
2023-02-22 20:34:08,148 DEBUG TRAIN Batch 24/300 loss 9.194895 loss_att 12.145329 loss_ctc 12.263526 loss_rnnt 8.049096 hw_loss 0.274802 lr 0.00035316 rank 0
2023-02-22 20:34:08,180 DEBUG TRAIN Batch 24/300 loss 8.255158 loss_att 10.154593 loss_ctc 10.379404 loss_rnnt 7.441385 hw_loss 0.282476 lr 0.00035315 rank 1
2023-02-22 20:35:22,028 DEBUG TRAIN Batch 24/400 loss 5.680292 loss_att 8.098341 loss_ctc 7.412971 loss_rnnt 4.784398 hw_loss 0.339863 lr 0.00035302 rank 2
2023-02-22 20:35:22,028 DEBUG TRAIN Batch 24/400 loss 8.879480 loss_att 12.233000 loss_ctc 13.725981 loss_rnnt 7.450541 hw_loss 0.210067 lr 0.00035297 rank 7
2023-02-22 20:35:22,031 DEBUG TRAIN Batch 24/400 loss 8.521565 loss_att 12.013489 loss_ctc 15.404249 loss_rnnt 6.712458 hw_loss 0.361933 lr 0.00035307 rank 3
2023-02-22 20:35:22,034 DEBUG TRAIN Batch 24/400 loss 2.611459 loss_att 4.558144 loss_ctc 4.187743 loss_rnnt 1.933451 hw_loss 0.147186 lr 0.00035306 rank 1
2023-02-22 20:35:22,035 DEBUG TRAIN Batch 24/400 loss 10.423142 loss_att 11.543062 loss_ctc 14.071987 loss_rnnt 9.600086 hw_loss 0.211047 lr 0.00035299 rank 6
2023-02-22 20:35:22,036 DEBUG TRAIN Batch 24/400 loss 6.818947 loss_att 9.669068 loss_ctc 13.466306 loss_rnnt 5.103818 hw_loss 0.485231 lr 0.00035302 rank 5
2023-02-22 20:35:22,037 DEBUG TRAIN Batch 24/400 loss 7.939841 loss_att 10.039494 loss_ctc 9.724424 loss_rnnt 7.126963 hw_loss 0.290629 lr 0.00035308 rank 4
2023-02-22 20:35:22,037 DEBUG TRAIN Batch 24/400 loss 15.272781 loss_att 15.196270 loss_ctc 20.843521 loss_rnnt 14.375012 hw_loss 0.319322 lr 0.00035307 rank 0
2023-02-22 20:36:34,494 DEBUG TRAIN Batch 24/500 loss 7.156154 loss_att 9.368793 loss_ctc 10.696692 loss_rnnt 6.102325 hw_loss 0.261055 lr 0.00035299 rank 4
2023-02-22 20:36:34,494 DEBUG TRAIN Batch 24/500 loss 10.243910 loss_att 11.706514 loss_ctc 14.461330 loss_rnnt 9.268638 hw_loss 0.225804 lr 0.00035299 rank 3
2023-02-22 20:36:34,496 DEBUG TRAIN Batch 24/500 loss 7.135541 loss_att 8.924941 loss_ctc 8.728289 loss_rnnt 6.439067 hw_loss 0.236676 lr 0.00035293 rank 2
2023-02-22 20:36:34,496 DEBUG TRAIN Batch 24/500 loss 10.990394 loss_att 11.874466 loss_ctc 13.794310 loss_rnnt 10.331520 hw_loss 0.202881 lr 0.00035290 rank 6
2023-02-22 20:36:34,499 DEBUG TRAIN Batch 24/500 loss 11.594203 loss_att 13.141182 loss_ctc 14.549367 loss_rnnt 10.747805 hw_loss 0.268088 lr 0.00035298 rank 0
2023-02-22 20:36:34,509 DEBUG TRAIN Batch 24/500 loss 10.377700 loss_att 10.280712 loss_ctc 13.033022 loss_rnnt 9.930454 hw_loss 0.211127 lr 0.00035288 rank 7
2023-02-22 20:36:34,531 DEBUG TRAIN Batch 24/500 loss 21.789202 loss_att 19.832603 loss_ctc 29.429703 loss_rnnt 21.091782 hw_loss 0.131260 lr 0.00035294 rank 5
2023-02-22 20:36:34,547 DEBUG TRAIN Batch 24/500 loss 12.616970 loss_att 13.780123 loss_ctc 18.445723 loss_rnnt 11.517355 hw_loss 0.168410 lr 0.00035297 rank 1
2023-02-22 20:37:47,126 DEBUG TRAIN Batch 24/600 loss 7.341388 loss_att 8.515757 loss_ctc 10.592353 loss_rnnt 6.455670 hw_loss 0.407588 lr 0.00035290 rank 3
2023-02-22 20:37:47,131 DEBUG TRAIN Batch 24/600 loss 8.601542 loss_att 9.554079 loss_ctc 11.269777 loss_rnnt 7.785323 hw_loss 0.506151 lr 0.00035281 rank 6
2023-02-22 20:37:47,131 DEBUG TRAIN Batch 24/600 loss 9.638878 loss_att 9.183566 loss_ctc 12.319582 loss_rnnt 9.240814 hw_loss 0.246936 lr 0.00035285 rank 5
2023-02-22 20:37:47,133 DEBUG TRAIN Batch 24/600 loss 9.810142 loss_att 10.697888 loss_ctc 14.667243 loss_rnnt 8.795054 hw_loss 0.356110 lr 0.00035280 rank 7
2023-02-22 20:37:47,132 DEBUG TRAIN Batch 24/600 loss 5.147650 loss_att 5.742673 loss_ctc 6.932936 loss_rnnt 4.605292 hw_loss 0.347465 lr 0.00035285 rank 2
2023-02-22 20:37:47,139 DEBUG TRAIN Batch 24/600 loss 9.224338 loss_att 9.909916 loss_ctc 13.834315 loss_rnnt 8.309855 hw_loss 0.305070 lr 0.00035288 rank 1
2023-02-22 20:37:47,140 DEBUG TRAIN Batch 24/600 loss 11.190766 loss_att 14.128072 loss_ctc 13.956705 loss_rnnt 10.093668 hw_loss 0.264085 lr 0.00035290 rank 0
2023-02-22 20:37:47,179 DEBUG TRAIN Batch 24/600 loss 6.534412 loss_att 10.027387 loss_ctc 10.242354 loss_rnnt 5.145817 hw_loss 0.366765 lr 0.00035290 rank 4
2023-02-22 20:39:01,988 DEBUG TRAIN Batch 24/700 loss 8.081393 loss_att 12.079097 loss_ctc 11.483203 loss_rnnt 6.710233 hw_loss 0.221334 lr 0.00035281 rank 3
2023-02-22 20:39:01,993 DEBUG TRAIN Batch 24/700 loss 10.661475 loss_att 15.327106 loss_ctc 11.995245 loss_rnnt 9.441198 hw_loss 0.204966 lr 0.00035272 rank 6
2023-02-22 20:39:01,997 DEBUG TRAIN Batch 24/700 loss 5.523602 loss_att 11.484072 loss_ctc 9.587807 loss_rnnt 3.730016 hw_loss 0.111745 lr 0.00035276 rank 5
2023-02-22 20:39:01,998 DEBUG TRAIN Batch 24/700 loss 10.897388 loss_att 14.095526 loss_ctc 13.852703 loss_rnnt 9.618958 hw_loss 0.458928 lr 0.00035280 rank 1
2023-02-22 20:39:02,005 DEBUG TRAIN Batch 24/700 loss 6.982389 loss_att 10.785027 loss_ctc 9.618064 loss_rnnt 5.772620 hw_loss 0.183411 lr 0.00035276 rank 2
2023-02-22 20:39:02,023 DEBUG TRAIN Batch 24/700 loss 2.179036 loss_att 3.762144 loss_ctc 3.173267 loss_rnnt 1.554191 hw_loss 0.329363 lr 0.00035271 rank 7
2023-02-22 20:39:02,031 DEBUG TRAIN Batch 24/700 loss 4.437785 loss_att 6.232284 loss_ctc 9.203864 loss_rnnt 3.216379 hw_loss 0.425680 lr 0.00035281 rank 0
2023-02-22 20:39:02,044 DEBUG TRAIN Batch 24/700 loss 15.410519 loss_att 20.216461 loss_ctc 19.444273 loss_rnnt 13.758047 hw_loss 0.287719 lr 0.00035281 rank 4
2023-02-22 20:40:14,343 DEBUG TRAIN Batch 24/800 loss 3.242930 loss_att 4.614725 loss_ctc 3.777793 loss_rnnt 2.744183 hw_loss 0.287012 lr 0.00035271 rank 1
2023-02-22 20:40:14,344 DEBUG TRAIN Batch 24/800 loss 7.044424 loss_att 10.113403 loss_ctc 10.196383 loss_rnnt 5.955131 hw_loss 0.103567 lr 0.00035267 rank 2
2023-02-22 20:40:14,345 DEBUG TRAIN Batch 24/800 loss 13.296361 loss_att 15.826332 loss_ctc 16.008053 loss_rnnt 12.287112 hw_loss 0.265679 lr 0.00035272 rank 3
2023-02-22 20:40:14,346 DEBUG TRAIN Batch 24/800 loss 7.641013 loss_att 11.795624 loss_ctc 8.565132 loss_rnnt 6.596973 hw_loss 0.168566 lr 0.00035273 rank 4
2023-02-22 20:40:14,347 DEBUG TRAIN Batch 24/800 loss 6.141668 loss_att 8.954347 loss_ctc 10.143639 loss_rnnt 4.938490 hw_loss 0.200712 lr 0.00035262 rank 7
2023-02-22 20:40:14,347 DEBUG TRAIN Batch 24/800 loss 19.609928 loss_att 20.542534 loss_ctc 29.428463 loss_rnnt 18.049765 hw_loss 0.120945 lr 0.00035264 rank 6
2023-02-22 20:40:14,350 DEBUG TRAIN Batch 24/800 loss 6.039986 loss_att 9.547002 loss_ctc 7.183296 loss_rnnt 5.069778 hw_loss 0.218180 lr 0.00035272 rank 0
2023-02-22 20:40:14,404 DEBUG TRAIN Batch 24/800 loss 27.194040 loss_att 31.842402 loss_ctc 43.636253 loss_rnnt 23.960014 hw_loss 0.210110 lr 0.00035267 rank 5
2023-02-22 20:41:26,471 DEBUG TRAIN Batch 24/900 loss 6.316599 loss_att 9.154385 loss_ctc 7.541488 loss_rnnt 5.508831 hw_loss 0.144173 lr 0.00035264 rank 3
2023-02-22 20:41:26,471 DEBUG TRAIN Batch 24/900 loss 5.211607 loss_att 9.345799 loss_ctc 9.013109 loss_rnnt 3.716121 hw_loss 0.303340 lr 0.00035255 rank 6
2023-02-22 20:41:26,472 DEBUG TRAIN Batch 24/900 loss 12.045263 loss_att 12.254440 loss_ctc 21.355328 loss_rnnt 10.584912 hw_loss 0.332201 lr 0.00035258 rank 2
2023-02-22 20:41:26,474 DEBUG TRAIN Batch 24/900 loss 6.853130 loss_att 9.785660 loss_ctc 9.631847 loss_rnnt 5.742789 hw_loss 0.287510 lr 0.00035258 rank 5
2023-02-22 20:41:26,477 DEBUG TRAIN Batch 24/900 loss 10.616095 loss_att 11.745573 loss_ctc 14.464710 loss_rnnt 9.737067 hw_loss 0.262469 lr 0.00035264 rank 4
2023-02-22 20:41:26,479 DEBUG TRAIN Batch 24/900 loss 6.151546 loss_att 9.591717 loss_ctc 9.456287 loss_rnnt 4.931932 hw_loss 0.170527 lr 0.00035263 rank 0
2023-02-22 20:41:26,487 DEBUG TRAIN Batch 24/900 loss 5.732609 loss_att 8.633268 loss_ctc 8.093791 loss_rnnt 4.716311 hw_loss 0.227516 lr 0.00035262 rank 1
2023-02-22 20:41:26,522 DEBUG TRAIN Batch 24/900 loss 12.610147 loss_att 15.403122 loss_ctc 20.040638 loss_rnnt 10.939050 hw_loss 0.228316 lr 0.00035253 rank 7
2023-02-22 20:42:39,470 DEBUG TRAIN Batch 24/1000 loss 11.026661 loss_att 12.414238 loss_ctc 11.815996 loss_rnnt 10.502073 hw_loss 0.265925 lr 0.00035250 rank 5
2023-02-22 20:42:39,473 DEBUG TRAIN Batch 24/1000 loss 13.003876 loss_att 14.545679 loss_ctc 16.854445 loss_rnnt 12.048535 hw_loss 0.250443 lr 0.00035254 rank 0
2023-02-22 20:42:39,473 DEBUG TRAIN Batch 24/1000 loss 14.980301 loss_att 17.816795 loss_ctc 20.980000 loss_rnnt 13.516836 hw_loss 0.180387 lr 0.00035250 rank 2
2023-02-22 20:42:39,479 DEBUG TRAIN Batch 24/1000 loss 12.643869 loss_att 15.891878 loss_ctc 15.160469 loss_rnnt 11.568621 hw_loss 0.168938 lr 0.00035255 rank 3
2023-02-22 20:42:39,480 DEBUG TRAIN Batch 24/1000 loss 7.374020 loss_att 9.749454 loss_ctc 8.613760 loss_rnnt 6.600882 hw_loss 0.248912 lr 0.00035246 rank 6
2023-02-22 20:42:39,480 DEBUG TRAIN Batch 24/1000 loss 8.678648 loss_att 14.633278 loss_ctc 16.327641 loss_rnnt 6.292792 hw_loss 0.328245 lr 0.00035255 rank 4
2023-02-22 20:42:39,483 DEBUG TRAIN Batch 24/1000 loss 5.868885 loss_att 8.367085 loss_ctc 10.144929 loss_rnnt 4.669608 hw_loss 0.242809 lr 0.00035245 rank 7
2023-02-22 20:42:39,533 DEBUG TRAIN Batch 24/1000 loss 14.477882 loss_att 18.860432 loss_ctc 15.234232 loss_rnnt 13.319246 hw_loss 0.339898 lr 0.00035253 rank 1
2023-02-22 20:43:53,589 DEBUG TRAIN Batch 24/1100 loss 10.655091 loss_att 10.038427 loss_ctc 14.162831 loss_rnnt 10.121018 hw_loss 0.355699 lr 0.00035236 rank 7
2023-02-22 20:43:53,589 DEBUG TRAIN Batch 24/1100 loss 4.858936 loss_att 5.962826 loss_ctc 4.970627 loss_rnnt 4.488132 hw_loss 0.253377 lr 0.00035246 rank 0
2023-02-22 20:43:53,590 DEBUG TRAIN Batch 24/1100 loss 8.641351 loss_att 10.590808 loss_ctc 13.074972 loss_rnnt 7.525344 hw_loss 0.253063 lr 0.00035246 rank 3
2023-02-22 20:43:53,591 DEBUG TRAIN Batch 24/1100 loss 4.115919 loss_att 6.414384 loss_ctc 4.826392 loss_rnnt 3.379927 hw_loss 0.340441 lr 0.00035237 rank 6
2023-02-22 20:43:53,592 DEBUG TRAIN Batch 24/1100 loss 9.715334 loss_att 10.376557 loss_ctc 15.127060 loss_rnnt 8.795680 hw_loss 0.123463 lr 0.00035241 rank 2
2023-02-22 20:43:53,592 DEBUG TRAIN Batch 24/1100 loss 16.876188 loss_att 20.883583 loss_ctc 28.306202 loss_rnnt 14.454884 hw_loss 0.179668 lr 0.00035241 rank 5
2023-02-22 20:43:53,598 DEBUG TRAIN Batch 24/1100 loss 7.176180 loss_att 8.943347 loss_ctc 10.748550 loss_rnnt 6.244941 hw_loss 0.190295 lr 0.00035246 rank 4
2023-02-22 20:43:53,600 DEBUG TRAIN Batch 24/1100 loss 10.549807 loss_att 12.075216 loss_ctc 17.148930 loss_rnnt 9.209967 hw_loss 0.290390 lr 0.00035244 rank 1
2023-02-22 20:45:05,651 DEBUG TRAIN Batch 24/1200 loss 14.065730 loss_att 13.878704 loss_ctc 17.619080 loss_rnnt 13.448378 hw_loss 0.339334 lr 0.00035232 rank 2
2023-02-22 20:45:05,651 DEBUG TRAIN Batch 24/1200 loss 6.300533 loss_att 7.858999 loss_ctc 8.108163 loss_rnnt 5.557940 hw_loss 0.356029 lr 0.00035237 rank 3
2023-02-22 20:45:05,655 DEBUG TRAIN Batch 24/1200 loss 5.450624 loss_att 7.291860 loss_ctc 10.469553 loss_rnnt 4.304279 hw_loss 0.204201 lr 0.00035237 rank 0
2023-02-22 20:45:05,657 DEBUG TRAIN Batch 24/1200 loss 4.928256 loss_att 6.431300 loss_ctc 6.780963 loss_rnnt 4.252616 hw_loss 0.240006 lr 0.00035238 rank 4
2023-02-22 20:45:05,657 DEBUG TRAIN Batch 24/1200 loss 8.171422 loss_att 10.032509 loss_ctc 11.012374 loss_rnnt 7.250429 hw_loss 0.318717 lr 0.00035229 rank 6
2023-02-22 20:45:05,658 DEBUG TRAIN Batch 24/1200 loss 10.801000 loss_att 11.780039 loss_ctc 14.893781 loss_rnnt 9.891289 hw_loss 0.315372 lr 0.00035227 rank 7
2023-02-22 20:45:05,695 DEBUG TRAIN Batch 24/1200 loss 5.905869 loss_att 9.761549 loss_ctc 9.108988 loss_rnnt 4.578979 hw_loss 0.241261 lr 0.00035236 rank 1
2023-02-22 20:45:05,705 DEBUG TRAIN Batch 24/1200 loss 11.466461 loss_att 17.602259 loss_ctc 19.182388 loss_rnnt 9.012356 hw_loss 0.371541 lr 0.00035232 rank 5
2023-02-22 20:46:18,499 DEBUG TRAIN Batch 24/1300 loss 9.822099 loss_att 9.749506 loss_ctc 12.234157 loss_rnnt 9.249060 hw_loss 0.498654 lr 0.00035228 rank 3
2023-02-22 20:46:18,502 DEBUG TRAIN Batch 24/1300 loss 6.670464 loss_att 11.730638 loss_ctc 14.642154 loss_rnnt 4.463637 hw_loss 0.247310 lr 0.00035220 rank 6
2023-02-22 20:46:18,503 DEBUG TRAIN Batch 24/1300 loss 7.281427 loss_att 7.868562 loss_ctc 10.103250 loss_rnnt 6.578693 hw_loss 0.391995 lr 0.00035229 rank 4
2023-02-22 20:46:18,506 DEBUG TRAIN Batch 24/1300 loss 9.660580 loss_att 13.003866 loss_ctc 12.166864 loss_rnnt 8.617046 hw_loss 0.076323 lr 0.00035223 rank 2
2023-02-22 20:46:18,508 DEBUG TRAIN Batch 24/1300 loss 6.363747 loss_att 7.775809 loss_ctc 7.138283 loss_rnnt 5.859145 hw_loss 0.222971 lr 0.00035218 rank 7
2023-02-22 20:46:18,511 DEBUG TRAIN Batch 24/1300 loss 10.289450 loss_att 12.241369 loss_ctc 15.457571 loss_rnnt 9.075683 hw_loss 0.251814 lr 0.00035227 rank 1
2023-02-22 20:46:18,514 DEBUG TRAIN Batch 24/1300 loss 7.355076 loss_att 7.432070 loss_ctc 9.224692 loss_rnnt 6.801812 hw_loss 0.541094 lr 0.00035223 rank 5
2023-02-22 20:46:18,553 DEBUG TRAIN Batch 24/1300 loss 9.871658 loss_att 11.336712 loss_ctc 15.075705 loss_rnnt 8.770689 hw_loss 0.213909 lr 0.00035228 rank 0
2023-02-22 20:47:33,151 DEBUG TRAIN Batch 24/1400 loss 7.409208 loss_att 11.215403 loss_ctc 12.031963 loss_rnnt 5.924446 hw_loss 0.200918 lr 0.00035220 rank 3
2023-02-22 20:47:33,152 DEBUG TRAIN Batch 24/1400 loss 8.665475 loss_att 11.658192 loss_ctc 12.416098 loss_rnnt 7.420223 hw_loss 0.274923 lr 0.00035211 rank 6
2023-02-22 20:47:33,156 DEBUG TRAIN Batch 24/1400 loss 8.532714 loss_att 10.510294 loss_ctc 11.211515 loss_rnnt 7.595276 hw_loss 0.346403 lr 0.00035218 rank 1
2023-02-22 20:47:33,158 DEBUG TRAIN Batch 24/1400 loss 16.084265 loss_att 19.144497 loss_ctc 21.480215 loss_rnnt 14.616950 hw_loss 0.254640 lr 0.00035219 rank 0
2023-02-22 20:47:33,161 DEBUG TRAIN Batch 24/1400 loss 7.319956 loss_att 10.414768 loss_ctc 8.975941 loss_rnnt 6.293371 hw_loss 0.350296 lr 0.00035220 rank 4
2023-02-22 20:47:33,161 DEBUG TRAIN Batch 24/1400 loss 6.791624 loss_att 12.144343 loss_ctc 13.377840 loss_rnnt 4.686143 hw_loss 0.293953 lr 0.00035210 rank 7
2023-02-22 20:47:33,182 DEBUG TRAIN Batch 24/1400 loss 6.756065 loss_att 11.627935 loss_ctc 10.898139 loss_rnnt 5.145030 hw_loss 0.158222 lr 0.00035215 rank 2
2023-02-22 20:47:33,192 DEBUG TRAIN Batch 24/1400 loss 5.392589 loss_att 9.259275 loss_ctc 7.187398 loss_rnnt 4.257408 hw_loss 0.229755 lr 0.00035215 rank 5
2023-02-22 20:48:46,353 DEBUG TRAIN Batch 24/1500 loss 13.125607 loss_att 16.212200 loss_ctc 14.815338 loss_rnnt 12.116028 hw_loss 0.313052 lr 0.00035211 rank 3
2023-02-22 20:48:46,354 DEBUG TRAIN Batch 24/1500 loss 4.905452 loss_att 8.835604 loss_ctc 8.770586 loss_rnnt 3.437090 hw_loss 0.313088 lr 0.00035206 rank 2
2023-02-22 20:48:46,358 DEBUG TRAIN Batch 24/1500 loss 2.625219 loss_att 5.222433 loss_ctc 4.334803 loss_rnnt 1.834111 hw_loss 0.081975 lr 0.00035210 rank 1
2023-02-22 20:48:46,359 DEBUG TRAIN Batch 24/1500 loss 2.199315 loss_att 4.497511 loss_ctc 3.959531 loss_rnnt 1.346103 hw_loss 0.297896 lr 0.00035211 rank 0
2023-02-22 20:48:46,359 DEBUG TRAIN Batch 24/1500 loss 7.040353 loss_att 12.448603 loss_ctc 13.392894 loss_rnnt 4.947124 hw_loss 0.308574 lr 0.00035202 rank 6
2023-02-22 20:48:46,361 DEBUG TRAIN Batch 24/1500 loss 10.159420 loss_att 14.201314 loss_ctc 16.452379 loss_rnnt 8.324955 hw_loss 0.350672 lr 0.00035201 rank 7
2023-02-22 20:48:46,363 DEBUG TRAIN Batch 24/1500 loss 9.949742 loss_att 11.579538 loss_ctc 12.354953 loss_rnnt 9.138563 hw_loss 0.308485 lr 0.00035206 rank 5
2023-02-22 20:48:46,366 DEBUG TRAIN Batch 24/1500 loss 5.966739 loss_att 8.248345 loss_ctc 8.832676 loss_rnnt 5.000171 hw_loss 0.240228 lr 0.00035211 rank 4
2023-02-22 20:49:58,049 DEBUG TRAIN Batch 24/1600 loss 11.392031 loss_att 14.652369 loss_ctc 17.826086 loss_rnnt 9.781509 hw_loss 0.188584 lr 0.00035192 rank 7
2023-02-22 20:49:58,051 DEBUG TRAIN Batch 24/1600 loss 5.985776 loss_att 9.044632 loss_ctc 8.442115 loss_rnnt 4.957279 hw_loss 0.167276 lr 0.00035201 rank 1
2023-02-22 20:49:58,052 DEBUG TRAIN Batch 24/1600 loss 8.189018 loss_att 9.584005 loss_ctc 9.688250 loss_rnnt 7.542075 hw_loss 0.315092 lr 0.00035202 rank 3
2023-02-22 20:49:58,051 DEBUG TRAIN Batch 24/1600 loss 6.253193 loss_att 9.231038 loss_ctc 11.518087 loss_rnnt 4.846974 hw_loss 0.203743 lr 0.00035197 rank 2
2023-02-22 20:49:58,052 DEBUG TRAIN Batch 24/1600 loss 11.035617 loss_att 13.982887 loss_ctc 12.260479 loss_rnnt 10.121747 hw_loss 0.302065 lr 0.00035194 rank 6
2023-02-22 20:49:58,054 DEBUG TRAIN Batch 24/1600 loss 5.666798 loss_att 7.401963 loss_ctc 10.526285 loss_rnnt 4.446949 hw_loss 0.421658 lr 0.00035202 rank 0
2023-02-22 20:49:58,056 DEBUG TRAIN Batch 24/1600 loss 3.375990 loss_att 5.266830 loss_ctc 5.123453 loss_rnnt 2.587607 hw_loss 0.332287 lr 0.00035203 rank 4
2023-02-22 20:49:58,062 DEBUG TRAIN Batch 24/1600 loss 1.638257 loss_att 5.003564 loss_ctc 3.110869 loss_rnnt 0.659726 hw_loss 0.204604 lr 0.00035197 rank 5
2023-02-22 20:51:10,522 DEBUG TRAIN Batch 24/1700 loss 6.624027 loss_att 8.719080 loss_ctc 7.597150 loss_rnnt 5.900309 hw_loss 0.328046 lr 0.00035183 rank 7
2023-02-22 20:51:10,527 DEBUG TRAIN Batch 24/1700 loss 11.639270 loss_att 12.913021 loss_ctc 18.458399 loss_rnnt 10.332787 hw_loss 0.267217 lr 0.00035189 rank 5
2023-02-22 20:51:10,530 DEBUG TRAIN Batch 24/1700 loss 8.375342 loss_att 10.351431 loss_ctc 9.567654 loss_rnnt 7.695975 hw_loss 0.234703 lr 0.00035188 rank 2
2023-02-22 20:51:10,536 DEBUG TRAIN Batch 24/1700 loss 9.159096 loss_att 12.088514 loss_ctc 10.868771 loss_rnnt 8.207905 hw_loss 0.257532 lr 0.00035192 rank 1
2023-02-22 20:51:10,537 DEBUG TRAIN Batch 24/1700 loss 8.518774 loss_att 10.636825 loss_ctc 12.827670 loss_rnnt 7.426307 hw_loss 0.176882 lr 0.00035194 rank 3
2023-02-22 20:51:10,543 DEBUG TRAIN Batch 24/1700 loss 3.853164 loss_att 6.074473 loss_ctc 5.064880 loss_rnnt 3.123775 hw_loss 0.231685 lr 0.00035185 rank 6
2023-02-22 20:51:10,560 DEBUG TRAIN Batch 24/1700 loss 8.041484 loss_att 11.542244 loss_ctc 15.059557 loss_rnnt 6.266985 hw_loss 0.259882 lr 0.00035194 rank 4
2023-02-22 20:51:10,574 DEBUG TRAIN Batch 24/1700 loss 6.615540 loss_att 9.349962 loss_ctc 12.793366 loss_rnnt 5.185695 hw_loss 0.111095 lr 0.00035193 rank 0
2023-02-22 20:52:25,072 DEBUG TRAIN Batch 24/1800 loss 10.577666 loss_att 12.001822 loss_ctc 12.373688 loss_rnnt 9.856461 hw_loss 0.369198 lr 0.00035185 rank 3
2023-02-22 20:52:25,074 DEBUG TRAIN Batch 24/1800 loss 8.813031 loss_att 10.985447 loss_ctc 12.143318 loss_rnnt 7.781927 hw_loss 0.286096 lr 0.00035180 rank 2
2023-02-22 20:52:25,075 DEBUG TRAIN Batch 24/1800 loss 15.251106 loss_att 14.981275 loss_ctc 23.936508 loss_rnnt 14.020391 hw_loss 0.237427 lr 0.00035180 rank 5
2023-02-22 20:52:25,078 DEBUG TRAIN Batch 24/1800 loss 11.215863 loss_att 14.016343 loss_ctc 15.195535 loss_rnnt 10.004065 hw_loss 0.227024 lr 0.00035185 rank 0
2023-02-22 20:52:25,080 DEBUG TRAIN Batch 24/1800 loss 5.600899 loss_att 7.846233 loss_ctc 8.186865 loss_rnnt 4.581008 hw_loss 0.423804 lr 0.00035176 rank 6
2023-02-22 20:52:25,084 DEBUG TRAIN Batch 24/1800 loss 13.135523 loss_att 15.324878 loss_ctc 21.962233 loss_rnnt 11.344249 hw_loss 0.330954 lr 0.00035175 rank 7
2023-02-22 20:52:25,089 DEBUG TRAIN Batch 24/1800 loss 3.100445 loss_att 6.481182 loss_ctc 6.733444 loss_rnnt 1.779907 hw_loss 0.299984 lr 0.00035183 rank 1
2023-02-22 20:52:25,126 DEBUG TRAIN Batch 24/1800 loss 16.412582 loss_att 18.169121 loss_ctc 19.961653 loss_rnnt 15.347221 hw_loss 0.451584 lr 0.00035185 rank 4
2023-02-22 20:53:37,375 DEBUG TRAIN Batch 24/1900 loss 14.044162 loss_att 19.038486 loss_ctc 21.089794 loss_rnnt 11.990759 hw_loss 0.215852 lr 0.00035166 rank 7
2023-02-22 20:53:37,385 DEBUG TRAIN Batch 24/1900 loss 11.582695 loss_att 13.591980 loss_ctc 14.049842 loss_rnnt 10.685397 hw_loss 0.312163 lr 0.00035171 rank 2
2023-02-22 20:53:37,389 DEBUG TRAIN Batch 24/1900 loss 9.189173 loss_att 9.735235 loss_ctc 10.143813 loss_rnnt 8.773112 hw_loss 0.336680 lr 0.00035176 rank 0
2023-02-22 20:53:37,388 DEBUG TRAIN Batch 24/1900 loss 7.801277 loss_att 8.359480 loss_ctc 9.641886 loss_rnnt 7.146158 hw_loss 0.558871 lr 0.00035176 rank 3
2023-02-22 20:53:37,391 DEBUG TRAIN Batch 24/1900 loss 14.628141 loss_att 13.808941 loss_ctc 19.637070 loss_rnnt 13.952669 hw_loss 0.321476 lr 0.00035176 rank 4
2023-02-22 20:53:37,392 DEBUG TRAIN Batch 24/1900 loss 15.139029 loss_att 16.145998 loss_ctc 21.671734 loss_rnnt 13.966614 hw_loss 0.187487 lr 0.00035168 rank 6
2023-02-22 20:53:37,395 DEBUG TRAIN Batch 24/1900 loss 6.300879 loss_att 7.680873 loss_ctc 9.271312 loss_rnnt 5.513334 hw_loss 0.216541 lr 0.00035171 rank 5
2023-02-22 20:53:37,443 DEBUG TRAIN Batch 24/1900 loss 5.430562 loss_att 6.683664 loss_ctc 8.491053 loss_rnnt 4.571544 hw_loss 0.375624 lr 0.00035175 rank 1
2023-02-22 20:54:50,079 DEBUG TRAIN Batch 24/2000 loss 6.590465 loss_att 9.028456 loss_ctc 10.904330 loss_rnnt 5.416203 hw_loss 0.209029 lr 0.00035162 rank 2
2023-02-22 20:54:50,080 DEBUG TRAIN Batch 24/2000 loss 4.797562 loss_att 7.207746 loss_ctc 6.307124 loss_rnnt 3.972678 hw_loss 0.265447 lr 0.00035159 rank 6
2023-02-22 20:54:50,082 DEBUG TRAIN Batch 24/2000 loss 19.217407 loss_att 22.231121 loss_ctc 27.290543 loss_rnnt 17.358957 hw_loss 0.336165 lr 0.00035168 rank 4
2023-02-22 20:54:50,085 DEBUG TRAIN Batch 24/2000 loss 3.512284 loss_att 6.970196 loss_ctc 6.481496 loss_rnnt 2.360071 hw_loss 0.121379 lr 0.00035167 rank 3
2023-02-22 20:54:50,085 DEBUG TRAIN Batch 24/2000 loss 6.635588 loss_att 7.842708 loss_ctc 9.569190 loss_rnnt 5.734858 hw_loss 0.502796 lr 0.00035167 rank 0
2023-02-22 20:54:50,088 DEBUG TRAIN Batch 24/2000 loss 10.048059 loss_att 10.313643 loss_ctc 13.341885 loss_rnnt 9.490947 hw_loss 0.121537 lr 0.00035166 rank 1
2023-02-22 20:54:50,090 DEBUG TRAIN Batch 24/2000 loss 4.071969 loss_att 6.681863 loss_ctc 9.072032 loss_rnnt 2.757056 hw_loss 0.236736 lr 0.00035162 rank 5
2023-02-22 20:54:50,136 DEBUG TRAIN Batch 24/2000 loss 11.300643 loss_att 13.563955 loss_ctc 12.508451 loss_rnnt 10.597682 hw_loss 0.167358 lr 0.00035157 rank 7
2023-02-22 20:56:04,378 DEBUG TRAIN Batch 24/2100 loss 5.180950 loss_att 9.474862 loss_ctc 7.902662 loss_rnnt 3.828475 hw_loss 0.245246 lr 0.00035159 rank 4
2023-02-22 20:56:04,378 DEBUG TRAIN Batch 24/2100 loss 2.378323 loss_att 5.484712 loss_ctc 4.968761 loss_rnnt 1.279312 hw_loss 0.248142 lr 0.00035154 rank 2
2023-02-22 20:56:04,388 DEBUG TRAIN Batch 24/2100 loss 11.638059 loss_att 15.628629 loss_ctc 21.528255 loss_rnnt 9.361403 hw_loss 0.299716 lr 0.00035158 rank 0
2023-02-22 20:56:04,388 DEBUG TRAIN Batch 24/2100 loss 6.312744 loss_att 6.665261 loss_ctc 7.854011 loss_rnnt 5.954877 hw_loss 0.153488 lr 0.00035154 rank 5
2023-02-22 20:56:04,392 DEBUG TRAIN Batch 24/2100 loss 9.627381 loss_att 12.205735 loss_ctc 15.854668 loss_rnnt 8.144110 hw_loss 0.257431 lr 0.00035149 rank 7
2023-02-22 20:56:04,395 DEBUG TRAIN Batch 24/2100 loss 5.315333 loss_att 8.213224 loss_ctc 10.545666 loss_rnnt 3.955265 hw_loss 0.155835 lr 0.00035157 rank 1
2023-02-22 20:56:04,427 DEBUG TRAIN Batch 24/2100 loss 2.026042 loss_att 4.995895 loss_ctc 2.930288 loss_rnnt 1.170676 hw_loss 0.264054 lr 0.00035159 rank 3
2023-02-22 20:56:04,435 DEBUG TRAIN Batch 24/2100 loss 10.984912 loss_att 13.887754 loss_ctc 15.907593 loss_rnnt 9.625341 hw_loss 0.229960 lr 0.00035150 rank 6
2023-02-22 20:57:17,059 DEBUG TRAIN Batch 24/2200 loss 12.994653 loss_att 15.263535 loss_ctc 16.892038 loss_rnnt 11.891922 hw_loss 0.242441 lr 0.00035142 rank 6
2023-02-22 20:57:17,060 DEBUG TRAIN Batch 24/2200 loss 10.904108 loss_att 12.405258 loss_ctc 16.293680 loss_rnnt 9.687376 hw_loss 0.371047 lr 0.00035145 rank 2
2023-02-22 20:57:17,061 DEBUG TRAIN Batch 24/2200 loss 11.019412 loss_att 14.261467 loss_ctc 15.815082 loss_rnnt 9.641933 hw_loss 0.168086 lr 0.00035149 rank 1
2023-02-22 20:57:17,065 DEBUG TRAIN Batch 24/2200 loss 9.304310 loss_att 13.862499 loss_ctc 16.191147 loss_rnnt 7.239608 hw_loss 0.440286 lr 0.00035150 rank 3
2023-02-22 20:57:17,065 DEBUG TRAIN Batch 24/2200 loss 11.626659 loss_att 13.803503 loss_ctc 16.249195 loss_rnnt 10.384657 hw_loss 0.356803 lr 0.00035140 rank 7
2023-02-22 20:57:17,067 DEBUG TRAIN Batch 24/2200 loss 7.330324 loss_att 9.765927 loss_ctc 12.917540 loss_rnnt 5.931359 hw_loss 0.312903 lr 0.00035150 rank 0
2023-02-22 20:57:17,067 DEBUG TRAIN Batch 24/2200 loss 5.133369 loss_att 7.853848 loss_ctc 8.051346 loss_rnnt 3.974256 hw_loss 0.423663 lr 0.00035150 rank 4
2023-02-22 20:57:17,070 DEBUG TRAIN Batch 24/2200 loss 5.918756 loss_att 8.121512 loss_ctc 8.085669 loss_rnnt 5.074480 hw_loss 0.215254 lr 0.00035145 rank 5
2023-02-22 20:58:29,754 DEBUG TRAIN Batch 24/2300 loss 8.950002 loss_att 14.134701 loss_ctc 10.316613 loss_rnnt 7.554868 hw_loss 0.329958 lr 0.00035140 rank 1
2023-02-22 20:58:29,775 DEBUG TRAIN Batch 24/2300 loss 8.094212 loss_att 9.337291 loss_ctc 14.241777 loss_rnnt 6.835082 hw_loss 0.357823 lr 0.00035141 rank 3
2023-02-22 20:58:29,776 DEBUG TRAIN Batch 24/2300 loss 13.768765 loss_att 15.306637 loss_ctc 23.634682 loss_rnnt 11.946117 hw_loss 0.374283 lr 0.00035136 rank 2
2023-02-22 20:58:29,777 DEBUG TRAIN Batch 24/2300 loss 6.733738 loss_att 8.877079 loss_ctc 8.439220 loss_rnnt 5.921044 hw_loss 0.293675 lr 0.00035133 rank 6
2023-02-22 20:58:29,778 DEBUG TRAIN Batch 24/2300 loss 12.026448 loss_att 15.501899 loss_ctc 24.473869 loss_rnnt 9.585452 hw_loss 0.161719 lr 0.00035141 rank 0
2023-02-22 20:58:29,782 DEBUG TRAIN Batch 24/2300 loss 5.193913 loss_att 7.230110 loss_ctc 7.683140 loss_rnnt 4.243316 hw_loss 0.396488 lr 0.00035142 rank 4
2023-02-22 20:58:29,782 DEBUG TRAIN Batch 24/2300 loss 9.507876 loss_att 13.259365 loss_ctc 15.896357 loss_rnnt 7.673709 hw_loss 0.435136 lr 0.00035131 rank 7
2023-02-22 20:58:29,835 DEBUG TRAIN Batch 24/2300 loss 1.988164 loss_att 4.275312 loss_ctc 3.175682 loss_rnnt 1.209848 hw_loss 0.304782 lr 0.00035136 rank 5
2023-02-22 20:59:42,491 DEBUG TRAIN Batch 24/2400 loss 7.744958 loss_att 10.362685 loss_ctc 9.861712 loss_rnnt 6.818145 hw_loss 0.226939 lr 0.00035133 rank 3
2023-02-22 20:59:42,493 DEBUG TRAIN Batch 24/2400 loss 7.678765 loss_att 10.784878 loss_ctc 13.623014 loss_rnnt 6.107687 hw_loss 0.294919 lr 0.00035133 rank 4
2023-02-22 20:59:42,494 DEBUG TRAIN Batch 24/2400 loss 5.205269 loss_att 7.667570 loss_ctc 7.301561 loss_rnnt 4.306296 hw_loss 0.238138 lr 0.00035128 rank 2
2023-02-22 20:59:42,495 DEBUG TRAIN Batch 24/2400 loss 4.255791 loss_att 6.062006 loss_ctc 5.439949 loss_rnnt 3.470454 hw_loss 0.499136 lr 0.00035131 rank 1
2023-02-22 20:59:42,495 DEBUG TRAIN Batch 24/2400 loss 8.012644 loss_att 11.270814 loss_ctc 14.218315 loss_rnnt 6.374748 hw_loss 0.297822 lr 0.00035123 rank 7
2023-02-22 20:59:42,497 DEBUG TRAIN Batch 24/2400 loss 7.023947 loss_att 8.667377 loss_ctc 8.668021 loss_rnnt 6.315479 hw_loss 0.301071 lr 0.00035124 rank 6
2023-02-22 20:59:42,503 DEBUG TRAIN Batch 24/2400 loss 13.659878 loss_att 17.607393 loss_ctc 18.808346 loss_rnnt 11.935960 hw_loss 0.464911 lr 0.00035128 rank 5
2023-02-22 20:59:42,505 DEBUG TRAIN Batch 24/2400 loss 10.042882 loss_att 11.772631 loss_ctc 12.959637 loss_rnnt 9.158850 hw_loss 0.279716 lr 0.00035132 rank 0
2023-02-22 21:00:58,303 DEBUG TRAIN Batch 24/2500 loss 8.771988 loss_att 9.958410 loss_ctc 12.296471 loss_rnnt 7.851264 hw_loss 0.400328 lr 0.00035119 rank 2
2023-02-22 21:00:58,304 DEBUG TRAIN Batch 24/2500 loss 8.619228 loss_att 10.761814 loss_ctc 15.661138 loss_rnnt 6.945935 hw_loss 0.573476 lr 0.00035124 rank 0
2023-02-22 21:00:58,307 DEBUG TRAIN Batch 24/2500 loss 10.545486 loss_att 9.974310 loss_ctc 12.885769 loss_rnnt 10.122098 hw_loss 0.422973 lr 0.00035124 rank 3
2023-02-22 21:00:58,306 DEBUG TRAIN Batch 24/2500 loss 8.229527 loss_att 9.252223 loss_ctc 12.662844 loss_rnnt 7.320203 hw_loss 0.213143 lr 0.00035116 rank 6
2023-02-22 21:00:58,308 DEBUG TRAIN Batch 24/2500 loss 4.989496 loss_att 8.192171 loss_ctc 10.868168 loss_rnnt 3.444882 hw_loss 0.225479 lr 0.00035123 rank 1
2023-02-22 21:00:58,310 DEBUG TRAIN Batch 24/2500 loss 11.999243 loss_att 16.034172 loss_ctc 17.904390 loss_rnnt 10.255239 hw_loss 0.280623 lr 0.00035124 rank 4
2023-02-22 21:00:58,312 DEBUG TRAIN Batch 24/2500 loss 5.485769 loss_att 8.301111 loss_ctc 10.050018 loss_rnnt 4.130678 hw_loss 0.343979 lr 0.00035119 rank 5
2023-02-22 21:00:58,313 DEBUG TRAIN Batch 24/2500 loss 8.671467 loss_att 8.287768 loss_ctc 10.508821 loss_rnnt 8.209354 hw_loss 0.551009 lr 0.00035114 rank 7
2023-02-22 21:02:10,487 DEBUG TRAIN Batch 24/2600 loss 10.048262 loss_att 13.543036 loss_ctc 14.107574 loss_rnnt 8.660828 hw_loss 0.276069 lr 0.00035110 rank 2
2023-02-22 21:02:10,495 DEBUG TRAIN Batch 24/2600 loss 11.141783 loss_att 14.095578 loss_ctc 15.557169 loss_rnnt 9.853348 hw_loss 0.204296 lr 0.00035114 rank 1
2023-02-22 21:02:10,496 DEBUG TRAIN Batch 24/2600 loss 13.690743 loss_att 18.599289 loss_ctc 22.542522 loss_rnnt 11.323347 hw_loss 0.385221 lr 0.00035115 rank 3
2023-02-22 21:02:10,497 DEBUG TRAIN Batch 24/2600 loss 8.711054 loss_att 12.500785 loss_ctc 11.218468 loss_rnnt 7.506749 hw_loss 0.210068 lr 0.00035105 rank 7
2023-02-22 21:02:10,499 DEBUG TRAIN Batch 24/2600 loss 9.981339 loss_att 9.962762 loss_ctc 12.935521 loss_rnnt 9.288178 hw_loss 0.568093 lr 0.00035116 rank 4
2023-02-22 21:02:10,500 DEBUG TRAIN Batch 24/2600 loss 6.752898 loss_att 9.357615 loss_ctc 12.050696 loss_rnnt 5.442839 hw_loss 0.155144 lr 0.00035107 rank 6
2023-02-22 21:02:10,503 DEBUG TRAIN Batch 24/2600 loss 9.743318 loss_att 10.236693 loss_ctc 13.847137 loss_rnnt 8.893356 hw_loss 0.382704 lr 0.00035115 rank 0
2023-02-22 21:02:10,550 DEBUG TRAIN Batch 24/2600 loss 6.930554 loss_att 7.187671 loss_ctc 9.499376 loss_rnnt 6.238549 hw_loss 0.558883 lr 0.00035110 rank 5
2023-02-22 21:03:22,452 DEBUG TRAIN Batch 24/2700 loss 9.687782 loss_att 12.955574 loss_ctc 14.268461 loss_rnnt 8.297379 hw_loss 0.236415 lr 0.00035107 rank 4
2023-02-22 21:03:22,468 DEBUG TRAIN Batch 24/2700 loss 18.462889 loss_att 20.763046 loss_ctc 32.860016 loss_rnnt 15.934484 hw_loss 0.278918 lr 0.00035102 rank 2
2023-02-22 21:03:22,468 DEBUG TRAIN Batch 24/2700 loss 6.099610 loss_att 10.868801 loss_ctc 8.825760 loss_rnnt 4.591992 hw_loss 0.356799 lr 0.00035107 rank 3
2023-02-22 21:03:22,469 DEBUG TRAIN Batch 24/2700 loss 6.294354 loss_att 8.363434 loss_ctc 6.000501 loss_rnnt 5.743021 hw_loss 0.331309 lr 0.00035105 rank 1
2023-02-22 21:03:22,471 DEBUG TRAIN Batch 24/2700 loss 7.221596 loss_att 12.101109 loss_ctc 11.801298 loss_rnnt 5.464906 hw_loss 0.319051 lr 0.00035098 rank 6
2023-02-22 21:03:22,472 DEBUG TRAIN Batch 24/2700 loss 14.097854 loss_att 17.543495 loss_ctc 19.258091 loss_rnnt 12.599081 hw_loss 0.228025 lr 0.00035097 rank 7
2023-02-22 21:03:22,475 DEBUG TRAIN Batch 24/2700 loss 4.881535 loss_att 10.128648 loss_ctc 9.602625 loss_rnnt 3.074733 hw_loss 0.239814 lr 0.00035106 rank 0
2023-02-22 21:03:22,479 DEBUG TRAIN Batch 24/2700 loss 6.637780 loss_att 9.940024 loss_ctc 9.120809 loss_rnnt 5.555372 hw_loss 0.170416 lr 0.00035102 rank 5
2023-02-22 21:04:37,056 DEBUG TRAIN Batch 24/2800 loss 4.458059 loss_att 7.241015 loss_ctc 6.462400 loss_rnnt 3.496329 hw_loss 0.258550 lr 0.00035097 rank 1
2023-02-22 21:04:37,058 DEBUG TRAIN Batch 24/2800 loss 4.341794 loss_att 8.162405 loss_ctc 4.668847 loss_rnnt 3.363000 hw_loss 0.320747 lr 0.00035098 rank 4
2023-02-22 21:04:37,060 DEBUG TRAIN Batch 24/2800 loss 8.750861 loss_att 9.840527 loss_ctc 11.079576 loss_rnnt 8.058601 hw_loss 0.307182 lr 0.00035093 rank 2
2023-02-22 21:04:37,060 DEBUG TRAIN Batch 24/2800 loss 13.879108 loss_att 14.565755 loss_ctc 18.807243 loss_rnnt 12.940391 hw_loss 0.270571 lr 0.00035090 rank 6
2023-02-22 21:04:37,062 DEBUG TRAIN Batch 24/2800 loss 4.544986 loss_att 8.978794 loss_ctc 7.731322 loss_rnnt 3.094567 hw_loss 0.260275 lr 0.00035088 rank 7
2023-02-22 21:04:37,064 DEBUG TRAIN Batch 24/2800 loss 7.982559 loss_att 13.071564 loss_ctc 8.252055 loss_rnnt 6.773970 hw_loss 0.290354 lr 0.00035093 rank 5
2023-02-22 21:04:37,063 DEBUG TRAIN Batch 24/2800 loss 5.919025 loss_att 8.733232 loss_ctc 11.076011 loss_rnnt 4.558220 hw_loss 0.206934 lr 0.00035098 rank 3
2023-02-22 21:04:37,081 DEBUG TRAIN Batch 24/2800 loss 7.790182 loss_att 10.802282 loss_ctc 10.626420 loss_rnnt 6.624568 hw_loss 0.346928 lr 0.00035098 rank 0
2023-02-22 21:05:50,947 DEBUG TRAIN Batch 24/2900 loss 17.485441 loss_att 23.249363 loss_ctc 23.314636 loss_rnnt 15.456154 hw_loss 0.186141 lr 0.00035089 rank 3
2023-02-22 21:05:50,949 DEBUG TRAIN Batch 24/2900 loss 11.986594 loss_att 12.615391 loss_ctc 19.175463 loss_rnnt 10.828335 hw_loss 0.138718 lr 0.00035084 rank 2
2023-02-22 21:05:50,950 DEBUG TRAIN Batch 24/2900 loss 8.042353 loss_att 10.072534 loss_ctc 11.591387 loss_rnnt 7.004281 hw_loss 0.297808 lr 0.00035088 rank 1
2023-02-22 21:05:50,956 DEBUG TRAIN Batch 24/2900 loss 6.486048 loss_att 8.515558 loss_ctc 7.642566 loss_rnnt 5.777158 hw_loss 0.278974 lr 0.00035089 rank 0
2023-02-22 21:05:50,956 DEBUG TRAIN Batch 24/2900 loss 14.061113 loss_att 14.556067 loss_ctc 13.034271 loss_rnnt 13.890287 hw_loss 0.391402 lr 0.00035081 rank 6
2023-02-22 21:05:50,957 DEBUG TRAIN Batch 24/2900 loss 10.233644 loss_att 13.010252 loss_ctc 16.612312 loss_rnnt 8.593308 hw_loss 0.439732 lr 0.00035079 rank 7
2023-02-22 21:05:50,960 DEBUG TRAIN Batch 24/2900 loss 8.228762 loss_att 11.376978 loss_ctc 11.036139 loss_rnnt 7.034366 hw_loss 0.357068 lr 0.00035084 rank 5
2023-02-22 21:05:51,004 DEBUG TRAIN Batch 24/2900 loss 6.785569 loss_att 9.556505 loss_ctc 8.526201 loss_rnnt 5.838735 hw_loss 0.301053 lr 0.00035090 rank 4
2023-02-22 21:07:03,130 DEBUG TRAIN Batch 24/3000 loss 3.581292 loss_att 7.630973 loss_ctc 5.164750 loss_rnnt 2.426499 hw_loss 0.250744 lr 0.00035081 rank 3
2023-02-22 21:07:03,131 DEBUG TRAIN Batch 24/3000 loss 14.536400 loss_att 13.713032 loss_ctc 17.849642 loss_rnnt 14.155114 hw_loss 0.195360 lr 0.00035076 rank 2
2023-02-22 21:07:03,133 DEBUG TRAIN Batch 24/3000 loss 11.752383 loss_att 13.808276 loss_ctc 14.703551 loss_rnnt 10.723918 hw_loss 0.419621 lr 0.00035081 rank 0
2023-02-22 21:07:03,133 DEBUG TRAIN Batch 24/3000 loss 11.771406 loss_att 10.885496 loss_ctc 15.052463 loss_rnnt 11.333371 hw_loss 0.333266 lr 0.00035072 rank 6
2023-02-22 21:07:03,133 DEBUG TRAIN Batch 24/3000 loss 8.926367 loss_att 10.711298 loss_ctc 13.729553 loss_rnnt 7.798782 hw_loss 0.244077 lr 0.00035071 rank 7
2023-02-22 21:07:03,134 DEBUG TRAIN Batch 24/3000 loss 14.670913 loss_att 19.477119 loss_ctc 24.423920 loss_rnnt 12.264662 hw_loss 0.271142 lr 0.00035079 rank 1
2023-02-22 21:07:03,140 DEBUG TRAIN Batch 24/3000 loss 14.389706 loss_att 16.199852 loss_ctc 22.391985 loss_rnnt 12.814252 hw_loss 0.274602 lr 0.00035081 rank 4
2023-02-22 21:07:03,139 DEBUG TRAIN Batch 24/3000 loss 5.513595 loss_att 7.717086 loss_ctc 10.615655 loss_rnnt 4.307258 hw_loss 0.160059 lr 0.00035076 rank 5
2023-02-22 21:08:16,396 DEBUG TRAIN Batch 24/3100 loss 14.471277 loss_att 15.007166 loss_ctc 18.665735 loss_rnnt 13.636509 hw_loss 0.315619 lr 0.00035072 rank 3
2023-02-22 21:08:16,396 DEBUG TRAIN Batch 24/3100 loss 9.692051 loss_att 10.847650 loss_ctc 12.399334 loss_rnnt 8.929473 hw_loss 0.319664 lr 0.00035067 rank 2
2023-02-22 21:08:16,397 DEBUG TRAIN Batch 24/3100 loss 9.850181 loss_att 11.041972 loss_ctc 13.372473 loss_rnnt 8.917111 hw_loss 0.422010 lr 0.00035062 rank 7
2023-02-22 21:08:16,399 DEBUG TRAIN Batch 24/3100 loss 9.344486 loss_att 11.899753 loss_ctc 10.850751 loss_rnnt 8.527476 hw_loss 0.197103 lr 0.00035072 rank 4
2023-02-22 21:08:16,401 DEBUG TRAIN Batch 24/3100 loss 9.992892 loss_att 11.052398 loss_ctc 13.062004 loss_rnnt 9.194759 hw_loss 0.331907 lr 0.00035067 rank 5
2023-02-22 21:08:16,403 DEBUG TRAIN Batch 24/3100 loss 9.089520 loss_att 9.552590 loss_ctc 11.519691 loss_rnnt 8.456378 hw_loss 0.405949 lr 0.00035064 rank 6
2023-02-22 21:08:16,405 DEBUG TRAIN Batch 24/3100 loss 7.419196 loss_att 8.767303 loss_ctc 9.888796 loss_rnnt 6.677251 hw_loss 0.268206 lr 0.00035072 rank 0
2023-02-22 21:08:16,446 DEBUG TRAIN Batch 24/3100 loss 4.616369 loss_att 6.192069 loss_ctc 6.836609 loss_rnnt 3.788980 hw_loss 0.405407 lr 0.00035071 rank 1
2023-02-22 21:09:32,174 DEBUG TRAIN Batch 24/3200 loss 15.016100 loss_att 27.666653 loss_ctc 27.158295 loss_rnnt 10.702471 hw_loss 0.308547 lr 0.00035055 rank 6
2023-02-22 21:09:32,174 DEBUG TRAIN Batch 24/3200 loss 5.087304 loss_att 8.098057 loss_ctc 7.988496 loss_rnnt 3.881174 hw_loss 0.407164 lr 0.00035058 rank 2
2023-02-22 21:09:32,176 DEBUG TRAIN Batch 24/3200 loss 8.197017 loss_att 10.858020 loss_ctc 12.931328 loss_rnnt 6.870168 hw_loss 0.306387 lr 0.00035064 rank 3
2023-02-22 21:09:32,177 DEBUG TRAIN Batch 24/3200 loss 7.549676 loss_att 9.018242 loss_ctc 8.878647 loss_rnnt 6.950027 hw_loss 0.241385 lr 0.00035063 rank 0
2023-02-22 21:09:32,178 DEBUG TRAIN Batch 24/3200 loss 12.783845 loss_att 13.758961 loss_ctc 19.892126 loss_rnnt 11.427112 hw_loss 0.401137 lr 0.00035064 rank 4
2023-02-22 21:09:32,178 DEBUG TRAIN Batch 24/3200 loss 14.545156 loss_att 18.535728 loss_ctc 21.865665 loss_rnnt 12.675323 hw_loss 0.179346 lr 0.00035062 rank 1
2023-02-22 21:09:32,180 DEBUG TRAIN Batch 24/3200 loss 12.062177 loss_att 14.435806 loss_ctc 20.792751 loss_rnnt 10.235523 hw_loss 0.352221 lr 0.00035054 rank 7
2023-02-22 21:09:32,181 DEBUG TRAIN Batch 24/3200 loss 8.908168 loss_att 12.169090 loss_ctc 13.765189 loss_rnnt 7.412690 hw_loss 0.366919 lr 0.00035059 rank 5
2023-02-22 21:10:45,183 DEBUG TRAIN Batch 24/3300 loss 7.011809 loss_att 7.314623 loss_ctc 7.977927 loss_rnnt 6.681583 hw_loss 0.264089 lr 0.00035050 rank 2
2023-02-22 21:10:45,187 DEBUG TRAIN Batch 24/3300 loss 7.485617 loss_att 8.923915 loss_ctc 8.897167 loss_rnnt 6.933650 hw_loss 0.142690 lr 0.00035050 rank 5
2023-02-22 21:10:45,189 DEBUG TRAIN Batch 24/3300 loss 3.917549 loss_att 6.049420 loss_ctc 7.231581 loss_rnnt 2.955294 hw_loss 0.176268 lr 0.00035046 rank 6
2023-02-22 21:10:45,190 DEBUG TRAIN Batch 24/3300 loss 5.422616 loss_att 7.111629 loss_ctc 6.641435 loss_rnnt 4.706596 hw_loss 0.404453 lr 0.00035053 rank 1
2023-02-22 21:10:45,193 DEBUG TRAIN Batch 24/3300 loss 1.813193 loss_att 5.598831 loss_ctc 3.328465 loss_rnnt 0.742419 hw_loss 0.209268 lr 0.00035055 rank 3
2023-02-22 21:10:45,193 DEBUG TRAIN Batch 24/3300 loss 9.475674 loss_att 14.180592 loss_ctc 17.865314 loss_rnnt 7.291737 hw_loss 0.233129 lr 0.00035055 rank 0
2023-02-22 21:10:45,201 DEBUG TRAIN Batch 24/3300 loss 4.037743 loss_att 5.886427 loss_ctc 5.282832 loss_rnnt 3.386146 hw_loss 0.217215 lr 0.00035045 rank 7
2023-02-22 21:10:45,252 DEBUG TRAIN Batch 24/3300 loss 6.405376 loss_att 10.586767 loss_ctc 9.073466 loss_rnnt 5.139740 hw_loss 0.138024 lr 0.00035055 rank 4
2023-02-22 21:11:58,616 DEBUG TRAIN Batch 24/3400 loss 6.614201 loss_att 7.542501 loss_ctc 8.507727 loss_rnnt 5.938665 hw_loss 0.445136 lr 0.00035046 rank 0
2023-02-22 21:11:58,615 DEBUG TRAIN Batch 24/3400 loss 10.164259 loss_att 13.208706 loss_ctc 12.751285 loss_rnnt 9.116489 hw_loss 0.176143 lr 0.00035047 rank 4
2023-02-22 21:11:58,617 DEBUG TRAIN Batch 24/3400 loss 8.981799 loss_att 11.036133 loss_ctc 14.757838 loss_rnnt 7.562416 hw_loss 0.446959 lr 0.00035038 rank 6
2023-02-22 21:11:58,617 DEBUG TRAIN Batch 24/3400 loss 3.385082 loss_att 5.337304 loss_ctc 5.425703 loss_rnnt 2.550609 hw_loss 0.322398 lr 0.00035046 rank 3
2023-02-22 21:11:58,621 DEBUG TRAIN Batch 24/3400 loss 4.048305 loss_att 6.458463 loss_ctc 7.153409 loss_rnnt 2.984874 hw_loss 0.313849 lr 0.00035041 rank 2
2023-02-22 21:11:58,622 DEBUG TRAIN Batch 24/3400 loss 8.576752 loss_att 13.093352 loss_ctc 13.335637 loss_rnnt 6.880000 hw_loss 0.297964 lr 0.00035036 rank 7
2023-02-22 21:11:58,624 DEBUG TRAIN Batch 24/3400 loss 4.720457 loss_att 8.093019 loss_ctc 7.681986 loss_rnnt 3.591356 hw_loss 0.111973 lr 0.00035041 rank 5
2023-02-22 21:11:58,623 DEBUG TRAIN Batch 24/3400 loss 14.329471 loss_att 17.509979 loss_ctc 18.355795 loss_rnnt 13.055552 hw_loss 0.189324 lr 0.00035045 rank 1
2023-02-22 21:13:11,712 DEBUG TRAIN Batch 24/3500 loss 13.600798 loss_att 15.940400 loss_ctc 20.973593 loss_rnnt 11.909349 hw_loss 0.450915 lr 0.00035033 rank 5
2023-02-22 21:13:11,724 DEBUG TRAIN Batch 24/3500 loss 7.350640 loss_att 9.855942 loss_ctc 9.771202 loss_rnnt 6.364104 hw_loss 0.305127 lr 0.00035038 rank 3
2023-02-22 21:13:11,724 DEBUG TRAIN Batch 24/3500 loss 10.350265 loss_att 13.815099 loss_ctc 14.133238 loss_rnnt 8.974862 hw_loss 0.333823 lr 0.00035036 rank 1
2023-02-22 21:13:11,725 DEBUG TRAIN Batch 24/3500 loss 8.553299 loss_att 9.296445 loss_ctc 12.601198 loss_rnnt 7.720221 hw_loss 0.271366 lr 0.00035033 rank 2
2023-02-22 21:13:11,727 DEBUG TRAIN Batch 24/3500 loss 7.347687 loss_att 12.126948 loss_ctc 11.244175 loss_rnnt 5.826519 hw_loss 0.085843 lr 0.00035029 rank 6
2023-02-22 21:13:11,729 DEBUG TRAIN Batch 24/3500 loss 9.335453 loss_att 14.772514 loss_ctc 12.197236 loss_rnnt 7.784783 hw_loss 0.153162 lr 0.00035028 rank 7
2023-02-22 21:13:11,730 DEBUG TRAIN Batch 24/3500 loss 6.534842 loss_att 9.567459 loss_ctc 7.643252 loss_rnnt 5.672127 hw_loss 0.203259 lr 0.00035037 rank 0
2023-02-22 21:13:11,730 DEBUG TRAIN Batch 24/3500 loss 9.382545 loss_att 12.865571 loss_ctc 10.739519 loss_rnnt 8.379967 hw_loss 0.234456 lr 0.00035038 rank 4
2023-02-22 21:14:25,995 DEBUG TRAIN Batch 24/3600 loss 5.143417 loss_att 8.012157 loss_ctc 8.533491 loss_rnnt 4.060230 hw_loss 0.107679 lr 0.00035024 rank 2
2023-02-22 21:14:26,012 DEBUG TRAIN Batch 24/3600 loss 11.370728 loss_att 13.190272 loss_ctc 11.934753 loss_rnnt 10.803764 hw_loss 0.239723 lr 0.00035021 rank 6
2023-02-22 21:14:26,013 DEBUG TRAIN Batch 24/3600 loss 9.210516 loss_att 11.712692 loss_ctc 12.731245 loss_rnnt 8.118779 hw_loss 0.228508 lr 0.00035019 rank 7
2023-02-22 21:14:26,014 DEBUG TRAIN Batch 24/3600 loss 13.489075 loss_att 16.172098 loss_ctc 20.957275 loss_rnnt 11.787279 hw_loss 0.317680 lr 0.00035029 rank 3
2023-02-22 21:14:26,014 DEBUG TRAIN Batch 24/3600 loss 7.756599 loss_att 9.710417 loss_ctc 11.156784 loss_rnnt 6.750762 hw_loss 0.303216 lr 0.00035024 rank 5
2023-02-22 21:14:26,015 DEBUG TRAIN Batch 24/3600 loss 8.146910 loss_att 10.630657 loss_ctc 11.470575 loss_rnnt 6.988532 hw_loss 0.409636 lr 0.00035029 rank 4
2023-02-22 21:14:26,017 DEBUG TRAIN Batch 24/3600 loss 7.477424 loss_att 9.916414 loss_ctc 11.528793 loss_rnnt 6.361860 hw_loss 0.164219 lr 0.00035028 rank 1
2023-02-22 21:14:26,020 DEBUG TRAIN Batch 24/3600 loss 8.706561 loss_att 12.218622 loss_ctc 11.281675 loss_rnnt 7.556993 hw_loss 0.194637 lr 0.00035029 rank 0
2023-02-22 21:15:38,501 DEBUG TRAIN Batch 24/3700 loss 9.279424 loss_att 10.249022 loss_ctc 13.138074 loss_rnnt 8.356034 hw_loss 0.403091 lr 0.00035015 rank 2
2023-02-22 21:15:38,506 DEBUG TRAIN Batch 24/3700 loss 9.026405 loss_att 8.980433 loss_ctc 10.560818 loss_rnnt 8.664331 hw_loss 0.312524 lr 0.00035020 rank 3
2023-02-22 21:15:38,508 DEBUG TRAIN Batch 24/3700 loss 6.612865 loss_att 8.199783 loss_ctc 9.545316 loss_rnnt 5.769898 hw_loss 0.252357 lr 0.00035011 rank 7
2023-02-22 21:15:38,508 DEBUG TRAIN Batch 24/3700 loss 9.788757 loss_att 12.821595 loss_ctc 11.314507 loss_rnnt 8.809367 hw_loss 0.317603 lr 0.00035012 rank 6
2023-02-22 21:15:38,509 DEBUG TRAIN Batch 24/3700 loss 13.441922 loss_att 16.379612 loss_ctc 23.668196 loss_rnnt 11.363506 hw_loss 0.238830 lr 0.00035020 rank 0
2023-02-22 21:15:38,512 DEBUG TRAIN Batch 24/3700 loss 5.376418 loss_att 7.518744 loss_ctc 9.054842 loss_rnnt 4.300666 hw_loss 0.294058 lr 0.00035021 rank 4
2023-02-22 21:15:38,516 DEBUG TRAIN Batch 24/3700 loss 8.210933 loss_att 12.078592 loss_ctc 12.470533 loss_rnnt 6.656984 hw_loss 0.398383 lr 0.00035019 rank 1
2023-02-22 21:15:38,565 DEBUG TRAIN Batch 24/3700 loss 10.064315 loss_att 11.428722 loss_ctc 13.166439 loss_rnnt 9.250376 hw_loss 0.238950 lr 0.00035015 rank 5
2023-02-22 21:16:51,181 DEBUG TRAIN Batch 24/3800 loss 6.952394 loss_att 11.282513 loss_ctc 11.671725 loss_rnnt 5.359577 hw_loss 0.182906 lr 0.00035012 rank 3
2023-02-22 21:16:51,182 DEBUG TRAIN Batch 24/3800 loss 9.064811 loss_att 9.997094 loss_ctc 11.069369 loss_rnnt 8.475641 hw_loss 0.253946 lr 0.00035007 rank 2
2023-02-22 21:16:51,183 DEBUG TRAIN Batch 24/3800 loss 13.629002 loss_att 15.780710 loss_ctc 21.128262 loss_rnnt 12.002646 hw_loss 0.367712 lr 0.00035010 rank 1
2023-02-22 21:16:51,184 DEBUG TRAIN Batch 24/3800 loss 8.163866 loss_att 9.159596 loss_ctc 10.869712 loss_rnnt 7.425956 hw_loss 0.333719 lr 0.00035012 rank 4
2023-02-22 21:16:51,185 DEBUG TRAIN Batch 24/3800 loss 9.360317 loss_att 11.353507 loss_ctc 13.623672 loss_rnnt 8.283792 hw_loss 0.205199 lr 0.00035003 rank 6
2023-02-22 21:16:51,185 DEBUG TRAIN Batch 24/3800 loss 11.368891 loss_att 11.856427 loss_ctc 16.141212 loss_rnnt 10.496156 hw_loss 0.260471 lr 0.00035002 rank 7
2023-02-22 21:16:51,188 DEBUG TRAIN Batch 24/3800 loss 11.075720 loss_att 11.490864 loss_ctc 15.416427 loss_rnnt 10.279617 hw_loss 0.251835 lr 0.00035012 rank 0
2023-02-22 21:16:51,191 DEBUG TRAIN Batch 24/3800 loss 6.366226 loss_att 10.269629 loss_ctc 10.380947 loss_rnnt 4.852088 hw_loss 0.371552 lr 0.00035007 rank 5
2023-02-22 21:18:07,169 DEBUG TRAIN Batch 24/3900 loss 12.021108 loss_att 14.641165 loss_ctc 26.162716 loss_rnnt 9.394785 hw_loss 0.406431 lr 0.00035003 rank 3
2023-02-22 21:18:07,170 DEBUG TRAIN Batch 24/3900 loss 7.862440 loss_att 10.735411 loss_ctc 9.551046 loss_rnnt 6.942340 hw_loss 0.225671 lr 0.00034998 rank 2
2023-02-22 21:18:07,174 DEBUG TRAIN Batch 24/3900 loss 4.503368 loss_att 4.465361 loss_ctc 6.288319 loss_rnnt 3.906235 hw_loss 0.687641 lr 0.00035002 rank 1
2023-02-22 21:18:07,173 DEBUG TRAIN Batch 24/3900 loss 2.511972 loss_att 5.185795 loss_ctc 4.106558 loss_rnnt 1.617926 hw_loss 0.275007 lr 0.00034995 rank 6
2023-02-22 21:18:07,175 DEBUG TRAIN Batch 24/3900 loss 12.930658 loss_att 18.025286 loss_ctc 18.183571 loss_rnnt 11.018047 hw_loss 0.362429 lr 0.00035004 rank 4
2023-02-22 21:18:07,176 DEBUG TRAIN Batch 24/3900 loss 7.728165 loss_att 8.456118 loss_ctc 11.337932 loss_rnnt 6.854846 hw_loss 0.462047 lr 0.00035003 rank 0
2023-02-22 21:18:07,179 DEBUG TRAIN Batch 24/3900 loss 13.478632 loss_att 14.298173 loss_ctc 19.854687 loss_rnnt 12.275298 hw_loss 0.354911 lr 0.00034998 rank 5
2023-02-22 21:18:07,221 DEBUG TRAIN Batch 24/3900 loss 2.439750 loss_att 4.771981 loss_ctc 3.545575 loss_rnnt 1.696768 hw_loss 0.242047 lr 0.00034993 rank 7
2023-02-22 21:19:19,823 DEBUG TRAIN Batch 24/4000 loss 3.947462 loss_att 4.191681 loss_ctc 4.258101 loss_rnnt 3.709334 hw_loss 0.277248 lr 0.00034990 rank 2
2023-02-22 21:19:19,825 DEBUG TRAIN Batch 24/4000 loss 10.273039 loss_att 12.980603 loss_ctc 14.201900 loss_rnnt 9.073200 hw_loss 0.252147 lr 0.00034985 rank 7
2023-02-22 21:19:19,826 DEBUG TRAIN Batch 24/4000 loss 8.642389 loss_att 12.840187 loss_ctc 13.743317 loss_rnnt 6.998975 hw_loss 0.231996 lr 0.00034995 rank 3
2023-02-22 21:19:19,829 DEBUG TRAIN Batch 24/4000 loss 3.546376 loss_att 8.266904 loss_ctc 7.268404 loss_rnnt 1.947546 hw_loss 0.297101 lr 0.00034994 rank 0
2023-02-22 21:19:19,829 DEBUG TRAIN Batch 24/4000 loss 3.930888 loss_att 6.408137 loss_ctc 4.510080 loss_rnnt 3.269921 hw_loss 0.165546 lr 0.00034993 rank 1
2023-02-22 21:19:19,831 DEBUG TRAIN Batch 24/4000 loss 4.168431 loss_att 5.182949 loss_ctc 4.586513 loss_rnnt 3.732426 hw_loss 0.332544 lr 0.00034986 rank 6
2023-02-22 21:19:19,837 DEBUG TRAIN Batch 24/4000 loss 21.275099 loss_att 22.110600 loss_ctc 25.974724 loss_rnnt 20.367537 hw_loss 0.213462 lr 0.00034990 rank 5
2023-02-22 21:19:19,840 DEBUG TRAIN Batch 24/4000 loss 1.272094 loss_att 3.352633 loss_ctc 1.334569 loss_rnnt 0.559523 hw_loss 0.540250 lr 0.00034995 rank 4
2023-02-22 21:20:32,499 DEBUG TRAIN Batch 24/4100 loss 6.749435 loss_att 9.044697 loss_ctc 11.837126 loss_rnnt 5.450206 hw_loss 0.303409 lr 0.00034981 rank 5
2023-02-22 21:20:32,507 DEBUG TRAIN Batch 24/4100 loss 6.945342 loss_att 7.593575 loss_ctc 7.039530 loss_rnnt 6.641202 hw_loss 0.303627 lr 0.00034986 rank 3
2023-02-22 21:20:32,511 DEBUG TRAIN Batch 24/4100 loss 9.674744 loss_att 11.367413 loss_ctc 12.946054 loss_rnnt 8.729763 hw_loss 0.319262 lr 0.00034976 rank 7
2023-02-22 21:20:32,514 DEBUG TRAIN Batch 24/4100 loss 8.575273 loss_att 9.370845 loss_ctc 10.576633 loss_rnnt 8.052279 hw_loss 0.181934 lr 0.00034978 rank 6
2023-02-22 21:20:32,514 DEBUG TRAIN Batch 24/4100 loss 8.342851 loss_att 9.229802 loss_ctc 8.787037 loss_rnnt 8.002641 hw_loss 0.194240 lr 0.00034981 rank 2
2023-02-22 21:20:32,516 DEBUG TRAIN Batch 24/4100 loss 10.626452 loss_att 16.006483 loss_ctc 22.510677 loss_rnnt 7.761146 hw_loss 0.383882 lr 0.00034987 rank 4
2023-02-22 21:20:32,517 DEBUG TRAIN Batch 24/4100 loss 7.982540 loss_att 9.423588 loss_ctc 10.364051 loss_rnnt 7.282453 hw_loss 0.176892 lr 0.00034985 rank 1
2023-02-22 21:20:32,565 DEBUG TRAIN Batch 24/4100 loss 20.740814 loss_att 20.171247 loss_ctc 25.557089 loss_rnnt 20.064703 hw_loss 0.277224 lr 0.00034986 rank 0
2023-02-22 21:21:45,442 DEBUG TRAIN Batch 24/4200 loss 14.382463 loss_att 16.633919 loss_ctc 18.404598 loss_rnnt 13.280334 hw_loss 0.216661 lr 0.00034973 rank 2
2023-02-22 21:21:45,442 DEBUG TRAIN Batch 24/4200 loss 4.354784 loss_att 7.492539 loss_ctc 6.902830 loss_rnnt 3.308990 hw_loss 0.147195 lr 0.00034978 rank 4
2023-02-22 21:21:45,442 DEBUG TRAIN Batch 24/4200 loss 16.001673 loss_att 15.372862 loss_ctc 21.654467 loss_rnnt 15.229473 hw_loss 0.270483 lr 0.00034978 rank 3
2023-02-22 21:21:45,443 DEBUG TRAIN Batch 24/4200 loss 4.025856 loss_att 5.717932 loss_ctc 7.389372 loss_rnnt 3.105813 hw_loss 0.249675 lr 0.00034968 rank 7
2023-02-22 21:21:45,446 DEBUG TRAIN Batch 24/4200 loss 7.250558 loss_att 11.121221 loss_ctc 10.989510 loss_rnnt 5.851557 hw_loss 0.236892 lr 0.00034973 rank 5
2023-02-22 21:21:45,458 DEBUG TRAIN Batch 24/4200 loss 5.850062 loss_att 10.432527 loss_ctc 11.772291 loss_rnnt 3.989148 hw_loss 0.290231 lr 0.00034969 rank 6
2023-02-22 21:21:45,476 DEBUG TRAIN Batch 24/4200 loss 6.057767 loss_att 7.892634 loss_ctc 6.362167 loss_rnnt 5.513090 hw_loss 0.257095 lr 0.00034977 rank 0
2023-02-22 21:21:45,495 DEBUG TRAIN Batch 24/4200 loss 8.368230 loss_att 12.043627 loss_ctc 13.656320 loss_rnnt 6.742070 hw_loss 0.348752 lr 0.00034976 rank 1
2023-02-22 21:22:59,467 DEBUG TRAIN Batch 24/4300 loss 3.182712 loss_att 6.475933 loss_ctc 3.402956 loss_rnnt 2.383697 hw_loss 0.208134 lr 0.00034964 rank 2
2023-02-22 21:22:59,467 DEBUG TRAIN Batch 24/4300 loss 2.751744 loss_att 4.931012 loss_ctc 6.944172 loss_rnnt 1.585362 hw_loss 0.321633 lr 0.00034961 rank 6
2023-02-22 21:22:59,471 DEBUG TRAIN Batch 24/4300 loss 9.231387 loss_att 9.708199 loss_ctc 11.383019 loss_rnnt 8.682067 hw_loss 0.313264 lr 0.00034959 rank 7
2023-02-22 21:22:59,474 DEBUG TRAIN Batch 24/4300 loss 8.212301 loss_att 9.087182 loss_ctc 13.514032 loss_rnnt 7.120076 hw_loss 0.394410 lr 0.00034969 rank 3
2023-02-22 21:22:59,477 DEBUG TRAIN Batch 24/4300 loss 9.933434 loss_att 11.196101 loss_ctc 13.690840 loss_rnnt 9.079540 hw_loss 0.188198 lr 0.00034969 rank 0
2023-02-22 21:22:59,476 DEBUG TRAIN Batch 24/4300 loss 3.669778 loss_att 5.975116 loss_ctc 5.762405 loss_rnnt 2.827909 hw_loss 0.190844 lr 0.00034969 rank 4
2023-02-22 21:22:59,479 DEBUG TRAIN Batch 24/4300 loss 13.506516 loss_att 13.617246 loss_ctc 15.358464 loss_rnnt 13.115805 hw_loss 0.228070 lr 0.00034968 rank 1
2023-02-22 21:22:59,483 DEBUG TRAIN Batch 24/4300 loss 3.194354 loss_att 6.151486 loss_ctc 4.933850 loss_rnnt 2.281050 hw_loss 0.168645 lr 0.00034964 rank 5
2023-02-22 21:24:13,070 DEBUG TRAIN Batch 24/4400 loss 4.033384 loss_att 6.030027 loss_ctc 7.407781 loss_rnnt 3.074032 hw_loss 0.206445 lr 0.00034959 rank 1
2023-02-22 21:24:13,085 DEBUG TRAIN Batch 24/4400 loss 7.482956 loss_att 7.313040 loss_ctc 10.127244 loss_rnnt 6.873739 hw_loss 0.544928 lr 0.00034955 rank 2
2023-02-22 21:24:13,088 DEBUG TRAIN Batch 24/4400 loss 3.388551 loss_att 3.839088 loss_ctc 4.419848 loss_rnnt 2.918212 hw_loss 0.455110 lr 0.00034951 rank 7
2023-02-22 21:24:13,089 DEBUG TRAIN Batch 24/4400 loss 13.957201 loss_att 15.734465 loss_ctc 17.551779 loss_rnnt 13.068872 hw_loss 0.100499 lr 0.00034956 rank 5
2023-02-22 21:24:13,089 DEBUG TRAIN Batch 24/4400 loss 8.079436 loss_att 8.199428 loss_ctc 9.038264 loss_rnnt 7.600224 hw_loss 0.613820 lr 0.00034952 rank 6
2023-02-22 21:24:13,090 DEBUG TRAIN Batch 24/4400 loss 6.983427 loss_att 9.453759 loss_ctc 10.612733 loss_rnnt 5.929519 hw_loss 0.142375 lr 0.00034961 rank 3
2023-02-22 21:24:13,095 DEBUG TRAIN Batch 24/4400 loss 1.888609 loss_att 3.562148 loss_ctc 1.514580 loss_rnnt 1.478810 hw_loss 0.234304 lr 0.00034960 rank 0
2023-02-22 21:24:13,139 DEBUG TRAIN Batch 24/4400 loss 6.516966 loss_att 8.105266 loss_ctc 9.594302 loss_rnnt 5.641216 hw_loss 0.277084 lr 0.00034961 rank 4
2023-02-22 21:25:25,623 DEBUG TRAIN Batch 24/4500 loss 3.669474 loss_att 6.571575 loss_ctc 9.548443 loss_rnnt 2.169637 hw_loss 0.254165 lr 0.00034952 rank 4
2023-02-22 21:25:25,623 DEBUG TRAIN Batch 24/4500 loss 3.254432 loss_att 6.057754 loss_ctc 3.084344 loss_rnnt 2.628240 hw_loss 0.165387 lr 0.00034952 rank 3
2023-02-22 21:25:25,625 DEBUG TRAIN Batch 24/4500 loss 13.702732 loss_att 17.526196 loss_ctc 19.783957 loss_rnnt 12.022058 hw_loss 0.197158 lr 0.00034944 rank 6
2023-02-22 21:25:25,626 DEBUG TRAIN Batch 24/4500 loss 7.945984 loss_att 7.431491 loss_ctc 10.174601 loss_rnnt 7.602365 hw_loss 0.280067 lr 0.00034942 rank 7
2023-02-22 21:25:25,627 DEBUG TRAIN Batch 24/4500 loss 8.516777 loss_att 9.416541 loss_ctc 12.780018 loss_rnnt 7.597767 hw_loss 0.319922 lr 0.00034952 rank 0
2023-02-22 21:25:25,628 DEBUG TRAIN Batch 24/4500 loss 9.726926 loss_att 15.048498 loss_ctc 17.134748 loss_rnnt 7.505489 hw_loss 0.317647 lr 0.00034947 rank 2
2023-02-22 21:25:25,631 DEBUG TRAIN Batch 24/4500 loss 8.591471 loss_att 8.758522 loss_ctc 14.651052 loss_rnnt 7.462713 hw_loss 0.538882 lr 0.00034951 rank 1
2023-02-22 21:25:25,631 DEBUG TRAIN Batch 24/4500 loss 11.476446 loss_att 12.527725 loss_ctc 20.778954 loss_rnnt 9.787738 hw_loss 0.446472 lr 0.00034947 rank 5
2023-02-22 21:26:40,098 DEBUG TRAIN Batch 24/4600 loss 4.319510 loss_att 8.785537 loss_ctc 6.182631 loss_rnnt 3.051139 hw_loss 0.237656 lr 0.00034943 rank 3
2023-02-22 21:26:40,101 DEBUG TRAIN Batch 24/4600 loss 6.274433 loss_att 8.947583 loss_ctc 7.102012 loss_rnnt 5.446596 hw_loss 0.342866 lr 0.00034935 rank 6
2023-02-22 21:26:40,103 DEBUG TRAIN Batch 24/4600 loss 1.547228 loss_att 3.872147 loss_ctc 1.680867 loss_rnnt 0.901030 hw_loss 0.306367 lr 0.00034943 rank 0
2023-02-22 21:26:40,107 DEBUG TRAIN Batch 24/4600 loss 6.878847 loss_att 10.780038 loss_ctc 8.855776 loss_rnnt 5.744176 hw_loss 0.170328 lr 0.00034938 rank 2
2023-02-22 21:26:40,108 DEBUG TRAIN Batch 24/4600 loss 4.548923 loss_att 8.243225 loss_ctc 8.071792 loss_rnnt 3.119848 hw_loss 0.413435 lr 0.00034938 rank 5
2023-02-22 21:26:40,110 DEBUG TRAIN Batch 24/4600 loss 8.656151 loss_att 12.910433 loss_ctc 13.053659 loss_rnnt 7.065616 hw_loss 0.287520 lr 0.00034944 rank 4
2023-02-22 21:26:40,132 DEBUG TRAIN Batch 24/4600 loss 6.163426 loss_att 9.330155 loss_ctc 6.430915 loss_rnnt 5.397960 hw_loss 0.180854 lr 0.00034934 rank 7
2023-02-22 21:26:40,138 DEBUG TRAIN Batch 24/4600 loss 5.343591 loss_att 9.338340 loss_ctc 8.213950 loss_rnnt 4.079441 hw_loss 0.154659 lr 0.00034942 rank 1
2023-02-22 21:27:54,582 DEBUG TRAIN Batch 24/4700 loss 3.705245 loss_att 5.719243 loss_ctc 4.375113 loss_rnnt 3.092988 hw_loss 0.225267 lr 0.00034930 rank 2
2023-02-22 21:27:54,588 DEBUG TRAIN Batch 24/4700 loss 9.286652 loss_att 16.352879 loss_ctc 14.955524 loss_rnnt 6.897877 hw_loss 0.411899 lr 0.00034935 rank 4
2023-02-22 21:27:54,587 DEBUG TRAIN Batch 24/4700 loss 5.645652 loss_att 10.111839 loss_ctc 8.854929 loss_rnnt 4.163671 hw_loss 0.301573 lr 0.00034925 rank 7
2023-02-22 21:27:54,594 DEBUG TRAIN Batch 24/4700 loss 8.502412 loss_att 11.111261 loss_ctc 13.123693 loss_rnnt 7.180653 hw_loss 0.344659 lr 0.00034935 rank 3
2023-02-22 21:27:54,593 DEBUG TRAIN Batch 24/4700 loss 4.631345 loss_att 9.233994 loss_ctc 5.413718 loss_rnnt 3.445059 hw_loss 0.302699 lr 0.00034927 rank 6
2023-02-22 21:27:54,595 DEBUG TRAIN Batch 24/4700 loss 8.058927 loss_att 12.623981 loss_ctc 12.136852 loss_rnnt 6.486197 hw_loss 0.217491 lr 0.00034933 rank 1
2023-02-22 21:27:54,597 DEBUG TRAIN Batch 24/4700 loss 6.612812 loss_att 7.283312 loss_ctc 7.710754 loss_rnnt 6.212060 hw_loss 0.225486 lr 0.00034935 rank 0
2023-02-22 21:27:54,601 DEBUG TRAIN Batch 24/4700 loss 5.989629 loss_att 11.075658 loss_ctc 12.472891 loss_rnnt 3.909185 hw_loss 0.372755 lr 0.00034930 rank 5
2023-02-22 21:29:06,084 DEBUG TRAIN Batch 24/4800 loss 5.525775 loss_att 7.031446 loss_ctc 6.377874 loss_rnnt 4.962057 hw_loss 0.279319 lr 0.00034921 rank 2
2023-02-22 21:29:06,086 DEBUG TRAIN Batch 24/4800 loss 6.682616 loss_att 9.115936 loss_ctc 9.763804 loss_rnnt 5.601025 hw_loss 0.345191 lr 0.00034927 rank 4
2023-02-22 21:29:06,086 DEBUG TRAIN Batch 24/4800 loss 9.535729 loss_att 12.833890 loss_ctc 15.391433 loss_rnnt 7.873584 hw_loss 0.415787 lr 0.00034925 rank 1
2023-02-22 21:29:06,088 DEBUG TRAIN Batch 24/4800 loss 11.313233 loss_att 14.200443 loss_ctc 17.808613 loss_rnnt 9.744598 hw_loss 0.234643 lr 0.00034926 rank 3
2023-02-22 21:29:06,088 DEBUG TRAIN Batch 24/4800 loss 13.267251 loss_att 14.544370 loss_ctc 21.322906 loss_rnnt 11.653835 hw_loss 0.532320 lr 0.00034921 rank 5
2023-02-22 21:29:06,089 DEBUG TRAIN Batch 24/4800 loss 12.092147 loss_att 15.929809 loss_ctc 21.514271 loss_rnnt 9.941863 hw_loss 0.237129 lr 0.00034918 rank 6
2023-02-22 21:29:06,094 DEBUG TRAIN Batch 24/4800 loss 6.081217 loss_att 9.063855 loss_ctc 9.129759 loss_rnnt 4.915662 hw_loss 0.304791 lr 0.00034916 rank 7
2023-02-22 21:29:06,093 DEBUG TRAIN Batch 24/4800 loss 9.724581 loss_att 11.555223 loss_ctc 14.538771 loss_rnnt 8.613564 hw_loss 0.193118 lr 0.00034926 rank 0
2023-02-22 21:30:18,636 DEBUG TRAIN Batch 24/4900 loss 9.998359 loss_att 12.313258 loss_ctc 13.032278 loss_rnnt 8.989457 hw_loss 0.265124 lr 0.00034910 rank 6
2023-02-22 21:30:18,636 DEBUG TRAIN Batch 24/4900 loss 4.773598 loss_att 8.297236 loss_ctc 7.616476 loss_rnnt 3.521091 hw_loss 0.316364 lr 0.00034913 rank 2
2023-02-22 21:30:18,637 DEBUG TRAIN Batch 24/4900 loss 7.168435 loss_att 12.061371 loss_ctc 12.298978 loss_rnnt 5.423289 hw_loss 0.154662 lr 0.00034918 rank 4
2023-02-22 21:30:18,638 DEBUG TRAIN Batch 24/4900 loss 5.745797 loss_att 8.265011 loss_ctc 8.691878 loss_rnnt 4.747907 hw_loss 0.189818 lr 0.00034918 rank 3
2023-02-22 21:30:18,637 DEBUG TRAIN Batch 24/4900 loss 5.549599 loss_att 8.483529 loss_ctc 10.847475 loss_rnnt 4.110593 hw_loss 0.273443 lr 0.00034913 rank 5
2023-02-22 21:30:18,642 DEBUG TRAIN Batch 24/4900 loss 7.388979 loss_att 9.418466 loss_ctc 8.875505 loss_rnnt 6.623520 hw_loss 0.302548 lr 0.00034908 rank 7
2023-02-22 21:30:18,649 DEBUG TRAIN Batch 24/4900 loss 8.602957 loss_att 10.736515 loss_ctc 13.659570 loss_rnnt 7.293909 hw_loss 0.390226 lr 0.00034918 rank 0
2023-02-22 21:30:18,660 DEBUG TRAIN Batch 24/4900 loss 17.656063 loss_att 20.090374 loss_ctc 26.157402 loss_rnnt 15.918158 hw_loss 0.220375 lr 0.00034916 rank 1
2023-02-22 21:31:33,712 DEBUG TRAIN Batch 24/5000 loss 9.484376 loss_att 12.819324 loss_ctc 14.389128 loss_rnnt 7.975014 hw_loss 0.353260 lr 0.00034909 rank 3
2023-02-22 21:31:33,734 DEBUG TRAIN Batch 24/5000 loss 11.275562 loss_att 14.973946 loss_ctc 17.096592 loss_rnnt 9.640246 hw_loss 0.224065 lr 0.00034910 rank 4
2023-02-22 21:31:33,734 DEBUG TRAIN Batch 24/5000 loss 18.492470 loss_att 18.691031 loss_ctc 21.548302 loss_rnnt 17.802061 hw_loss 0.456100 lr 0.00034901 rank 6
2023-02-22 21:31:33,735 DEBUG TRAIN Batch 24/5000 loss 5.401564 loss_att 6.730213 loss_ctc 8.606566 loss_rnnt 4.459196 hw_loss 0.467445 lr 0.00034899 rank 7
2023-02-22 21:31:33,736 DEBUG TRAIN Batch 24/5000 loss 7.853247 loss_att 8.724425 loss_ctc 10.804075 loss_rnnt 7.151788 hw_loss 0.250837 lr 0.00034909 rank 0
2023-02-22 21:31:33,739 DEBUG TRAIN Batch 24/5000 loss 8.049632 loss_att 11.552063 loss_ctc 12.213919 loss_rnnt 6.653202 hw_loss 0.263823 lr 0.00034904 rank 2
2023-02-22 21:31:33,740 DEBUG TRAIN Batch 24/5000 loss 14.024897 loss_att 16.680447 loss_ctc 21.167995 loss_rnnt 12.428750 hw_loss 0.211168 lr 0.00034904 rank 5
2023-02-22 21:31:33,742 DEBUG TRAIN Batch 24/5000 loss 7.943605 loss_att 11.773676 loss_ctc 13.752871 loss_rnnt 6.224167 hw_loss 0.335355 lr 0.00034908 rank 1
2023-02-22 21:32:46,029 DEBUG TRAIN Batch 24/5100 loss 6.734591 loss_att 10.710333 loss_ctc 11.323421 loss_rnnt 5.170735 hw_loss 0.294117 lr 0.00034896 rank 2
2023-02-22 21:32:46,043 DEBUG TRAIN Batch 24/5100 loss 4.869438 loss_att 7.506831 loss_ctc 7.775071 loss_rnnt 3.863263 hw_loss 0.171148 lr 0.00034901 rank 3
2023-02-22 21:32:46,045 DEBUG TRAIN Batch 24/5100 loss 4.433261 loss_att 5.583865 loss_ctc 6.755475 loss_rnnt 3.667760 hw_loss 0.423285 lr 0.00034901 rank 4
2023-02-22 21:32:46,045 DEBUG TRAIN Batch 24/5100 loss 10.331270 loss_att 10.240819 loss_ctc 20.154722 loss_rnnt 8.877684 hw_loss 0.303530 lr 0.00034901 rank 0
2023-02-22 21:32:46,046 DEBUG TRAIN Batch 24/5100 loss 5.593599 loss_att 10.759499 loss_ctc 8.387228 loss_rnnt 4.130720 hw_loss 0.107278 lr 0.00034893 rank 6
2023-02-22 21:32:46,046 DEBUG TRAIN Batch 24/5100 loss 7.370488 loss_att 9.045294 loss_ctc 6.493813 loss_rnnt 7.045911 hw_loss 0.199698 lr 0.00034891 rank 7
2023-02-22 21:32:46,048 DEBUG TRAIN Batch 24/5100 loss 5.657729 loss_att 6.955705 loss_ctc 8.556340 loss_rnnt 4.814326 hw_loss 0.369987 lr 0.00034896 rank 5
2023-02-22 21:32:46,050 DEBUG TRAIN Batch 24/5100 loss 4.395079 loss_att 5.967689 loss_ctc 6.732032 loss_rnnt 3.586862 hw_loss 0.341440 lr 0.00034899 rank 1
2023-02-22 21:33:58,719 DEBUG TRAIN Batch 24/5200 loss 2.738478 loss_att 4.412451 loss_ctc 4.918164 loss_rnnt 2.050814 hw_loss 0.116710 lr 0.00034892 rank 3
2023-02-22 21:33:58,722 DEBUG TRAIN Batch 24/5200 loss 2.224574 loss_att 5.203971 loss_ctc 3.817773 loss_rnnt 1.292473 hw_loss 0.232116 lr 0.00034893 rank 4
2023-02-22 21:33:58,724 DEBUG TRAIN Batch 24/5200 loss 4.717376 loss_att 6.897558 loss_ctc 6.890929 loss_rnnt 3.897031 hw_loss 0.177192 lr 0.00034882 rank 7
2023-02-22 21:33:58,726 DEBUG TRAIN Batch 24/5200 loss 9.106305 loss_att 9.987905 loss_ctc 12.581020 loss_rnnt 8.303148 hw_loss 0.306640 lr 0.00034887 rank 2
2023-02-22 21:33:58,726 DEBUG TRAIN Batch 24/5200 loss 15.263773 loss_att 18.098454 loss_ctc 22.241180 loss_rnnt 13.591640 hw_loss 0.327892 lr 0.00034892 rank 0
2023-02-22 21:33:58,729 DEBUG TRAIN Batch 24/5200 loss 2.464381 loss_att 5.452823 loss_ctc 3.689010 loss_rnnt 1.479028 hw_loss 0.420714 lr 0.00034884 rank 6
2023-02-22 21:33:58,740 DEBUG TRAIN Batch 24/5200 loss 4.076070 loss_att 8.168602 loss_ctc 6.307901 loss_rnnt 2.893425 hw_loss 0.124803 lr 0.00034887 rank 5
2023-02-22 21:33:58,785 DEBUG TRAIN Batch 24/5200 loss 4.092905 loss_att 6.216173 loss_ctc 5.369588 loss_rnnt 3.342436 hw_loss 0.291732 lr 0.00034891 rank 1
2023-02-22 21:35:13,282 DEBUG TRAIN Batch 24/5300 loss 6.494302 loss_att 10.823866 loss_ctc 9.897910 loss_rnnt 4.980621 hw_loss 0.363663 lr 0.00034884 rank 4
2023-02-22 21:35:13,295 DEBUG TRAIN Batch 24/5300 loss 4.009398 loss_att 6.808581 loss_ctc 5.062158 loss_rnnt 3.166455 hw_loss 0.267635 lr 0.00034876 rank 6
2023-02-22 21:35:13,298 DEBUG TRAIN Batch 24/5300 loss 17.407158 loss_att 20.777861 loss_ctc 24.633957 loss_rnnt 15.658160 hw_loss 0.208655 lr 0.00034879 rank 2
2023-02-22 21:35:13,303 DEBUG TRAIN Batch 24/5300 loss 3.448611 loss_att 10.335386 loss_ctc 5.694219 loss_rnnt 1.641043 hw_loss 0.245248 lr 0.00034884 rank 0
2023-02-22 21:35:13,304 DEBUG TRAIN Batch 24/5300 loss 14.201860 loss_att 20.570263 loss_ctc 22.585575 loss_rnnt 11.577169 hw_loss 0.437217 lr 0.00034879 rank 5
2023-02-22 21:35:13,307 DEBUG TRAIN Batch 24/5300 loss 2.568623 loss_att 4.644532 loss_ctc 3.201714 loss_rnnt 1.921557 hw_loss 0.276511 lr 0.00034884 rank 3
2023-02-22 21:35:13,312 DEBUG TRAIN Batch 24/5300 loss 12.641433 loss_att 17.006552 loss_ctc 20.031874 loss_rnnt 10.643035 hw_loss 0.262467 lr 0.00034882 rank 1
2023-02-22 21:35:13,330 DEBUG TRAIN Batch 24/5300 loss 10.592106 loss_att 10.007487 loss_ctc 16.313587 loss_rnnt 9.865289 hw_loss 0.151642 lr 0.00034874 rank 7
2023-02-22 21:36:26,600 DEBUG TRAIN Batch 24/5400 loss 22.783562 loss_att 19.702616 loss_ctc 29.102600 loss_rnnt 22.304180 hw_loss 0.474440 lr 0.00034870 rank 2
2023-02-22 21:36:26,605 DEBUG TRAIN Batch 24/5400 loss 5.597579 loss_att 8.123152 loss_ctc 7.513042 loss_rnnt 4.754913 hw_loss 0.154042 lr 0.00034875 rank 3
2023-02-22 21:36:26,607 DEBUG TRAIN Batch 24/5400 loss 5.458495 loss_att 7.292718 loss_ctc 7.801327 loss_rnnt 4.680985 hw_loss 0.184290 lr 0.00034875 rank 0
2023-02-22 21:36:26,609 DEBUG TRAIN Batch 24/5400 loss 4.724650 loss_att 7.588441 loss_ctc 7.138616 loss_rnnt 3.678880 hw_loss 0.283406 lr 0.00034867 rank 6
2023-02-22 21:36:26,610 DEBUG TRAIN Batch 24/5400 loss 6.733767 loss_att 9.321791 loss_ctc 10.705104 loss_rnnt 5.611811 hw_loss 0.140325 lr 0.00034876 rank 4
2023-02-22 21:36:26,611 DEBUG TRAIN Batch 24/5400 loss 15.610043 loss_att 17.524208 loss_ctc 20.327955 loss_rnnt 14.463696 hw_loss 0.252105 lr 0.00034866 rank 7
2023-02-22 21:36:26,616 DEBUG TRAIN Batch 24/5400 loss 3.160074 loss_att 6.940866 loss_ctc 6.139557 loss_rnnt 1.881368 hw_loss 0.234906 lr 0.00034870 rank 5
2023-02-22 21:36:26,660 DEBUG TRAIN Batch 24/5400 loss 12.842119 loss_att 12.879787 loss_ctc 13.271061 loss_rnnt 12.619823 hw_loss 0.295444 lr 0.00034874 rank 1
2023-02-22 21:37:38,925 DEBUG TRAIN Batch 24/5500 loss 11.282435 loss_att 13.991881 loss_ctc 15.252909 loss_rnnt 10.125418 hw_loss 0.160747 lr 0.00034862 rank 2
2023-02-22 21:37:38,925 DEBUG TRAIN Batch 24/5500 loss 11.894201 loss_att 14.164243 loss_ctc 16.238043 loss_rnnt 10.672985 hw_loss 0.352555 lr 0.00034867 rank 0
2023-02-22 21:37:38,928 DEBUG TRAIN Batch 24/5500 loss 4.743840 loss_att 7.149526 loss_ctc 9.334753 loss_rnnt 3.520795 hw_loss 0.243348 lr 0.00034862 rank 5
2023-02-22 21:37:38,929 DEBUG TRAIN Batch 24/5500 loss 4.164408 loss_att 6.300437 loss_ctc 8.397340 loss_rnnt 2.999044 hw_loss 0.325814 lr 0.00034859 rank 6
2023-02-22 21:37:38,930 DEBUG TRAIN Batch 24/5500 loss 9.464497 loss_att 9.565006 loss_ctc 11.082591 loss_rnnt 9.123332 hw_loss 0.197468 lr 0.00034867 rank 3
2023-02-22 21:37:38,932 DEBUG TRAIN Batch 24/5500 loss 9.156246 loss_att 10.840411 loss_ctc 15.080938 loss_rnnt 7.896862 hw_loss 0.248611 lr 0.00034867 rank 4
2023-02-22 21:37:38,935 DEBUG TRAIN Batch 24/5500 loss 5.600158 loss_att 9.431581 loss_ctc 10.847308 loss_rnnt 4.013398 hw_loss 0.226605 lr 0.00034865 rank 1
2023-02-22 21:37:38,938 DEBUG TRAIN Batch 24/5500 loss 13.596232 loss_att 16.782764 loss_ctc 17.443449 loss_rnnt 12.308264 hw_loss 0.258188 lr 0.00034857 rank 7
2023-02-22 21:38:51,778 DEBUG TRAIN Batch 24/5600 loss 11.917404 loss_att 13.672125 loss_ctc 15.659321 loss_rnnt 10.873925 hw_loss 0.363020 lr 0.00034853 rank 5
2023-02-22 21:38:51,789 DEBUG TRAIN Batch 24/5600 loss 13.030014 loss_att 18.617104 loss_ctc 23.034864 loss_rnnt 10.429323 hw_loss 0.279924 lr 0.00034858 rank 3
2023-02-22 21:38:51,789 DEBUG TRAIN Batch 24/5600 loss 7.748907 loss_att 10.443588 loss_ctc 11.041377 loss_rnnt 6.659645 hw_loss 0.208742 lr 0.00034853 rank 2
2023-02-22 21:38:51,790 DEBUG TRAIN Batch 24/5600 loss 12.964355 loss_att 13.612255 loss_ctc 15.195688 loss_rnnt 12.409584 hw_loss 0.239400 lr 0.00034849 rank 7
2023-02-22 21:38:51,790 DEBUG TRAIN Batch 24/5600 loss 10.385229 loss_att 11.322749 loss_ctc 13.138809 loss_rnnt 9.643853 hw_loss 0.350114 lr 0.00034850 rank 6
2023-02-22 21:38:51,794 DEBUG TRAIN Batch 24/5600 loss 7.211430 loss_att 10.409861 loss_ctc 10.766624 loss_rnnt 5.924623 hw_loss 0.324551 lr 0.00034859 rank 4
2023-02-22 21:38:51,821 DEBUG TRAIN Batch 24/5600 loss 7.387308 loss_att 10.024260 loss_ctc 7.957581 loss_rnnt 6.649117 hw_loss 0.252683 lr 0.00034857 rank 1
2023-02-22 21:38:51,865 DEBUG TRAIN Batch 24/5600 loss 10.568834 loss_att 15.512461 loss_ctc 16.649235 loss_rnnt 8.691864 hw_loss 0.145359 lr 0.00034858 rank 0
2023-02-22 21:40:07,005 DEBUG TRAIN Batch 24/5700 loss 10.108768 loss_att 12.066824 loss_ctc 16.219221 loss_rnnt 8.782178 hw_loss 0.225469 lr 0.00034850 rank 0
2023-02-22 21:40:07,006 DEBUG TRAIN Batch 24/5700 loss 11.299344 loss_att 11.202993 loss_ctc 16.289709 loss_rnnt 10.417693 hw_loss 0.441634 lr 0.00034845 rank 2
2023-02-22 21:40:07,005 DEBUG TRAIN Batch 24/5700 loss 6.299407 loss_att 8.506308 loss_ctc 8.952780 loss_rnnt 5.343025 hw_loss 0.302287 lr 0.00034850 rank 4
2023-02-22 21:40:07,010 DEBUG TRAIN Batch 24/5700 loss 5.231927 loss_att 8.013333 loss_ctc 6.556837 loss_rnnt 4.302936 hw_loss 0.367605 lr 0.00034850 rank 3
2023-02-22 21:40:07,010 DEBUG TRAIN Batch 24/5700 loss 15.980050 loss_att 14.826889 loss_ctc 22.532696 loss_rnnt 15.218241 hw_loss 0.222665 lr 0.00034842 rank 6
2023-02-22 21:40:07,013 DEBUG TRAIN Batch 24/5700 loss 7.402417 loss_att 8.446183 loss_ctc 10.494119 loss_rnnt 6.671040 hw_loss 0.206994 lr 0.00034845 rank 5
2023-02-22 21:40:07,016 DEBUG TRAIN Batch 24/5700 loss 10.163360 loss_att 11.902103 loss_ctc 19.749065 loss_rnnt 8.374932 hw_loss 0.304845 lr 0.00034848 rank 1
2023-02-22 21:40:07,047 DEBUG TRAIN Batch 24/5700 loss 4.558513 loss_att 9.556905 loss_ctc 6.151681 loss_rnnt 3.111264 hw_loss 0.440903 lr 0.00034840 rank 7
2023-02-22 21:41:19,501 DEBUG TRAIN Batch 24/5800 loss 8.978113 loss_att 14.160276 loss_ctc 14.701434 loss_rnnt 7.027069 hw_loss 0.284066 lr 0.00034836 rank 2
2023-02-22 21:41:19,503 DEBUG TRAIN Batch 24/5800 loss 7.369932 loss_att 8.887354 loss_ctc 8.861399 loss_rnnt 6.657989 hw_loss 0.392993 lr 0.00034833 rank 6
2023-02-22 21:41:19,503 DEBUG TRAIN Batch 24/5800 loss 5.665900 loss_att 7.408274 loss_ctc 6.477397 loss_rnnt 5.128894 hw_loss 0.150623 lr 0.00034842 rank 4
2023-02-22 21:41:19,506 DEBUG TRAIN Batch 24/5800 loss 15.217736 loss_att 20.839977 loss_ctc 27.737835 loss_rnnt 12.303508 hw_loss 0.225812 lr 0.00034832 rank 7
2023-02-22 21:41:19,507 DEBUG TRAIN Batch 24/5800 loss 11.871738 loss_att 16.024225 loss_ctc 16.241392 loss_rnnt 10.326391 hw_loss 0.247929 lr 0.00034841 rank 3
2023-02-22 21:41:19,508 DEBUG TRAIN Batch 24/5800 loss 6.467203 loss_att 9.846277 loss_ctc 9.861620 loss_rnnt 5.183862 hw_loss 0.290507 lr 0.00034841 rank 0
2023-02-22 21:41:19,510 DEBUG TRAIN Batch 24/5800 loss 7.848747 loss_att 8.477576 loss_ctc 9.512197 loss_rnnt 7.322665 hw_loss 0.334731 lr 0.00034840 rank 1
2023-02-22 21:41:19,510 DEBUG TRAIN Batch 24/5800 loss 3.695159 loss_att 4.880722 loss_ctc 6.947417 loss_rnnt 2.858426 hw_loss 0.311223 lr 0.00034837 rank 5
2023-02-22 21:42:31,235 DEBUG TRAIN Batch 24/5900 loss 9.454768 loss_att 13.090275 loss_ctc 11.732001 loss_rnnt 8.216915 hw_loss 0.388351 lr 0.00034833 rank 3
2023-02-22 21:42:31,237 DEBUG TRAIN Batch 24/5900 loss 6.725412 loss_att 7.530891 loss_ctc 12.024647 loss_rnnt 5.694875 hw_loss 0.305394 lr 0.00034828 rank 2
2023-02-22 21:42:31,237 DEBUG TRAIN Batch 24/5900 loss 8.769535 loss_att 11.519490 loss_ctc 14.534479 loss_rnnt 7.370286 hw_loss 0.151121 lr 0.00034825 rank 6
2023-02-22 21:42:31,241 DEBUG TRAIN Batch 24/5900 loss 7.089977 loss_att 9.535969 loss_ctc 11.558867 loss_rnnt 5.877590 hw_loss 0.238756 lr 0.00034833 rank 4
2023-02-22 21:42:31,241 DEBUG TRAIN Batch 24/5900 loss 9.687337 loss_att 14.948395 loss_ctc 19.055153 loss_rnnt 7.220403 hw_loss 0.310650 lr 0.00034833 rank 0
2023-02-22 21:42:31,243 DEBUG TRAIN Batch 24/5900 loss 4.994575 loss_att 9.803171 loss_ctc 7.658088 loss_rnnt 3.524536 hw_loss 0.287222 lr 0.00034832 rank 1
2023-02-22 21:42:31,247 DEBUG TRAIN Batch 24/5900 loss 3.183356 loss_att 7.202539 loss_ctc 5.663564 loss_rnnt 1.895617 hw_loss 0.287263 lr 0.00034823 rank 7
2023-02-22 21:42:31,290 DEBUG TRAIN Batch 24/5900 loss 7.614964 loss_att 11.488995 loss_ctc 9.396791 loss_rnnt 6.374510 hw_loss 0.427633 lr 0.00034828 rank 5
2023-02-22 21:43:45,007 DEBUG TRAIN Batch 24/6000 loss 4.399655 loss_att 6.730004 loss_ctc 7.599035 loss_rnnt 3.394202 hw_loss 0.211497 lr 0.00034823 rank 1
2023-02-22 21:43:45,014 DEBUG TRAIN Batch 24/6000 loss 8.595446 loss_att 11.509904 loss_ctc 11.010189 loss_rnnt 7.555553 hw_loss 0.253191 lr 0.00034815 rank 7
2023-02-22 21:43:45,014 DEBUG TRAIN Batch 24/6000 loss 6.640001 loss_att 10.433288 loss_ctc 8.449748 loss_rnnt 5.570878 hw_loss 0.129684 lr 0.00034820 rank 2
2023-02-22 21:43:45,015 DEBUG TRAIN Batch 24/6000 loss 6.002162 loss_att 10.007381 loss_ctc 9.244437 loss_rnnt 4.706235 hw_loss 0.117337 lr 0.00034820 rank 5
2023-02-22 21:43:45,017 DEBUG TRAIN Batch 24/6000 loss 5.473787 loss_att 6.061057 loss_ctc 6.290160 loss_rnnt 5.024176 hw_loss 0.418701 lr 0.00034824 rank 0
2023-02-22 21:43:45,018 DEBUG TRAIN Batch 24/6000 loss 4.846419 loss_att 9.223108 loss_ctc 7.788305 loss_rnnt 3.468826 hw_loss 0.206257 lr 0.00034825 rank 4
2023-02-22 21:43:45,018 DEBUG TRAIN Batch 24/6000 loss 6.185729 loss_att 10.314986 loss_ctc 7.396787 loss_rnnt 5.002931 hw_loss 0.366509 lr 0.00034825 rank 3
2023-02-22 21:43:45,019 DEBUG TRAIN Batch 24/6000 loss 8.372340 loss_att 12.555899 loss_ctc 12.316011 loss_rnnt 6.847092 hw_loss 0.305087 lr 0.00034816 rank 6
2023-02-22 21:44:58,781 DEBUG TRAIN Batch 24/6100 loss 15.861287 loss_att 18.192940 loss_ctc 19.418310 loss_rnnt 14.809828 hw_loss 0.207862 lr 0.00034808 rank 6
2023-02-22 21:44:58,782 DEBUG TRAIN Batch 24/6100 loss 9.696173 loss_att 12.007157 loss_ctc 13.015547 loss_rnnt 8.663975 hw_loss 0.238906 lr 0.00034811 rank 2
2023-02-22 21:44:58,785 DEBUG TRAIN Batch 24/6100 loss 10.595523 loss_att 17.185814 loss_ctc 17.630249 loss_rnnt 8.207932 hw_loss 0.246689 lr 0.00034806 rank 7
2023-02-22 21:44:58,787 DEBUG TRAIN Batch 24/6100 loss 18.602955 loss_att 22.300341 loss_ctc 22.872524 loss_rnnt 17.072083 hw_loss 0.416472 lr 0.00034811 rank 5
2023-02-22 21:44:58,788 DEBUG TRAIN Batch 24/6100 loss 5.149991 loss_att 7.677658 loss_ctc 6.749297 loss_rnnt 4.286530 hw_loss 0.271286 lr 0.00034816 rank 3
2023-02-22 21:44:58,790 DEBUG TRAIN Batch 24/6100 loss 3.631696 loss_att 7.696109 loss_ctc 7.392469 loss_rnnt 2.145974 hw_loss 0.321380 lr 0.00034816 rank 4
2023-02-22 21:44:58,793 DEBUG TRAIN Batch 24/6100 loss 6.763372 loss_att 10.803450 loss_ctc 10.489685 loss_rnnt 5.348543 hw_loss 0.206199 lr 0.00034816 rank 0
2023-02-22 21:44:58,795 DEBUG TRAIN Batch 24/6100 loss 4.857945 loss_att 7.779647 loss_ctc 6.687994 loss_rnnt 3.855235 hw_loss 0.326930 lr 0.00034815 rank 1
2023-02-22 21:46:10,976 DEBUG TRAIN Batch 24/6200 loss 13.589542 loss_att 17.339426 loss_ctc 24.432011 loss_rnnt 11.272350 hw_loss 0.227911 lr 0.00034808 rank 3
2023-02-22 21:46:10,985 DEBUG TRAIN Batch 24/6200 loss 4.730092 loss_att 7.509825 loss_ctc 6.725163 loss_rnnt 3.745662 hw_loss 0.304639 lr 0.00034803 rank 2
2023-02-22 21:46:10,993 DEBUG TRAIN Batch 24/6200 loss 6.506753 loss_att 8.639895 loss_ctc 9.842211 loss_rnnt 5.418157 hw_loss 0.407324 lr 0.00034798 rank 7
2023-02-22 21:46:10,994 DEBUG TRAIN Batch 24/6200 loss 8.325998 loss_att 12.303522 loss_ctc 13.340281 loss_rnnt 6.662855 hw_loss 0.373250 lr 0.00034803 rank 5
2023-02-22 21:46:10,994 DEBUG TRAIN Batch 24/6200 loss 7.428685 loss_att 9.703263 loss_ctc 11.509547 loss_rnnt 6.308748 hw_loss 0.226699 lr 0.00034799 rank 6
2023-02-22 21:46:11,018 DEBUG TRAIN Batch 24/6200 loss 8.547760 loss_att 10.562781 loss_ctc 14.311499 loss_rnnt 7.259508 hw_loss 0.218907 lr 0.00034807 rank 0
2023-02-22 21:46:11,027 DEBUG TRAIN Batch 24/6200 loss 10.765364 loss_att 13.510410 loss_ctc 14.054279 loss_rnnt 9.618659 hw_loss 0.298450 lr 0.00034808 rank 4
2023-02-22 21:46:11,039 DEBUG TRAIN Batch 24/6200 loss 7.589281 loss_att 11.893426 loss_ctc 12.307736 loss_rnnt 5.882299 hw_loss 0.406922 lr 0.00034806 rank 1
2023-02-22 21:47:23,980 DEBUG TRAIN Batch 24/6300 loss 9.326903 loss_att 11.785671 loss_ctc 12.191187 loss_rnnt 8.288681 hw_loss 0.308559 lr 0.00034794 rank 5
2023-02-22 21:47:23,988 DEBUG TRAIN Batch 24/6300 loss 12.230223 loss_att 14.578445 loss_ctc 18.643612 loss_rnnt 10.715770 hw_loss 0.355670 lr 0.00034800 rank 4
2023-02-22 21:47:23,989 DEBUG TRAIN Batch 24/6300 loss 9.962375 loss_att 10.571736 loss_ctc 16.601376 loss_rnnt 8.877957 hw_loss 0.145024 lr 0.00034799 rank 0
2023-02-22 21:47:23,989 DEBUG TRAIN Batch 24/6300 loss 7.352197 loss_att 8.118348 loss_ctc 13.360538 loss_rnnt 6.289328 hw_loss 0.203489 lr 0.00034794 rank 2
2023-02-22 21:47:23,990 DEBUG TRAIN Batch 24/6300 loss 6.143599 loss_att 10.150507 loss_ctc 8.106712 loss_rnnt 5.005954 hw_loss 0.139716 lr 0.00034791 rank 6
2023-02-22 21:47:23,990 DEBUG TRAIN Batch 24/6300 loss 12.592396 loss_att 13.981816 loss_ctc 16.225378 loss_rnnt 11.677119 hw_loss 0.286866 lr 0.00034799 rank 3
2023-02-22 21:47:23,992 DEBUG TRAIN Batch 24/6300 loss 2.433429 loss_att 4.647258 loss_ctc 5.274519 loss_rnnt 1.441914 hw_loss 0.318633 lr 0.00034798 rank 1
2023-02-22 21:47:23,994 DEBUG TRAIN Batch 24/6300 loss 9.040352 loss_att 13.164253 loss_ctc 12.536169 loss_rnnt 7.623155 hw_loss 0.236826 lr 0.00034789 rank 7
2023-02-22 21:48:39,275 DEBUG TRAIN Batch 24/6400 loss 11.776937 loss_att 16.859167 loss_ctc 20.296118 loss_rnnt 9.496431 hw_loss 0.240313 lr 0.00034786 rank 2
2023-02-22 21:48:39,277 DEBUG TRAIN Batch 24/6400 loss 10.120104 loss_att 15.197018 loss_ctc 16.076859 loss_rnnt 8.141562 hw_loss 0.316735 lr 0.00034791 rank 3
2023-02-22 21:48:39,281 DEBUG TRAIN Batch 24/6400 loss 6.114970 loss_att 7.609296 loss_ctc 10.214255 loss_rnnt 5.147306 hw_loss 0.229176 lr 0.00034789 rank 1
2023-02-22 21:48:39,282 DEBUG TRAIN Batch 24/6400 loss 14.829151 loss_att 15.098148 loss_ctc 24.151815 loss_rnnt 13.412819 hw_loss 0.224080 lr 0.00034783 rank 6
2023-02-22 21:48:39,282 DEBUG TRAIN Batch 24/6400 loss 6.430829 loss_att 7.237752 loss_ctc 7.428736 loss_rnnt 5.877068 hw_loss 0.486228 lr 0.00034791 rank 0
2023-02-22 21:48:39,282 DEBUG TRAIN Batch 24/6400 loss 8.785838 loss_att 12.796654 loss_ctc 8.856828 loss_rnnt 7.797943 hw_loss 0.330500 lr 0.00034781 rank 7
2023-02-22 21:48:39,324 DEBUG TRAIN Batch 24/6400 loss 9.522141 loss_att 10.397061 loss_ctc 14.909250 loss_rnnt 8.478880 hw_loss 0.281244 lr 0.00034791 rank 4
2023-02-22 21:48:39,329 DEBUG TRAIN Batch 24/6400 loss 11.096653 loss_att 12.058705 loss_ctc 14.098282 loss_rnnt 10.351449 hw_loss 0.286081 lr 0.00034786 rank 5
2023-02-22 21:49:51,138 DEBUG TRAIN Batch 24/6500 loss 6.652533 loss_att 10.872051 loss_ctc 12.517021 loss_rnnt 4.837511 hw_loss 0.354722 lr 0.00034782 rank 3
2023-02-22 21:49:51,139 DEBUG TRAIN Batch 24/6500 loss 8.264388 loss_att 11.824619 loss_ctc 10.303404 loss_rnnt 7.157133 hw_loss 0.231264 lr 0.00034773 rank 7
2023-02-22 21:49:51,140 DEBUG TRAIN Batch 24/6500 loss 9.836543 loss_att 11.177411 loss_ctc 11.535141 loss_rnnt 9.216791 hw_loss 0.234558 lr 0.00034774 rank 6
2023-02-22 21:49:51,141 DEBUG TRAIN Batch 24/6500 loss 4.157091 loss_att 7.274887 loss_ctc 6.731179 loss_rnnt 2.936023 hw_loss 0.476809 lr 0.00034783 rank 4
2023-02-22 21:49:51,142 DEBUG TRAIN Batch 24/6500 loss 9.666904 loss_att 13.924570 loss_ctc 11.152618 loss_rnnt 8.390332 hw_loss 0.425521 lr 0.00034777 rank 2
2023-02-22 21:49:51,147 DEBUG TRAIN Batch 24/6500 loss 5.161564 loss_att 8.059136 loss_ctc 6.074385 loss_rnnt 4.340631 hw_loss 0.224454 lr 0.00034782 rank 0
2023-02-22 21:49:51,150 DEBUG TRAIN Batch 24/6500 loss 8.017541 loss_att 10.230211 loss_ctc 10.945374 loss_rnnt 6.991374 hw_loss 0.362355 lr 0.00034781 rank 1
2023-02-22 21:49:51,153 DEBUG TRAIN Batch 24/6500 loss 12.125138 loss_att 17.691769 loss_ctc 23.770603 loss_rnnt 9.321840 hw_loss 0.257330 lr 0.00034778 rank 5
2023-02-22 21:51:03,474 DEBUG TRAIN Batch 24/6600 loss 29.632093 loss_att 37.454231 loss_ctc 52.002270 loss_rnnt 25.033089 hw_loss 0.097284 lr 0.00034769 rank 2
2023-02-22 21:51:03,476 DEBUG TRAIN Batch 24/6600 loss 14.587345 loss_att 19.181320 loss_ctc 17.082256 loss_rnnt 13.266659 hw_loss 0.129819 lr 0.00034773 rank 1
2023-02-22 21:51:03,477 DEBUG TRAIN Batch 24/6600 loss 10.005686 loss_att 13.210958 loss_ctc 18.007767 loss_rnnt 8.102815 hw_loss 0.365385 lr 0.00034774 rank 3
2023-02-22 21:51:03,476 DEBUG TRAIN Batch 24/6600 loss 7.703039 loss_att 11.862574 loss_ctc 13.381285 loss_rnnt 5.966846 hw_loss 0.275973 lr 0.00034769 rank 5
2023-02-22 21:51:03,477 DEBUG TRAIN Batch 24/6600 loss 9.898034 loss_att 11.133879 loss_ctc 15.105879 loss_rnnt 8.758106 hw_loss 0.371961 lr 0.00034766 rank 6
2023-02-22 21:51:03,478 DEBUG TRAIN Batch 24/6600 loss 4.028964 loss_att 6.747218 loss_ctc 8.405689 loss_rnnt 2.725034 hw_loss 0.331340 lr 0.00034764 rank 7
2023-02-22 21:51:03,479 DEBUG TRAIN Batch 24/6600 loss 7.231730 loss_att 11.027203 loss_ctc 8.703621 loss_rnnt 6.114306 hw_loss 0.303893 lr 0.00034774 rank 4
2023-02-22 21:51:03,484 DEBUG TRAIN Batch 24/6600 loss 5.930978 loss_att 7.898518 loss_ctc 10.699328 loss_rnnt 4.822488 hw_loss 0.148503 lr 0.00034774 rank 0
2023-02-22 21:52:16,922 DEBUG TRAIN Batch 24/6700 loss 5.984140 loss_att 9.838138 loss_ctc 12.482108 loss_rnnt 4.125027 hw_loss 0.416097 lr 0.00034761 rank 5
2023-02-22 21:52:16,936 DEBUG TRAIN Batch 24/6700 loss 9.318789 loss_att 10.056231 loss_ctc 11.180035 loss_rnnt 8.818624 hw_loss 0.195958 lr 0.00034757 rank 6
2023-02-22 21:52:16,940 DEBUG TRAIN Batch 24/6700 loss 6.099138 loss_att 7.041687 loss_ctc 6.493221 loss_rnnt 5.787296 hw_loss 0.132726 lr 0.00034764 rank 1
2023-02-22 21:52:16,940 DEBUG TRAIN Batch 24/6700 loss 9.770579 loss_att 12.736772 loss_ctc 12.423671 loss_rnnt 8.713861 hw_loss 0.205750 lr 0.00034761 rank 2
2023-02-22 21:52:16,940 DEBUG TRAIN Batch 24/6700 loss 7.380304 loss_att 9.476852 loss_ctc 9.762256 loss_rnnt 6.550862 hw_loss 0.173511 lr 0.00034765 rank 0
2023-02-22 21:52:16,942 DEBUG TRAIN Batch 24/6700 loss 12.249587 loss_att 13.776390 loss_ctc 15.058048 loss_rnnt 11.341886 hw_loss 0.427273 lr 0.00034756 rank 7
2023-02-22 21:52:16,947 DEBUG TRAIN Batch 24/6700 loss 9.176328 loss_att 11.844845 loss_ctc 13.635022 loss_rnnt 7.919689 hw_loss 0.240828 lr 0.00034766 rank 3
2023-02-22 21:52:16,967 DEBUG TRAIN Batch 24/6700 loss 8.574782 loss_att 9.152470 loss_ctc 8.920588 loss_rnnt 8.272165 hw_loss 0.264322 lr 0.00034766 rank 4
2023-02-22 21:53:31,273 DEBUG TRAIN Batch 24/6800 loss 12.071097 loss_att 16.412214 loss_ctc 19.876661 loss_rnnt 9.973797 hw_loss 0.353129 lr 0.00034758 rank 4
2023-02-22 21:53:31,283 DEBUG TRAIN Batch 24/6800 loss 8.719535 loss_att 11.718308 loss_ctc 10.868565 loss_rnnt 7.724338 hw_loss 0.204198 lr 0.00034752 rank 2
2023-02-22 21:53:31,287 DEBUG TRAIN Batch 24/6800 loss 12.162004 loss_att 13.384421 loss_ctc 15.844606 loss_rnnt 11.258115 hw_loss 0.315737 lr 0.00034757 rank 3
2023-02-22 21:53:31,287 DEBUG TRAIN Batch 24/6800 loss 7.569299 loss_att 14.832184 loss_ctc 10.017927 loss_rnnt 5.606339 hw_loss 0.344812 lr 0.00034756 rank 1
2023-02-22 21:53:31,287 DEBUG TRAIN Batch 24/6800 loss 13.996794 loss_att 16.572184 loss_ctc 23.374260 loss_rnnt 12.090307 hw_loss 0.264525 lr 0.00034747 rank 7
2023-02-22 21:53:31,287 DEBUG TRAIN Batch 24/6800 loss 11.053904 loss_att 12.182014 loss_ctc 13.774353 loss_rnnt 10.312485 hw_loss 0.287006 lr 0.00034749 rank 6
2023-02-22 21:53:31,294 DEBUG TRAIN Batch 24/6800 loss 2.495806 loss_att 5.557602 loss_ctc 3.396332 loss_rnnt 1.697044 hw_loss 0.124375 lr 0.00034757 rank 0
2023-02-22 21:53:31,332 DEBUG TRAIN Batch 24/6800 loss 3.730943 loss_att 7.438554 loss_ctc 8.946939 loss_rnnt 2.126307 hw_loss 0.314339 lr 0.00034752 rank 5
2023-02-22 21:54:42,606 DEBUG TRAIN Batch 24/6900 loss 4.861469 loss_att 6.899441 loss_ctc 6.980860 loss_rnnt 4.063449 hw_loss 0.202199 lr 0.00034744 rank 2
2023-02-22 21:54:42,606 DEBUG TRAIN Batch 24/6900 loss 6.374921 loss_att 7.329091 loss_ctc 8.868963 loss_rnnt 5.708537 hw_loss 0.268146 lr 0.00034749 rank 0
2023-02-22 21:54:42,608 DEBUG TRAIN Batch 24/6900 loss 6.976787 loss_att 8.684356 loss_ctc 8.877331 loss_rnnt 6.226171 hw_loss 0.291930 lr 0.00034739 rank 7
2023-02-22 21:54:42,610 DEBUG TRAIN Batch 24/6900 loss 8.926202 loss_att 12.355018 loss_ctc 12.115377 loss_rnnt 7.725336 hw_loss 0.168524 lr 0.00034749 rank 3
2023-02-22 21:54:42,609 DEBUG TRAIN Batch 24/6900 loss 9.460820 loss_att 12.102898 loss_ctc 17.431280 loss_rnnt 7.809473 hw_loss 0.112884 lr 0.00034741 rank 6
2023-02-22 21:54:42,611 DEBUG TRAIN Batch 24/6900 loss 11.897883 loss_att 13.596098 loss_ctc 20.237226 loss_rnnt 10.321363 hw_loss 0.234307 lr 0.00034744 rank 5
2023-02-22 21:54:42,614 DEBUG TRAIN Batch 24/6900 loss 12.755978 loss_att 13.914574 loss_ctc 17.025612 loss_rnnt 11.814657 hw_loss 0.263095 lr 0.00034747 rank 1
2023-02-22 21:54:42,614 DEBUG TRAIN Batch 24/6900 loss 7.426027 loss_att 8.862494 loss_ctc 9.248887 loss_rnnt 6.730306 hw_loss 0.310086 lr 0.00034749 rank 4
2023-02-22 21:55:55,760 DEBUG TRAIN Batch 24/7000 loss 2.475685 loss_att 5.122755 loss_ctc 3.124077 loss_rnnt 1.718982 hw_loss 0.264068 lr 0.00034741 rank 4
2023-02-22 21:55:55,763 DEBUG TRAIN Batch 24/7000 loss 7.774289 loss_att 7.075603 loss_ctc 10.244224 loss_rnnt 7.269458 hw_loss 0.591081 lr 0.00034735 rank 2
2023-02-22 21:55:55,763 DEBUG TRAIN Batch 24/7000 loss 4.811014 loss_att 7.580634 loss_ctc 5.095918 loss_rnnt 4.128476 hw_loss 0.169925 lr 0.00034732 rank 6
2023-02-22 21:55:55,764 DEBUG TRAIN Batch 24/7000 loss 10.264248 loss_att 14.226560 loss_ctc 14.503230 loss_rnnt 8.820057 hw_loss 0.162243 lr 0.00034740 rank 3
2023-02-22 21:55:55,769 DEBUG TRAIN Batch 24/7000 loss 2.894624 loss_att 5.439437 loss_ctc 5.074365 loss_rnnt 1.999101 hw_loss 0.179866 lr 0.00034739 rank 1
2023-02-22 21:55:55,770 DEBUG TRAIN Batch 24/7000 loss 9.550547 loss_att 10.516219 loss_ctc 11.709521 loss_rnnt 8.819370 hw_loss 0.469084 lr 0.00034740 rank 0
2023-02-22 21:55:55,770 DEBUG TRAIN Batch 24/7000 loss 12.956482 loss_att 12.753598 loss_ctc 17.649509 loss_rnnt 12.239467 hw_loss 0.247229 lr 0.00034736 rank 5
2023-02-22 21:55:55,813 DEBUG TRAIN Batch 24/7000 loss 8.744347 loss_att 10.644938 loss_ctc 8.819290 loss_rnnt 8.174797 hw_loss 0.336447 lr 0.00034731 rank 7
2023-02-22 21:57:10,763 DEBUG TRAIN Batch 24/7100 loss 9.067902 loss_att 11.611077 loss_ctc 15.019089 loss_rnnt 7.594074 hw_loss 0.321939 lr 0.00034724 rank 6
2023-02-22 21:57:10,765 DEBUG TRAIN Batch 24/7100 loss 5.732086 loss_att 7.712749 loss_ctc 7.303056 loss_rnnt 4.969294 hw_loss 0.294744 lr 0.00034732 rank 3
2023-02-22 21:57:10,766 DEBUG TRAIN Batch 24/7100 loss 10.513211 loss_att 10.646247 loss_ctc 11.253974 loss_rnnt 10.151549 hw_loss 0.443035 lr 0.00034732 rank 4
2023-02-22 21:57:10,767 DEBUG TRAIN Batch 24/7100 loss 2.615162 loss_att 5.039179 loss_ctc 3.408183 loss_rnnt 1.881919 hw_loss 0.267568 lr 0.00034722 rank 7
2023-02-22 21:57:10,769 DEBUG TRAIN Batch 24/7100 loss 10.117238 loss_att 9.352788 loss_ctc 14.212674 loss_rnnt 9.510411 hw_loss 0.400609 lr 0.00034731 rank 1
2023-02-22 21:57:10,790 DEBUG TRAIN Batch 24/7100 loss 6.717250 loss_att 11.085552 loss_ctc 10.809393 loss_rnnt 5.162787 hw_loss 0.253469 lr 0.00034727 rank 2
2023-02-22 21:57:10,795 DEBUG TRAIN Batch 24/7100 loss 10.905223 loss_att 11.902340 loss_ctc 14.736540 loss_rnnt 9.925850 hw_loss 0.504578 lr 0.00034727 rank 5
2023-02-22 21:57:10,818 DEBUG TRAIN Batch 24/7100 loss 4.174813 loss_att 5.858505 loss_ctc 6.706964 loss_rnnt 3.414257 hw_loss 0.161619 lr 0.00034732 rank 0
2023-02-22 21:58:24,193 DEBUG TRAIN Batch 24/7200 loss 7.328769 loss_att 9.989867 loss_ctc 17.846729 loss_rnnt 5.239191 hw_loss 0.290557 lr 0.00034722 rank 1
2023-02-22 21:58:24,205 DEBUG TRAIN Batch 24/7200 loss 9.321658 loss_att 11.295890 loss_ctc 14.372471 loss_rnnt 8.063375 hw_loss 0.356240 lr 0.00034723 rank 0
2023-02-22 21:58:24,206 DEBUG TRAIN Batch 24/7200 loss 9.266520 loss_att 10.525899 loss_ctc 11.237959 loss_rnnt 8.536003 hw_loss 0.404592 lr 0.00034719 rank 2
2023-02-22 21:58:24,208 DEBUG TRAIN Batch 24/7200 loss 3.571917 loss_att 8.527675 loss_ctc 6.334507 loss_rnnt 2.061047 hw_loss 0.283823 lr 0.00034724 rank 3
2023-02-22 21:58:24,207 DEBUG TRAIN Batch 24/7200 loss 10.558849 loss_att 14.963673 loss_ctc 17.883766 loss_rnnt 8.604368 hw_loss 0.181615 lr 0.00034719 rank 5
2023-02-22 21:58:24,209 DEBUG TRAIN Batch 24/7200 loss 15.242329 loss_att 18.306627 loss_ctc 21.226101 loss_rnnt 13.699501 hw_loss 0.247745 lr 0.00034714 rank 7
2023-02-22 21:58:24,211 DEBUG TRAIN Batch 24/7200 loss 7.770723 loss_att 10.244309 loss_ctc 10.282632 loss_rnnt 6.791485 hw_loss 0.280500 lr 0.00034715 rank 6
2023-02-22 21:58:24,258 DEBUG TRAIN Batch 24/7200 loss 4.609921 loss_att 8.509150 loss_ctc 7.662347 loss_rnnt 3.252866 hw_loss 0.319161 lr 0.00034724 rank 4
2023-02-22 21:59:37,453 DEBUG TRAIN Batch 24/7300 loss 7.405127 loss_att 9.508111 loss_ctc 10.983629 loss_rnnt 6.267306 hw_loss 0.450169 lr 0.00034715 rank 3
2023-02-22 21:59:37,464 DEBUG TRAIN Batch 24/7300 loss 8.729543 loss_att 12.294770 loss_ctc 13.215618 loss_rnnt 7.311015 hw_loss 0.201262 lr 0.00034710 rank 2
2023-02-22 21:59:37,473 DEBUG TRAIN Batch 24/7300 loss 13.625901 loss_att 17.438971 loss_ctc 17.642233 loss_rnnt 12.123492 hw_loss 0.383033 lr 0.00034715 rank 0
2023-02-22 21:59:37,474 DEBUG TRAIN Batch 24/7300 loss 7.808387 loss_att 11.194338 loss_ctc 8.756385 loss_rnnt 6.899005 hw_loss 0.198361 lr 0.00034714 rank 1
2023-02-22 21:59:37,476 DEBUG TRAIN Batch 24/7300 loss 13.635406 loss_att 19.652666 loss_ctc 22.575710 loss_rnnt 11.062970 hw_loss 0.331767 lr 0.00034706 rank 7
2023-02-22 21:59:37,477 DEBUG TRAIN Batch 24/7300 loss 10.288318 loss_att 12.883221 loss_ctc 12.326082 loss_rnnt 9.329536 hw_loss 0.315186 lr 0.00034716 rank 4
2023-02-22 21:59:37,479 DEBUG TRAIN Batch 24/7300 loss 3.987771 loss_att 6.116203 loss_ctc 6.735517 loss_rnnt 3.056533 hw_loss 0.260972 lr 0.00034707 rank 6
2023-02-22 21:59:37,532 DEBUG TRAIN Batch 24/7300 loss 6.939367 loss_att 11.616041 loss_ctc 10.777544 loss_rnnt 5.318898 hw_loss 0.325082 lr 0.00034710 rank 5
2023-02-22 22:00:50,360 DEBUG TRAIN Batch 24/7400 loss 4.329490 loss_att 6.545571 loss_ctc 5.711010 loss_rnnt 3.567653 hw_loss 0.252033 lr 0.00034702 rank 2
2023-02-22 22:00:50,363 DEBUG TRAIN Batch 24/7400 loss 5.135419 loss_att 7.531169 loss_ctc 8.940372 loss_rnnt 3.967556 hw_loss 0.340099 lr 0.00034707 rank 4
2023-02-22 22:00:50,364 DEBUG TRAIN Batch 24/7400 loss 7.602663 loss_att 8.410732 loss_ctc 9.787565 loss_rnnt 7.013341 hw_loss 0.255726 lr 0.00034697 rank 7
2023-02-22 22:00:50,366 DEBUG TRAIN Batch 24/7400 loss 7.281365 loss_att 8.990200 loss_ctc 9.519506 loss_rnnt 6.433926 hw_loss 0.388601 lr 0.00034707 rank 3
2023-02-22 22:00:50,368 DEBUG TRAIN Batch 24/7400 loss 15.037574 loss_att 17.213768 loss_ctc 24.006577 loss_rnnt 13.242968 hw_loss 0.306560 lr 0.00034702 rank 5
2023-02-22 22:00:50,368 DEBUG TRAIN Batch 24/7400 loss 11.629214 loss_att 12.096349 loss_ctc 14.081525 loss_rnnt 11.048209 hw_loss 0.301133 lr 0.00034699 rank 6
2023-02-22 22:00:50,370 DEBUG TRAIN Batch 24/7400 loss 4.824827 loss_att 6.430336 loss_ctc 7.698554 loss_rnnt 3.887979 hw_loss 0.436092 lr 0.00034705 rank 1
2023-02-22 22:00:50,417 DEBUG TRAIN Batch 24/7400 loss 11.657089 loss_att 16.548632 loss_ctc 15.790183 loss_rnnt 10.023590 hw_loss 0.195208 lr 0.00034707 rank 0
2023-02-22 22:02:05,332 DEBUG TRAIN Batch 24/7500 loss 9.714131 loss_att 10.644587 loss_ctc 10.687067 loss_rnnt 9.295079 hw_loss 0.193566 lr 0.00034699 rank 4
2023-02-22 22:02:05,335 DEBUG TRAIN Batch 24/7500 loss 7.347481 loss_att 10.982445 loss_ctc 9.869179 loss_rnnt 6.122226 hw_loss 0.303817 lr 0.00034694 rank 2
2023-02-22 22:02:05,337 DEBUG TRAIN Batch 24/7500 loss 8.856948 loss_att 8.805979 loss_ctc 13.051747 loss_rnnt 8.159680 hw_loss 0.277788 lr 0.00034690 rank 6
2023-02-22 22:02:05,338 DEBUG TRAIN Batch 24/7500 loss 7.790463 loss_att 9.861362 loss_ctc 14.241419 loss_rnnt 6.369250 hw_loss 0.275450 lr 0.00034699 rank 3
2023-02-22 22:02:05,337 DEBUG TRAIN Batch 24/7500 loss 8.347981 loss_att 11.000320 loss_ctc 13.568369 loss_rnnt 7.024610 hw_loss 0.181599 lr 0.00034694 rank 5
2023-02-22 22:02:05,338 DEBUG TRAIN Batch 24/7500 loss 4.308670 loss_att 7.984839 loss_ctc 7.929080 loss_rnnt 2.927564 hw_loss 0.305906 lr 0.00034698 rank 0
2023-02-22 22:02:05,339 DEBUG TRAIN Batch 24/7500 loss 10.528486 loss_att 13.551880 loss_ctc 14.914138 loss_rnnt 9.120917 hw_loss 0.409007 lr 0.00034697 rank 1
2023-02-22 22:02:05,340 DEBUG TRAIN Batch 24/7500 loss 18.498308 loss_att 19.710775 loss_ctc 27.735126 loss_rnnt 16.781797 hw_loss 0.454581 lr 0.00034689 rank 7
2023-02-22 22:03:17,822 DEBUG TRAIN Batch 24/7600 loss 7.264974 loss_att 10.608657 loss_ctc 11.494024 loss_rnnt 5.931858 hw_loss 0.188448 lr 0.00034690 rank 3
2023-02-22 22:03:17,824 DEBUG TRAIN Batch 24/7600 loss 4.264430 loss_att 8.882495 loss_ctc 6.744958 loss_rnnt 2.964282 hw_loss 0.085872 lr 0.00034691 rank 4
2023-02-22 22:03:17,825 DEBUG TRAIN Batch 24/7600 loss 8.384427 loss_att 8.783398 loss_ctc 12.157710 loss_rnnt 7.611331 hw_loss 0.356619 lr 0.00034685 rank 2
2023-02-22 22:03:17,825 DEBUG TRAIN Batch 24/7600 loss 8.030020 loss_att 9.906376 loss_ctc 13.221395 loss_rnnt 6.876124 hw_loss 0.162076 lr 0.00034682 rank 6
2023-02-22 22:03:17,826 DEBUG TRAIN Batch 24/7600 loss 3.479504 loss_att 4.778914 loss_ctc 3.443922 loss_rnnt 3.124216 hw_loss 0.187781 lr 0.00034689 rank 1
2023-02-22 22:03:17,826 DEBUG TRAIN Batch 24/7600 loss 6.333231 loss_att 7.888038 loss_ctc 8.417742 loss_rnnt 5.581191 hw_loss 0.305896 lr 0.00034690 rank 0
2023-02-22 22:03:17,831 DEBUG TRAIN Batch 24/7600 loss 12.733230 loss_att 19.012691 loss_ctc 18.560310 loss_rnnt 10.497755 hw_loss 0.379946 lr 0.00034681 rank 7
2023-02-22 22:03:17,833 DEBUG TRAIN Batch 24/7600 loss 7.530290 loss_att 8.299195 loss_ctc 12.465186 loss_rnnt 6.585531 hw_loss 0.249358 lr 0.00034685 rank 5
2023-02-22 22:04:30,598 DEBUG TRAIN Batch 24/7700 loss 10.196427 loss_att 11.903790 loss_ctc 16.637484 loss_rnnt 8.830498 hw_loss 0.310593 lr 0.00034674 rank 6
2023-02-22 22:04:30,603 DEBUG TRAIN Batch 24/7700 loss 5.814882 loss_att 6.822371 loss_ctc 8.597396 loss_rnnt 5.145057 hw_loss 0.182486 lr 0.00034677 rank 2
2023-02-22 22:04:30,617 DEBUG TRAIN Batch 24/7700 loss 11.075489 loss_att 13.630931 loss_ctc 16.437031 loss_rnnt 9.680591 hw_loss 0.316758 lr 0.00034680 rank 1
2023-02-22 22:04:30,618 DEBUG TRAIN Batch 24/7700 loss 9.149634 loss_att 12.834005 loss_ctc 8.320978 loss_rnnt 8.395526 hw_loss 0.239478 lr 0.00034682 rank 4
2023-02-22 22:04:30,620 DEBUG TRAIN Batch 24/7700 loss 2.448362 loss_att 8.446295 loss_ctc 4.081927 loss_rnnt 0.871039 hw_loss 0.299864 lr 0.00034672 rank 7
2023-02-22 22:04:30,623 DEBUG TRAIN Batch 24/7700 loss 13.589633 loss_att 16.948982 loss_ctc 23.293423 loss_rnnt 11.528262 hw_loss 0.179369 lr 0.00034682 rank 3
2023-02-22 22:04:30,628 DEBUG TRAIN Batch 24/7700 loss 11.836226 loss_att 12.464095 loss_ctc 16.105724 loss_rnnt 10.817075 hw_loss 0.608081 lr 0.00034682 rank 0
2023-02-22 22:04:30,670 DEBUG TRAIN Batch 24/7700 loss 9.855886 loss_att 10.924778 loss_ctc 11.981426 loss_rnnt 9.182680 hw_loss 0.330041 lr 0.00034677 rank 5
2023-02-22 22:05:45,312 DEBUG TRAIN Batch 24/7800 loss 8.400788 loss_att 10.067006 loss_ctc 10.755836 loss_rnnt 7.712317 hw_loss 0.077291 lr 0.00034669 rank 2
2023-02-22 22:05:45,312 DEBUG TRAIN Batch 24/7800 loss 9.953204 loss_att 13.815771 loss_ctc 11.215992 loss_rnnt 8.895165 hw_loss 0.219663 lr 0.00034674 rank 4
2023-02-22 22:05:45,317 DEBUG TRAIN Batch 24/7800 loss 3.550864 loss_att 6.087990 loss_ctc 6.021810 loss_rnnt 2.613309 hw_loss 0.188759 lr 0.00034673 rank 0
2023-02-22 22:05:45,317 DEBUG TRAIN Batch 24/7800 loss 10.033133 loss_att 17.031944 loss_ctc 11.387955 loss_rnnt 8.338911 hw_loss 0.213405 lr 0.00034672 rank 1
2023-02-22 22:05:45,319 DEBUG TRAIN Batch 24/7800 loss 7.705914 loss_att 11.530495 loss_ctc 11.577928 loss_rnnt 6.260278 hw_loss 0.308347 lr 0.00034665 rank 6
2023-02-22 22:05:45,323 DEBUG TRAIN Batch 24/7800 loss 10.923584 loss_att 13.964857 loss_ctc 13.222198 loss_rnnt 9.900391 hw_loss 0.203356 lr 0.00034674 rank 3
2023-02-22 22:05:45,335 DEBUG TRAIN Batch 24/7800 loss 4.882668 loss_att 6.579381 loss_ctc 7.139207 loss_rnnt 4.151707 hw_loss 0.170150 lr 0.00034664 rank 7
2023-02-22 22:05:45,398 DEBUG TRAIN Batch 24/7800 loss 2.222003 loss_att 4.913250 loss_ctc 2.788815 loss_rnnt 1.548051 hw_loss 0.112738 lr 0.00034669 rank 5
2023-02-22 22:06:58,216 DEBUG TRAIN Batch 24/7900 loss 13.907824 loss_att 14.634888 loss_ctc 17.652004 loss_rnnt 13.095795 hw_loss 0.313859 lr 0.00034666 rank 4
2023-02-22 22:06:58,227 DEBUG TRAIN Batch 24/7900 loss 7.804963 loss_att 10.850761 loss_ctc 15.550322 loss_rnnt 6.049005 hw_loss 0.213906 lr 0.00034660 rank 2
2023-02-22 22:06:58,227 DEBUG TRAIN Batch 24/7900 loss 6.010663 loss_att 8.113620 loss_ctc 8.179071 loss_rnnt 5.106917 hw_loss 0.363811 lr 0.00034656 rank 7
2023-02-22 22:06:58,228 DEBUG TRAIN Batch 24/7900 loss 4.191097 loss_att 6.029335 loss_ctc 9.020536 loss_rnnt 3.112082 hw_loss 0.126454 lr 0.00034664 rank 1
2023-02-22 22:06:58,229 DEBUG TRAIN Batch 24/7900 loss 8.378223 loss_att 8.771184 loss_ctc 11.368221 loss_rnnt 7.722605 hw_loss 0.334424 lr 0.00034665 rank 3
2023-02-22 22:06:58,231 DEBUG TRAIN Batch 24/7900 loss 6.084604 loss_att 8.743876 loss_ctc 8.261578 loss_rnnt 5.129878 hw_loss 0.248642 lr 0.00034657 rank 6
2023-02-22 22:06:58,234 DEBUG TRAIN Batch 24/7900 loss 11.250697 loss_att 12.814675 loss_ctc 13.681460 loss_rnnt 10.413584 hw_loss 0.375403 lr 0.00034660 rank 5
2023-02-22 22:06:58,241 DEBUG TRAIN Batch 24/7900 loss 10.462005 loss_att 13.554384 loss_ctc 16.371595 loss_rnnt 8.925671 hw_loss 0.243585 lr 0.00034665 rank 0
2023-02-22 22:08:10,739 DEBUG TRAIN Batch 24/8000 loss 14.580086 loss_att 19.439644 loss_ctc 24.527447 loss_rnnt 12.103725 hw_loss 0.334002 lr 0.00034652 rank 2
2023-02-22 22:08:10,740 DEBUG TRAIN Batch 24/8000 loss 12.480168 loss_att 18.049231 loss_ctc 25.778305 loss_rnnt 9.478650 hw_loss 0.214912 lr 0.00034655 rank 1
2023-02-22 22:08:10,741 DEBUG TRAIN Batch 24/8000 loss 10.124076 loss_att 14.421301 loss_ctc 13.289604 loss_rnnt 8.633322 hw_loss 0.392323 lr 0.00034657 rank 3
2023-02-22 22:08:10,741 DEBUG TRAIN Batch 24/8000 loss 7.084395 loss_att 10.650769 loss_ctc 11.245817 loss_rnnt 5.705434 hw_loss 0.207804 lr 0.00034649 rank 6
2023-02-22 22:08:10,745 DEBUG TRAIN Batch 24/8000 loss 12.778584 loss_att 15.152668 loss_ctc 18.784214 loss_rnnt 11.346729 hw_loss 0.293037 lr 0.00034652 rank 5
2023-02-22 22:08:10,748 DEBUG TRAIN Batch 24/8000 loss 7.021892 loss_att 11.342353 loss_ctc 8.834587 loss_rnnt 5.784405 hw_loss 0.246941 lr 0.00034657 rank 0
2023-02-22 22:08:10,750 DEBUG TRAIN Batch 24/8000 loss 9.402811 loss_att 11.830544 loss_ctc 11.266038 loss_rnnt 8.503403 hw_loss 0.310183 lr 0.00034657 rank 4
2023-02-22 22:08:10,749 DEBUG TRAIN Batch 24/8000 loss 8.213446 loss_att 9.409340 loss_ctc 12.007478 loss_rnnt 7.349572 hw_loss 0.222792 lr 0.00034647 rank 7
2023-02-22 22:09:23,714 DEBUG TRAIN Batch 24/8100 loss 15.826230 loss_att 17.892002 loss_ctc 22.283939 loss_rnnt 14.388574 hw_loss 0.306511 lr 0.00034644 rank 5
2023-02-22 22:09:23,727 DEBUG TRAIN Batch 24/8100 loss 10.231010 loss_att 12.839072 loss_ctc 14.366114 loss_rnnt 9.028125 hw_loss 0.243612 lr 0.00034644 rank 2
2023-02-22 22:09:23,727 DEBUG TRAIN Batch 24/8100 loss 7.280096 loss_att 8.389499 loss_ctc 9.442299 loss_rnnt 6.578337 hw_loss 0.359219 lr 0.00034639 rank 7
2023-02-22 22:09:23,729 DEBUG TRAIN Batch 24/8100 loss 8.653950 loss_att 11.523247 loss_ctc 10.122830 loss_rnnt 7.803447 hw_loss 0.151487 lr 0.00034649 rank 4
2023-02-22 22:09:23,730 DEBUG TRAIN Batch 24/8100 loss 17.499611 loss_att 18.807652 loss_ctc 22.422224 loss_rnnt 16.398088 hw_loss 0.344183 lr 0.00034640 rank 6
2023-02-22 22:09:23,733 DEBUG TRAIN Batch 24/8100 loss 9.269656 loss_att 10.815845 loss_ctc 13.447505 loss_rnnt 8.287935 hw_loss 0.216443 lr 0.00034649 rank 3
2023-02-22 22:09:23,737 DEBUG TRAIN Batch 24/8100 loss 15.779675 loss_att 15.887146 loss_ctc 19.264683 loss_rnnt 15.147232 hw_loss 0.274280 lr 0.00034647 rank 1
2023-02-22 22:09:23,755 DEBUG TRAIN Batch 24/8100 loss 13.525048 loss_att 15.364514 loss_ctc 18.535625 loss_rnnt 12.406078 hw_loss 0.155626 lr 0.00034648 rank 0
2023-02-22 22:10:37,241 DEBUG TRAIN Batch 24/8200 loss 7.145673 loss_att 8.698503 loss_ctc 12.483424 loss_rnnt 6.014221 hw_loss 0.204722 lr 0.00034640 rank 3
2023-02-22 22:10:37,244 DEBUG TRAIN Batch 24/8200 loss 9.143363 loss_att 10.594886 loss_ctc 14.513254 loss_rnnt 7.948650 hw_loss 0.353291 lr 0.00034632 rank 6
2023-02-22 22:10:37,245 DEBUG TRAIN Batch 24/8200 loss 12.994769 loss_att 16.219353 loss_ctc 21.590912 loss_rnnt 10.958102 hw_loss 0.460497 lr 0.00034639 rank 1
2023-02-22 22:10:37,246 DEBUG TRAIN Batch 24/8200 loss 10.389461 loss_att 13.725242 loss_ctc 15.346581 loss_rnnt 8.897169 hw_loss 0.307847 lr 0.00034635 rank 2
2023-02-22 22:10:37,248 DEBUG TRAIN Batch 24/8200 loss 9.314048 loss_att 8.678816 loss_ctc 11.917592 loss_rnnt 8.842875 hw_loss 0.470775 lr 0.00034631 rank 7
2023-02-22 22:10:37,249 DEBUG TRAIN Batch 24/8200 loss 11.626311 loss_att 10.408514 loss_ctc 14.400564 loss_rnnt 11.453058 hw_loss 0.087957 lr 0.00034635 rank 5
2023-02-22 22:10:37,250 DEBUG TRAIN Batch 24/8200 loss 19.104836 loss_att 20.978848 loss_ctc 25.689072 loss_rnnt 17.663589 hw_loss 0.353523 lr 0.00034641 rank 4
2023-02-22 22:10:37,253 DEBUG TRAIN Batch 24/8200 loss 11.223709 loss_att 12.949480 loss_ctc 13.970709 loss_rnnt 10.372068 hw_loss 0.262910 lr 0.00034640 rank 0
2023-02-22 22:11:49,162 DEBUG TRAIN Batch 24/8300 loss 7.658637 loss_att 8.376910 loss_ctc 7.972565 loss_rnnt 7.349447 hw_loss 0.231898 lr 0.00034630 rank 1
2023-02-22 22:11:49,162 DEBUG TRAIN Batch 24/8300 loss 11.106503 loss_att 13.259181 loss_ctc 11.288279 loss_rnnt 10.467760 hw_loss 0.344945 lr 0.00034624 rank 6
2023-02-22 22:11:49,163 DEBUG TRAIN Batch 24/8300 loss 8.473311 loss_att 11.809982 loss_ctc 10.332164 loss_rnnt 7.444435 hw_loss 0.213177 lr 0.00034622 rank 7
2023-02-22 22:11:49,164 DEBUG TRAIN Batch 24/8300 loss 8.578499 loss_att 11.696583 loss_ctc 11.871511 loss_rnnt 7.388383 hw_loss 0.238933 lr 0.00034627 rank 2
2023-02-22 22:11:49,164 DEBUG TRAIN Batch 24/8300 loss 7.234392 loss_att 10.804993 loss_ctc 11.860983 loss_rnnt 5.663119 hw_loss 0.450514 lr 0.00034627 rank 5
2023-02-22 22:11:49,167 DEBUG TRAIN Batch 24/8300 loss 3.438757 loss_att 5.635229 loss_ctc 4.656829 loss_rnnt 2.788402 hw_loss 0.091222 lr 0.00034632 rank 4
2023-02-22 22:11:49,168 DEBUG TRAIN Batch 24/8300 loss 5.681105 loss_att 7.724445 loss_ctc 8.139186 loss_rnnt 4.894805 hw_loss 0.093539 lr 0.00034632 rank 3
2023-02-22 22:11:49,171 DEBUG TRAIN Batch 24/8300 loss 16.823103 loss_att 18.414776 loss_ctc 24.699591 loss_rnnt 15.337802 hw_loss 0.218940 lr 0.00034632 rank 0
2023-02-22 22:12:44,443 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 0
2023-02-22 22:12:44,449 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 7
2023-02-22 22:12:44,449 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 5
2023-02-22 22:12:44,454 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 6
2023-02-22 22:12:44,455 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 3
2023-02-22 22:12:44,455 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 1
2023-02-22 22:12:44,457 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 4
2023-02-22 22:12:44,471 DEBUG CV Batch 24/0 loss 2.298390 loss_att 2.237705 loss_ctc 3.366208 loss_rnnt 1.868410 hw_loss 0.562016 history loss 2.213265 rank 2
2023-02-22 22:12:55,761 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 1
2023-02-22 22:12:55,828 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 5
2023-02-22 22:12:55,830 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 4
2023-02-22 22:12:55,951 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 2
2023-02-22 22:12:55,973 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 0
2023-02-22 22:12:56,062 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 3
2023-02-22 22:12:56,144 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 6
2023-02-22 22:12:56,250 DEBUG CV Batch 24/100 loss 5.113225 loss_att 7.560278 loss_ctc 7.832809 loss_rnnt 4.061489 hw_loss 0.374465 history loss 3.535308 rank 7
2023-02-22 22:13:09,194 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 4
2023-02-22 22:13:09,209 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 5
2023-02-22 22:13:09,378 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 1
2023-02-22 22:13:09,459 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 0
2023-02-22 22:13:09,462 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 2
2023-02-22 22:13:09,694 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 7
2023-02-22 22:13:09,801 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 6
2023-02-22 22:13:09,910 DEBUG CV Batch 24/200 loss 6.875374 loss_att 16.872541 loss_ctc 5.849123 loss_rnnt 4.917435 hw_loss 0.178762 history loss 4.071083 rank 3
2023-02-22 22:13:21,504 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 4
2023-02-22 22:13:21,576 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 5
2023-02-22 22:13:21,885 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 1
2023-02-22 22:13:21,889 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 2
2023-02-22 22:13:21,952 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 0
2023-02-22 22:13:22,063 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 7
2023-02-22 22:13:22,169 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 3
2023-02-22 22:13:22,315 DEBUG CV Batch 24/300 loss 6.020274 loss_att 6.154887 loss_ctc 8.518735 loss_rnnt 5.461447 hw_loss 0.372704 history loss 4.221470 rank 6
2023-02-22 22:13:33,586 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 4
2023-02-22 22:13:33,659 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 5
2023-02-22 22:13:33,902 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 1
2023-02-22 22:13:34,188 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 2
2023-02-22 22:13:34,208 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 7
2023-02-22 22:13:34,284 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 0
2023-02-22 22:13:34,654 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 3
2023-02-22 22:13:34,724 DEBUG CV Batch 24/400 loss 18.434572 loss_att 70.939514 loss_ctc 18.195784 loss_rnnt 7.887162 hw_loss 0.146739 history loss 5.218077 rank 6
2023-02-22 22:13:44,370 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 4
2023-02-22 22:13:44,712 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 5
2023-02-22 22:13:44,803 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 1
2023-02-22 22:13:45,139 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 7
2023-02-22 22:13:45,162 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 2
2023-02-22 22:13:45,333 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 0
2023-02-22 22:13:45,573 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 3
2023-02-22 22:13:45,819 DEBUG CV Batch 24/500 loss 5.203990 loss_att 5.270960 loss_ctc 6.214670 loss_rnnt 4.924966 hw_loss 0.245386 history loss 5.946216 rank 6
2023-02-22 22:13:56,500 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 4
2023-02-22 22:13:56,941 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 1
2023-02-22 22:13:57,245 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 5
2023-02-22 22:13:57,446 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 7
2023-02-22 22:13:57,469 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 2
2023-02-22 22:13:57,873 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 0
2023-02-22 22:13:58,059 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 3
2023-02-22 22:13:58,283 DEBUG CV Batch 24/600 loss 7.068202 loss_att 7.234447 loss_ctc 10.165099 loss_rnnt 6.421470 hw_loss 0.376059 history loss 6.961747 rank 6
2023-02-22 22:14:07,808 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 4
2023-02-22 22:14:08,295 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 1
2023-02-22 22:14:08,777 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 5
2023-02-22 22:14:09,086 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 2
2023-02-22 22:14:09,103 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 7
2023-02-22 22:14:09,787 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 3
2023-02-22 22:14:10,003 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 0
2023-02-22 22:14:10,075 DEBUG CV Batch 24/700 loss 12.564680 loss_att 34.323425 loss_ctc 13.375724 loss_rnnt 7.877642 hw_loss 0.425905 history loss 7.583083 rank 6
2023-02-22 22:14:19,200 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 4
2023-02-22 22:14:20,064 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 1
2023-02-22 22:14:20,423 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 5
2023-02-22 22:14:20,565 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 7
2023-02-22 22:14:20,775 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 2
2023-02-22 22:14:21,611 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 3
2023-02-22 22:14:21,726 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 6
2023-02-22 22:14:21,966 DEBUG CV Batch 24/800 loss 10.764156 loss_att 11.481024 loss_ctc 14.585783 loss_rnnt 9.922445 hw_loss 0.353976 history loss 7.031610 rank 0
2023-02-22 22:14:32,547 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 4
2023-02-22 22:14:33,789 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 1
2023-02-22 22:14:33,935 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 5
2023-02-22 22:14:34,076 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 7
2023-02-22 22:14:34,297 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 2
2023-02-22 22:14:35,194 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 3
2023-02-22 22:14:35,329 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 6
2023-02-22 22:14:35,826 DEBUG CV Batch 24/900 loss 13.226936 loss_att 16.224771 loss_ctc 25.485245 loss_rnnt 10.867655 hw_loss 0.234885 history loss 6.820495 rank 0
2023-02-22 22:14:44,937 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 4
2023-02-22 22:14:46,191 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 1
2023-02-22 22:14:46,378 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 5
2023-02-22 22:14:46,524 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 7
2023-02-22 22:14:46,688 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 2
2023-02-22 22:14:47,786 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 3
2023-02-22 22:14:47,891 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 6
2023-02-22 22:14:48,679 DEBUG CV Batch 24/1000 loss 4.166741 loss_att 4.409384 loss_ctc 4.677418 loss_rnnt 3.862525 hw_loss 0.351746 history loss 6.588704 rank 0
2023-02-22 22:14:56,830 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 4
2023-02-22 22:14:58,027 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 1
2023-02-22 22:14:58,686 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 5
2023-02-22 22:14:58,688 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 7
2023-02-22 22:14:58,959 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 2
2023-02-22 22:15:00,194 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 3
2023-02-22 22:15:00,279 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 6
2023-02-22 22:15:01,070 DEBUG CV Batch 24/1100 loss 7.304996 loss_att 6.134814 loss_ctc 8.918102 loss_rnnt 7.016670 hw_loss 0.576152 history loss 6.582423 rank 0
2023-02-22 22:15:07,613 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 4
2023-02-22 22:15:08,766 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 1
2023-02-22 22:15:09,703 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 7
2023-02-22 22:15:09,746 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 5
2023-02-22 22:15:09,942 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 2
2023-02-22 22:15:11,211 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 3
2023-02-22 22:15:11,395 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 6
2023-02-22 22:15:12,913 DEBUG CV Batch 24/1200 loss 8.341953 loss_att 8.324673 loss_ctc 9.076495 loss_rnnt 8.128547 hw_loss 0.222984 history loss 6.893334 rank 0
2023-02-22 22:15:19,648 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 4
2023-02-22 22:15:21,203 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 1
2023-02-22 22:15:22,114 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 5
2023-02-22 22:15:22,129 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 7
2023-02-22 22:15:22,218 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 2
2023-02-22 22:15:23,602 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 3
2023-02-22 22:15:23,789 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 6
2023-02-22 22:15:25,475 DEBUG CV Batch 24/1300 loss 5.111885 loss_att 5.201031 loss_ctc 7.910085 loss_rnnt 4.511686 hw_loss 0.392393 history loss 7.238471 rank 0
2023-02-22 22:15:30,935 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 4
2023-02-22 22:15:32,415 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 1
2023-02-22 22:15:33,536 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 7
2023-02-22 22:15:33,644 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 5
2023-02-22 22:15:33,714 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 2
2023-02-22 22:15:35,303 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 3
2023-02-22 22:15:35,402 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 6
2023-02-22 22:15:37,243 DEBUG CV Batch 24/1400 loss 3.635413 loss_att 10.739689 loss_ctc 2.613493 loss_rnnt 2.201689 hw_loss 0.279609 history loss 7.542844 rank 0
2023-02-22 22:15:42,518 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 4
2023-02-22 22:15:44,119 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 1
2023-02-22 22:15:45,470 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 5
2023-02-22 22:15:45,566 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 7
2023-02-22 22:15:45,608 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 2
2023-02-22 22:15:47,219 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 3
2023-02-22 22:15:47,279 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 6
2023-02-22 22:15:49,409 DEBUG CV Batch 24/1500 loss 5.418035 loss_att 7.187138 loss_ctc 6.166409 loss_rnnt 4.821340 hw_loss 0.268296 history loss 7.364839 rank 0
2023-02-22 22:15:55,731 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 4
2023-02-22 22:15:57,462 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 1
2023-02-22 22:15:58,717 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 5
2023-02-22 22:15:58,908 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 7
2023-02-22 22:15:58,957 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 2
2023-02-22 22:16:00,549 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 3
2023-02-22 22:16:00,684 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 6
2023-02-22 22:16:02,812 DEBUG CV Batch 24/1600 loss 5.898928 loss_att 12.214787 loss_ctc 10.026121 loss_rnnt 4.010593 hw_loss 0.140380 history loss 7.293108 rank 0
2023-02-22 22:16:08,320 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 4
2023-02-22 22:16:10,054 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 1
2023-02-22 22:16:11,448 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 7
2023-02-22 22:16:11,514 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 2
2023-02-22 22:16:11,710 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 5
2023-02-22 22:16:13,099 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 3
2023-02-22 22:16:13,206 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 6
2023-02-22 22:16:15,508 DEBUG CV Batch 24/1700 loss 9.450795 loss_att 8.554678 loss_ctc 14.703996 loss_rnnt 8.720316 hw_loss 0.392393 history loss 7.197313 rank 0
2023-02-22 22:16:17,349 INFO Epoch 24 CV info cv_loss 7.168498556879511
2023-02-22 22:16:17,349 INFO Epoch 25 TRAIN info lr 0.0003462741717222745
2023-02-22 22:16:17,351 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:16:19,036 INFO Epoch 24 CV info cv_loss 7.168498558154477
2023-02-22 22:16:19,037 INFO Epoch 25 TRAIN info lr 0.0003462999171682557
2023-02-22 22:16:19,042 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:16:20,582 INFO Epoch 24 CV info cv_loss 7.168498554605248
2023-02-22 22:16:20,583 INFO Epoch 25 TRAIN info lr 0.00034624262062048417
2023-02-22 22:16:20,587 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:16:20,597 INFO Epoch 24 CV info cv_loss 7.168498555111358
2023-02-22 22:16:20,597 INFO Epoch 25 TRAIN info lr 0.0003461762254290743
2023-02-22 22:16:20,602 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:16:20,978 INFO Epoch 24 CV info cv_loss 7.168498555294419
2023-02-22 22:16:20,979 INFO Epoch 25 TRAIN info lr 0.00034625092270583674
2023-02-22 22:16:20,984 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:16:22,238 INFO Epoch 24 CV info cv_loss 7.168498555636851
2023-02-22 22:16:22,239 INFO Epoch 25 TRAIN info lr 0.0003462617163096529
2023-02-22 22:16:22,244 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:16:22,359 INFO Epoch 24 CV info cv_loss 7.168498556121423
2023-02-22 22:16:22,359 INFO Epoch 25 TRAIN info lr 0.0003461878418303441
2023-02-22 22:16:22,361 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:16:24,980 INFO Epoch 24 CV info cv_loss 7.168498556226953
2023-02-22 22:16:24,981 INFO Checkpoint: save to checkpoint exp/2_20_rnnt_bias_loss_2_class_both_more_layer_0-3word_finetune/24.pt
2023-02-22 22:16:25,546 INFO Epoch 25 TRAIN info lr 0.00034629078103012466
2023-02-22 22:16:25,550 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 22:17:25,911 DEBUG TRAIN Batch 25/0 loss 12.762479 loss_att 11.325233 loss_ctc 16.132334 loss_rnnt 12.238295 hw_loss 0.679350 lr 0.00034627 rank 4
2023-02-22 22:17:25,911 DEBUG TRAIN Batch 25/0 loss 7.750428 loss_att 7.099178 loss_ctc 9.131253 loss_rnnt 7.346663 hw_loss 0.656072 lr 0.00034619 rank 6
2023-02-22 22:17:25,912 DEBUG TRAIN Batch 25/0 loss 9.199028 loss_att 9.405706 loss_ctc 13.033250 loss_rnnt 8.261600 hw_loss 0.721619 lr 0.00034624 rank 2
2023-02-22 22:17:25,912 DEBUG TRAIN Batch 25/0 loss 8.846859 loss_att 8.315958 loss_ctc 11.587203 loss_rnnt 8.236222 hw_loss 0.658944 lr 0.00034625 rank 5
2023-02-22 22:17:25,917 DEBUG TRAIN Batch 25/0 loss 8.236522 loss_att 7.675523 loss_ctc 10.303865 loss_rnnt 7.807103 hw_loss 0.498698 lr 0.00034618 rank 7
2023-02-22 22:17:25,923 DEBUG TRAIN Batch 25/0 loss 8.747538 loss_att 8.440531 loss_ctc 11.073308 loss_rnnt 8.158887 hw_loss 0.637405 lr 0.00034626 rank 3
2023-02-22 22:17:25,952 DEBUG TRAIN Batch 25/0 loss 10.540695 loss_att 10.426266 loss_ctc 12.849776 loss_rnnt 9.990424 hw_loss 0.497398 lr 0.00034629 rank 0
2023-02-22 22:17:25,962 DEBUG TRAIN Batch 25/0 loss 6.979686 loss_att 7.052451 loss_ctc 9.164644 loss_rnnt 6.411474 hw_loss 0.491871 lr 0.00034630 rank 1
2023-02-22 22:18:37,147 DEBUG TRAIN Batch 25/100 loss 13.288350 loss_att 20.725283 loss_ctc 18.909500 loss_rnnt 10.993404 hw_loss 0.108885 lr 0.00034616 rank 2
2023-02-22 22:18:37,147 DEBUG TRAIN Batch 25/100 loss 6.985537 loss_att 11.171049 loss_ctc 14.497845 loss_rnnt 5.000864 hw_loss 0.273617 lr 0.00034610 rank 6
2023-02-22 22:18:37,151 DEBUG TRAIN Batch 25/100 loss 1.385809 loss_att 4.433399 loss_ctc 2.347086 loss_rnnt 0.506419 hw_loss 0.265691 lr 0.00034621 rank 0
2023-02-22 22:18:37,151 DEBUG TRAIN Batch 25/100 loss 8.509695 loss_att 11.063038 loss_ctc 9.654386 loss_rnnt 7.647806 hw_loss 0.372368 lr 0.00034618 rank 3
2023-02-22 22:18:37,152 DEBUG TRAIN Batch 25/100 loss 5.505769 loss_att 8.621691 loss_ctc 9.757888 loss_rnnt 4.154636 hw_loss 0.301875 lr 0.00034622 rank 1
2023-02-22 22:18:37,152 DEBUG TRAIN Batch 25/100 loss 10.830735 loss_att 9.524576 loss_ctc 14.032660 loss_rnnt 10.546566 hw_loss 0.222146 lr 0.00034619 rank 4
2023-02-22 22:18:37,154 DEBUG TRAIN Batch 25/100 loss 14.862482 loss_att 15.324568 loss_ctc 18.577358 loss_rnnt 14.097725 hw_loss 0.331919 lr 0.00034617 rank 5
2023-02-22 22:18:37,157 DEBUG TRAIN Batch 25/100 loss 7.633367 loss_att 9.420147 loss_ctc 11.017534 loss_rnnt 6.594785 hw_loss 0.431258 lr 0.00034609 rank 7
2023-02-22 22:19:49,111 DEBUG TRAIN Batch 25/200 loss 4.744680 loss_att 7.372693 loss_ctc 6.448936 loss_rnnt 3.850900 hw_loss 0.264268 lr 0.00034608 rank 2
2023-02-22 22:19:49,116 DEBUG TRAIN Batch 25/200 loss 8.491059 loss_att 11.719782 loss_ctc 12.381468 loss_rnnt 7.212738 hw_loss 0.213479 lr 0.00034613 rank 1
2023-02-22 22:19:49,117 DEBUG TRAIN Batch 25/200 loss 13.175479 loss_att 16.795916 loss_ctc 19.350113 loss_rnnt 11.528353 hw_loss 0.187038 lr 0.00034602 rank 6
2023-02-22 22:19:49,117 DEBUG TRAIN Batch 25/200 loss 9.290159 loss_att 11.206758 loss_ctc 11.268970 loss_rnnt 8.503857 hw_loss 0.260889 lr 0.00034601 rank 7
2023-02-22 22:19:49,118 DEBUG TRAIN Batch 25/200 loss 3.926414 loss_att 4.488211 loss_ctc 3.821138 loss_rnnt 3.663598 hw_loss 0.308427 lr 0.00034609 rank 3
2023-02-22 22:19:49,121 DEBUG TRAIN Batch 25/200 loss 6.440974 loss_att 8.048635 loss_ctc 9.185028 loss_rnnt 5.663467 hw_loss 0.168939 lr 0.00034612 rank 0
2023-02-22 22:19:49,126 DEBUG TRAIN Batch 25/200 loss 7.422047 loss_att 9.741380 loss_ctc 9.830022 loss_rnnt 6.505897 hw_loss 0.246038 lr 0.00034608 rank 5
2023-02-22 22:19:49,168 DEBUG TRAIN Batch 25/200 loss 5.056978 loss_att 8.508380 loss_ctc 8.323339 loss_rnnt 3.773749 hw_loss 0.295188 lr 0.00034611 rank 4
2023-02-22 22:21:02,474 DEBUG TRAIN Batch 25/300 loss 8.367031 loss_att 9.301895 loss_ctc 11.177279 loss_rnnt 7.674845 hw_loss 0.244712 lr 0.00034599 rank 2
2023-02-22 22:21:02,474 DEBUG TRAIN Batch 25/300 loss 4.665301 loss_att 7.267388 loss_ctc 6.969964 loss_rnnt 3.749912 hw_loss 0.164407 lr 0.00034593 rank 7
2023-02-22 22:21:02,478 DEBUG TRAIN Batch 25/300 loss 6.244135 loss_att 9.401505 loss_ctc 9.095409 loss_rnnt 5.136479 hw_loss 0.180021 lr 0.00034604 rank 0
2023-02-22 22:21:02,480 DEBUG TRAIN Batch 25/300 loss 10.982434 loss_att 14.549704 loss_ctc 16.878944 loss_rnnt 9.351162 hw_loss 0.246780 lr 0.00034605 rank 1
2023-02-22 22:21:02,480 DEBUG TRAIN Batch 25/300 loss 6.596264 loss_att 10.204081 loss_ctc 9.496360 loss_rnnt 5.407502 hw_loss 0.150974 lr 0.00034594 rank 6
2023-02-22 22:21:02,482 DEBUG TRAIN Batch 25/300 loss 12.696008 loss_att 18.503166 loss_ctc 19.315773 loss_rnnt 10.547153 hw_loss 0.196473 lr 0.00034600 rank 5
2023-02-22 22:21:02,484 DEBUG TRAIN Batch 25/300 loss 8.866125 loss_att 11.884848 loss_ctc 12.913926 loss_rnnt 7.563987 hw_loss 0.297536 lr 0.00034601 rank 3
2023-02-22 22:21:02,495 DEBUG TRAIN Batch 25/300 loss 9.957668 loss_att 13.804684 loss_ctc 14.414871 loss_rnnt 8.478962 hw_loss 0.215642 lr 0.00034602 rank 4
2023-02-22 22:22:16,741 DEBUG TRAIN Batch 25/400 loss 8.639193 loss_att 12.503171 loss_ctc 13.487439 loss_rnnt 6.985737 hw_loss 0.439175 lr 0.00034597 rank 1
2023-02-22 22:22:16,744 DEBUG TRAIN Batch 25/400 loss 11.479082 loss_att 15.563171 loss_ctc 16.944769 loss_rnnt 9.826949 hw_loss 0.199795 lr 0.00034594 rank 4
2023-02-22 22:22:16,748 DEBUG TRAIN Batch 25/400 loss 8.457382 loss_att 10.772459 loss_ctc 12.156526 loss_rnnt 7.422096 hw_loss 0.148223 lr 0.00034591 rank 2
2023-02-22 22:22:16,749 DEBUG TRAIN Batch 25/400 loss 7.563251 loss_att 9.967781 loss_ctc 11.597300 loss_rnnt 6.372554 hw_loss 0.322348 lr 0.00034584 rank 7
2023-02-22 22:22:16,750 DEBUG TRAIN Batch 25/400 loss 6.877639 loss_att 8.650593 loss_ctc 8.517215 loss_rnnt 6.198381 hw_loss 0.198859 lr 0.00034593 rank 3
2023-02-22 22:22:16,751 DEBUG TRAIN Batch 25/400 loss 6.074750 loss_att 10.557312 loss_ctc 10.814310 loss_rnnt 4.456878 hw_loss 0.167660 lr 0.00034586 rank 6
2023-02-22 22:22:16,751 DEBUG TRAIN Batch 25/400 loss 6.726481 loss_att 9.419363 loss_ctc 11.670807 loss_rnnt 5.302861 hw_loss 0.423376 lr 0.00034592 rank 5
2023-02-22 22:22:16,802 DEBUG TRAIN Batch 25/400 loss 5.654769 loss_att 8.929616 loss_ctc 8.986949 loss_rnnt 4.429577 hw_loss 0.236122 lr 0.00034596 rank 0
2023-02-22 22:23:28,841 DEBUG TRAIN Batch 25/500 loss 6.856707 loss_att 10.460087 loss_ctc 9.118315 loss_rnnt 5.700932 hw_loss 0.250409 lr 0.00034583 rank 2
2023-02-22 22:23:28,844 DEBUG TRAIN Batch 25/500 loss 9.714750 loss_att 12.842628 loss_ctc 11.678284 loss_rnnt 8.643759 hw_loss 0.344272 lr 0.00034585 rank 3
2023-02-22 22:23:28,845 DEBUG TRAIN Batch 25/500 loss 19.319138 loss_att 20.775801 loss_ctc 27.089712 loss_rnnt 17.846445 hw_loss 0.272408 lr 0.00034576 rank 7
2023-02-22 22:23:28,845 DEBUG TRAIN Batch 25/500 loss 5.917755 loss_att 8.077802 loss_ctc 9.122870 loss_rnnt 4.858703 hw_loss 0.374427 lr 0.00034586 rank 4
2023-02-22 22:23:28,845 DEBUG TRAIN Batch 25/500 loss 18.389433 loss_att 18.665241 loss_ctc 21.630398 loss_rnnt 17.790773 hw_loss 0.208818 lr 0.00034577 rank 6
2023-02-22 22:23:28,849 DEBUG TRAIN Batch 25/500 loss 5.409415 loss_att 6.891449 loss_ctc 5.182747 loss_rnnt 4.917208 hw_loss 0.423791 lr 0.00034588 rank 1
2023-02-22 22:23:28,848 DEBUG TRAIN Batch 25/500 loss 7.409840 loss_att 11.856534 loss_ctc 10.272781 loss_rnnt 5.991426 hw_loss 0.276282 lr 0.00034588 rank 0
2023-02-22 22:23:28,894 DEBUG TRAIN Batch 25/500 loss 10.148817 loss_att 12.552652 loss_ctc 14.668765 loss_rnnt 8.957316 hw_loss 0.202638 lr 0.00034584 rank 5
2023-02-22 22:24:41,897 DEBUG TRAIN Batch 25/600 loss 9.467398 loss_att 10.569872 loss_ctc 14.208582 loss_rnnt 8.375187 hw_loss 0.449172 lr 0.00034578 rank 4
2023-02-22 22:24:41,900 DEBUG TRAIN Batch 25/600 loss 9.529435 loss_att 9.558686 loss_ctc 12.996450 loss_rnnt 8.921702 hw_loss 0.261775 lr 0.00034569 rank 6
2023-02-22 22:24:41,903 DEBUG TRAIN Batch 25/600 loss 12.151295 loss_att 12.044571 loss_ctc 16.614010 loss_rnnt 11.349209 hw_loss 0.428254 lr 0.00034574 rank 2
2023-02-22 22:24:41,903 DEBUG TRAIN Batch 25/600 loss 6.242896 loss_att 7.346534 loss_ctc 9.366304 loss_rnnt 5.446639 hw_loss 0.298266 lr 0.00034568 rank 7
2023-02-22 22:24:41,905 DEBUG TRAIN Batch 25/600 loss 13.398197 loss_att 12.656431 loss_ctc 16.716309 loss_rnnt 12.849140 hw_loss 0.478116 lr 0.00034576 rank 3
2023-02-22 22:24:41,907 DEBUG TRAIN Batch 25/600 loss 11.363988 loss_att 12.239493 loss_ctc 13.704494 loss_rnnt 10.685001 hw_loss 0.359658 lr 0.00034579 rank 0
2023-02-22 22:24:41,911 DEBUG TRAIN Batch 25/600 loss 8.733839 loss_att 9.744521 loss_ctc 12.787457 loss_rnnt 7.850195 hw_loss 0.264423 lr 0.00034580 rank 1
2023-02-22 22:24:41,954 DEBUG TRAIN Batch 25/600 loss 5.317190 loss_att 6.155142 loss_ctc 5.966410 loss_rnnt 4.842266 hw_loss 0.413947 lr 0.00034575 rank 5
run_2_20_rnnt_bias_both_2_class_more_layers_0-3word_fintune.sh: line 166: 44285 Terminated              python wenet/bin/train.py --gpu $gpu_id --config $train_config --data_type raw --symbol_table $dict --bpe_model ${bpemodel}.model --train_data $wave_data/$train_set/data.list --cv_data $wave_data/$dev_set/data.list ${checkpoint:+--checkpoint $checkpoint} --model_dir $dir --ddp.init_method $init_method --ddp.world_size $num_gpus --ddp.rank $i --ddp.dist_backend $dist_backend --num_workers 1 $cmvn_opts --pin_memory
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 103, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [192.168.0.37]:53127: Connection reset by peer
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 103, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [192.168.0.37]:53936: Connection reset by peer
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 103, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:1927
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 103, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:48527
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 103, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:4009
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 103, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:1947
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 103, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:57551
